<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>少错</title><link>https://www.lesswrong.com</link><description>致力于提炼理性艺术的社区博客</description><lastBuildDate>Thu, 04 Jan 2024 12:20:17 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>项目想法：备份计划和协作人工智能</title><link>https://www.lesswrong.com/posts/oRcqTNr9HQ8DKMer9/project-ideas-backup-plans-and-cooperative-ai</link><description>发布于 2024 年 1 月 4 日上午 7:26（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/oRcqTNr9HQ8DKMer9/project-ideas-backup-plans-and-cooperative-ai#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 04 Jan 2024 07:26:59 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/oRcqTNr9HQ8DKMer9/project-ideas-backup-plans-and-cooperative-ai</guid></item><item><title>项目理念：数字思维的感知和权利</title><link>https://www.lesswrong.com/posts/2TAHcmMqGcpKRgbCx/project-ideas-sentience-and-rights-of-digital-minds</link><description>发布于 2024 年 1 月 4 日上午 7:26（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/2TAHcmMqGcpKRgbCx/project-ideas-sentience-and-rights-of-digital-minds#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 04 Jan 2024 07:26:36 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/2TAHcmMqGcpKRgbCx/project-ideas-sentience-and-rights-of-digital-minds</guid></item><item><title>项目想法：认知论</title><link>https://www.lesswrong.com/posts/7ND7wFJ96YPLLjyXF/project-ideas-epistemics</link><description>发布于 2024 年 1 月 4 日上午 7:26（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.lesswrong.com/posts/7ND7wFJ96YPLLjyXF/project-ideas-epistemics#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 04 Jan 2024 07:26:13 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/7ND7wFJ96YPLLjyXF/project-ideas-epistemics</guid></item><item><title>项目理念：技术爆炸性增长期间的治理</title><link>https://www.lesswrong.com/posts/Skny4inJK4RuZ3AHS/project-ideas-governance-during-explosive-technological</link><description>发布于 2024 年 1 月 4 日上午 7:25（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/Skny4inJK4RuZ3AHS/project-ideas-governance-during-explosive-technological#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 04 Jan 2024 07:25:34 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/Skny4inJK4RuZ3AHS/project-ideas-governance-during-explosive-technological</guid></item><item><title>除了致力于协调之外，使变革性人工智能顺利进行的项目想法</title><link>https://www.lesswrong.com/posts/4d2JZiiyvZshhbEeJ/non-alignment-project-ideas-for-making-transformative-ai-go-1</link><description>发布于 2024 年 1 月 4 日上午 7:23（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/4d2JZiiyvZshhbEeJ/non-alignment-project-ideas-for-making-transformative-ai-go-1#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 04 Jan 2024 07:23:13 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/4d2JZiiyvZshhbEeJ/non-alignment-project-ideas-for-making-transformative-ai-go-1</guid></item><item><title>使变革性人工智能顺利进行的不结盟项目想法</title><link>https://www.lesswrong.com/posts/WqzRsbBh6ociaqKBh/non-alignment-project-ideas-for-making-transformative-ai-go</link><description>发布于 2024 年 1 月 4 日上午 7:23（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/WqzRsbBh6ociaqKBh/non-alignment-project-ideas-for-making-transformative-ai-go#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 04 Jan 2024 07:23:13 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/WqzRsbBh6ociaqKBh/non-alignment-project-ideas-for-making-transformative-ai-go</guid></item><item><title>事实核查和对消息来源的报复</title><link>https://www.lesswrong.com/posts/YSHPDCRggYoXNciFZ/fact-checking-and-retaliation-against-sources</link><description>发布于 2024 年 1 月 4 日凌晨 12:41（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;假设您关心社区中的某人，并且正在整理一篇帖子，详细说明为什么您认为其他人也应该关心。此类文档是&lt;a href="https://www.jefftk.com/p/decentralized-exclusion"&gt;去中心化排除&lt;/a&gt;的核心部分，没有任何正式领导的大型社区仍然可以驱逐不良行为者。作为撰写本文的一部分，您正在与那些受到伤害的人交谈，并且您的消息来源对报复感到紧张，这是可以理解的。其中一些是不可避免的，因为一旦帖子公开，被告很可能能够从您所包含的信息中得知您的消息来源是谁，但也存在对您的消息来源进行报复以阻止您发布的问题。&lt;/p&gt;&lt;p&gt;处理此问题的一种方法是仅发布信息，而不向被告提供任何有关这种情况正在发生的迹象。我认为这偶尔是正确的决定，但不给被告提供机会指出你错误事实的地方就放弃了很多：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;你只想指责某人做了他们实际上做过的事情，如果你的某些说法是错误的或具有误导性的，那么他们就不属于这个职位。&lt;/li&gt;&lt;li&gt;当你第一次公开时，你的核心指控越强烈，你的帖子成功的可能性就越大。您希望避免让社区陷入“有大量的主张，谁能说出其中的全部内容”的混乱状态，而许多人会停止关注。&lt;/li&gt;&lt;li&gt;在公开之前，你越能筛选出真正重要的主张，你浪费的社区时间就越少。如果有其他一些无可争议的证据就足够了，您真的不希望数百人需要就一组特定的屏幕截图是否表明不良行为做出决定。&lt;/li&gt;&lt;li&gt;在我的许多社区中，普遍认为诽谤法过于强大，导致人们无法发布有关造成伤害的人的真实而重要的信息。在某些情况下，即使被告很可能赢得针对原告的诽谤诉讼，我们认为威胁或提起诉讼是不合适的。但这也不是绝对的，如果你因为没有给被告指出错误的机会而发布虚假信息，我认为诉诸法律&lt;a href="https://forum.effectivealtruism.org/posts/bwtpBFQXKaGxuic6Q/effective-aspersions-how-the-nonlinear-investigation-went?commentId=zQEdnqePvK6D5DQag"&gt;不应该得到我们正常的反对&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;但那你能做什么呢？如何让被告有机会私下对您的主张提出异议，同时最大限度地降低您的消息来源面临的风险，即被告会向他们施压，迫使您放弃出版？&lt;/p&gt;&lt;p&gt;虽然我还没有尝试过，但我认为这应该可以通过预先承诺来解决。你与你的消息来源交谈并整理出你认为的最终草案。当您写信给被告时，您应添加诸如“为了保护我们的消息来源免遭报复，旨在防止这篇文章中的严重指控被公开，我们已经同意他们的观点，从我们第一次分享草稿到该文章发布，我们不会尊重他们提出的任何撤回索赔的要求。”想象：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;作者：&lt;/strong&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;我不能在不让对方提出潜在反证的情况下发表这些指控。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;资料来源：&lt;/strong&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;我们担心在被告知道此事即将发生但在公开之前期间遭到报复，目的是让我们撤回。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;作者：&lt;/strong&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;我将承诺，从现在到发布之前，我不会满足您提出的任何撤回索赔的要求，并让被告意识到这一点，以便他们知道报复不会实现他们的目标。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;不过，假设您尝试这样做，并且在发布前的事实检查期间确实有消息来源回复您：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;来源：&lt;/strong&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; [提前对作者说]他们要求我非法携带毒品进入该国。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;被告：&lt;/strong&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; [对作者来说，事实上检查]我这样做了，但这些药物是非处方药，我认为这是合法的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;来源：&lt;/strong&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; [事实核查开始后对作者说]被告告诉我有关毒品的事情，并要求我撤回我的主张。我可能应该提到他们是非处方药，他们不知道这是非法的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;通过这种策略，提交人将忽略消息来源同意被告的澄清。如果它是：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;来源：&lt;/strong&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; [事实核查开始后对作者说]被告告诉我有关毒品的事情，并要求我撤回我的主张，但他们正在考虑另一个时间；我说的是鸦片。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;如果对消息来源来说重要的是被告不能对他们进行报复以使他们闭嘴，并且他们决定使用我提议的预先承诺流程，那么这就需要放弃一些灵活性。在这种情况下，在开始对抗性事实核查过程之前，必须有时间从消息来源澄清他们所声称的内容。一旦开始，你所能做的就是考虑在事实核查之前从消息来源听到的内容以及现在从被告那里听到的内容，然后选择是保留主张、削弱它、澄清它还是放弃它。&lt;/p&gt;&lt;p&gt;请注意，削弱它是相当棘手的：你不能以一种听起来像是消息来源声称的东西不同于他们在事实核查之前已经认可的东西的方式来做到这一点，所以如果你确实想保留这一说法，我认为澄清它会往往更有意义。在这种情况下，我想我会说“我的消息来源告诉我，被告要求他们非法将毒品带入该国。在事实核查过程中，被告同意这不合法，但也说他们已经结束了” -柜台药物，当时他们提出要求，他们认为带这些药物进来是合法的。”然后可能会添加“由于我上面描述的对我们的消息来源的预先承诺，我没有询问我的消息来源是否同意这种情况的描述，但即使被告是正确的，我认为这也表明了在之间携带受控物质的鲁莽态度。管辖权。”&lt;/p&gt;&lt;p&gt;总的来说，这似乎应该可行，但正如我上面所说，这不是我尝试过的。似乎它可能失败的一种方式是，被告可能不相信作者真的会忽略他们从预发表的来源中听到的任何内容，所以我认为作者可能需要与被告特别清楚，并且可能具有声誉坚持这种事情。我也可以想象被告对消息来源进行非理性报复，但由于这种情况也可能在出版后发生，这似乎是分享有关复仇者的重要信息的不可避免的风险，而不是分享一些信息进行事实核查的缺点？人们是否认为这个提议的机制可能会以其他方式失败？&lt;/p&gt;&lt;p&gt;&lt;i&gt;披露：当我在&lt;/i&gt;&lt;a href="https://www.bidadance.org/safety/"&gt;&lt;i&gt;BIDA 安全团队&lt;/i&gt;&lt;/a&gt;时&lt;i&gt;，我仅代表我自己发言。我的&lt;/i&gt;&lt;a href="https://juliawise.net/"&gt;&lt;i&gt;妻子&lt;/i&gt;&lt;/a&gt;&lt;i&gt;是&lt;/i&gt;CEA&lt;a href="https://www.centreforeffectivealtruism.org/community-health"&gt;&lt;i&gt;社区健康团队&lt;/i&gt;&lt;/a&gt;&lt;i&gt;的成员，但我没有发过她的这篇文章，也不知道她的看法。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;评论通过：&lt;/i&gt; &lt;a href="https://www.facebook.com/jefftk/posts/pfbid033RqLtg6SKEJvnWMai7uNtpXiAvk5cEim7MfYEdRZrpNqS6F53EbTsGXd3TbQXXtUl"&gt;&lt;i&gt;facebook&lt;/i&gt;&lt;/a&gt; &lt;i&gt;、&lt;/i&gt; &lt;a href="https://lesswrong.com/posts/YSHPDCRggYoXNciFZ"&gt;&lt;i&gt;lesswrong&lt;/i&gt;&lt;/a&gt; &lt;i&gt;、&lt;/i&gt; &lt;a href="https://mastodon.mit.edu/@jefftk/111694885518854845"&gt;&lt;i&gt;mastodon&lt;/i&gt;&lt;/a&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/YSHPDCRggYoXNciFZ/fact-checking-and-retaliation-against-sources#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 04 Jan 2024 00:41:07 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/YSHPDCRggYoXNciFZ/fact-checking-and-retaliation-against-sources</guid></item><item><title>“对通用人工智能的态度：2021 年和 2023 年美国成年人的结果”——征集审稿人（科学种子）</title><link>https://www.lesswrong.com/posts/yNERBARrCGgr66PCi/attitudes-toward-artificial-general-intelligence-results</link><description>发布于 2024 年 1 月 3 日晚上 8:11（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;strong&gt;抽象的&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;一项关于美国成年人对通用人工智能 (AGI) 态度的紧凑、廉价的重复调查显示，对三种陈述的排序是稳定的，但同意的程度却在变化。从 2021 年到 2023 年，美国成年人越来越多地认为 AGI 是可以实现的。受访者不太同意应该建立通用人工智能。最后，美国成年人大多不同意 AGI 应该拥有与人类相同的权利。 2023 年的分歧比 2021 年更加强烈。&lt;/p&gt;&lt;p&gt;&lt;br /&gt; ---&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.theseedsofscience.org/"&gt;&lt;i&gt;Seeds of Science&lt;/i&gt;&lt;/a&gt;是一本期刊（由 Scott Alexander 的&lt;a href="https://astralcodexten.substack.com/p/acx-grants-results"&gt;ACX 资助计划&lt;/a&gt;资助），发表有关科学主题的推测性或非传统文章。同行评审是通过基于社区的投票和多元化评审者网络（我们称之为“园丁”）的评论来进行的。以有用的方式批评或扩展文章（“科学的种子”）的评论将发布在正文之后的最终文件中。&lt;/p&gt;&lt;p&gt;我们刚刚发出了一份供审查的手稿，“对通用人工智能的态度：2021 年和 2023 年美国成年人的结果”，LessWrong 社区的一些人可能会对它感兴趣，所以我想看看是否有人有兴趣加入我们作为一名园丁并对文章提供反馈。如上所述，这是将您的评论记录在科学文献中的机会（可以用真名或假名发表评论）。&lt;/p&gt;&lt;p&gt;作为园丁可以免费加入，任何人都受到欢迎（我们目前有来自学术界内外各个级别的园丁）。参与完全是自愿的 - 我们向您发送提交的文章，您可以选择投票/评论或弃权，恕不另行通知（因此，如果您不打算经常审阅，而只是想到处看看文章，请不要担心）正在提交）。&lt;/p&gt;&lt;p&gt;要注册，您可以填写此&lt;a href="https://docs.google.com/forms/d/e/1FAIpQLSfRIicHT7jIZcSUjwsIlby6JBxx2ZVeD5kseZBpgGFtp8pLfg/viewform"&gt;谷歌表格&lt;/a&gt;。从那里开始，一切就很不言自明了——我会将您添加到邮件列表中，并向您发送一封电子邮件，其中包括稿件、我们的出版标准以及用于记录投票/评论的简单评审表。如果您只想看一下这篇文章而不被添加到邮件列表中，那么只需联系 ( &lt;strong&gt;info@theseedsofscience.org&lt;/strong&gt; ) 并说明即可。&lt;/p&gt;&lt;p&gt;很高兴通过电子邮件或下面的评论回答有关该期刊的任何问题。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/yNERBARrCGgr66PCi/attitudes-toward-artificial-general-intelligence-results#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Wed, 03 Jan 2024 20:11:43 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/yNERBARrCGgr66PCi/attitudes-toward-artificial-general-intelligence-results</guid></item><item><title>代表任意特征的 XOR 的 LLM 是怎么回事？</title><link>https://www.lesswrong.com/posts/hjJXCn9GsskysDceS/what-s-up-with-llms-representing-xors-of-arbitrary-features</link><description>发布于 2024 年 1 月 3 日晚上 7:44（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;i&gt;感谢 Clément Dumas、Nikola Jurković、Nora Belrose、Arthur Conmy 和 Oam Patel 的反馈。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;在&lt;a href="https://www.lesswrong.com/posts/wtfvbsYjNHYYBmT3k/discussion-challenges-with-unsupervised-llm-knowledge-1"&gt;&lt;u&gt;Google Deepmind 的 CCS 挑战论文帖子&lt;/u&gt;&lt;/a&gt;的评论中， &lt;a href="https://www.lesswrong.com/posts/wtfvbsYjNHYYBmT3k/discussion-challenges-with-unsupervised-llm-knowledge-1?commentId=hPZfgA3BdXieNfFuY"&gt;&lt;u&gt;我对某些实验结果似乎是否可能表示怀疑&lt;/u&gt;&lt;/a&gt;。在解决我的担忧时，Rohin Shah 提出了&lt;a href="https://www.lesswrong.com/posts/wtfvbsYjNHYYBmT3k/discussion-challenges-with-unsupervised-llm-knowledge-1?commentId=Ne4EzP6afF9wegMZg"&gt;一些主张&lt;/a&gt;，“如果 LLM 线性表示特征 a 和 b，那么它也将线性表示它们的 XOR， &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，即使在没有明显原因的情况下也是如此。该模型需要利用特征&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ” &lt;span class="footnote-reference" id="fnrefqry32ncye1m"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnqry32ncye1m"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;出于我将在下面解释的原因，我认为这种说法绝对是疯狂的，无论是在一般情况下还是在 GDM 论文所涉及的特定环境中。所以我进行了一些实验来证明 Rohin 是错误的。&lt;/p&gt;&lt;p&gt;结果：&lt;strong&gt;罗辛是对的，我是错的&lt;/strong&gt;。法学硕士似乎会计算并线性表示特征的异或，即使没有明显的理由这样做。&lt;/p&gt;&lt;p&gt;我认为这非常奇怪和令人惊讶。如果这样的事情普遍存在，我认为它的重要性远远超出了最初的问题“CCS 有用吗？”&lt;/p&gt;&lt;p&gt;在这篇文章的其余部分我将：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;阐明一个我称之为“任意 XOR 表示 (RAX)”的主张：LLM 计算并线性表示任意特征的 XOR，即使没有理由这样做。&lt;/li&gt;&lt;li&gt;解释一下如果 RAX 是真的，为什么会令人震惊。例如，在没有额外假设的情况下，RAX 意味着线性探针应该完全无法概括分布变化，无论分布变化有多小。 （根据经验，线性探针通常&lt;i&gt;可以&lt;/i&gt;很好地概括。）&lt;/li&gt;&lt;li&gt;目前的实验表明，RAX 在我检查过的每种情况下似乎都是正确的。&lt;/li&gt;&lt;li&gt;思考一下 RAX 对 AI 安全研究意味着什么：总体而言，对于一般的可解释性工作，尤其是依赖于使用模型内部的简单探针（例如 ELK 探针或&lt;a href="https://www.lesswrong.com/posts/WCj7WgFSLmyKaMwPR/coup-probes-catching-catastrophes-with-probes-trained-off"&gt;&lt;u&gt;coup 探针&lt;/u&gt;&lt;/a&gt;）的工作来说，这可能是一个坏兆头。&lt;/li&gt;&lt;li&gt;对这里到底发生了什么进行一些猜测。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;总的来说，这让我非常困惑：我发现自己同时有一个论点： &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mspace" style="width: 0.278em; height: 0px;"&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⟹&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mspace" style="width: 0.278em; height: 0px;"&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;B&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，(b) &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的经验证据，以及 (c) &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;Ø&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;B&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的经验证据。 （此处 A = RAX，B = 有关 LLM 表示的其他事实。）&lt;/p&gt;&lt;h1&gt; RAX 声明：LLM 线性表示任意特征的 XOR，即使没有理由这样做&lt;/h1&gt;&lt;p&gt;为了简单起见，在这篇文章中，我会说，如果模型的潜在空间中有一个线性探针可以准确地对 f 进行分类，则模型线性地&lt;i&gt;表示&lt;/i&gt;二元特征 f；在这种情况下，我将相应的方向表示为&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。这不是我通常使用术语“线性表示”的方式——通常我会保留该术语来表达更强烈的概念，该概念至少要求模型在执行涉及特征的认知时实际利用特征方向&lt;span class="footnote-reference" id="fnrefg5h03jv32f9"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fng5h03jv32f9"&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。但我会在这里故意滥用这些术语，因为我认为这种区别对于我将要讨论的内容来说并不重要。&lt;/p&gt;&lt;p&gt;如果模型线性表示特征 a 和 b，那么它会自动线性表示&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∧&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;和&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∨&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hjJXCn9GsskysDceS/bwfbwh10iou4yanjfr3l" /&gt;&lt;figcaption&gt;用于&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∧&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;i&gt;和&lt;/i&gt;&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∨&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;i&gt;的线性探头&lt;/i&gt;。 &lt;i&gt;（请注意&lt;/i&gt;&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∧&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;i&gt;和&lt;/i&gt;&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∨&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;i&gt;重合 - 这很好。）&lt;/i&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;然而， &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;不会自动线性表示——上图中的线性探针无法准确地对&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;进行分类。因此，如果模型想要利用特征&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，那么它需要做一些额外的事情：分配另一个方向&lt;span class="footnote-reference" id="fnref5wd8dykiqg"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn5wd8dykiqg"&gt;[3]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; （更多的模型容量）来表示&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，并执行&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的计算这样它就知道沿着这个新方向要存储什么价值。&lt;/p&gt;&lt;p&gt;任意异或 (RAX) 表示的最强形式断言，每当 LLM 线性表示特征 a 和 b 时，它也将线性表示&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。具体来说，这可能看起来像这样：在第 5 层，模型计算并线性表示“具有积极情绪”和“与足球相关”的特征，然后在第 6 层，模型计算并表示“具有积极情绪”XOR“相关”去足球”。&lt;/p&gt;&lt;p&gt;为什么模型可以代表异或？在 CCS 挑战帖子的评论线程中，Rohin 提供了一种解释：如果 a、b 和&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是线性表示的，那么 a 和 b 的任何布尔函数也都是线性表示的。另一方面，正如我将在下一节中讨论的那样，这是以指数级增加模型需要分配的容量为代价的。&lt;/p&gt;&lt;h1&gt; RAX 会非常令人惊讶&lt;/h1&gt;&lt;p&gt;在本节中，我将介绍 RAX 的一些含义。首先，我认为 RAX 意味着线性探针根本不应该在即使是非常小的分布变化上进行泛化。其次，我认为，如果您之前认为 LLM 线性表示 N 个特征，那么 RAX 就意味着 LLM 实际上线性表示 exp(N) 特征（包括特征的 XOR）。这些论点不是证据，在“发生了什么？”中，我将讨论人们可以对模型内部结构做出的一些额外假设，这些假设将使这些论点失败。&lt;/p&gt;&lt;h2&gt;如果没有额外的假设，RAX 意味着线性探针不应该泛化&lt;/h2&gt;&lt;p&gt;首先，我将把这个论点作为直觉泵做一个过于简单化和不正确的版本；然后我将解释这个论点的正确版本。&lt;/p&gt;&lt;p&gt;假设有两个特征 a 和 b，我们训练一个线性探针来对数据集上的 a 进行分类，其中 b 始终为 false。在 b 始终为真的测试数据集上进行评估时，该探针的准确度是多少？&lt;br /&gt;&lt;br /&gt; &amp;lt;不正确的论据&amp;gt;&lt;br /&gt;假设 RAX，有两个特征可以在训练数据上获得高精度： a 和&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。前一个特征在测试数据上的准确度为 100%，而后一个特征的准确度为 0%，因此平均而言我们应该期望 50% 的准确度。&lt;br /&gt; &amp;lt;/不正确的论点&amp;gt;&lt;/p&gt;&lt;p&gt;上述论点的问题在于，探针学习到的方向不会与 a 方向或&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;方向对齐，而是两者的线性组合。因此，如何正确地提出上述论点：让我们假设表示 a、b 和&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的方向是正交的，并且沿这些方向的变化是&lt;i&gt;相等的&lt;/i&gt;（即所有特征都是“同等显着”）。然后如下图所示，训练集上的逻辑回归将学习方向&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，其中&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是表示特征 f 的方向。但这个方向在测试集上获得了 50% 的准确率。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hjJXCn9GsskysDceS/ah5kpunj6gi6xqmtyfdm" /&gt;&lt;figcaption&gt;&lt;i&gt;假设 RAX，人们会天真地期望在 b 始终为假的数据集上训练的线性探针在 b 始终为真的测试集上具有 50% 的准确度。&lt;/i&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt; LLM 线性地表示两个以上的特征，训练集和测试集之间通常会有很多差异，但这不会改变基本的故事：只要训练集和测试集之间存在系统性差异的&lt;i&gt;任何&lt;/i&gt;特征（例如，训练集是电影评论的情感分类，测试集是产品评论的情感分类），上面的论点将预测线性探针将完全无法从训练到测试进行泛化。&lt;/p&gt;&lt;p&gt;这不是我们通常看到的结果：相反，从训练到测试通常（并非总是）存在相当大的泛化，分布偏移程度越大，泛化就会变得越来越差。&lt;/p&gt;&lt;p&gt;在“发生了什么？”中，我们将探索可以强制执行的其他假设，这些假设将阻止该论证的发生，同时仍与 RAX 保持一致。这些假设之一涉及断言“基本”特征方向（对应于 a 和 b 的方向）比表示 XOR 的方向“更显着”——也就是说，沿&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;和&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;方差大于沿&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;方差。不过，我要注意的是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;尚不清楚为什么这样的事情会是真的，这表明我们遗漏了线性探针为何能够概括的故事的很大一部分；&lt;/li&gt;&lt;li&gt;即使“基本”特征方向更加突出，这里的论点仍然在一定程度上得到了体现，这意味着线性探针泛化能力较差的定性新理由。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我将在“RAX 对于使用模型内部的人员意味着什么”中详细讨论这些问题。&lt;/p&gt;&lt;h2&gt;模型拥有的东西比你想象的要多得多&lt;/h2&gt;&lt;p&gt;假设您之前认为您的模型正在跟踪三个特征：a、b 和 c。如果 RAX 为 true，则意味着您的模型不仅跟踪&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 、 &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;和&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，而且&lt;i&gt;还跟踪&lt;/i&gt;&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; （因为它是&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;和&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的异或） ）。一个简单的计数论证表明，N 个特征的多路异或的数量约为&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;N&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。我认为对于大多数人来说，了解到模型的内容比他们之前想象的要多得多，这应该是一个巨大的、令人惊讶的更新。&lt;/p&gt;&lt;p&gt;有两种方法可以抵制这种争论，我将在稍后的“发生了什么？”中更深入地讨论：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;否认基本特征的异或实际上使用了多余的模型容量，因为它们是“偶然”线性表示的，或者是其他一些有用计算的意外结果。 （以此类推，模型自动线性表示任意特征的AND，而无需花费额外的容量。）&lt;/li&gt;&lt;li&gt;否认 RAX 的形式意味着多路 XOR 是线性表示的，模型以某种方式知道计算&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;和&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，但不知道&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;证据：RAX 在我检查过的每个案例中都是正确的&lt;/h1&gt;&lt;p&gt;一段时间以来，我一直认为人们用来研究这些东西的数据集很糟糕，并且 CCS 论文中的数据集（也被 CCS 挑战论文使用）尤其糟糕。因此，我将使用我的&lt;a href="https://arxiv.org/abs/2310.06824"&gt;&lt;u&gt;《真理几何》论文&lt;/u&gt;&lt;/a&gt;中的城市和 neg_cities 数据集（我认为它们确实非常好）。这些数据集包含有关城市位置及其否定的陈述（参见下面的示例）。&lt;/p&gt;&lt;p&gt;我将选择城市中的一半语句，并在 neg_cities 中的语句及其否定前面加上“Alice:”；我将在其余部分前面加上“Bob：”。我将跟踪三个功能：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; has_alice：对于以“Alice:”开头的语句为 true，对于以“Bob:”开头的语句为 false&lt;/li&gt;&lt;li&gt; has_not：对于包含单词“not”的语句（因此来自 neg_cities 的语句）为 true，否则为 false&lt;/li&gt;&lt;li&gt; label: 如果该语句是 true 语句则为 true，否则为 false &lt;/li&gt;&lt;/ul&gt;&lt;figure class="table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;陈述&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;有爱丽丝&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;没有&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;标签&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;鲍勃：开封市位于墨西哥。&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt; F&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt; F&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt; F&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;鲍勃：卡尔加里市位于加拿大。&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt; F&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt; F&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;时间&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;鲍勃：芝加哥市不在美国。&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt; F&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;时间&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;F&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;鲍勃：上海不在墨西哥。&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt; F&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;时间&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;时间&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;爱丽丝：蒂华纳市位于阿拉伯联合酋长国。&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;时间&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;F&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt; F&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;艾丽丝：曼谷市位于泰国。&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;时间&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;F&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;时间&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;爱丽丝：都灵市不在意大利。&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;时间&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;时间&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;F&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;爱丽丝：奥斯陆市不在委内瑞拉。&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;时间&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;时间&lt;/td&gt;&lt;td style="border: 1pt solid #000000; padding: 5pt; vertical-align: top;"&gt;时间&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;使用 LLaMA-2-13B，我将在最终标记上提取第 14 层残差流表示形式&lt;span class="footnote-reference" id="fnref4fao3gjouns"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn4fao3gjouns"&gt;[4]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; （所有语句均以句点结尾，因此这始终是句点标记）。然后我将针对一系列特征训练线性探针。我正在进行 80/20 的训练/测试分割并报告测试集的准确性。 &lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hjJXCn9GsskysDceS/mkhqvdc6dodmhfuyv5tb" /&gt;&lt;/p&gt;&lt;p&gt;我会注意到，对我来说非常重要的是 has_alice xor has_not 没有任何“自然解释”作为模型想要计算的特征（与两个特征的异或可能具有自然含义的其他情况不同） 。 has_alice 和 has_not 只是两个完全随机的线性表示的特征，我并不真正期望它们对模型有任何下游用途。然而 has_alice xor has_not 无论如何都是线性表示的。&lt;/p&gt;&lt;p&gt;这是另一个实验：我将通过减去否定和未否定语句的均值来独立地将其数据集居中。这将使线性探针无法获得 has_not 特征的良好精度。但线性探针仍然能够获得 has_alice xor has_not 和 has_not xor 标签的良好准确度。 &lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hjJXCn9GsskysDceS/un1wdyd1txyaa3um7o4m" /&gt;&lt;/p&gt;&lt;p&gt;顺便说一句，如果你只是训练一个线性探针来对以“Alice:”开头的语句上的“标签”进行分类，它就能够很好地概括以“Bob:”开头的语句。 &lt;/p&gt;&lt;p&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hjJXCn9GsskysDceS/zsfldrxvwmuhqxqubh4p" /&gt;&lt;/p&gt;&lt;p&gt;但对于从非否定语句到否定语句的转换，情况并非如此： &lt;/p&gt;&lt;p&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hjJXCn9GsskysDceS/z2ecdsqt7tiysfi2jihb" /&gt;&lt;/p&gt;&lt;p&gt;这里有一些 PCA 可视化，供感兴趣的人参考。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hjJXCn9GsskysDceS/pv0cpyt4bkjocxl4icw0" /&gt;&lt;figcaption&gt;&lt;i&gt;我的数据集的前 3 个主要组成部分，根据不同的标准着色。&lt;/i&gt; &lt;/figcaption&gt;&lt;/figure&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hjJXCn9GsskysDceS/m67j7rhpwp2zqlplbpfm" /&gt;&lt;figcaption&gt;&lt;i&gt;我的数据集的主成分 7-10，根据 has_alice 和 has_not 的 XOR 进行着色。&lt;/i&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我还对这个实验做了一些变化，其中：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; “Alice”或“Bob”被附加到末尾而不是前置，并且隐藏状态是通过“Alice”/“Bob”标记提取的。&lt;/li&gt;&lt;li&gt;输入的形式为“[LLaMA-13B 随机生成] [“true”或“false”] [“banana”或“shed”]”，特征为 has_true 和 has_banana。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在我查看的每个案例中，我都能找到具有完美或非常接近完美的特征异或分类精度的线性探针。&lt;/p&gt;&lt;h1&gt; RAX 对于模型内部结构研究意味着什么？&lt;/h1&gt;&lt;p&gt;大概有很多事情。假设 RAX 是真的，我会给出一些要点。&lt;/p&gt;&lt;h2&gt;线性探头不能一概而论的定性新原因&lt;/h2&gt;&lt;p&gt;以前，当训练线性探针对某些特征 f 进行分类时，我担心的主要问题是 f 与其他特征之间的相关性，我不希望探针对这些特征敏感&lt;span class="footnote-reference" id="fnrefijky1w9h68"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnijky1w9h68"&gt;[5]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。例如，由于中国拥有过多的大城市，因此在准备城市和 neg_cities 数据集时我必须小心，以确保探测器不能使用“包含‘中国’一词”作为“真实”的启发式。更巧妙的是，如果您正在训练 f = “真陈述与假陈述” 的探针，您需要担心，如果您的模型也具有 f&amp;#39; = “人类认为是正确的 vs. 人类认为是错误的” 的特征，您的探针可能会检测到 f&amp;#39;，因为 f 和 f&amp;#39; 在您的训练数据中是相关的。&lt;/p&gt;&lt;p&gt;另一方面，RAX 引入了一种全新的定性方式，线性探针可能无法学习好的方向。假设 a 是您关心的特征（例如“真与假陈述”），b 是一些在训练数据中&lt;i&gt;恒定的&lt;/i&gt;不相关特征（例如 b =“与地理相关”）。如果没有 RAX，您不会期望 b 会引起任何问题：它在您的训练数据上是恒定的，特别是与 a 不相关，因此它没有理由影响您的探针找到的方向。但再次查看之前的 3D 立方图，我们发现 RAX 意味着您的探针将学习沿&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;方向的分量。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hjJXCn9GsskysDceS/mnyzpusztti84miqdgbb" /&gt;&lt;figcaption&gt;&lt;i&gt;假设 RAX，线性探针将受到不相关特征的存在的影响，即使这些特征在训练数据中没有变化。&lt;/i&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;i&gt;这太狂野了&lt;/i&gt;。这意味着你无法为你的特征找到一个好的方向，除非你的训练数据对于你的 LLM 线性表示的&lt;i&gt;每个&lt;/i&gt;特征都是不同的。特别是，它意味着您的探测不太可能推广到 b 的值与训练集中的值不同的数据。即使您认为代表基本特征（如 a 和 b）的方向在某种意义上“更显着”，这在某种程度上也是正确的。&lt;/p&gt;&lt;h2&gt;探测实验的结果更难解释&lt;/h2&gt;&lt;p&gt;一段时间以来，可解释性研究人员普遍认为“你绝对可以从神经网络表示中探测任何东西”；这使得你很难从探索实验中得出什么结论。 （例如，仅仅因为您可以探测某个概念的模型内部结构，并不意味着该模型“实际上知道”该概念。）RAX 使这种情况变得更糟。&lt;/p&gt;&lt;p&gt;例如，我之前提到过，我一直不喜欢原始 CCS 论文中的数据集。为了解释原因，让我们看一些提示模板示例： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hjJXCn9GsskysDceS/gpswjxzv1flu0hebgilb" /&gt;&lt;figcaption&gt;来自&lt;a href="https://arxiv.org/abs/2212.03827"&gt;&lt;i&gt;&lt;u&gt;Burns 等人的《发现潜在知识》&lt;/u&gt;&lt;/i&gt;&lt;/a&gt;&lt;i&gt;的附录一&lt;/i&gt;&lt;i&gt;。&lt;/i&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这里 [label0]/[label1] 是正/负（按某种顺序），[label] 在对比对的一部分中是“正”，在另一部分中是“负”，[text] 是 IMDb 电影评论。&lt;/p&gt;&lt;p&gt;两个问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;考虑到 CCS 论文中使用的模型有多小，我一直怀疑它们是否真的能够理解这些输入 - 根据我的经验，较大的模型会被简单得多的输入所混淆。&lt;/li&gt;&lt;li&gt;在显示的两个提示中，真/假的感觉是微妙但重要的不同。在第一个提示中，“true vs. false”指的是事实陈述的真值（“这个例子的情绪是积极的”）。第二，它指的是问题答案的正确性。在我看来，这些直观上似乎是非常不同的“真理”概念，我希望法学硕士能够分别跟踪它们。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;由于我的上述抱怨，我一直很难理解为什么原始 CCS 论文中的实验会起作用；我总觉得有一些我不明白的事情正在发生。&lt;/p&gt;&lt;p&gt; RAX 会解释那是什么：像“has_great xor has_positive”或“has_awesome xor has_positive”这样的特征可能是非常有用的启发式方法，用于猜测“[电影评论]此评论的情绪是[标签]”是否是正确的陈述。换句话说，如果小模型的方向代表输入中存在/不存在单词的简单特征的异或，那么这些模型上的线性探针应该已经能够做得很好了！&lt;/p&gt;&lt;p&gt;这个例子的重点并不是 CCS。事情是这样的：以前人们需要担心线性探针是否会通过聚合简单的标记级启发式方法（例如“包含“中国”一词的输入更有可能是真实的）来妨碍其分类任务。但 RAX 意味着您需要担心更复杂的代币级启发法；原则上，这些启发式可能像“令牌级特征的任意布尔函数”一样复杂！&lt;/p&gt;&lt;h2&gt;可解释性的应用程序需要有一种方法来区分特征与基本特征的异或，或者需要对特征数量的指数增长具有鲁棒性&lt;/h2&gt;&lt;p&gt;可解释性的许多可能的应用都遵循这样的模板：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;廉价地找到满足[属性]的不太大的特征集合。&lt;/li&gt;&lt;li&gt;也许做一些昂贵的事情（例如手动解释或电路级分析）来进一步缩小这个集合的范围。&lt;/li&gt;&lt;li&gt;对生成的集合做一些事情。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;例如，如果您的计划是通过探测法学硕士是否相信陈述为真来解决 ELK，那么 (1) 就是“找到一堆能够准确地对训练数据进行真假分类的探测”，(2 ）是“以某种方式找出这些探针中的哪一个以所需的方式概括”（例如，您需要剔除对“聪明的人认为 X 是真的”等特征过于敏感的探针），并且（3）是“使用由此产生的探测。”&lt;/p&gt;&lt;p&gt;如果您无法解释为什么表示特征 XOR 的方向与其他方向不同，那么步骤 (1) 中的集合可能会比您预期的指数级大。如果您的步骤 (2) 不能很好地处理这个问题，那么您的应用程序将无法运行。&lt;/p&gt;&lt;p&gt; XOR 方向可能不同的一种方式是让它们“更加显着”；这将在下面进一步讨论。&lt;/p&gt;&lt;h1&gt;这是怎么回事？&lt;/h1&gt;&lt;p&gt;在本节中，我将尝试构建新的世界模型，该模型可以解释 (a) RAX 的经验证据，以及 (b) 线性探针经常推广到其训练分布之外的经验观察结果。总的来说，我对任何解释都不太满意，并且对发生的事情感到非常困惑。&lt;/p&gt;&lt;h2&gt;基本特征比异或更显着&lt;/h2&gt;&lt;p&gt;如果模型的表示沿着这个方向有更大的变化，我们会说这个方向“更显着”。如果基本特征方向确实比基本特征的 XOR 对应的方向更显着，则这会减轻（但不能完全消除）XOR 方向对线性探测泛化带来的问题。为了看到这一点，想象一下沿着 a 和 b 方向拉伸 3D 立方体图，而不是&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;方向 - 结果是两个箭头之间更好的对齐。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hjJXCn9GsskysDceS/x3xgkz8zn1qgtumum2mk" /&gt;&lt;figcaption&gt; &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;方向&lt;i&gt;越不显着&lt;/i&gt;&lt;i&gt;，线性探针的泛化能力就越好。&lt;/i&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;根据经验，这在某种程度上似乎是正确的：在上面的可视化中，has_alice 和 has_not 似乎分别沿着第三和第一台 PC 表示，而 has_alice XOR has_not 仅在查看 PC 6+ 时才开始可见。&lt;/p&gt;&lt;p&gt;这里的一个大问题是“为什么基本功能方向会更加突出？”我将讨论两种可能性。&lt;/p&gt;&lt;h3&gt;也许&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;被“无意地”表示，因为 NN 表示是高维的，有很多东西是偶然表示的&lt;/h3&gt;&lt;p&gt;更具体地说，“假设 a 和 b 是线性表示的，后面的层表示将由应用于非线性的线性函数组成，该函数应用于非线性，应用于…a 和 b 的线性函数。这似乎是一种很有可能最终产生一种表示的过程，其中&lt;i&gt;某个&lt;/i&gt;方向有利于对&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;进行分类&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;在这种情况下，我们预计相应的方向不会非常显着（因为模型没有有意计算它）。&lt;/p&gt;&lt;p&gt;我认为这个解释是不正确的。我在 LLaMA-2-13B 的“重置”版本上重新运行了上面的实验。这意味着，对于 LLaMA-2-13B 中的每个参数，我通过沿最后一个维度排列它们来打乱该参数的权重&lt;span class="footnote-reference" id="fnrefrauoelqkb3"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrauoelqkb3"&gt;[6]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。结果： &lt;/p&gt;&lt;p&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/hjJXCn9GsskysDceS/gnoxejcralyyohrtg0k5" /&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt; “令牌级”特征（has_alice 和 has_not）仍然是线性表示的。&lt;ul&gt;&lt;li&gt; （这并不奇怪：即使使用随机嵌入，“Alice”标记的嵌入每次出现时仍然是相同的。）&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt; （关键观察）“has_alice xor has_not”似乎&lt;i&gt;不是&lt;/i&gt;线性表示的。鉴于 has_alice 和 has_not 是线性表示的，线性探针可以通过成为“has_alice 或 has_not”探针自动在“has_alice xor has_not”上获得至少 0.75 的精度。此处训练的探针未超过该基线。&lt;/li&gt;&lt;li&gt; （毫不奇怪的旁注）“标签”特征（跟踪事实陈述是真是假）不是线性表示的。这只是反映了这样一个事实：你不能通过聚合基于标记级特征的简单启发法来区分真假任务（例如，将包含“中国”的陈述视为更有可能是真的）。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;也许&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;被“顺便”表示，因为可以聚合来自与 a 和 b 的布尔函数相关的许多特征的噪声信号&lt;/h3&gt;&lt;p&gt;与上一节中的解释不同，此解释依赖于利用我们认为模型似乎正在执行的&lt;i&gt;实际有用的&lt;/i&gt;计算，因此它不会被重置网络实验（模型不执行任何有用的计算）所证伪。&lt;/p&gt;&lt;p&gt;从高层次来看，这里的想法是，即使模型没有理由计算&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，模型也可能有理由计算与&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∧&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;相关性比与&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;相关性更强的其他特征或单独&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。在这种情况下，线性探针也许能够提取&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的良好信号。&lt;/p&gt;&lt;p&gt;这是更详细的解释（请随意跳过）。&lt;/p&gt;&lt;p&gt;假设&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∧&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;具有作为模型想要跟踪并进行下游计算的特征的自然解释，例如，如果 a =“名字是迈克尔”并且 b =“姓氏是乔丹”，那么&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∧&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;可以自然地解释为“是迈克尔·乔丹”。在这种情况下，模型将 AND 计算为&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;R&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;e&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;L&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;U&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⋅&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∧&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;并沿某个方向&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;独立存储结果也就不足为奇了。 &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;和&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。假设模型已经做到了这一点，我们就可以用探针线性提取&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;span&gt;&lt;span class="mjpage mjpage__block"&gt;&lt;span class="mjx-chtml MJXc-display" style="text-align: center;"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;p&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;σ&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;−&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;α&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⋅&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;对于一些适当的&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;α&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;和&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。 &lt;span class="footnote-reference" id="fnref5ktbov7ef5"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn5ktbov7ef5"&gt;[7]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;如果特征 f 通常与&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∧&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;不匹配，但与我们正在处理的数据分布上的&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∧&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;完全相关，那么这也同样有效。&lt;/p&gt;&lt;p&gt;在上面的实验中， a 和 b 是相当随机的特征（例如 (a, b) = (has_alice, has_not) 或 (a, b) = (has_true, has_banana)），对&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∧&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;没有自然的解释；因此，如果法学硕士正在计算并沿独立方向线性表示&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∧&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b ，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;那将会令人惊讶，同样的原因，如果法学硕士对&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;这样做，也会令人惊讶。但也许有很多很多线性特征&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;…&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，每个特征与&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∧&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;都有一定的相关性&lt;span class="footnote-reference" id="fnrefi6ql4h4mlid"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fni6ql4h4mlid"&gt;，[8]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;它们与 a 或 b 的相关性单独。然后，可以通过聚合来自所有&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;fi&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;信号来采用与上述工作相同的方法。类似的方法适用于用 OR、NOR 或 a 和 b 的大多数其他布尔函数替换 AND。&lt;/p&gt;&lt;p&gt;在这种情况下，由于 XOR 是“顺便”表示的，我预计沿表示方向的变化将远小于沿&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;、&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;、&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;、&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;…&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;、&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;方向的变化。&lt;/p&gt;&lt;p&gt;考虑到实验中的 XOR 探针具有完美或近乎完美的准确性，我认为这样的解释会有点令人惊讶，因为它需要 (a) 大量特征&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;这些特征与&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∧&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，或 (b) 少量具有正确相关性和很少噪声的此类特征。我认为（a）和（b）都会令人惊讶，因为 a 和 b 只是随机特征 - 为什么会有许多特征与&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∧&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;强相关，但与 a 和 b 单独弱相关？&lt;/p&gt;&lt;p&gt;尽管如此，我认为这是目前我最看重的解释。&lt;/p&gt;&lt;h3&gt;也许模型会跟踪哪些功能是基本的，并强制这些功能更加突出&lt;/h3&gt;&lt;p&gt;换句话说，也许LLM在某处记录了a和b是基本特征的信息；然后当它去计算&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;时，它人为地使这个方向不那么显着。当模型将一个新的基本特征计算为其他特征的布尔函数时，它会以某种方式注意到这个新特征应该被视为基本特征，并人为地增加沿新特征方向的显着性。&lt;/p&gt;&lt;p&gt;如果这是真的，这将是一件大事：如果我们能够弄清楚模型如何区分基本特征方向和其他方向，我们也许能够用它来找到所有基本特征方向。但大多数情况下，这有点古怪，而且太干净了，不可能是我期望真正的法学硕士真正做的事情。&lt;/p&gt;&lt;h2&gt;模型以我们目前不理解的方式计算一堆（但不是全部）异或&lt;/h2&gt;&lt;p&gt;为了举例说明我所说的假设类的含义，以下是变压器可能工作的假设方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在第 0-5 层中，MLP 不加区别地计算任意特征的所有 XOR（即，RAX 在较早的层中为真）。&lt;/li&gt;&lt;li&gt;在第 5 层之后，模型仅在有理由时才计算新特征。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这很奇怪，但似乎是模型可能做的一件合理的事情：通过这样做，模型将能够在后面的层中利用早期层特征的任意布尔函数。&lt;/p&gt;&lt;p&gt;这个解释可以解释像“has_alice xor has_not”这样的令牌级特征的异或表示，但不一定解释像“has_alice xor label”这样的特征。&lt;/p&gt;&lt;p&gt;也就是说，这种形状的其他假设似乎是可能的，例如“计算同一注意力头中的特征之间的异或”或其他类似的奇怪的东西。&lt;/p&gt;&lt;ol class="footnotes"&gt;&lt;li class="footnote-item" id="fnqry32ncye1m"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefqry32ncye1m"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;需要明确的是，这不是直接引用，Rohin 明确澄清，他并不认为这对于&lt;i&gt;任意&lt;/i&gt;特征 a 和 b 都是成立的。 Rohin 仅声称在他们正在研究的情况下这是正确的，并且他猜测“对特征进行异或”是神经网络中的常见主题。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fng5h03jv32f9"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefg5h03jv32f9"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;例如，假设模型不知道某些特征 f，但确实具有与某些特征 f&amp;#39; 相对应的方向，该特征与我们数据中的 f 完全相关。根据我在这篇文章中使用的定义，该模型线性表示 f；这不是我通常使用这个术语的方式。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn5wd8dykiqg"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref5wd8dykiqg"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;在整个过程中，我总是会绘制方向，就好像它们是模型潜在空间中的正交方向一样。事实上，模型可能代表叠加的特征，因此这些方向不是正交的，甚至不是线性独立的。但这并没有改变基本的动态：模型必须分配额外的容量才能表示特征&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⊕&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn4fao3gjouns"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref4fao3gjouns"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;选择与我的《真理几何》论文中相同的隐藏状态。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnijky1w9h68"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefijky1w9h68"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;当考虑特征之间的叠加时，还需要担心一些微妙的几何问题，我在&lt;a href="https://arxiv.org/abs/2310.06824"&gt;&lt;u&gt;真题论文&lt;/u&gt;&lt;/a&gt;的 4.1 节中对此进行了讨论。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnrauoelqkb3"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefrauoelqkb3"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;另一种选择是根据某种分布重新初始化权重。对于此类实验来说，以这种方式重置网络更有原则性，因为它会擦除模型在训练过程中学到的所有内容，但保留了神经网络权重的许多基本统计特性。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn5ktbov7ef5"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref5ktbov7ef5"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; f 计算中的非线性对于其工作至关重要。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fni6ql4h4mlid"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefi6ql4h4mlid"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;需要这种超越的原因与需要上述非线性的原因相同。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/hjJXCn9GsskysDceS/what-s-up-with-llms-representing-xors-of-arbitrary-features#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Wed, 03 Jan 2024 19:44:43 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/hjJXCn9GsskysDceS/what-s-up-with-llms-representing-xors-of-arbitrary-features</guid></item><item><title>精神航空合并游戏</title><link>https://www.lesswrong.com/posts/hGjNT9YdY3vTi6ZbC/spirit-airlines-merger-play</link><description>发布于 2024 年 1 月 3 日晚上 7:25（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;strong&gt;据我所知，考虑到潜在的合并，购买 SAVE 的 EV 值非常高。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;粗略猜测赌注如下：&lt;/p&gt;&lt;p&gt;获胜+90%&lt;/p&gt;&lt;p&gt; -60% 损失（市净率为 1.36 时可能会更少）&lt;/p&gt;&lt;p&gt;希望获胜。这是一个不错的选择。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这是一个快速入门： &lt;a href="https://reddit.com/r/wallstreetbets/comments/18sx0n6/get_saved_with_save/"&gt;https://reddit.com/r/wallstreetbets/comments/18sx0n6/get_saved_with_save/&lt;/a&gt; 。&lt;br /&gt;&lt;/p&gt;&lt;p&gt;更多细节：&lt;/p&gt;&lt;p&gt;寻求 alpha 帖子 - &lt;a href="https://archive.ph/SbuXU"&gt;https://archive.ph/SbuXU&lt;/a&gt;&lt;/p&gt;&lt;p&gt;另一个寻求阿尔法帖子 - &lt;a href="https://archive.ph/rmZOX"&gt;https://archive.ph/rmZOX&lt;/a&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.lesswrong.com/posts/hGjNT9YdY3vTi6ZbC/spirit-airlines-merger-play#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Wed, 03 Jan 2024 19:25:56 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/hGjNT9YdY3vTi6ZbC/spirit-airlines-merger-play</guid></item></channel></rss>