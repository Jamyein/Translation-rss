<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>少错</title><link>https://www.lesswrong.com</link><description>致力于提炼理性艺术的社区博客</description><lastBuildDate>Sun, 14 Jan 2024 06:14:24 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>与大多数人工智能风险类比相比</title><link>https://www.lesswrong.com/posts/SnfjK9ALrzFJB8x7B/against-most-ai-risk-analogies</link><description>发布于 2024 年 1 月 14 日凌晨 3:36（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;我不喜欢人们使用的大多数人工智能风险类比。虽然我认为类比有助于第一次向人们解释一个概念，但我认为类比经常被误用，而且常常是有害的。根本问题是，类比一直被错误地认为，并且经常被故意用作特定人工智能风险立场的&lt;i&gt;论据&lt;/i&gt;。大多数时候，当以这种方式使用类比时，我认为它们具有误导性和不精确性，通常会传达特定的、可信的人工智能模型的错误印象，即使不存在这样的可信模型。&lt;/p&gt;&lt;p&gt;以下是我在人工智能风险背景下发现的类比示例的随机列表：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href="https://people.eecs.berkeley.edu/~russell/papers/russell-bostonglobe23-AI"&gt;斯图尔特·拉塞尔&lt;/a&gt;：“这并不完全像邀请一个高级外星物种来永远成为我们的奴隶，但它有点像那样。”&lt;/li&gt;&lt;li&gt; &lt;a href="https://80000hours.org/podcast/episodes/ajeya-cotra-accidentally-teaching-ai-to-deceive-us/#aliens-and-other-analogies-013822"&gt;罗布·维布林&lt;/a&gt;：“这有点像试图了解章鱼如何思考或如何行为——只不过章鱼还不存在，我们要做的就是研究它们的祖先海蜗牛，然后我们必须从中弄清楚成为章鱼是什么感觉。”&lt;/li&gt;&lt;li&gt; &lt;a href="https://twitter.com/ESYudkowsky/status/1633219449724760065"&gt;Eliezer Yudkowsky&lt;/a&gt; ：“这个人工智能扮演的角色不是人工智能。人工智能是一个看不见的女演员，目前正在扮演这个角色。如果人工智能变得更聪明，这可能会适得其反。”&lt;/li&gt;&lt;li&gt; &lt;a href="https://www.lesswrong.com/posts/GNhMPAWcfBCASy8e6/a-central-ai-alignment-problem-capabilities-generalization#Discussion_of_a_problem"&gt;Nate Soares&lt;/a&gt; ：“我对人工智能进展的猜测是，在某个时刻，一些团队得到的人工智能开始足够好地泛化，远远超出其训练分布，它可以掌握物理、生物工程和心理学等领域[...] 在其能力飞跃发展的同一过程中，其对齐属性被揭示为肤浅的，并且无法概括。&lt;strong&gt;这里的中心类比是，优化猿类的包容性遗传适应性（IGF）并不会使由此产生的人类在心理上针对 IGF 进行了优化。&lt;/strong&gt; ”&lt;/li&gt;&lt;li&gt;&lt;a href="https://lukemuehlhauser.com/wiener-on-the-ai-control-problem-in-1960/"&gt;诺伯特·维纳&lt;/a&gt;：“当我们建造的机器能够以我们无法跟上的速度对其输入数据进行操作时，我们可能不知道何时将其关闭，直到为时已晚。我们都知道魔法师学徒的寓言……”&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.datanami.com/2023/05/03/ai-threat-like-nuclear-weapons-hinton-says/"&gt;杰弗里·辛顿（Geoffry Hinton）&lt;/a&gt; ：“这就像核武器。如果发生核战争，我们都会失败。这些东西接管也是如此。”&lt;/li&gt;&lt;li&gt; &lt;a href="https://www.lesswrong.com/posts/76etTtAiKtZGGzkmi/video-and-transcript-of-presentation-on-existential-risk"&gt;乔·卡尔史密斯&lt;/a&gt;：“我认为人工智能的一个更好的比喻是一种工程病毒，如果它泄露出去，它会变得越来越难控制，这是一个越来越大的问题。”&lt;/li&gt;&lt;li&gt; &lt;a href="https://80000hours.org/podcast/episodes/ajeya-cotra-accidentally-teaching-ai-to-deceive-us/#aliens-and-other-analogies-013822"&gt;Ajeya Cotra&lt;/a&gt; ：“从某种意义上说，企业可能是比整个经济更好的类比：它们是由这些人类部分组成的，但最终往往追求的东西实际上并不是目标和目标的简单平均数。组成这台机器的人类的愿望，这台机器就是可口可乐公司之类的。”&lt;/li&gt;&lt;li&gt; &lt;a href="https://archive.is/K0Arj#selection-581.152-585.113"&gt;Ezra Klein&lt;/a&gt; ：“正如我的同事 Ross Douthat &lt;a href="https://archive.is/o/K0Arj/https://www.nytimes.com/2023/03/02/opinion/magic-science-ufo-ai.html"&gt;所写&lt;/a&gt;，这是一种召唤行为。施展这些咒语的程序员不知道什么会绊倒传送门。”&lt;/li&gt;&lt;li&gt; &lt;a href="https://forum.effectivealtruism.org/posts/zsFCj2mfnYZmSW2FF/ai-risk-is-like-terminator-stop-saying-it-s-not-1"&gt;SKLUUG：&lt;/a&gt; “人工智能风险就像&lt;i&gt;终结者&lt;/i&gt;！人工智能可能会变得非常聪明，并决定杀死我们所有人！我们需要对此采取一些措施！”&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这些类比涵盖的范围很广，其中许多类比有时确实有助于传达有意义的信息。我的观点并不是说它们毫无用处，而是这些类比通常很肤浅且具有误导性。它们几乎没有建立关于真实人工智能的行为和工作的任何重要内容，但仍然给人留下了我们应该如何思考人工智能的模型的&lt;i&gt;印象&lt;/i&gt;。&lt;/p&gt;&lt;p&gt;并注意这些类比如何给人一种连贯的人工智能模型的印象，即使演讲​​者没有直接断言它&lt;i&gt;是&lt;/i&gt;一个模型。不管演讲者的意图如何，我认为&lt;i&gt;实际的&lt;/i&gt;效果往往是在听众的脑海中植入一幅详细但虚假的画面，从而引发关于真正的人工智能在未来如何运作的似是而非的想法。&lt;/p&gt;&lt;p&gt;另外，这些类比经常是&lt;i&gt;有选择性地&lt;/i&gt;选择的——基于唤起特定的偏好图像而选择，而不是基于识别可能的最&lt;i&gt;自然&lt;/i&gt;的比较点。考虑&lt;a href="https://80000hours.org/podcast/episodes/ajeya-cotra-accidentally-teaching-ai-to-deceive-us/#aliens-and-other-analogies-013822"&gt;Ajeya Cotra 的这个例子&lt;/a&gt;，&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;strong&gt;Rob Wiblin：&lt;/strong&gt;我想花一点时间谈谈人们用来推理所有这些问题的不同类比和不同的心理图像。 [...]您认为还有其他值得强调的心理模型或类比吗？&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Ajeya Cotra：&lt;/strong&gt;我听过的一个播客实际上做了另一个类比——这是一个艺术播客，随着人工智能艺术开始真正起飞，关于人工智能的一集也是如此——这就像你在养一只狮子幼崽，或者你有这些人抚养黑猩猩宝宝，而你正试图引导他们走向正确的方向。也许它非常可爱、迷人，但从根本上来说它与你格格不入。无论你多么努力地抚养它或引导它，它都可能在它成年后撕掉你的脸。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;当“金毛猎犬”同样有效时，科特拉选择“黑猩猩”作为比较点有什么原因吗？很难知道，但似乎她没有选择金毛猎犬，因为这会破坏她的一般论文。&lt;/p&gt;&lt;p&gt;我同意，如果她的目标是传达错位的&lt;i&gt;逻辑可能性&lt;/i&gt;，那么与金毛猎犬的类比可能行不通。但如果她的目标是传达错位的&lt;i&gt;合理性&lt;/i&gt;，或者类似我们应该如何看待人工智能的“心智模型”之类的东西，我认为没有充分的理由更喜欢其中一种。一个类比会让人联想到负面形象，而另一个类比会让人联想到正面形象，这一事实本身似乎并没有任何使用偏好的基础。&lt;/p&gt;&lt;p&gt;或者考虑与人类进化的类比。如果你试图表达内在错位的&lt;i&gt;逻辑可能性&lt;/i&gt;，那么与人类进化的类比是有道理的。但是，如果你试图传达内在错位的&lt;i&gt;合理性&lt;/i&gt;，或者内在错位的心理模型，为什么不选择将这种情况与&lt;a href="https://www.lesswrong.com/posts/FyChg3kYG54tEN3u6/evolution-is-a-bad-analogy-for-agi-inner-alignment"&gt;人类一生中的学习&lt;/a&gt;进行类比呢？事实上，正如昆廷·波普（Quintin Pope） &lt;a href="https://www.lesswrong.com/posts/hvz9qjWyv8cLX9JJR/evolution-provides-no-evidence-for-the-sharp-left-turn#Human__misalignment__with_inclusive_genetic_fitness_provides_no_evidence_for_AI_misalignment"&gt;所解释的&lt;/a&gt;那样，与其他类比相比，进化类比似乎有一些很大的缺点：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; “祖先环境中的人类行为”与“现代环境中的人类行为”并不是训练和部署环境之间行为差异的有效示例。人类并不是在祖先环境中“训练”，然后在现代环境中“部署”的。相反，人类在一生中不断地接受“训练”（通过奖励信号和感官预测错误信号）。人类在祖先和现代环境中的“训练运行”是不同的。&lt;/p&gt;&lt;p&gt;因此，人类进化不是以下例子：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;我们在环境 A 中训练系统。然后，经过训练的系统处理来自环境 B 的不同输入分布，现在系统的行为有所不同。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这是一个例子：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;我们在环境 A 中训练了一个系统。然后，我们在环境 B 的不同输入分布上训练了同一系统的&lt;i&gt;新版本&lt;/i&gt;，现在这&lt;i&gt;两个不同的系统&lt;/i&gt;表现不同。&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;p&gt;许多人工智能风险的支持者似乎很乐意在&lt;i&gt;不&lt;/i&gt;支持预期结论（例如&lt;a href="https://www.lesswrong.com/posts/RcZeZt8cPk48xxiQ8/anthropomorphic-optimism"&gt;拟人类比）&lt;/a&gt;时批评类比。有时，他们甚至会批评&lt;a href="https://80000hours.org/podcast/episodes/ajeya-cotra-accidentally-teaching-ai-to-deceive-us/#aliens-and-other-analogies-013822"&gt;他们想象的其他人使用的类比&lt;/a&gt;，例如“它就像烤面包机”或“它就像谷歌地图”。当然，在这些情况下，他们可以轻松识别缺陷：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;strong&gt;Ajeya Cotra：&lt;/strong&gt;我认为谷歌地图与所有这些东西和人工智能系统之间真正的不相似之处在于，我们没有以与生产谷歌地图相同的方式生产这些人工智能系统：由一些人坐下来思考它应该是什么样子就像，然后编写代码来确定它应该是什么样子。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;需要明确的是，我同意谷歌地图是一个糟糕的类比。但黑猩猩的比喻真的好得多吗？难道我们不应该对我们自己的类比应用同样程度的严格性吗？&lt;/p&gt;&lt;p&gt;我的观点不仅仅是“使用不同的类比”。我的观点是，我们&lt;i&gt;首先&lt;/i&gt;应该&lt;i&gt;停止依赖类比&lt;/i&gt;。请改用详细的对象级参数！&lt;/p&gt;&lt;p&gt;虽然类比的目的是提供知识来代替无知——解释一种见解或一个概念——但我相信许多人工智能风险类比主要是误导或迷惑人们，而不是启发他们；他们可以插入不必要的错误&lt;i&gt;假设&lt;/i&gt;来代替真正的理解。它们想要传达的基本概念可能很值得理解，但伴随着这个概念的是一大堆额外的猜测。&lt;/p&gt;&lt;hr /&gt;&lt;p&gt;部分原因是我不会分享其他人对人工智能未来实际情况的看法。这只是我论点的一小部分，因为我的主要观点是，我们应该少用类比，而不是改用不同的类比来表达不同的画面。但这种差异仍然是我对使用人工智能风险类比感到沮丧的一个重要原因。&lt;/p&gt;&lt;p&gt;例如，也许你认为外星人和动物的类比很棒，但我完全不明白其中的原因。但我仍然很难看到这一点。至少，让我比较一下我的照片，也许你能明白我来自哪里。&lt;/p&gt;&lt;p&gt;在我看来，默认的画面——在我看来，这就像对 2024 年当前趋势到中期未来的直接推断，因为人工智能匹配并开始略微超过人类智能——看起来与大多数人所描绘的漫画完全不同。标准类比。与人工智能将成为外星人的模型相反，我预计人工智能将直接诞生于我们的社会，由我们有意塑造，目的是填补我们世界中大部分人形的漏洞。他们将在社会上与我们融为一体，并可能在很大程度上分享我们关于社会和物理世界的概念，接受过我们的数据培训并能流利地使用我们的语言。他们会不断地与我们互动，帮助我们，与我们合作，甚至为亿万人民提供友谊。人工智能将由我们评估、检查和选择，它们的行为将直接由我们的工程决定。&lt;/p&gt;&lt;p&gt;我觉得这张图是现有趋势的相对简单的延伸，法学硕士&lt;i&gt;已经&lt;/i&gt;接受了对我们友善和乐于助人的培训，并与我们合作，首先受到我们综合文化输出的影响。我预计，在可预见的未来，这种融入我们社会的趋势将会加剧，因为消费者对人们可以信任并愿意与之互动的人工智能会有需求。&lt;a href="https://aiimpacts.org/discontinuous-progress-investigation/"&gt;进展可能是渐进式的&lt;/a&gt;，而不是随着超级强大特工的到来而突然出现。也许最重要的是，我预计随着人工智能开始产生大规模影响&lt;a href="https://www.lesswrong.com/posts/EaZghEwcCJRAuee66/my-thoughts-on-the-social-response-to-ai-risk"&gt;，监督和监管将随着时间的推移而急剧增加&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;我无意在此描绘一幅一致乐观的景象。在我所呈现的场景中，仍然有很多可能出错的地方。其中大部分内容都没有具体说明，因为&lt;a href="https://forum.effectivealtruism.org/posts/zrSx3NRZEaJENazHK/why-i-think-it-s-important-to-work-on-ai-forecasting"&gt;我根本不知道未来会发生什么&lt;/a&gt;。但至少，也许你现在可以同情我的感觉，鉴于我的观点，大多数现有的人工智能风险类比都非常令人沮丧。&lt;/p&gt;&lt;hr /&gt;&lt;p&gt;再次强调，我并不是说类比在人工智能风险讨论中没有地位。我自己也确实使用过它们很多次。但我认为它们可以，而且经常被粗心地使用，并且似乎经常将各种关于未来人工智能将如何表现&lt;i&gt;的错误&lt;/i&gt;说明放入人们的心理模型中，即使进行类比的人没有任何意图。在我看来，总体而言，如果我们减少对人工智能风险类比的依赖，并用特定的对象级点代替它们，情况会好得多。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.lesswrong.com/posts/SnfjK9ALrzFJB8x7B/against-most-ai-risk-analogies#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sun, 14 Jan 2024 03:36:16 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/SnfjK9ALrzFJB8x7B/against-most-ai-risk-analogies</guid></item><item><title>用脸投票</title><link>https://www.lesswrong.com/posts/EitMbGASqTAuyWPJA/vote-with-your-face</link><description>发布于 2024 年 1 月 14 日凌晨 3:30（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;span&gt;从 7 月 2 日的舞蹈开始，&lt;/span&gt; &lt;a href="https://www.bidadance.org/"&gt;BIDA&lt;/a&gt;一半的舞蹈都是&lt;a href="https://blog.bidadance.org/2023/06/some-mask-optional-dances.html"&gt;不戴面具的&lt;/a&gt;。有些人只想在知道地板上的每个人都戴着&lt;a href="https://blog.bidadance.org/2022/05/requiring-high-filtration-masks.html"&gt;高过滤口罩的&lt;/a&gt;情况下参加，其他人只想在不需要口罩的情况下参加，当然其他人无论如何都会或不会参加。提供每种舞蹈中的一些，让人们选择适合自己喜好的舞蹈。&lt;/p&gt;&lt;p&gt;另外，作为一个喜欢实验的人，这几乎就像一个关于出勤戴口罩要求的随机对照试验！&lt;/p&gt;&lt;p&gt;在我们改为要​​求和可选佩戴口罩交替使用之前，我们不知道这会对出勤率产生什么影响：在可选佩戴口罩的夜晚（更有趣！）还是在需要佩戴口罩的夜晚（更安全！）会有更多的人。回顾一下出席情况，我发现：&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.jefftk.com/bida-attendance-by-mask-status-big.png"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/EitMbGASqTAuyWPJA/jncoepfisn8qg4hz7ujn" /&gt;&lt;/a&gt;&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;请注意，除了只有十一种舞蹈外，您可能还需要调整某些舞蹈的一些独特方面：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt; 7/2 舞蹈是第一个可选面具舞蹈，因此可能会受到那些很高兴不戴面具跳舞但不会每次都来的人们的鼓舞。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; 7/2 和 9/3 舞会是我们夏季前的最后一场舞会，也是回归后的第一场舞会，这可以增加上座率。但同时也是假期周末，这可能会减少出席人数。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; 11/5和11/19的舞会都是双人舞，上座率普遍较高。但我们（大部分是偶然的）背靠背做了两次，每一次。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; 12/3舞会是家庭舞会，这通常也意味着更高的出席率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; 12/17 的舞会在另一个地点萨默维尔军械库举行，这通常意味着出席率较低。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; 1/7 舞会是在一场大暴风雪期间举行的，这通常意味着出席人数要少得多。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;总的来说，看起来不戴面具的夜晚更受欢迎，但考虑到所有的警告，这很难说。无论如何，差异显然没有大到足以成为停止其中之一的理由。我预计我们会继续轮流参加，因为我们仍然听到很多人说他们只想参加其中之一。&lt;/p&gt;&lt;p&gt; （所有这些都是代表我自己，而不是 BIDA 董事会。）&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.lesswrong.com/posts/EitMbGASqTAuyWPJA/vote-with-your-face#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sun, 14 Jan 2024 03:30:06 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/EitMbGASqTAuyWPJA/vote-with-your-face</guid></item><item><title>使用 MLP 线性化对稀疏自动编码器特征进行逆向工程的案例研究</title><link>https://www.lesswrong.com/posts/93nKtsDL6YY5fRbQv/case-studies-in-reverse-engineering-sparse-autoencoder</link><description>发布于 2024 年 1 月 14 日凌晨 2:06（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;i&gt;认知状态：初步/探索性。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;作为 Neel Nanda 的 MATS 5.0（2023-2024 年冬季）研究冲刺的一部分进行的工作。&lt;/i&gt;&lt;/p&gt;&lt;p&gt; TL;DR：我们开发了一种方法，通过对 MLP 子层进行局部线性逼近，来理解 Transformer 模型中的稀疏自动编码器特征是如何从早期组件计算出来的。我们研究该特征如何在特定输入上激活，并采取措施通过检查模型权重来寻找与输入无关的解释。我们通过几个深入的案例研究演示了这种方法，以解释简单变压器（GELU-1L 和 GELU-2L）用于计算某些特定特征的机制，并验证它与因果方法的结果一致。&lt;/p&gt;&lt;h1&gt;介绍&lt;/h1&gt;&lt;p&gt;机械可解释性的核心目标是解决维度灾难，将神经网络的高维激活和参数分解为单独可理解的部分。&lt;a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html"&gt;稀疏自动编码器（SAE）&lt;/a&gt;是最近一项令人兴奋的发展，它使我们能够采用高维激活（可能处于叠加状态）并将它们分解为激活空间中代表（大部分）独立概念的有意义的方向。&lt;/p&gt;&lt;p&gt;当应用于 MLP 激活/输出时，SAE 的一个主要限制是很难研究如何根据早期模型组件的输出计算特征。有了有意义的神经元，我们可以直接查看它与早期组件的连接/&lt;a href="https://transformer-circuits.pub/2021/framework/index.html#residual-comms"&gt;虚拟权重&lt;/a&gt;——例如&lt;a href="https://distill.pub/2020/circuits/zoom-in/"&gt;，视觉模型中的汽车神经元是由车窗、车身和车轮神经元构建的&lt;/a&gt;——但 SAE 特征通常密集在神经元基础。这意味着，为了理解特征是如何计算的，我们需要理解数千个神经元激活的复杂非线性函数。维度的诅咒依然存在！&lt;/p&gt;&lt;p&gt;在这篇文章中，我们提出了一种技术来探索如何从前面的模型组件计算神经元密集的 SAE 特征。这种方法涉及采用 MLP 子层的导数，以获得 SAE 特征的局部线性逼近——这种技术在先前的工作（例如&lt;a href="https://www.neelnanda.io/mechanistic-interpretability/attribution-patching"&gt;属性修补）&lt;/a&gt;中已经取得了一些成功。重要的是，我们的方法更进一步，将这种线性近似与模型权重本身结合起来，以获得模型行为的&lt;i&gt;全局&lt;/i&gt;图像，而不是局限于特定的输入示例&lt;span class="footnote-reference" id="fnref5ns12vjb0f8"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn5ns12vjb0f8"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。最终结果是一种获取有关模型如何计算 SAE 特征的独立于输入的信息的有效方法。&lt;/p&gt;&lt;p&gt;我们证明这种方法为一系列案例研究提供了有用的见解，使我们能够将特征逆向工程回到原始的令牌嵌入，并与因果干预的结果一致。我们研究这种近似的准确性和原则性。尽管它最终只是一个近似值，并且有时可能会崩溃，但我们相信这是一个有用的工具，可以让您更好地理解 SAE 特征的计算方式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;免责声明&lt;/strong&gt;：这是非常初步的工作！我们认为这些结果都相当具有探索性；这篇文章并不试图对我们如何准确地理解这些 SAE 特征以及计算它们的机制做出强有力的声明。但我们希望我们的结果是有趣的，它们可以让其他人在它们的基础上进行构建，并且它们可能有助于为思考 SAE 提供更好的直觉。&lt;/p&gt;&lt;p&gt;这篇文章代表了我们作为 Neel Nanda 的 MATS 5.0 计划的一部分的两周冲刺的成果，我们将在该计划的其余部分继续以此为基础。如果您想以这些想法为基础，请联系我们！ （请随时在 LessWrong 上给我们留言，或者如果您愿意，请发送电子邮件至&lt;a href="mailto:jacob.dunefsky@yale.edu"&gt;jacob.dunefsky@yale.edu&lt;/a&gt; ）&lt;/p&gt;&lt;h2&gt;为什么这很重要？&lt;/h2&gt;&lt;p&gt;我们认为这是一个需要解决的重要问题，原因有很多：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;对 SAE 功能进行逆向工程使我们能够更有效地解释它们。&lt;/strong&gt;特别是，这样做可以揭示其他方法可能遗漏&lt;i&gt;的意外行为&lt;/i&gt;。例如，在我们的一个案例研究中，我们发现一个功能最初似乎只在令牌&lt;code&gt;(&amp;#39;&lt;/code&gt;上激活；然而，在应用逆向工程之后，我们发现该功能也在令牌&lt;code&gt;ह&lt;/code&gt; （&lt;a href="https://en.wiktionary.org/wiki/%E0%A4%B9"&gt;一个印地语字符）&lt;/a&gt;上激活我们对 SAE 功能理解上的差距限制了它们在预测和分析不安全或不需要的模型行为方面的效用，因此逆向工程对于帮助我们识别这些差距非常重要。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;对 SAE 特征进行逆向工程可能会揭示模型的新故障模式。&lt;/strong&gt;通过了解计算给定特征的算法，我们也许能够更好地理解导致模型表现出不良行为的原因。例如，如果我们可以在模型中找到重要的下游特征（例如候选人是否会在工作中表现良好）并将其追溯到输入的受保护特征（例如种族或性别），那么我们可以使用它来了解模型计算中的固有偏差。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;对 SAE 特征进行逆向工程可以帮助我们更好地提出关于特征通用性的理论主张。&lt;/strong&gt;例如，人们有兴趣了解不同的模型是否学习通用特征。 SAE 可以通过在不同模型的激活上训练 SAE 并比较它们学到的特征来解决这个问题（请参阅&lt;a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html#phenomenology-universality"&gt;Anthropic 的 SAE 论文中的“通用性”讨论&lt;/a&gt;）。由于逆向工程揭示了计算 SAE 特征的机制，因此它可以为评估通用性提供补充视角，让我们测试 SAE 是否不仅有助于学习通用特征，还有助于学习通用机制。它还可以帮助我们捕捉虚幻的“普遍性”，即特征表面上相似，但通过不同的机制计算，并在适当的情况下分开&lt;span class="footnote-reference" id="fnrefa1rxph5d74"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fna1rxph5d74"&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;对 SAE 功能进行逆向工程对于获得有关 SAE 一般功能和局限性的各种见解非常有用。&lt;/strong&gt;例如，在一个 2 层 Transformer 的实验中，我们使用我们的方法用第 0 层 SAE 特征来表达第 1 层 SAE 特征；我们发现第 0 层特征和第 1 层特征之间的连接很密集，这表明当前训练的 SAE 不容易产生有关同一模型不同层的特征如何相互关联的稀疏信息。这表明要么内部模型连接确实不稀疏，要么我们的 SAE 训练方法存在局限性，这两者都是有用的见解！我们预计，只有深入研究这些模型的内部结构以及它们如何组合在一起，我们才能发现有关模型和 SAE 的许多其他见解。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;如果没有逆向工程，SAE 功能就是一个不完整的故事。&lt;/strong&gt;仅在纯粹的美学层面上，我们发现对产生这些特征的计算一无所知是令人不满意的。&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;概述&lt;/h1&gt;&lt;p&gt;本文的其余部分分为以下部分：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;我们对用于进行逆向工程的方法进行了高级概述。&lt;/strong&gt;我们建议阅读本节，因为它为理解我们的案例研究中发生的情况提供了有用的背景。对明确的数学细节感兴趣的读者可能有兴趣阅读详细阐述此方法的附录部分。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;我们提供了许多案例研究，其中我们对特定的 SAE 功能进行了逆向工程。&lt;/strong&gt;这是我们文章的重点，我们希望大多数读者能够从中获得最大收益（尽管我们不希望所有读者都阅读所有案例研究）。这是一个很长的部分，我们在这里确实进行了非常深入的细节，但我们认为它可以帮助读者理解这些特征的计算方式以及逆向工程过程的总体工作原理。以下案例研究摘要可能会帮助您决定要进一步了解哪些案例：&lt;ul&gt;&lt;li&gt; GELU-1L 中的一项功能的案例研究，该功能主要在令牌上触发&lt;code&gt;(&amp;#39;&lt;/code&gt; .&lt;ul&gt;&lt;li&gt;在本案例研究中，我们使用逆向工程来揭示看似单义的特征有时会在不相关的标记上触发，例如&lt;code&gt;ह&lt;/code&gt; ，这是使用这种方法构建对抗性提示的概念验证，以及如何使用这种方法的示例了解意外行为。&lt;/li&gt;&lt;li&gt;我们还发现注意力头 0 和 3 通过触发指示代码相关或列表相关上下文的标记来贡献该功能。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt; GELU-1L 中一个特征的案例研究，当前面有标点符号时，该特征往往会触发二元词“it is”。&lt;ul&gt;&lt;li&gt;在此案例研究中，我们发现直接路径通过触发令牌来贡献该特征，这&lt;code&gt;is&lt;/code&gt;预期的那样，并且注意力头 0 触发了前面的&lt;code&gt;It&lt;/code&gt;令牌。这使我们能够理解计算二元特征的主题。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt; GELU-1L 中倾向于在令牌&lt;code&gt;&amp;#39;t&lt;/code&gt;上触发的功能的案例研究。&lt;ul&gt;&lt;li&gt;在这个案例研究中，我们发现直接路径非常容易解释。线性化表明注意力是无关紧要的，但更可靠的重采样消融因果干预表明它确实很重要，这表明线性化在这里具有误导性。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt; GELU-1L 中倾向于在代币上引发的功能的案例研究&lt;code&gt;is&lt;/code&gt;在神学/政治背景下进行的。&lt;ul&gt;&lt;li&gt;在这个案例研究中，我们研究了模型如何主要通过单个可解释的注意力头来计算上下文相关的特征。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt; GELU-2L 中某个功能的案例研究，该功能往往会在&lt;code&gt;{&amp;#39;name&amp;#39;: &amp;#39;&lt;/code&gt;等字符串上触发。&lt;ul&gt;&lt;li&gt;在本案例研究中，我们在两层模型中执行逆向工程，包括查看第 1 层 SAE 特征和第 0 层 SAE 特征之间的连接。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;我们更深入地讨论 MLP 线性化，提供实验结果，以便开始了解这种方法在哪里有效以及在哪里失败。&lt;/strong&gt;大多数读者可能会跳过本节，尽管对 Transformer 或该方法的有效性有更多理论兴趣的读者可能会从阅读中有所收获。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;与路径修补等因果方法相比，我们讨论了我们的方法的优点和缺点。&lt;/strong&gt;我们建议阅读本简短的部分，以便了解我们的方法与更广泛的机械可解释性方法的契合点。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;我们从整体上反思该方法及其优点和局限性。&lt;/strong&gt;我们建议您阅读本简短的部分，以校准您对该方法的用处以及未来的方向可能会是什么样子的想法。&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;我们的方法&lt;/h1&gt;&lt;p&gt;在本节中，我们将简要介绍我们的 SAE 功能逆向工程方法。如需更详细的解释，感兴趣的读者应该查看“附录：我们方法的详细信息”部分。&lt;/p&gt;&lt;p&gt;我们应用并扩展了&lt;a href="https://www.lesswrong.com/posts/jDfjqu2qJLcPco9cf/automatically-finding-feature-vectors-in-the-ov-circuits-of"&gt;这篇文章&lt;/a&gt;和&lt;a href="https://arxiv.org/abs/2312.16291"&gt;本文&lt;/a&gt;中描述的方法，以实现逆向工程 SAE 功能。我们将首先了解它在 1 层变压器中的工作原理，然后了解如何扩展它。&lt;/p&gt;&lt;h2&gt;线性化：将 MLP 特征引入残差流&lt;/h2&gt;&lt;p&gt;计算 SAE 特征需要什么？回想一下，模型的残差流是所有先前模型组件的输出之和。这意味着，如果该特征是残差流的线性函数（即，该特征是通过将线性流投影到给定特征向量上来计算的），那么我们可以应用&lt;a href="https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=disz2gTx-jooAcR0a5r8e7LZ"&gt;直接特征归因等&lt;/a&gt;技术来了解每个模型组件如何贡献该功能。&lt;/p&gt;&lt;p&gt;不幸的是，对于在 MLP 输出激活上训练的 SAE，特征在 MLP 输出空间而不是残余流中“实时”。因此，在进行任何进一步的分析之前，我们必须通过MLP拉回SAE特征向量，以获得残差流中与原始MLP输出特征向量相对应的特征向量。&lt;/p&gt;&lt;p&gt;如果 MLP 是线性的，那么这可以完全完成——但是 MLP 不是线性的！它们是由许多神经元组成的复杂非线性函数，并且大多数 SAE 特征都是密集的，这意味着我们需要了解每个神经元才能理解 SAE 特征。然而，&lt;strong&gt;我们可以通过获取 MLP 的梯度 来获得 MLP 的局部线性近似&lt;/strong&gt;。这使我们能够找到近似对应于 MLP 后特征向量的残差流特征向量。具体来说，我们在特定提示中的特定标记上，对输入到 MLP 层的残差流求 SAE 特征（ReLU 前）的导数。&lt;/p&gt;&lt;p&gt;请注意，这是一种基于激活的技术，而不是基于权重的技术；换句话说，获得的特征向量取决于特定的MLP激活，不同的输入会产生不同的线性化特征向量。我们稍后研究这些特征向量的一致性及其准确性。&lt;/p&gt;&lt;h3&gt;技术旁白：冻结 LayerNorm&lt;/h3&gt;&lt;p&gt;请注意，MLP 子层（与 Transformer 中的所有子层一样）前面有 LayerNorm，它由线性变换、非线性归一化操作和线性变换组成。人们可以通过采用 LayerNorm 的梯度以及 MLP 来解释这种非线性，但由于稍后讨论的原因，这并不总是能产生良好的结果。因此，有时需要通过忽略非线性并仅考虑线性变换来&lt;strong&gt;冻结&lt;/strong&gt;LayerNorms。 （这意味着，当我们将冻结的 LayerNorm 应用于残差流时，我们仍然将残差流除以估计残差流标准差的值——但是现在，我们将该值视为常数，而不是另一个函数的残余流。）&lt;/p&gt;&lt;h2&gt;术语说明：直接得分归因&lt;/h2&gt;&lt;p&gt;&lt;a href="https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=disz2gTx-jooAcR0a5r8e7LZ"&gt;直接 Logit 归因&lt;/a&gt;是一种众所周知的技术，用于了解模型组件对模型 Logit 的贡献。现在我们有了残差流特征向量，我们也可以应用它来了解模型组件对 SAE 特征得分的贡献。由于在查看 SAE 特征得分时谈论“logits”是没有意义的，因此我们在整篇文章中将 SAE 特征的直接 logit 归因称为&lt;strong&gt;直接得分归因&lt;/strong&gt;。核心思想是相同的：将残差流分解为分量之和，将每个分量与特征向量进行点积，看看哪些分量是重要的。&lt;/p&gt;&lt;h2&gt;直接路径和去嵌入&lt;/h2&gt;&lt;p&gt;现在我们有了残差流特征向量，我们可以用它来理解原始标记嵌入如何促进 SAE 特征激活。遵循&lt;a href="https://transformer-circuits.pub/2021/framework/index.html"&gt;Elhage 等人的&lt;/a&gt;观点，我们将这条从原始 token 嵌入到 SAE 特征的路径称为&lt;strong&gt;直接路径&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;解释直接路径的一种方法是使用一种我们称为&lt;strong&gt;“去嵌入”&lt;/strong&gt;的技术。去嵌入的思想是获取残差流特征向量，并与模型的输入嵌入矩阵中的每个向量取点积；这会在模型的词汇空间中产生一个特征向量。该向量中每个令牌的系数提供了该令牌通过直接路径对 SAE 功能贡献程度的近似值。&lt;i&gt;重要的是，我们可以查看该向量中系数最高的标记，以便了解模型词汇表中的哪些标记对于直接路径最重要。&lt;/i&gt;&lt;/p&gt;&lt;h2&gt;注意力&lt;/h2&gt;&lt;h3&gt;OV电路和QK电路分析&lt;/h3&gt;&lt;p&gt;我们还可以使用残差流特征向量来了解不同的注意力头如何对 SAE 特征激活做出贡献。回想一下，注意力头的功能可以分解为计算注意力分数的 QK 电路和转换 token 信息的 OV 电路。尽管注意力头是残差流的非线性函数，但如果我们孤立地看待 OV 电路，那么注意力输出只是每个注意力头和每个 token 的线性变换的加权和。&lt;/p&gt;&lt;p&gt;因此，我们可以通过 OV 矩阵拉回残余流特征向量来了解给定头的 OV 电路如何对 SAE 特征做出贡献。&lt;i&gt;请注意，完成此操作后，我们可以应用去嵌入等技术来了解模型词汇表中的哪些标记通过该注意头的 OV 电路对 SAE 功能贡献最大。&lt;/i&gt;换句话说，我们可以确定哪些令牌&lt;i&gt;如果&lt;/i&gt;受到该头的关注，最能激活该功能。然后可以通过查看哪些令牌具有最高的 QK 分数以及对 OV 电路很重要的令牌来单独分析 QK 电路。&lt;/p&gt;&lt;h3&gt; （头、源标记）对的直接分数归因&lt;/h3&gt;&lt;p&gt;我们在案例研究中经常使用的一种工具是对关注中的个体（头、源标记）对进行直接评分归因。我们可以这样做，因为注意力头的输出是每个源令牌贡献的加权和。这使我们能够了解每个源令牌通过每个注意力头对 SAE 功能的贡献有多大。&lt;/p&gt;&lt;h2&gt;多层模型&lt;/h2&gt;&lt;h3&gt;计算路径&lt;/h3&gt;&lt;p&gt;在多层变压器中，事情变得更加复杂。这是因为从输入到 SAE 特征的可能计算路径集随着层数的增加（呈指数级）增加。两层模型中的不同路径可能包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;令牌嵌入 → MLP1（直接路径）&lt;/li&gt;&lt;li&gt;令牌嵌入 → MLP0 → 注意力 1 head 5 → MLP1&lt;/li&gt;&lt;li&gt;令牌嵌入 → 注意力 0 头 3 → MLP0 → MLP1&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;然而，总体原理是相同的：通过路径中的每个组件不断拉回特征向量。&lt;/p&gt;&lt;p&gt;请注意，某些计算路径可能涉及&lt;i&gt;多个非线性&lt;/i&gt;，例如两个不同的 MLP 子层。在这种情况下，我们分别对每个非线性进行线性化。计算路径中存在的非线性越多，我们期望的近似误差就越大，但这仍然可以产生有用的结果。另一种选择是查看计算路径，而不是一直返回到原始标记嵌入，而是仅返回到前一层的 MLP。现在我们将看到这如何允许我们解释先前 MLP 中各个 SAE 特征的路径。&lt;/p&gt;&lt;h3&gt; SAE 虚拟重量&lt;/h3&gt;&lt;p&gt;多层模型中可用的一种有用的基于权重的技术是&lt;i&gt;能够根据前一层 SAE 特征在给定层编写 SAE 特征&lt;/i&gt;。我们将此称为查看&lt;strong&gt;SAE 虚拟权重&lt;/strong&gt;。为此，需要获取后续 SAE 特征的残差流特征向量，并通过前一层 SAE 的解码器矩阵将其拉回。就像去嵌入一样​​，作为此过程的结果，您将获得一个向量，该向量告诉您前一层 SAE 特征与后一层 SAE 特征的对应程度。&lt;/p&gt;&lt;h2&gt;其他标准特征解释技术&lt;/h2&gt;&lt;p&gt;除了尝试对特征的计算方式进行逆向工程之外，我们还遵循 Anthropic 的方法通过研究最大/均匀激活示例以及研究每个特征对模型词汇表中每个标记的 logits 的影响来理解这些特征。&lt;/p&gt;&lt;h3&gt;最大/均匀激活示例&lt;/h3&gt;&lt;p&gt;获得 SAE 功能的初步解释的一种方法是查看数据集中的哪些示例最能激活该功能。然而，按照&lt;a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html#setup-interface"&gt;Anthropic 的方法&lt;/a&gt;，在整个特征激活分数范围内采样示例有时也是有用的，以便更广泛地了解特征所代表的含义。在这种情况下，我们找到特征分数均匀分布的样本（尽可能）。例如，如果某个特征在某个数据集上被激活在 0.0 到 10.0 之间，并且我们想要查看 10 个均匀间隔的示例，那么我们将尝试找到一个特征得分为 1.0 的示例，一个具有某个特征的示例分数为2.0等&lt;/p&gt;&lt;h3&gt;Logit 权重&lt;/h3&gt;&lt;p&gt;Anthropic 使用的另一种方法是检查 SAE 特征对模型词汇表中每个标记的 logits 的影响。直观上，这让我们了解模型期望哪些令牌遵循高度激活该功能的令牌。其原理类似于 Logit 透镜：通过获取 SAE 特征的解码器向量并将其乘以模型的非嵌入矩阵，然后查看模型词汇表中在结果向量中得分最高的标记来完成此操作。有时，这可以让我们初步了解模型如何使用该特征，但情况并非总是如此；因此，将我们通过查看 logit 权重获得的理解与通过执行逆向工程获得的理解进行比较是有用的。&lt;/p&gt;&lt;h1&gt;实例探究&lt;/h1&gt;&lt;h2&gt;实验装置&lt;/h2&gt;&lt;p&gt;我们研究的两个模型来自 Neel Nanda 的 ToyLM 系列，特别是&lt;a href="https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=U-XWl8ddNkvId7o4ElrpehQ0"&gt;GELU-1L 和 GELU-2L 模型&lt;/a&gt;，（顾名思义）它们分别是 1 层和 2 层模型。前四个案例研究针对 GELU-1L，最后一个案例研究针对 GELU-2L。这些模型“在 22B 个数据标记上进行训练，其中 80% 来自 C4（网络文本），20% 来自 Python 代码”；他们的模型维度&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;m&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;o&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;e&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;l&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是 512，他们的 MLP 维度&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;m&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;l&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;p&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是 1,024，他们每个注意力子层有 8 个注意力头，他们的词汇表包含 48,262 个标记。&lt;/p&gt;&lt;p&gt;当我们使用数据集（例如查看最大激活示例）时，我们使用&lt;a href="https://NeelNanda/c4-code-20k"&gt;c4-code-20k&lt;/a&gt;中的 1,638,400 个标记，其中包含与训练模型的数据集相同的数据分布。该语料库分为每个提示 128 个标记。&lt;/p&gt;&lt;p&gt;我们针对 GELU-1L 调查的 SAE 可&lt;a href="https://huggingface.co/NeelNanda/sparse_autoencoder"&gt;通过此链接&lt;/a&gt;作为&lt;a href="https://huggingface.co/NeelNanda/sparse_autoencoder"&gt;SAE&lt;/a&gt; &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;#&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 25 获得，这是单个 SAE 训练运行的最终检查点，由 Neel Nanda 在 GELU-1L 激活上进行训练。我们针对 GELU-2L 调查的 SAE 可&lt;a href="https://huggingface.co/NeelNanda/sparse_autoencoder"&gt;通过此链接作为前缀为“gelu-2l”的 SAE&lt;/a&gt;获得。所有 SAE 都有 16,384 个功能。 GELU-1L SAE 在模型的&lt;code&gt;mlp_post&lt;/code&gt;激活（维度 1,024）上进行训练，而 GELU-2L SAE 在模型的&lt;code&gt;mlp_output&lt;/code&gt;激活（维度 512）上进行训练。您可以&lt;a href="https://colab.research.google.com/drive/1u8larhpxy8w4mMsJiSBddNOzFGj7_RTn#scrollTo=riilpvs-CgoQ"&gt;在此处找到使用这些 SAE 的代码。&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;关于研究特征的选择&lt;/h2&gt;&lt;p&gt;案例研究所涉及的特征是以相对无原则的方式选择的，很大程度上是基于我们认为研究有趣的内容。指导我们选择的是特征审核，其目的是通过计算特征标记对的 F1 分数来确定所有特征表现出上下文依赖性的程度。选择每个功能的原因如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;选择&lt;code&gt;(&amp;#39;&lt;/code&gt;特征是因为它是最早的高频特征之一（按特征索引排序，没有内在含义）。&lt;/li&gt;&lt;li&gt;选择&lt;code&gt;it is&lt;/code&gt;功能是因为功能审核表明它主要在单个令牌上激活，并且仅在非常有限的上下文中激活，因此我们认为进一步研究这一点会很酷。&lt;/li&gt;&lt;li&gt;选择&lt;code&gt;&amp;#39;t&lt;/code&gt;功能是因为功能审核表明该功能在单个令牌上以及几乎所有出现此令牌的情况下都被高度激活。因此，我们想要研究这个看似与上下文无关的功能。&lt;/li&gt;&lt;li&gt; “神学/政治背景下的‘是’”特征很大程度上是随机选择的。&lt;/li&gt;&lt;li&gt;选择 GELU-2L 特征是因为它是最早的高频特征之一。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;请注意，一旦我们开始案例研究，我们就不会放弃它。因此，您看到的结果考虑了我们调查的所有功能。&lt;/p&gt;&lt;h2&gt; A &lt;code&gt;(&amp;#39;&lt;/code&gt; GELU-1L 中的功能&lt;/h2&gt;&lt;h3&gt;最大激活示例&lt;/h3&gt;&lt;p&gt;我们要研究的第一个功能是 GELU-1L SAE 中的功能 8。查看顶部激活示例可以立即解释此功能：主要在令牌&lt;code&gt;(&amp;#39;&lt;/code&gt; . &lt;/p&gt;&lt;figure class="image image_resized" style="width: 76.43%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/cg14g3ktiocvo6wibwrh" /&gt;&lt;figcaption&gt;相关 SAE 功能的热门激活示例。有趣的是，大多数这些顶级激活令牌似乎都后面跟着相同的“django”令牌，即使模型看不到下一个令牌。请注意，↩ 表示换行符，· 表示空格&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Logit 权重&lt;/h3&gt;&lt;p&gt;这个 SAE 功能最有力地提升了&lt;code&gt;django&lt;/code&gt;代币的 logits，这反映了我们在顶级激活示例中看到的情况。它还提高了其他与代码相关的标记的 logits，例如&lt;code&gt;&amp;lt;&lt;/code&gt;和&lt;code&gt;utf&lt;/code&gt; 。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 19.85%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/mjd51l7bp6g7xxexrpvw" /&gt;&lt;figcaption&gt;此功能具有最高 Logit 权重的令牌&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;直接路径和意外发现&lt;/h3&gt;&lt;p&gt;现在，我们执行“去嵌入”，以便了解哪些令牌通过直接路径对此功能贡献最大。具体来说：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们通过 MLP0 区分该 SAE 功能在特定高激活示例上的激活。这给了我们残差流&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;中&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;长度&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;为&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;model&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;特征向量&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。&lt;/li&gt;&lt;li&gt;我们将此特征向量乘以嵌入矩阵，以查看哪些标记可以通过直接路径激活它，即查看长度为&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;o&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;c&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的向量&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。自然地，我们预测&lt;code&gt;(&amp;#39;&lt;/code&gt;会得分很高。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;结果如下： &lt;/p&gt;&lt;figure class="image image_resized" style="width: 44.02%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/tjrongai1hr8kq5ix77s" /&gt;&lt;figcaption&gt;去嵌入标记分数以获得线性化 SAE 特征的直接路径&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;果然，顶部的标记是我们在顶部激活示例中看到的&lt;code&gt;(&amp;#39;&lt;/code&gt;标记。但是还有一些其他意想不到的标记，例如标记&lt;code&gt;ह&lt;/code&gt; 。这让我们感到惊讶；为了了解这是否是一个由于我们方法中的错误，我们在包含此标记的对抗性提示上运行模型，并记录每个标记的原始特征激活（不考虑 SAE 偏差或 ReLU）： &lt;/p&gt;&lt;figure class="image image_resized" style="width: 30.95%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/h1nqcwu5y2kc0jjpk38m" /&gt;&lt;figcaption&gt;对抗性提示的 SAE 原始特征评分&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;正如我们所看到的， &lt;i&gt;SAE 功能实际上确实在此令牌上激活&lt;/i&gt;，尽管其程度与在&lt;code&gt;(&amp;#39;&lt;/code&gt;令牌上激活的程度不同。这对我们来说是令人惊讶和兴奋的，因为这从标准方法中根本不明显查看顶级激活示例。我们认为这是我们方法的令人兴奋的概念证明，帮助我们构建 SAE 特征的对抗性示例！ &lt;span class="footnote-reference" id="fnref36xy0nowkoe"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn36xy0nowkoe"&gt;[3]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;注意力&lt;/h3&gt;&lt;p&gt;对注意力头进行直接评分归因似乎表明头 0 和 3 很重要。在下面的示例中，我们看到 head 0 通过&lt;code&gt;&amp;#39;:&lt;/code&gt;标记和&lt;code&gt;(&amp;#39;&lt;/code&gt;标记贡献了该功能。Head 3 通过右括号标记&lt;code&gt;&amp;quot;}),&lt;/code&gt;贡献了该功能。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 80.02%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/evdzdjejy64k8hvv3ho9" /&gt;&lt;figcaption&gt;注意力的直接评分归因&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;查看 head 0 &lt;span class="footnote-reference" id="fnref1tpfjhj7ezr"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn1tpfjhj7ezr"&gt;[4]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;的 OV 电路去嵌入表明，顶部标记往往包括各种开头字符串标记，例如&lt;code&gt;&amp;quot;&lt;/code&gt; 、 &lt;code&gt;([&amp;#39;&lt;/code&gt;和标记&lt;code&gt;(&amp;#39;&lt;/code&gt;本身，但也包括后跟空格的换行符的各种排列。有趣的是，尽管标记&lt;code&gt;&amp;#39;&lt;/code&gt;的去嵌入分数很高，但上面的直接分数归因示例表明该标记对特征激活贡献不大。这似乎是因为头 0 对该标记的关注程度不高。事实上，来自 token &lt;code&gt;(&amp;#39;&lt;/code&gt; to the token &lt;code&gt;&amp;#39;&lt;/code&gt;的 pre-softmax 注意力得分为 51.15，小于来自 token &lt;code&gt;(&amp;#39;&lt;/code&gt; to the token &lt;code&gt;&amp;#39;:&lt;/code&gt;的 softmax 之前的注意力得分 63.86)。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 36.41%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/ogt3x7bfvfln4mpnaxeg" /&gt;&lt;figcaption&gt;模型词汇表中头 0 的 OV 电路去嵌入得分最高的标记&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;头 3 的 OV 电路去嵌入中的顶部标记中有许多右大括号标记，例如&lt;code&gt;})&lt;/code&gt; 、 &lt;code&gt;)})&lt;/code&gt;和&lt;code&gt;&amp;#39;)&lt;/code&gt; 。这表明，除了初始空白标记（正如我们在直接得分归因结果中看到的那样）之外，头 3 还通过这些右大括号标记对 SAE 功能做出了贡献。然而，使这张图片稍微复杂化的是，去嵌入中的顶部标记是不相关的标记&lt;code&gt;Illustration&lt;/code&gt; ，在测试一些初始对抗性提示时，它似乎对特征分数没有影响。我们后来对线性化的探索表明，像这样的 token 的存在可能是线性逼近 MLP 的产物。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 28.23%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/tnya7vpo5ch3jynxwien" /&gt;&lt;figcaption&gt;头 3 的 OV 电路的最佳去嵌入结果。&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;概括&lt;/h3&gt;&lt;p&gt;我们的逆向工程和去嵌入，结合通过查看最大激活示例获得的证据，表明该功能具有以下解释：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;该功能主要在代码上下文中的标记&lt;code&gt;(&amp;#39;&lt;/code&gt;上触发，特别是在涉及包含字符串的列表或元组的上下文中。&lt;ul&gt;&lt;li&gt;该功能的直接路径在&lt;code&gt;(&amp;#39;&lt;/code&gt; .&lt;/li&gt;&lt;li&gt;头 0 和头 3 通过触发初始空白标记来建立代码上下文。&lt;/li&gt;&lt;li&gt; Head 0 通过触发表示此类列表和元组开头的标记（例如标记&lt;code&gt;[&amp;quot;&lt;/code&gt; ）来建立涉及包含字符串的列表和元组的上下文。Head 3 通过触发右大括号标记（例如&lt;code&gt;})&lt;/code&gt; , &lt;code&gt;)})&lt;/code&gt;来建立此上下文， 和&lt;code&gt;&amp;#39;)&lt;/code&gt; 。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;但该功能也会在代币&lt;code&gt;ह&lt;/code&gt;上触发，尽管没有那么强烈！&lt;ul&gt;&lt;li&gt;这是在查看此功能的直接路径去嵌入后得出的意外发现。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;仍然存在一些悬而未决的问题，以及一些难以解释的结果。尤其：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; Head 3 OV 去嵌入的最重要标记是&lt;code&gt;Illustration&lt;/code&gt; ，它似乎对对抗性提示中的 SAE 功能没有贡献。这是该方法的缺点，还是在某些上下文中该令牌确实对该功能有所贡献？&lt;/li&gt;&lt;li&gt;在本案例研究中，我们没有研究 QK 电路。这是否可以揭示更复杂的行为，或者可以解释&lt;code&gt;Illustration&lt;/code&gt;令牌发生了什么？&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt; GELU-1L 中“[标点符号] it is”的功能&lt;/h2&gt;&lt;p&gt;这是我们正在研究的 SAE 中的功能 4542。&lt;/p&gt;&lt;h3&gt;最大激活示例&lt;/h3&gt;&lt;p&gt;当标记&lt;code&gt;it&lt;/code&gt; （或其大写变体）前面有标记时，此功能&lt;code&gt;is&lt;/code&gt;会在标记上最大程度地激活，并且标记&lt;code&gt;it&lt;/code&gt;前面通常带有标点符号。&lt;/p&gt;&lt;h3&gt; Logit 权重&lt;/h3&gt;&lt;p&gt;查看 SAE 功能的 logit 权重，该功能最能提高标记&lt;code&gt;advis&lt;/code&gt; 、 &lt;code&gt;advised&lt;/code&gt; 、 &lt;code&gt;conceivable&lt;/code&gt; 、 &lt;code&gt;recommended&lt;/code&gt;和类似标记的 logit ——所有这些标记都倾向于用在“It is”之后的非人称结构中，例如作为“建议......” &lt;/p&gt;&lt;figure class="image image_resized" style="width: 26.98%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/o0mvbdliwhsfmr6fhvqj" /&gt;&lt;figcaption&gt;此功能具有最高 Logit 权重的令牌&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;直接路径&lt;/h3&gt;&lt;p&gt;在直接路径去嵌入中，当不考虑预MLP LayerNorm时，该特征的顶部标记是标记&lt;code&gt;is&lt;/code&gt; 。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 28.36%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/hb9vnjiftl3i7kyzyirj" /&gt;&lt;figcaption&gt;直接路径去嵌入中的顶级标记，不考虑 pre-MLP LayerNorm&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;请注意，具有第二高去嵌入分数的标记&lt;code&gt;are&lt;/code&gt; ，在对抗性提示中使用时会稍微激活该功能： 提示&lt;code&gt;. It are&lt;/code&gt;导致该功能以 0.151 分触发。&lt;/p&gt;&lt;p&gt;然而，当线性化 pre-MLP LayerNorm 时，此功能的顶部标记更加难以解释（尽管&lt;code&gt;Is&lt;/code&gt;是第二高激活标记）。关于线性化的部分给出了为什么线性化预 MLP LayerNorm 可能会导致这些更糟糕的结果的潜在理论基础。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 28.69%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/zgsqi973ntbldne2pyzj" /&gt;&lt;figcaption&gt;考虑预 MLP LayerNorm 时，直接路径去嵌入中的顶级标记&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;注意力&lt;/h3&gt;&lt;p&gt;对注意力进行直接评分归因表明，头 0 以及较小程度上的头 1 通过触发“it”等标记来对该特征做出贡献。我们还看到 head 1 在某种程度上对标点符号进行触发，尽管远低于最初的最大激活示例可能暗示的情况。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 81.7%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/jh67o1jlpwx3nwwj53pg" /&gt;&lt;figcaption&gt;注意力头/标记对的直接得分归因&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;对头 0 的 OV 电路执行去嵌入，毫无疑问，揭示了前三个标记是“it”的变体。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 29.01%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/uhmbhm7tiqz41onlexw5" /&gt;&lt;figcaption&gt;注意头 0 OV 电路去嵌入顶部令牌&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;然而，头 1 的去嵌入顶部标记更令人费解：所有前 20 个标记都很难解释，并且似乎与该特征无关，例如&lt;code&gt;stitial&lt;/code&gt; 、 &lt;code&gt;undes&lt;/code&gt;和&lt;code&gt;consc&lt;/code&gt; 。有趣的是，这些令牌似乎可以用于构建激活该功能的对抗提示。例如，提示“然后是”使该功能以1.390的分数触发，但是对抗性提示”是“ stitial”是“导致功能以分数为1.521发射，而对抗性提示则是“ undes”，它使功能是“使功能”使该功能降低。得分为1.626。 （请注意，提示“是”使该功能以1.733的分数触发，高于这些对抗性提示。）&lt;/p&gt;&lt;p&gt;同样令人惊讶的是，我们在令牌中没有看到任何标点令牌，因为头部1-令牌是最高的&lt;code&gt;.&lt;/code&gt;例如，仅是第9077位得分最高的令牌。尽管这个令牌提高了特征分数：提示&lt;code&gt;. It is&lt;/code&gt;由于该功能以分数1.903激活的功能，而提示&lt;code&gt;It is&lt;/code&gt;导致该功能以分数1.820激活。&lt;/p&gt;&lt;h3&gt;概括&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;该功能似乎在令牌上激活的&lt;code&gt;is&lt;/code&gt;在像&lt;code&gt;It&lt;/code&gt;和&lt;code&gt;it&lt;/code&gt; &lt;code&gt;it&lt;/code&gt;的代币之前。&lt;ul&gt;&lt;li&gt;在没有线性化前MLP分层的情况下获得的直接路径去除膜显示出很高的&lt;code&gt;is&lt;/code&gt;分数。但是，当我们将前MLP分层线性化时，这会产生更多无法解释的令牌。这反映了我们稍后讨论的与线性分层相关的某些行为。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt; Head 0通过像&lt;code&gt;it&lt;/code&gt; &lt;code&gt;It&lt;/code&gt;向代币射击来为功能做出贡献。肯定的， &lt;code&gt;It&lt;/code&gt; ， &lt;code&gt;it&lt;/code&gt;和&lt;code&gt;It&lt;/code&gt;是拆卸中的顶级令牌。&lt;/li&gt;&lt;li&gt;直接分数归因表明，Head 1通过在标点令牌上稍微触发来促进该功能。但是，这并不反映在头1的拆卸中，这是完全无法解释的。更深入的调查可能会阐明标点符号正在发生的事情。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt; gelu-1l中的&lt;code&gt;&amp;#39;t&lt;/code&gt;功能&lt;/h2&gt;&lt;p&gt;这是我们正在研究的S​​AE中的功能编号10996。&lt;/p&gt;&lt;h3&gt;统一的激活示例&lt;/h3&gt;&lt;p&gt;查看此功能激活的示例，似乎此功能主要在诸如“ not”，“ not”，“ not”之类的单词的末尾激活在&lt;code&gt;&amp;#39;t&lt;/code&gt;上，并且类似&lt;span class="footnote-reference" id="fnref2belxv37guh"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn2belxv37guh"&gt;[5 ]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。在较低的激活水平下，此功能还会在诸如“ dont”和“ dot”之类的拼写错误上发射。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 77.92%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/umgpxcigopmzht3jpco9" /&gt;&lt;figcaption&gt;统一激活的例子&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;logit重量&lt;/h3&gt;&lt;p&gt;此功能最强烈地增强了由标点符号组成的&lt;code&gt;s&lt;/code&gt;和令牌的逻辑，然后是引号。这并没有反映在统一的激活示例中，这表明观察该功能的计算方式（例如，通过拆卸等方法）可能比一旦计算出该功能的下游效应，可能会带来更多的果实。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 19.82%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/uzydvausyd0bz9jhc9o1" /&gt;&lt;figcaption&gt;该功能的logit权重最高的令牌&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;直接路径&lt;/h3&gt;&lt;p&gt;直接路径中得分最高的令牌为&lt;code&gt;&amp;#39;t&lt;/code&gt; 。得分很高的其他代币是上述宫缩的拼写错误，例如&lt;code&gt;wont&lt;/code&gt;和&lt;code&gt;didnt&lt;/code&gt; ，以及像&lt;code&gt;not&lt;/code&gt;和&lt;code&gt;Not&lt;/code&gt;负面因素。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 29.45%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/ubomlalnhgnqrtlb8xx9" /&gt;&lt;figcaption&gt;直接路径在模型的词汇量中删除顶级令牌&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;注意力&lt;/h3&gt;&lt;p&gt;执行直接分数归因似乎表明注意力并没有发挥太大作用。在一个例子上，除&lt;code&gt;&amp;lt;|BOS|&amp;gt;&lt;/code&gt;令牌以外的其他代币的总贡献（忽略注意力偏见）仅为0.34。 Head 1似乎在&lt;code&gt;&amp;#39;t&lt;/code&gt;代币上略有激活，看着这个头部的OV去除确实表明，在48k代币词汇中， &lt;code&gt;&amp;#39;t&lt;/code&gt;令牌”的消除得分是第35位。&lt;/p&gt;&lt;p&gt;但是，重新样本消融注意力头的输出（一种因果干预）讲述了另一个故事。在更换注意力输出的提示/令牌时，该功能通过其注意力输出发射的提示/令牌，该功能未发射该功能，并比较清洁和损坏的运行之间的SAE功能激活，激活的差异是1.1226。这表明注意力在这里做一些有用的事情，尽管我们说什么还为时过早。请注意，重塑消融结果与直接分数归因结果之间差异的一种可能性是，作为因果干预，重新样品消融融合了从MLP中忽略的非线性效应，这些效应在直接分数归因中被忽略。&lt;/p&gt;&lt;h3&gt;概括&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;该功能似乎主要在&lt;code&gt;&amp;#39;t&lt;/code&gt;代币上激活，例如“不”。直接路径隔离反映了这一点， &lt;code&gt;&amp;#39;t&lt;/code&gt;得分最高 - 尽管拼写错误的单词也&lt;code&gt;didnt&lt;/code&gt;得分很高。&lt;/li&gt;&lt;li&gt;直接得分归因表明，尽管Head 1似乎通过激活&lt;code&gt;&amp;#39;t&lt;/code&gt;令牌”而做出了一些贡献，但对此功能并不重要。但是重新样本消融以引起注意，这表明注意力确实有效。这表明线性化在这里具有误导性。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt; GELU-1L中的上下文依赖性“ IS”功能&lt;/h2&gt;&lt;p&gt;此功能是我们正在研究的S​​AE中的功能编号4958。&lt;/p&gt;&lt;h3&gt;最大激活示例&lt;/h3&gt;&lt;figure class="image image_resized" style="width: 73.2%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/od0nhmfvsdlshzec13e1" /&gt;&lt;figcaption&gt;该功能的最大激活示例&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;查看最大激活示例，该功能主要在令牌上&lt;code&gt;is&lt;/code&gt; （并且偶尔在动词“要”的其他形式上）。但是这个功能似乎更多：它似乎在涉及神学和政治的上下文中激活。因此，此功能让人联想到拟人化的SAE纸中讨论的特征，例如“在抽象代数的背景下的令牌&lt;code&gt;a&lt;/code&gt; ”。&lt;/p&gt;&lt;h3&gt; logit重量&lt;/h3&gt;&lt;p&gt;该功能最大程度地提高逻辑的令牌没有立即解释。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 24.3%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/qks7eoejz2ymyuqvvhat" /&gt;&lt;figcaption&gt;该功能的logit权重最高的令牌&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最高的代币&lt;code&gt;rael&lt;/code&gt;可能与代币结合在一起&lt;code&gt;is&lt;/code&gt;形成“以色列”，这与一些最大的激活例子中的宗教主题保持一致。 &lt;code&gt;manifested&lt;/code&gt;和&lt;code&gt;violated&lt;/code&gt;代币也暗示了圣经的含义。但是，很难看到&lt;code&gt;aroused&lt;/code&gt;和&lt;code&gt;assertEquals&lt;/code&gt;地方发挥作用。&lt;/p&gt;&lt;h3&gt;直接路径&lt;/h3&gt;&lt;figure class="image image_resized" style="width: 30.75%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/jpccjcqsatmoomvnutcy" /&gt;&lt;figcaption&gt;直接路径在模型的词汇量中删除顶级令牌&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;直接路径去除得分证实了最大激活示例：得分最高的令牌&lt;code&gt;is&lt;/code&gt; ，随后是动词的其他形式的“要”。&lt;/p&gt;&lt;h3&gt;注意力&lt;/h3&gt;&lt;p&gt;由于最大激活的示例表明此功能与上下文有关，因此我们希望注意力将发挥相当重要的作用。执行直接分数归因表明两个重要的注意力头：头0和头4。特别是，我们发现头部0倾向于自我介绍为&lt;code&gt;is&lt;/code&gt;代币，并在该令牌上发射，而诸如ISM等令牌上有4个Head 4点火（如&lt;code&gt;ism&lt;/code&gt; （例如用“原教旨主义”， &lt;code&gt;spirit&lt;/code&gt;甚至&lt;code&gt;Plato&lt;/code&gt;之类的词。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/a9wkhhycups1mqdnktpf" /&gt;&lt;figcaption&gt;在与柏拉图有关的示例中关注的直接分数归因&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/rcm85t951nlfytyvxvss" /&gt;&lt;figcaption&gt;在包含令牌&lt;code&gt;ism&lt;/code&gt;的示例上关注的直接分数归因&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure class="image image_resized" style="width: 89.35%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/bwyo50tif8ywl037umof" /&gt;&lt;figcaption&gt;直接分数归因于包含令牌&lt;code&gt;spirit&lt;/code&gt;的示例的关注&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;查看头部0的ov de缩放得分，顶部令牌是动词的各种形式的“要”（ &lt;code&gt;be&lt;/code&gt; ， &lt;code&gt;was&lt;/code&gt; ，， &lt;code&gt;is&lt;/code&gt; &lt;code&gt;s&lt;/code&gt;可能是clitic &lt;code&gt;&amp;#39;s&lt;/code&gt; ），又&lt;code&gt;been&lt;/code&gt; &lt;code&gt;&amp;#39;s&lt;/code&gt; ）。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 29.97%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/yiwqopwdtlub3rabgvzj" /&gt;&lt;figcaption&gt;拆卸头0 OV电路&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Head 4的OV De-ebedding分数非常有启发性：顶级令牌都是&lt;code&gt;mythology&lt;/code&gt; ， &lt;code&gt;soul&lt;/code&gt; ， &lt;code&gt;urrection&lt;/code&gt; ， &lt;code&gt;existential&lt;/code&gt; ，死亡， &lt;code&gt;Divine&lt;/code&gt; ， &lt;code&gt;psy&lt;/code&gt; ，以及类似的标记等神话，灵魂，尿道， &lt;code&gt;Death&lt;/code&gt; ，死亡，神灵。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 30.85%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/mtvh431o6bhi2nvoms8m" /&gt;&lt;figcaption&gt;拆卸4 OV电路的头部&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;概括&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;该功能似乎主要是在代币上发射的&lt;code&gt;is&lt;/code&gt;在神学和政治的背景下。&lt;/li&gt;&lt;li&gt;直接路径的动词形式为“ be”。&lt;/li&gt;&lt;li&gt;注意力0似乎在令牌&lt;code&gt;is&lt;/code&gt;强烈发射，而Head 4似乎负责合并环境。 OV De-Abedding得分进一步支持了这一点。&lt;/li&gt;&lt;li&gt;此功能运行的机制暗示了一种计算这些“在某个上下文中的令牌”特征的一般机制：主令牌上的直接路径触发，而稀疏的注意力头则负责从一个从一个令牌上触发的令牌。共享语义字段。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt; Python词典的“值”字符串中的开口撇号的Gelu-2l中的一个功能&lt;/h2&gt;&lt;p&gt;此功能 -  MLP1 SAE的功能8是我们将在GELU-2L中进行调查的第一个功能。随着更多的层的复杂性，此案例研究是对这种特征反向工程是否可以扩展到多层模型的测试。&lt;/p&gt;&lt;p&gt;特别是，由于此功能是MLP1的功能，即变压器第二层中的MLP，因此有更多有助于特征激活的计算路径。在此案例研究中，我们将研究这些计算路径。&lt;/p&gt;&lt;h3&gt;统一的激活示例&lt;/h3&gt;&lt;p&gt;查看此功能的均匀激活示例，我们看到它往往会激活（尤其是在更高的激活时）在令牌上&lt;code&gt;&amp;#39;&lt;/code&gt;在代币之前&lt;code&gt;&amp;#39;:&lt;/code&gt; 。这可以识别为撇号启动键值字典中的“值”字符串。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 70.45%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/xcuhmxq8iecp5m8doikj" /&gt;&lt;figcaption&gt;我们正在研究的MLP1 SAE功能的均匀激活示例&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;logit重量&lt;/h3&gt;&lt;p&gt;该特征最大程度地提高逻辑的令牌是&lt;code&gt;Male&lt;/code&gt;和&lt;code&gt;Female&lt;/code&gt; ，这可能是&lt;code&gt;{&amp;#39;gender: &amp;#39;Male&amp;#39;}&lt;/code&gt;字典中的值。同样，大多数顶级令牌始于大写字母。虽然有趣，但这并不能告诉我们我们正在寻找的信息。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 23.26%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/f7d9edi8dpollkmud8zf" /&gt;&lt;figcaption&gt;该功能的logit权重最高的令牌&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;直接通往MLP1的路径&lt;/h3&gt;&lt;p&gt;首先，让我们研究从输入到MLP1的直接路径。有理由期望这种直接路径可能不像输入到MLP0的路径那样解释，因为MLP1可能正在处理更高级别的抽象。 &lt;span class="footnote-reference" id="fnref0hyqmgltk21m"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn0hyqmgltk21m"&gt;[6]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;然而，值得一看的是这一直接路径是值得的，因为我们不能&lt;i&gt;确定&lt;/i&gt;这一直接路径对特征激活不负责。&lt;/p&gt;&lt;p&gt;查看具有最高拆卸得分的令牌，前十个令牌都是无法解释的令牌，例如&lt;code&gt;inex&lt;/code&gt; ， &lt;code&gt;έ&lt;/code&gt;和&lt;code&gt;immer&lt;/code&gt; 。也就是说，值得注意的是，“预期”代币&lt;code&gt;&amp;#39;&lt;/code&gt;是得分最高的标记，是超过48k代币的词汇。&lt;/p&gt;&lt;p&gt;回想一下，为了获得残留流特征向量，我们在一个特定示例上对MLP sublayer进行线性化，这意味着每个示例都会产生不同的特征向量。因为我们发现的不可解释的代币数量令我们令人惊讶，所以我们想探索这种不可解释的令牌现象的程度是我们在该特定示例中线性化MLP的特定示例的伪像。因此，我们在100个顶部激活的示例中采用了MLP1梯度的平均值，并研究了该平均特征向量。再一次，顶级令牌是无法解释的，例如&lt;code&gt;corro&lt;/code&gt; ， &lt;code&gt;deton&lt;/code&gt; &lt;code&gt;VERY&lt;/code&gt; &lt;code&gt;έ&lt;/code&gt; ，尽管现在，预期的令牌&lt;code&gt;&amp;#39;&lt;/code&gt;是分数最高的标记。&lt;/p&gt;&lt;p&gt;为了进一步衡量这些线性化特征向量的解放结果的依赖性依赖性的程度，我们查看了平均特征矢量和单个示例特征向量的最高&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;最高解放得分的令牌；然后，我们改变了&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;K&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，并查看了这些得分最高令牌的交点中令牌的比例。当&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;k&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;200&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;时，有119个令牌（即59.5％的令牌。这似乎表明了中等程度的示例依赖性。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 74.56%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/lsieldpkxyq1pd2nhq5t" /&gt;&lt;figcaption&gt;关于用单个示例获得的特征矢量与特征向量与通过在100个示例上取出平均特征向量获得的特征向量获得的特征矢量相似性的结果。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;这些结果在多大程度上准确地反映了模型的行为？&lt;/strong&gt;我们在该直接路径上进行了路径修补，从令牌&lt;code&gt;&amp;#39;&lt;/code&gt;到令牌&lt;code&gt;corro&lt;/code&gt; （即MLP1将其输入视为令牌&lt;code&gt;corro&lt;/code&gt; ，而所有其他模型组件仍然将输入令牌视为&lt;code&gt;&amp;#39;&lt;/code&gt; ）。我们发现这样做&lt;i&gt;实际上将特征激活略微增加了&lt;/i&gt;+0.1079。在这种情况下，意外结果实际上确实反映了模型的行为。但这不是其他令牌。在这些情况下，似乎线性近似过程中的错误是罪魁祸首。例如，当&lt;code&gt;VERY&lt;/code&gt;向量很小时，从&lt;code&gt;&amp;#39;&lt;/code&gt;方向上的路径弥补。但是，随着修补的激活越来越近&lt;code&gt;&amp;#39;&lt;/code&gt;并且距离越来越&lt;code&gt;VERY&lt;/code&gt; ，功能激活停止增加，然后开始减少。我们的直觉是，令牌嵌入的空间是一个离散的空间，而不是连续的空间。由于该模型永远不会在&lt;code&gt;VERY&lt;/code&gt;和&lt;code&gt;&amp;#39;&lt;/code&gt;之间的一半之间看到嵌入，因此在它们之间线性插值可能没有太多含义。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 71.55%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/fu0bit1gzzlagtwtg3h2" /&gt;&lt;figcaption&gt;路径修补结果， &lt;code&gt;VERY&lt;/code&gt;在干净的&lt;code&gt;&amp;#39;&lt;/code&gt;和肮脏的令牌之间插值。&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;从MLP0到MLP1的路径&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;MLP0 SAE功能与MLP1 SAE功能之间的连接&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;因为我们正在处理多层变压器，所以我们现在可以查看从MLP0到MLP1的路径。结果之一是，使用与拆卸相同的原理，我们可以&lt;i&gt;根据MLP0 SAE功能直接表达我们的MLP1功能&lt;/i&gt;。为此，将MLP1特征乘以MLP0 SAE解码器矩阵的转置。重要的是，这是一个纯粹基于权重的操作，没有参考我们的特定示例上的内部模型激活（除了区分MLP1以获取初始特征向量）。这使我们可以看到哪些MLP0 SAE功能对MLP1功能贡献最大。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 39.39%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/ati0xyol2s8qadnpak2y" /&gt;&lt;figcaption&gt;根据其标准化分数&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在进行此实验之前，我们希望最佳功能会&lt;i&gt;很少&lt;/i&gt;-  MLP1功能可以用很少的MLP0功能表示。不幸的是，情况并非如此：有512 MLP0功能具有MLP1特征得分大于平均值的两个标准偏差。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 77.24%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/akmpx0yzwxhsvaxn8wji" /&gt;&lt;figcaption&gt;线性化MLP1特征的MLP0归一化特征得分的直方图。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;但是，从这个过程中可以获得有趣的见解。例如，如果我们查看最佳功能的统一激活示例，功能81，我们发现此功能似乎在非常相似的示例上与原始的MLP1 SAE功能一起激活，该功能由令牌&lt;code&gt;&amp;#39;&lt;/code&gt;由标记之前&lt;code&gt;&amp;#39;:&lt;/code&gt;组成。 : &lt;code&gt;&amp;#39;:&lt;/code&gt;但是，在MLP1功能和MLP0功能之间，这些示例的功能得分通常在功能分数上差异。换句话说，尽管这些功能似乎在类似类型的输入上激活，但MLP1功能通常会激活高度，以使MLP0功能在该输入中激活低，反之亦然。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 84.57%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/owcrrfmj6ult1mu81djs" /&gt;&lt;figcaption&gt; MLP0特征81的均匀激活示例&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;其他最高得分的功能更难解释。一方面，特征11265在令牌&lt;code&gt;=&amp;quot;&lt;/code&gt;中触发，这是在我们之前讨论过的MLP1功能的均匀激活示例之一中发现的。激活在我们的代码中呈现为Gibberish的令牌。&lt;/p&gt;&lt;p&gt;这里的要点是，尽管从MLP0 SAE功能方面可以从查看MLP1 SAE功能中获得一些见解，但仍有许多密集的计算可能会阻止一种幼稚的解释。一个有趣的未来研究领域是研究是否可以同时在不同层进行训练，以鼓励其特征之间的稀疏连接。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从MLP0到MLP1的路径的特征解释&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;现在，让我们看一下从令牌嵌入的计算路径如何通过MLP0，然后通过MLP1启用SAE功能。重要的是，由于该计算路径涉及两个连续的MLP，&lt;i&gt;因此我们采用MLP0和MLP1的线性近似&lt;/i&gt;。 （特别是，一旦我们拥有MLP1的线性化特征向量向量，然后我们就MLP0的此特征向量进行线性性化。）我们期望随着我们近似更多的非线性，线性化的错误会变得复合，但是尽管如此，我们认为我们可能会认为我们可以能够在这里获得有趣的结果。&lt;/p&gt;&lt;p&gt;在执行了这种双线性化后，当查看此计算路径的功能的解释时，顶部令牌包括&lt;code&gt;=”&lt;/code&gt; &lt;code&gt;&amp;#39;:&amp;#39;&lt;/code&gt; and&amp;#39;and &lt;code&gt;=&amp;quot;&lt;/code&gt; 。有趣的是，这些令牌具有与我们期望的&lt;code&gt;&amp;#39;&lt;/code&gt;代币”相似的语义要找到：所有这些顶级令牌都介绍了“键值”构造的“值”部分，例如&lt;code&gt;&amp;#39;name&amp;#39;:&amp;#39;John&amp;#39;&lt;/code&gt;或&lt;code&gt;&amp;quot;address&amp;quot;=&amp;quot;123 Greenfield Lane&amp;quot;&lt;/code&gt; 。&lt;/p&gt;&lt;p&gt;请注意，“预期”令牌&lt;code&gt;&amp;#39;&lt;/code&gt;的脱水得分为第102高。总体而言，这些结果与我们的期望更一致，而不是对MLP1的直接途径的拆卸结果，尽管令牌&lt;code&gt;&amp;#39;&lt;/code&gt;位置仍然比我们预期的要低。&lt;/p&gt;&lt;h3&gt;从ATTN0到MLP1的路径&lt;/h3&gt;&lt;p&gt;给定一个高度激活的示例，在MLP1功能上执行ATTN0上的直接分数归因表明，对该功能的主要贡献来自Head 2，该功能在&amp;#39;：&amp;#39;：在&lt;code&gt;&amp;#39;:&lt;/code&gt;在&amp;#39;：在&amp;#39;&amp;#39;&amp;#39;&amp;#39; &lt;code&gt;&amp;#39;&lt;/code&gt;上之前的doken上强烈启动，例如&lt;code&gt;{&amp;#39;name&amp;#39;: &amp;#39;John&amp;#39;}&lt;/code&gt; 。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/hqhusm3quxpld1gd6lox" /&gt;&lt;figcaption&gt;第0层的MLP1功能的直接分数归因&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;此外，在目的地令牌时，查看&lt;code&gt;&amp;#39;&lt;/code&gt; &lt;code&gt;&amp;#39;:&lt;/code&gt;令牌”的QK分数表明，当源代币远离目的地时，注意力评分非常急剧下降。&lt;/p&gt;&lt;p&gt;将HEAD 2的OV功能解释为&lt;code&gt;:&amp;quot;&lt;/code&gt;和&lt;code&gt;:&amp;#39;&lt;/code&gt;是第四和第5个得分最高的令牌，这符合我们对头部功能的直觉。但是，排名最高的最高得分标记是出乎意料的：出乎意料的是： &lt;code&gt;Î&lt;/code&gt; ， &lt;code&gt;)=\&lt;/code&gt; ，和&lt;code&gt;))**(&lt;/code&gt;分别。我们在提示中使用了这些令牌，以查看它们是否激活了该特征；对于参考，提示&lt;code&gt;&amp;#39;: &amp;#39;&lt;/code&gt;产生了4.535的特征激活。我们发现提示&lt;code&gt;Î &amp;#39;&lt;/code&gt;时， &lt;code&gt;Î &amp;#39;&lt;/code&gt;根本没有激活该功能，提示&lt;code&gt;))**( &amp;#39;&lt;/code&gt;弱激活该功能，得分为1.038。&lt;/p&gt;&lt;h3&gt;从ATTN0到MLP0再到MLP1的路径&lt;/h3&gt;&lt;p&gt;在一个高度激活的示例上的直接分数归因表明，大多数贡献再次来自&lt;code&gt;&amp;#39;:&lt;/code&gt; ”令牌之前的“ &lt;code&gt;&amp;#39;&lt;/code&gt;令牌”。此路径的Head 2的OV De插度得分最高的令牌为&lt;code&gt;&amp;#39;:&lt;/code&gt; ，”，例如&lt;code&gt;&amp;quot;:&lt;/code&gt; and &lt;code&gt;&amp;#39;):&lt;/code&gt;也存在于前十个令牌中。&lt;/p&gt;&lt;p&gt;有趣的是，令牌&lt;code&gt;perhaps&lt;/code&gt;是第四高的分数，并在提示中使用它的&lt;code&gt;&amp;#39;&lt;/code&gt;令牌”弱激活了原始的MLP1 SAE功能（激活为0.787）。&lt;/p&gt;&lt;h3&gt;涉及ATTN1的路径&lt;/h3&gt;&lt;p&gt;在模型的所有子层上执行直接得分归因，表明ATTN1对特征分数有负贡献，这在很大程度上是由于注意力输出偏置向量。因此，我们没有对涉及ATTN1的路径进行非常彻底的研究。对其头的OV脱落得分的初步研究是无法解释的。也就是说，对此SAE功能的全面调查将花费更多时间查看ATTN1。&lt;/p&gt;&lt;h3&gt;概括&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;均匀的激活示例表明，MLP1特征似乎在Bigram &lt;code&gt;&amp;#39;: &amp;#39;&lt;/code&gt;上激活。&lt;/li&gt;&lt;li&gt;在MLP1的直接路径上执行去除力会产生大量难以理解的令牌，作为得分最高的令牌。也就是说，预期的令牌&lt;code&gt;&amp;#39;&lt;/code&gt;得分排名第159。使用一些难以理解的令牌进行路径修补实际上确实增加了特征激活，但是其他难以理解的令牌的存在似乎是线性化过程的伪像。&lt;/li&gt;&lt;li&gt;用MLP0 SAE功能表达MLP1 SAE功能表明，大量MLP0功能有助于MLP1功能。最重要的MLP0功能具有顶部激活示例，看起来与MLP1功能的顶级激活示例非常相似，但是这些功能分数之间通常存在差异。&lt;/li&gt;&lt;li&gt;查看从MLP0到MLP1的路径的解释，顶部令牌包括&lt;code&gt;=”&lt;/code&gt; and &lt;code&gt;&amp;#39;:&amp;#39;&lt;/code&gt; and &lt;code&gt;=&amp;quot;&lt;/code&gt; ;“预期”令牌&lt;code&gt;&amp;#39;&lt;/code&gt;分数为102级最高分数。&lt;/li&gt;&lt;li&gt;查看从ATTN0到MLP1的路径以及从MLP0到MLP0再到MLP1的路径表明，注意力头2似乎通过&lt;code&gt;&amp;#39;:&lt;/code&gt; &lt;code&gt;&amp;#39;&lt;/code&gt; De-bedding支持了这一点，但也揭示了一些意外的令牌，当在提示中使用时，它们会弱激活原始的SAE功能。&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;线性化实验&lt;/h1&gt;&lt;p&gt;由于反向工程过程通过采用梯度线性近似MLP，而MLP是高度非线性的，因此这提出了该方法的准确性。为了获得一些初始直觉，我们进行了一些实验测试这种线性化方法。我们的初步发现是，线性化倾向于为激活SAE特征的输入提供良好的近似值，但其准确性在非激活输入方面却少得多。&lt;/p&gt;&lt;h2&gt; gelu-1L中的&lt;code&gt;&amp;#39;t&lt;/code&gt;功能”的激活转向&lt;/h2&gt;&lt;p&gt;回想我们先前研究的GELU-1L中的&lt;code&gt;&amp;#39;t&lt;/code&gt;功能”。为了了解通过线性化MLP获得的特征向量是否有用，我们执行了激活转向实验，在该实验中，我们将线性化的特征向量添加到模型的MLP激活中，并查看SAE特征得分的变化程度。&lt;/p&gt;&lt;p&gt;特别是，我们查看了“快速棕狐&lt;code&gt;[TOKEN]&lt;/code&gt;狐”）的提示，在那里&lt;code&gt;[TOKEN]&lt;/code&gt;被“测试”，“测试”，“饮食”，“ will”和“ not”代替。 SAE RAW功能分数（没有Relu或偏见；这使我们可以在每个提示中记录最终令牌的SAE功能的部分激活；然后，当在每个提示中添加了线性化的特征向量（带系数1）时，将SAE RAW特征分数记录在MLP激活中时。&lt;/p&gt;&lt;figure class="table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;代币&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;干净分数&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;肮脏的分数&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;“测试”&lt;/td&gt;&lt;td&gt; -1.4542&lt;/td&gt;&lt;td&gt; 1.4392&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; “测试”&lt;/td&gt;&lt;td&gt; -0.9500&lt;/td&gt;&lt;td&gt; 2.4638&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; “吃”&lt;/td&gt;&lt;td&gt; -0.6423&lt;/td&gt;&lt;td&gt; 3.7210&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; “将要”&lt;/td&gt;&lt;td&gt; 1.1101&lt;/td&gt;&lt;td&gt; 6.1618&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; “不”&lt;/td&gt;&lt;td&gt; 2.5207&lt;/td&gt;&lt;td&gt; 8.6271&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;结果可以在上表中找到。我们看到，在所有情况下，用线性化特征向量的激活转向确实会提高原始特征得分。但特别是，随着原始令牌会激活SAE功能，激活转向变得更加有效。现在，我们通过在一个高激活的示例上区分了功能向量，并且直观地，示例与示例相比，该功能火灾更相似，因此，该功能矢量却不奇怪，因此此功能向量的工作原理越多，越多，越好原始令牌激活该功能。&lt;/p&gt;&lt;h2&gt; Gelu-1L中的&lt;code&gt;&amp;#39;t&lt;/code&gt;特征”的线性化余弦相似性&lt;/h2&gt;&lt;p&gt;再次，我们查看了Gelu-1L中的&lt;code&gt;&amp;#39;t&lt;/code&gt;功能”，以及“快速棕狐&lt;code&gt;[TOKEN]&lt;/code&gt; ”形式的提示，在该形式中， &lt;code&gt;[TOKEN]&lt;/code&gt;被“测试”，“测试”，“ EAT”，“ WILL WILL”代替。 ”和“不”。我们计算了这些提示中每个提示的最后一个令牌计算的线性化特征与在最后一个令牌上计算的线性化功能之间的余弦相似性，以提示“快速棕色狐狸没有”。我们通过冻结分层和通过分层区分来做到这一点。结果在下表中提供。&lt;/p&gt;&lt;figure class="table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;代币&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;冷冻分层&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;分化的分层&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;“测试”&lt;/td&gt;&lt;td&gt; 0.7745&lt;/td&gt;&lt;td&gt; 0.3155&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; “测试”&lt;/td&gt;&lt;td&gt; 0.7897&lt;/td&gt;&lt;td&gt; 0.3500&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; “吃”&lt;/td&gt;&lt;td&gt; 0.8373&lt;/td&gt;&lt;td&gt; 0.4508&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; “将要”&lt;/td&gt;&lt;td&gt; 0.9095&lt;/td&gt;&lt;td&gt; 0.6253&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; “不”&lt;/td&gt;&lt;td&gt; 0.9570&lt;/td&gt;&lt;td&gt; 0.8189&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;有两个含义跳出来。首先，当我们将MLP线性化的令牌激活SAE功能时，余弦相似性变得更高。我们假设这是因为激活SAE特征的示例往往位于MLP具有相似行为的激活空间的相似区域。&lt;/p&gt;&lt;p&gt;其次，当余弦相似性与分层线性化时，余弦相似性之间存在鲜明的对比，尤其是对于激活SAE的代币而言，它的特征最少。这违背了最初的直觉，即分层不会极大地影响特征向量方向。&lt;/p&gt;&lt;p&gt; Neel建议这可能是因为在数学上，地图&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mfrac MJXc-space3"&gt;&lt;span class="mjx-box MJXc-stacked" style="width: 0.878em; padding: 0px 0.12em;"&gt;&lt;span class="mjx-numerator"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-denominator"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-vsize"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。通过此区分将平行于&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;方向设置为零，并且所有其他方向不变，因此在这里，它将特征向量的组件平行于与残留流相平行。如果“ true”特征向量是残差流的重要组成部分，则将删除特征向量的大部分，从而产生错误。参见&lt;a href="https://www.neelnanda.io/mechanistic-interpretability/attribution-patching#layernorm"&gt;&lt;u&gt;Nanda等。&lt;/u&gt;&lt;/a&gt;有关在归因修补程序中有关此效果的更多讨论。鉴于这些结果，我们建议在可能的情况下冻结分层，而不是通过它区分。&lt;/p&gt;&lt;h2&gt; GELU-2L MLP1特征的线性化余弦相似性&lt;/h2&gt;&lt;p&gt;在此实验中，我们研究了前面讨论的GELU-2L MLP1功能。我们采用了48个示例，该示例大约在MLP1 SAE特征原始得分范围内分布（即不考虑偏见和relu）。然后，我们采用了通过在每个示例中取梯度来获得的线性化MLP1特征的成对余弦相似性。结果可以在以下图中找到。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 58.95%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/hper8jjqxbu9ziniwbih" /&gt;&lt;figcaption&gt; MLP1梯度之间的成对余弦相似性&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;此外，我们有以下结果：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;最低激活的24个示例和自身之间的平均成对余弦相似性： &lt;strong&gt;0.3089&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;最低激活的24个示例与最高激活的24个示例之间的平均成对余弦相似性： &lt;strong&gt;0.1097&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;最高激活的24个示例与自身之间的平均成对余弦相似性： &lt;strong&gt;0.7037&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该实验中的一些有趣的收获：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们看到，较高激活的例子彼此具有较高的成对余弦相似性。这令人兴奋，因为这表明我们不需要每个示例获得单独的功能向量，我们可以在许多高激活示例中平均每个功能获得一个一致的矢量，这似乎更强大和可靠！&lt;/li&gt;&lt;li&gt;我们似乎观察到不连续的行为：SAE功能开始发射（绘图中途），所有成对余弦的相似性都会更高。请注意，我们在区分时会忽略SAE的依赖，因此它不能成为这种不连续性的来源。&lt;/li&gt;&lt;li&gt;激活最低的示例的梯度都比彼此更相似，而不是吸引最大的示例梯度。&lt;ul&gt;&lt;li&gt;令人惊讶的是，这似乎很弱暗示了最低激活的例子中的某种聚类行为，而不仅仅是激活的例子。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt; GELU-2L的线性化特征系数与注射结果&lt;/h2&gt;&lt;p&gt;再次，我们正在考虑GELU-2L案例研究。回想一下，我们以MLP0 SAE功能来表达线性化的MLP1特征向量。这提供了系数的向量，该矢量表示每个MLP0 SAE特征在多大程度上有助于线性化的MLP1特征。让我们称此矢量&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ；让MLP0功能的&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;系数&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;表示&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;为&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;现在，考虑一下如果我们一次将每个MLP0 SAE功能注入每个MLP0 SAE功能，也就是说，我们将MLP0 SAE功能&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;I I&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;添加到模型的Pre-MLP1残差流中，并查看这如何影响这MLP1 SAE原始功能分数（即忽略偏差术语和relu）。如果MLP1是线性的，那么SAE原始特征分数的变化将完全等于&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。因此，测量MLP1线性近似的准确性的一种方法是查看&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;与每个MLP0特征的注入，C与SAE原始特征分数的变化之间的相关性。&lt;/p&gt;&lt;p&gt;首先，我们使用提示&lt;code&gt;{&amp;#39;name&amp;#39;: &amp;#39;&lt;/code&gt;作为基本提示进行了剩余流的编辑。请注意，MLP1 SAE功能在此提示的最后一个令牌上高度激活。结果可以在以下图中找到。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 62.42%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/pvjtobymrlftw26ccozv" /&gt;&lt;figcaption&gt;在高度激活的示例与线性特征系数上注射结果&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;接下来，我们使用提示&lt;code&gt;{&amp;#39;name&amp;#39;: testing testing&lt;/code&gt;作为基本提示，对其进行了编辑。请注意，MLP1 SAE功能不会在此提示的最后一个令牌上激活。结果可以在以下图中找到。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 64.95%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/o6od0kltshhrzukl6kbt" /&gt;&lt;figcaption&gt;注射示例与线性化特征系数的注射结果&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这些结果产生以下含义：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;线性化非常有效地近似于高度激活的示例，但根本没有有效的例子。&lt;/li&gt;&lt;li&gt;当基本提示弱或未激活时，近似值较弱。&lt;/li&gt;&lt;li&gt;在弱激活或非激活的示例上，基本提示和编辑提示的原始特征得分的差异较小。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;组件的直接分数归因与零消融&lt;/h2&gt;&lt;p&gt;研究线性化疗效的另一种方法如下。给定一组提示，对于每个提示，将不同模型组件的输出（即原始的令牌嵌入和注意Sublayer）的输出为零，并查看这如何改变SAE功能的激活。然后，对于相同的提示，将直接分数归因与线性化SAE功能一起使用，以估计每个组件对SAE功能的重要性。线性化越准确，直接分数归因结果与零消融结果之间的相关性越大。&lt;/p&gt;&lt;p&gt;我们使用前200个激活示例和均匀分布的200个激活示例对每个案例研究的特征进行了此实验。对于每个功能，我们进行了两次实验：一次，通过前MLP分层区分以获得线性化特征向量，而不是通过PRE-MLP分层进行区分（仅考虑其实现的线性转换， ）。&lt;/p&gt;&lt;p&gt;我们发现，总体而言，在激活示例时，具有线性化特征的直接得分归因与零消融得分相关。正如我们先前的线性化结果所表明的那样，我们发现，在顶部激活示例上的相关性比均匀激活示例更大。但是，对于某些特征，通过分层线性化导致相关性较小，而对于其他人来说，冻结分层导致相关性较小。&lt;/p&gt;&lt;p&gt;每个案例研究的具体结果在下面给出。&lt;/p&gt;&lt;h3&gt; gelu-1l &lt;code&gt;(&amp;#39;&lt;/code&gt;功能&lt;/h3&gt;&lt;figure class="image image_resized" style="width: 80.02%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/qsttjn1itkpi2g0e5j04" /&gt;&lt;/figure&gt;&lt;p&gt;对于此功能，即使在统一激活的示例（而不仅仅是最高的激活示例），直接得分归因的结果与零消融的结果之间也存在很强的相关性。这表明线性化在此设置中的性能很好。另请注意，使用分层和冻结分层之间的性能似乎没有太大差异。&lt;/p&gt;&lt;h3&gt; gelu-1l“是”功能&lt;/h3&gt;&lt;figure class="image image_resized" style="width: 84.15%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/fx08tqlfjvmkz3rjubyf" /&gt;&lt;/figure&gt;&lt;p&gt;对于此功能，我们可以看到，当通过分层区分分化时，直接得分归因与零消融结果高度相关。但是，当冻结分层时，直接得分归因完全停止工作。&lt;/p&gt;&lt;h3&gt; gelu- &lt;code&gt;&amp;#39;t&lt;/code&gt;功能&lt;/h3&gt;&lt;figure class="image image_resized" style="width: 84.21%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/yuvm5beqpt1jiw5vp3he" /&gt;&lt;/figure&gt;&lt;p&gt;对于此功能，与线性化特征向量的直接得分归因似乎与通过分化通过LaiseNorm区分获得特征向量时的零消融结果非常吻合。然而，冻结分层对于直接得分归因而产生的性能明显较差，尤其是在统一分布的激活示例集中。&lt;/p&gt;&lt;h3&gt; GELU-1L上下文依赖性“ IS”功能&lt;/h3&gt;&lt;figure class="image image_resized" style="width: 78.71%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/emoeshjjvhytgqiouhcx" /&gt;&lt;/figure&gt;&lt;p&gt;对于此功能，直接分数归因结果与零消融结果之间的相关性小于以前的特征，尽管仍然存在不错的相关性。有趣的是，在统一分布的激活示例测试时，冻结分层可以明显地获得直接得分归因的更好的结果。&lt;/p&gt;&lt;h3&gt; Gelu-2l Python词典功能&lt;/h3&gt;&lt;figure class="image image_resized" style="width: 84.79%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/zs8h05rwibtjivwkd8xd" /&gt;&lt;/figure&gt;&lt;p&gt; For this feature, we see decent correlation between the results of direct score attribution and zero ablation on the top 200 highest-activating examples, with freezing LayerNorm yielding somewhat better results than differentiating through LayerNorm. However, when testing on the broader set of uniformly-activating examples, the performance of direct score attribution drops precipitously.&lt;/p&gt;&lt;h2&gt; Linearization experiments: overall takeaways and hypotheses&lt;/h2&gt;&lt;ul&gt;&lt;li&gt; Taking the gradient of an MLP&amp;#39;s dot product with an SAE feature seems to be an OK approximation of the MLP&amp;#39;s behavior on inputs that highly activate the SAE feature. However, on inputs that don&amp;#39;t activate the SAE feature, the gradient is not a good approximation of MLP behavior.&lt;ul&gt;&lt;li&gt; A hypothesis as to why this is the case is that inputs that highly activate the SAE feature tend to lie within a cluster in activation space in which the MLP has similar behavior for all points in the cluster. Additionally, the pairwise cosine similarity results that we obtained suggest that there might also be some sort of weak clustering behavior for non-activating examples as well.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt; LayerNorm does not play nice with linearization in small models, where individual tokens&amp;#39; representations take up large portions of the residual stream. We recommend freezing LayerNorm rather than differentiating through it.&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt; Discussion: comparison to causal methods&lt;/h1&gt;&lt;p&gt; A natural question to ask is what our method adds over causal interventions such as path patching. For example, looking at the projection of attention heads onto a given feature vector is an approximation to just zero-ablating the path from that head into the MLP layer for just this SAE feature. Even the weights-based techniques applied, such as de-embedding, may be done causally by path patching the direct path from the embedding into the MLP layer (for just this SAE feature) for each token in the vocab, one at a time.&lt;/p&gt;&lt;p&gt; We think that MLP linearization presents significant advantages in speed, especially for weights-based approaches on larger models, where a forward pass for each token in the vocabulary may be prohibitive! MLP linearization is very mathematically similar to &lt;a href="https://www.neelnanda.io/mechanistic-interpretability/attribution-patching#path-patching"&gt;attribution path patching&lt;/a&gt; , and as such, this relationship between MLP linearization and causal interventions is analogous to that between &lt;a href="https://neelnanda.io/attribution-patching"&gt;&lt;u&gt;attribution patching and activation patching&lt;/u&gt;&lt;/a&gt; . Indeed, attribution patching also takes a gradient-based approximation to a causal intervention, yielding a substantial speed-up at the cost of some reliability ( &lt;a href="https://arxiv.org/abs/2310.10348"&gt;&lt;u&gt;but note that it is surprisingly useful&lt;/u&gt;&lt;/a&gt; &lt;u&gt;!&lt;/u&gt; ).&lt;/p&gt;&lt;p&gt; We also think that MLP linearization has promise for better understanding the SAE features on a more general level than path patching: if the feature vectors obtained via MLP linearization point in similar directions across many examples where the feature fires, then this provides a significant hint about the mechanism underpinning the feature. And we can also use such an averaged feature vector to try to understand the SAE feature on a more input-independent level. However, we also think there are many situations where path patching is sufficient and more reliable, and the feature vectors obtained by MLP linearization may be very different on different examples! As such, we think this is a promising technique that needs further investigation, but it&amp;#39;s not yet a slam dunk.&lt;/p&gt;&lt;h1&gt; &lt;strong&gt;Discussion: Is this approach useful?&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt; We&amp;#39;ve presented 5 case studies of applying MLP linearization to reverse-engineer SAE features. But fundamentally, this approach involves taking linear approximations of highly nonlinear transformations, so there are naturally some major limitations to this method. As such, can we take away an idea of whether this approach is useful, and if so, when?&lt;/p&gt;&lt;h2&gt;好的&lt;/h2&gt;&lt;p&gt;In favor of this approach, we find that it can yield rich, weights-based, input-independent information about what causes a given SAE feature to activate:&lt;/p&gt;&lt;ul&gt;&lt;li&gt; The information provided by de-embeddings is rich in that it allows us to interpret SAE features at the token level according to how different computational paths use these tokens; we personally found this new way of interpreting features to be very cool.&lt;/li&gt;&lt;li&gt; This method is largely weights-based because, with the exception of taking derivatives of MLP sublayers, it relies on the fixed trained model weights rather than internal activations on a given prompt. As a result, this approach is more naturally faithful to the model&amp;#39;s computation than to probing-based methods and is faster and more scalable than causal methods.&lt;/li&gt;&lt;li&gt; This method is largely input-independent in that, unlike traditional attribution methods, it provides information about the model&amp;#39;s computation on all inputs rather than information locally relevant to a single input.&lt;/li&gt;&lt;li&gt; Note that there is some input dependence when we take derivatives of MLP sublayers. However, our linearization experiments suggest that the derivatives of MLP sublayers are very similar across different inputs that highly activate an SAE feature.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt; Using this approach allowed us to construct adversarial prompts that revealed unexpected polysemanticity in certain SAE features; this suggests that this approach can complement existing techniques by picking up on behaviors that they might miss. And with regard to the accuracy of this approach, we found that, particularly on highly-activating examples, this approach often agreed with the results obtained by causal interventions.&lt;/p&gt;&lt;h2&gt;不好的&lt;/h2&gt;&lt;p&gt;Among the limitations of this approach, it still remains to be seen whether this can scale to larger, far more complex models. Additionally, some of the information obtained by this approach can be opaque: in particular, looking at the importance of layer 0 SAE features for a layer 1 SAE feature, the layer 0 features didn&amp;#39;t seem very sparse, limiting our ability to understand later-layer features in terms of earlier-layer ones. (Note that this might also just reflect an unavoidable reality of how models compute using SAE features, but if this is the case, then this still hampers our ability to understand the model using our approach.) Most importantly, the linear approximations of MLPs are not always accurate: in our case study for the &lt;code&gt;&amp;#39;t&lt;/code&gt; feature in GELU-1L, direct score attribution with the linearized feature indicated that attention was not important for the feature, but this was contradicted by a causal attention ablation. Indeed, right now, it&amp;#39;s hard to tell whether the method will be reliable for a given context (although preliminary results suggest greater reliability on highly-activating prompts), and in theory, the linearized feature directions can be totally different for each example.&lt;/p&gt;&lt;h2&gt;结论&lt;/h2&gt;&lt;p&gt;Overall, we think that this is a useful but limited technique; thus, we have high uncertainty on how far it can be applicable. In our preliminary experiments, this approach seems valuable for getting a sense of how a feature is computed, finding hypotheses for feature behavior that other methods might miss, and iterating fast, but it seems like it will be more difficult to get to a point where the approach is fully robust or reliable. We hope to spend the rest of the MATS program exploring the strengths and limitations of this approach to reverse-engineering SAE features.&lt;/p&gt;&lt;h1&gt;作者贡献声明&lt;/h1&gt;&lt;p&gt;Jacob and Philippe were core contributors on this project and both contributed equally. Jacob formulated the original reverse-engineering method and wrote the original reverse-engineering code; carried out the case studies for the &lt;code&gt;&amp;#39;{&lt;/code&gt; feature, the &lt;code&gt;&amp;#39;t&lt;/code&gt; feature, the context-dependent &amp;quot;is&amp;quot; feature, and the GELU-2L feature; and carried out the linearization experiments. Philippe performed a feature audit, calculating F1 scores to guide our selection of interesting features to investigate; carried out the case study for the &amp;quot;it is&amp;quot; feature; and refactored and organized code. Sen and Neel gave guidance and feedback throughout the project, including suggesting ideas for causal experiments to test the efficacy of linearization. The original project idea was suggested by Neel.&lt;/p&gt;&lt;h1&gt; Appendix: mathematical details on our method&lt;/h1&gt;&lt;p&gt; In this section, we elaborate with ample mathematical details upon the explanation of our method provided earlier in the post.&lt;/p&gt;&lt;h2&gt; 1-Layer Transformers&lt;/h2&gt;&lt;h3&gt; Finding a feature vector in MLP input space&lt;/h3&gt;&lt;p&gt; Let&amp;#39;s say that we have an SAE feature trained on &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;MLP_out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∈&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mtext MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-ams-R"&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;model&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , the output of the MLP sublayer, and we want to understand what causes that feature to activate. Then, the activation of the &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; -th SAE feature on &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;MLP_out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is given by &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;ReLU&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;MLP_out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;−&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , where &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; -th row of the SAE encoder weight matrix and &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; -th value in the encoder bias vector &lt;span class="footnote-reference" id="fnrefszr2mm7vzrh"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnszr2mm7vzrh"&gt;[7]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; . This means that the SAE feature activation is determined by the dot product &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;MLP_out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . As such, we can consider &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; to be the relevant feature vector in the output space of the MLP.&lt;/p&gt;&lt;p&gt; Our first task is to determine a feature vector &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; in the input space of the MLP that corresponds to &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . What this means is that if &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the input to the MLP, then we want &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;≈&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;MLP_out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , which is the same as &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;≈&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;MLP&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . If the MLP were linear, then we could write &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;MLP&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; as &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; for some matrix &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . In this hypothetical, we would have that &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;MLP&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , implying that &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; .&lt;/p&gt;&lt;p&gt; Unfortunately, MLPs are not linear in real life! But we can &lt;i&gt;linearly approximate&lt;/i&gt; &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;i&gt;by taking the gradient of the MLP&lt;/i&gt; . As such, our feature vector in MLP input space, &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , is given by &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∇&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;MLP&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;（&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;X&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;）&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt; An important question is this: to what extent is this linearization accurate, given that MLPs are in fact highly nonlinear? We have performed some initial investigations into this, which can be found in the section on linearization experiments; we intend to look deeply into this question as we continue our research.&lt;/p&gt;&lt;h3&gt; Different paths&lt;/h3&gt;&lt;p&gt; Now, we have a feature vector &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; in the MLP input space, ie the residual stream prior to the MLP sublayer.我们能用它做什么？ The first thing that we have to understand is that the residual stream at this point is the sum of two different computational paths in the model: the path directly from the input tokens and the path from the input tokens through the attention sublayer. &lt;span class="footnote-reference" id="fnreff7rrxo2wv7k"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnf7rrxo2wv7k"&gt;[8]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; As such, the activation of &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is given by the sum of the contributions of each path. This means that we can analyze and find feature vectors for each path separately.&lt;/p&gt;&lt;h3&gt; The direct path and de-embedding&lt;/h3&gt;&lt;p&gt; First, let&amp;#39;s look at the direct path. This is the path that implements the computation &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;token&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , where &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;token&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the one-hot vector for the token at the current position, and &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the embedding matrix that maps each token to its embedding. At this point, the activation of &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; due to the direct path is given by &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;token&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , which is equal to &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.851em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;token&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . As such, the feature vector in token input space for the direct path is given by &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; .&lt;/p&gt;&lt;p&gt; Now, &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is a vector whose dimension is equal to the number of tokens in the model vocabulary, where the &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; -th entry in the vector represents the amount that token &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; contributes to activating the feature &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . And since &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is just an approximation for the original SAE feature, this means that &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;i&gt;is an approximation of how much each token in the model&amp;#39;s vocabulary contributes to activating the original SAE feature&lt;/i&gt; .&lt;/p&gt;&lt;p&gt; We refer to this process of obtaining a vector of token scores for a given residual stream feature as &lt;strong&gt;de-embedding&lt;/strong&gt; . De-embedding forms a key part of the reverse-engineering process, as it allows us to analyze at a concrete token level the extent to which each token contributes to the feature. Importantly, this process works for any feature that lives in the residual stream of the model. This means that de-embedding can be used for understanding not just pre-MLP features, but also pre-attention features, and features at different layers of multi-layer models.&lt;/p&gt;&lt;h3&gt;注意力&lt;/h3&gt;&lt;p&gt;Now, let&amp;#39;s look at the path from the tokens to the attention sublayer. The first step is to note that the output of attention, for the destination token at position &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , is given by&lt;/p&gt; &lt;span&gt;&lt;span class="mjpage mjpage__block"&gt;&lt;span class="mjx-chtml MJXc-display" style="text-align: center;"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;attn_out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-munderover MJXc-space3"&gt;&lt;span class="mjx-itable"&gt;&lt;span class="mjx-row"&gt;&lt;span class="mjx-cell"&gt;&lt;span class="mjx-op" style="padding-left: 1.8em;"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size2-R" style="padding-top: 0.74em; padding-bottom: 0.74em;"&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-row"&gt;&lt;span class="mjx-under" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;attention head&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-munderover MJXc-space1"&gt;&lt;span class="mjx-itable"&gt;&lt;span class="mjx-row"&gt;&lt;span class="mjx-cell"&gt;&lt;span class="mjx-op" style="padding-left: 2.32em;"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size2-R" style="padding-top: 0.74em; padding-bottom: 0.74em;"&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-row"&gt;&lt;span class="mjx-under" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;source token index&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;score&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;O&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt; where &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the residual stream before attention (ie after token and positional embeddings) for token &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;O&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the OV matrix for head &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , and &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;score&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the attention weight for head &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; from the source token at position &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; to the destination token at position &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . &lt;span class="footnote-reference" id="fnref2e6edu41698"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn2e6edu41698"&gt;[9]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt; If we treat attention scores as a constant, only focusing on the OV circuit, then this output is just the sum of linear functions on the source t​okens, one for each head, given by &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;↦&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;O&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . This means that the feature vector for the OV circuit of head &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is given by &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;O&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . De-embedding can be applied directly to this feature vector too, in order to understand which tokens contribute the most (through the OV circuit for this head) to the overall SAE feature.&lt;/p&gt;&lt;p&gt; As for analyzing the QK circuits of attention (ie the part of attention responsible for determining attention scores between tokens), we found that the best way to do this was to directly calculate the QK scores for pairs of tokens relevant in the OV circuit, or between different token positions. Examples of this can be found in our case studies.&lt;/p&gt;&lt;h3&gt; Direct score attribution for individual heads and tokens in attention sublayers&lt;/h3&gt;&lt;p&gt; Recall again the equation for attention sublayers, which explains that &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;attn_out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , the output of attention for the destination token at position &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is given by &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;attn_out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-munderover MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;attention head&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-munderover MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;source token index&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;score&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;O&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt; where &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the residual stream before attention for token &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;O&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the OV matrix for head &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , and &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;score&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the attention weight for head &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; from the source token at position &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; to the destination token at position &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; .&lt;/p&gt;&lt;p&gt; Applying the idea of direct score attribution to this equation, this means that the contribution of head &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; and source token &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; to feature vector &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; at destination token &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is given by &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;score&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mrow MJXc-space1"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;O&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; .&lt;/p&gt;&lt;p&gt; &lt;strong&gt;The takeaway:&lt;/strong&gt; it&amp;#39;s possible to see how much each token, at each attention head, contributes to a given feature.&lt;/p&gt;&lt;h3&gt; Wait, what about LayerNorms?&lt;/h3&gt;&lt;p&gt; One thing that we haven&amp;#39;t yet mentioned is the ubiquitous presence of LayerNorm nonlinearities in the model. These can be handled by linearizing them in the same way that we approximate MLPs. But, as is discussed in the &lt;a href="https://www.neelnanda.io/mechanistic-interpretability/attribution-patching"&gt;attribution patching post&lt;/a&gt; , LayerNorms, in general, shouldn&amp;#39;t affect the direction of feature vectors, so there is a theoretical basis for them to be ignored. However, we find that this doesn&amp;#39;t always hold in our &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;实验。 Hypotheses as for why this is the case, along with further discussion, can be found in our section on linearization.&lt;/p&gt;&lt;h2&gt; Multi-layer transformers&lt;/h2&gt;&lt;p&gt; Although the above exposition only discusses 1-layer transformers, it is straightforward to extend this to multi-layer transformers. After all, we now know how to propagate feature vectors through every type of sublayer found in a transformer. As such, given a computational path in a multi-layer transformer, we can simply propagate the SAE feature through this computational path by iteratively propagating it through each sublayer in the computational path, as described above.&lt;/p&gt;&lt;ol class="footnotes"&gt;&lt;li class="footnote-item" id="fn5ns12vjb0f8"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref5ns12vjb0f8"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; Though the feature vector obtained still depends on the input we differentiated on, so it&amp;#39;s not fully input independent. Each input has a different local linear approximation.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fna1rxph5d74"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefa1rxph5d74"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; We note that this may be catchable via non-mechanistic approaches, such as running the models on a large corpus of data and analysing whether the feature activations are highly correlated, as in &lt;a href="https://arxiv.org/abs/2306.09346"&gt;Dravid et al.&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn36xy0nowkoe"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref36xy0nowkoe"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; We&amp;#39;re not sure this counts as an adversarial example. Possibly this is a genuinely polysemantic feature that &amp;quot;wants&amp;quot; to fire on &lt;code&gt;ह&lt;/code&gt; too, or possibly it&amp;#39;s undesirable but hard to disentangle. We speculated there might be superposition where the token embeddings were highly similar, but found that other tokens are more similar to &lt;code&gt;(&amp;#39;&lt;/code&gt; than &lt;code&gt;ह&lt;/code&gt; is, but these do not trigger the SAE feature.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn1tpfjhj7ezr"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref1tpfjhj7ezr"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; That is, &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;O&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.852em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . Looking at the greatest components in this vector answers the following question: given that head 0 is attending to a position, which tokens, if they were at that position, will activate the feature the most?&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn2belxv37guh"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref2belxv37guh"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; Note that &lt;code&gt;&amp;#39;t&lt;/code&gt; basically never appears &lt;i&gt;without&lt;/i&gt; don/can/won/etc as a prefix, so it&amp;#39;s unclear from just the maximum activating examples whether these matter for the SAE feature.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn0hyqmgltk21m"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref0hyqmgltk21m"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; For the sake of intuition regarding why we might expect this: imagine a limit case where we&amp;#39;re looking at a feature at layer 48 of some gigantic transformer. In this exaggerated case, we would probably not expect that this feature can be directly interpreted in terms of the original token embeddings.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnszr2mm7vzrh"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefszr2mm7vzrh"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; This formulation assumes that the SAE encoder weight matrix &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is a &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-ams-R"&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;SAE&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;×&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;model&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; matrix, where &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;SAE&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the hidden dimension of the SAE and &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;model&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the dimension of the input to the SAE (this could be the hidden dimension of the model or the dimensionality of MLP sublayers, depending on which activations the SAE is trained on). In this formulation, vectors multiply on the right of matrices. However, note that certain libraries, such as TransformerLens, use the opposite convention, in which column vectors multiply on the left of matrices.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnf7rrxo2wv7k"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnreff7rrxo2wv7k"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; For a clearer explanation of this, refer to the &lt;a href="https://transformer-circuits.pub/2021/framework/index.html#one-layer-attention-only-transformers"&gt;seminal Transformer Circuits paper&lt;/a&gt; .&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn2e6edu41698"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref2e6edu41698"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; Note that we ignore bias terms here. We can get away with this when we care about understanding which inputs cause a feature to activate; this is because bias terms merely add a constant to the feature score that&amp;#39;s independent of all inputs. However, when analyzing the different contributions that sublayers have to feature scores (eg when performing analysis via direct score attribution), bias terms should be taken into account.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnaeodi9xhson"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefaeodi9xhson"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; The discrepancy between the top tokens when linearizing through LayerNorm and the top tokens without taking into account LayerNorm is explored further in our section on discussing linearization.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/93nKtsDL6YY5fRbQv/case-studies-in-reverse-engineering-sparse-autoencoder#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sun, 14 Jan 2024 02:06:00 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/93nKtsDL6YY5fRbQv/case-studies-in-reverse-engineering-sparse-autoencoder</guid></item><item><title>D&amp;amp;D.Sci 超球面分析第 1 部分：数据字段和初步分析</title><link>https://www.lesswrong.com/posts/rAnS5jCQ5r87eMvus/d-and-d-sci-hypersphere-analysis-part-1-datafields-and</link><description>发布于 2024 年 1 月 13 日晚上 8:16（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;这是一篇文章（希望最终是一个简短的系列文章），详细介绍了我对 Abstractapplic &lt;a href="https://www.lesswrong.com/posts/T3iG4MQ76988JBfkq/d-and-d-sci-fi-colonizing-the-superhypersphere"&gt;最近发布的 D&amp;amp;D.Sci 场景&lt;/a&gt;的分析。我决定记录一下我所做的事情——如果你打算在没有帮助的情况下自己玩这个场景，你应该在阅读本文之前这样做。如果您想在解决方案中使用此信息，请继续。&lt;/p&gt;&lt;h2&gt;原始数据和列&lt;/h2&gt;&lt;p&gt;我首先获取原始数据并将其保存为 csv，然后将其导入到&lt;a href="https://raw.githubusercontent.com/aphyer1992/dndsci_hypersphere/main/dndsci_zppg.py"&gt;Python&lt;/a&gt;和 Excel 中进行使用。我现在不想做任何特定的分析，只是想熟悉数据并看看是否有什么发现。&lt;/p&gt;&lt;p&gt;我们将一一浏览这些列，并在 Excel 中制作一些图表以进行可视化&lt;span class="footnote-reference" id="fnrefxtxl79an65"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnxtxl79an65"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;经度&lt;/strong&gt;在-180 到+180 之间相对均匀分布。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/gsxtboyyggz2mxhkjf2f" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;纬度&lt;/strong&gt;可以从 -90 到 +90 变化，但是是双峰的，通常取 45 左右的值 - 我们很少降落在赤道附近或两极附近。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/qoczvq1wh3qqroqqdqnr" /&gt;&lt;/figure&gt;&lt;p&gt; Shortitude 和 Deltitude 看起来与 Latitude 相同： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/ysq41ourfgbxn7mhb2vb" /&gt;&lt;/figure&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/wvowp0jltzgnarvxdgxy" /&gt;&lt;/figure&gt;&lt;p&gt;这可能是您在 4D 球体上的随机点着陆时自然期望的结果 - 当然，+-90 附近的值不太可能自然发生，因为这些是“极点”并且占用的面积较小。我没有足够好的直觉来知道一旦添加更多维度，接近 0 的值是否自然也很少见，或者我们是否出于某种原因避免使用“赤道”。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;奇怪的气味&lt;/strong&gt;通常会有些存在，但很少会非常存在： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/peeleskulznbxszrcn9m" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;空气味道&lt;/strong&gt;有一些不同的值，一些常见，一些罕见： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/wt1p7m3qlzk12qmscuoo" /&gt;&lt;/figure&gt;&lt;p&gt;风水通常是充足的，有时不好，很少有好的： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/u4iqlmilkvafcph6dgoa" /&gt;&lt;/figure&gt;&lt;p&gt;奇怪的声音有五个可能的值，我们一次最多可以看到三个：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;诡异的沉默&lt;/li&gt;&lt;li&gt;不可能的嗡嗡声&lt;/li&gt;&lt;li&gt;超凡脱俗的掠过&lt;/li&gt;&lt;li&gt;异常压制&lt;/li&gt;&lt;li&gt;不自然的嗡嗡声&lt;/li&gt;&lt;/ul&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/y09cf6krublcyreepjxe" /&gt;&lt;/figure&gt;&lt;p&gt;当没有其他声音出现时，诡异的寂静就出现了。&lt;/p&gt;&lt;p&gt;掠过声和嗡嗡声永远不会同时发生（尽管它们分别是最常见的声音）。&lt;/p&gt;&lt;p&gt; Pi 的局部值的分布看起来非常整齐： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/es5olev4slmim6cnbmi0" /&gt;&lt;/figure&gt;&lt;p&gt; 3.141 + (1d41-1d41)/1000 从字面上看并不准确，因为我们看到的小数位数比这更多，但这可能是一种合理的思考方式？&lt;/p&gt;&lt;p&gt;墨菲常数有一个非常奇怪的分布： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/cbhhf3e2xbk5cdouyymz" /&gt;&lt;/figure&gt;&lt;p&gt;我会猜测这样的事情：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; MC 的分布与我们看到 Pi 的分布类型相同，概率从 0 线性增加到 ~5.5，然后从 ~5.5 线性增加到 ~11。&lt;/li&gt;&lt;li&gt;但我们光辉帝国从来不选择MC&amp;gt;6的地盘。&lt;/li&gt;&lt;li&gt;此外，我们在 MC=4 和 MC=5 处设置了一些限制或条件，使得感知频率在这些点处下降。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;性能看起来不太好： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/humjat6wv5du0g3yyf2p" /&gt;&lt;/figure&gt;&lt;p&gt;在 10,000 多个站点中，有&lt;strong&gt;2 个&lt;/strong&gt;站点的性能 &amp;gt;=100%。&lt;/p&gt;&lt;p&gt;诚然，我们确实有 11 万个预先批准的站点可供选择。这表明在全部可能的数据中大约有 20 个站点的性能可以接受——这反过来又表明我们的任务不会有太多余地。如果我们不能几乎完美地识别影响性能的&lt;strong&gt;所有&lt;/strong&gt;因素，我们实际上就无法找到 12 100%+ 的站点。&lt;/p&gt;&lt;h2&gt;重新格式化以供使用&lt;/h2&gt;&lt;p&gt;我调整了一些列以使其更加用户友好：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; “Weird Sounds”变成了 4 个独立的布尔列来表示不同的噪音（忽略了当没有其他噪音时我们得到的“Silence”）。&lt;/li&gt;&lt;li&gt; “奇怪的气味？”而“周边风水”则变成从0到2的数字：0表示没有气味/风水不好，1表示有气味/风水好，2表示气味极重/风水好。&lt;/li&gt;&lt;li&gt; “Air Tastes Like” 变成 4 个独立的布尔列（适用于除“Nothing”之外的所有气味）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;然后将结果输出为一个我认为更方便的&lt;a href="https://raw.githubusercontent.com/aphyer1992/dndsci_hypersphere/main/dndsci_zppg_formatted.csv"&gt;新文件&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;相关矩阵&lt;/h2&gt;&lt;p&gt;我们可以利用这些数据做的最简单有用的事情之一就是构建一个相关矩阵。 &lt;span class="footnote-reference" id="fnrefegy9fnduwep"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnegy9fnduwep"&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;figure class="table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;洛&lt;/td&gt;&lt;td&gt;拉&lt;/td&gt;&lt;td&gt;什&lt;/td&gt;&lt;td&gt;德&lt;/td&gt;&lt;td&gt;圆周率&lt;/td&gt;&lt;td&gt;亩&lt;/td&gt;&lt;td&gt;闻&lt;/td&gt;&lt;td&gt;冯&lt;/td&gt;&lt;td&gt;应用程序&lt;/td&gt;&lt;td&gt;烧伤&lt;/td&gt;&lt;td&gt;科普&lt;/td&gt;&lt;td&gt;薄荷&lt;/td&gt;&lt;td&gt;哼&lt;/td&gt;&lt;td&gt;短剧&lt;/td&gt;&lt;td&gt;斯奎&lt;/td&gt;&lt;td&gt;嗡嗡声&lt;/td&gt;&lt;td&gt;性能&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;洛&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #F8E984; text-align: right;"&gt;0.01&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FCEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F3E884; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #D2DE82; text-align: right;"&gt; 0.07&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;拉&lt;/td&gt;&lt;td style="background-color: #F8E984; text-align: right;"&gt;0.01&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F3E884; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FAEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #F6E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F4E884; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;什&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt;-0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #F9EA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F7E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #F8E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;德&lt;/td&gt;&lt;td style="background-color: #FCEA84; text-align: right;"&gt;0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F9EA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F0E784; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F6E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #F5E984; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;圆周率&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt;0.00&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE683; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F7E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #BDD881; text-align: right;"&gt; 0.11&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;亩&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt;0.00&lt;/td&gt;&lt;td style="background-color: #FCEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F0E784; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F9EA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F98871; text-align: right;"&gt; -0.40&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;闻&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt;0.00&lt;/td&gt;&lt;td style="background-color: #F3E884; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F5E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE683; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F7E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FCC37C; text-align: right;"&gt; -0.16&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;冯&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt;-0.01&lt;/td&gt;&lt;td style="background-color: #FAEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F9EA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #F9EA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FAEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #C0D981; text-align: right;"&gt; 0.10&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;应用程序&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt;-0.01&lt;/td&gt;&lt;td style="background-color: #F6E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE683; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F9EA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FDC67C; text-align: right;"&gt; -0.15&lt;/td&gt;&lt;td style="background-color: #FDD17F; text-align: right;"&gt; -0.11&lt;/td&gt;&lt;td style="background-color: #F97C6E; text-align: right;"&gt; -0.45&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FED980; text-align: right;"&gt; -0.07&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;烧伤&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt;-0.01&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F6E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FDC67C; text-align: right;"&gt; -0.15&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FEDE81; text-align: right;"&gt; -0.05&lt;/td&gt;&lt;td style="background-color: #FCB379; text-align: right;"&gt; -0.23&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FCEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FAEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #C5DB81; text-align: right;"&gt; 0.09&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;科普&lt;/td&gt;&lt;td style="background-color: #F3E884; text-align: right;"&gt;0.02&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F5E984; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FDD17F; text-align: right;"&gt; -0.11&lt;/td&gt;&lt;td style="background-color: #FEDE81; text-align: right;"&gt; -0.05&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FCC37C; text-align: right;"&gt; -0.16&lt;/td&gt;&lt;td style="background-color: #F2E884; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #F7E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #E8E583; text-align: right;"&gt; 0.04&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;薄荷&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt;0.00&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F7E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FAEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #F97C6E; text-align: right;"&gt; -0.45&lt;/td&gt;&lt;td style="background-color: #FCB379; text-align: right;"&gt; -0.23&lt;/td&gt;&lt;td style="background-color: #FCC37C; text-align: right;"&gt; -0.16&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #63BE7B; text-align: right;"&gt; 0.26&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;哼&lt;/td&gt;&lt;td style="background-color: #FCEA84; text-align: right;"&gt;0.00&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #F5E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F2E884; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #F5E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F8786D; text-align: right;"&gt; -0.47&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;短剧&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt;0.00&lt;/td&gt;&lt;td style="background-color: #F4E884; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #F8E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F7E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE683; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F7E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #F5E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F8696B; text-align: right;"&gt; -0.53&lt;/td&gt;&lt;td style="background-color: #D7E082; text-align: right;"&gt; 0.06&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;斯奎&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt;-0.01&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #F6E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FBA276; text-align: right;"&gt; -0.29&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;嗡嗡声&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt;0.00&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F7E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FAEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F8696B; text-align: right;"&gt; -0.53&lt;/td&gt;&lt;td style="background-color: #F6E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FCC17B; text-align: right;"&gt; -0.17&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;性能&lt;/td&gt;&lt;td style="background-color: #D2DE82; text-align: right;"&gt;0.07&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #BDD881; text-align: right;"&gt; 0.11&lt;/td&gt;&lt;td style="background-color: #F98871; text-align: right;"&gt; -0.40&lt;/td&gt;&lt;td style="background-color: #FCC37C; text-align: right;"&gt; -0.16&lt;/td&gt;&lt;td style="background-color: #C0D981; text-align: right;"&gt; 0.10&lt;/td&gt;&lt;td style="background-color: #FED980; text-align: right;"&gt; -0.07&lt;/td&gt;&lt;td style="background-color: #C5DB81; text-align: right;"&gt; 0.09&lt;/td&gt;&lt;td style="background-color: #E8E583; text-align: right;"&gt; 0.04&lt;/td&gt;&lt;td style="background-color: #63BE7B; text-align: right;"&gt; 0.26&lt;/td&gt;&lt;td style="background-color: #F8786D; text-align: right;"&gt; -0.47&lt;/td&gt;&lt;td style="background-color: #D7E082; text-align: right;"&gt; 0.06&lt;/td&gt;&lt;td style="background-color: #FBA276; text-align: right;"&gt; -0.29&lt;/td&gt;&lt;td style="background-color: #FCC17B; text-align: right;"&gt; -0.17&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;有几点值得注意：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;大多数条目对几乎没有相关性。这使得诸如“邪恶的压制生物有铜的气味”或“薄荷味驱赶蜂鸣器”之类的理论变得非常难以置信。&lt;/li&gt;&lt;li&gt;所有空气味道都是负相关的（显然，因为它们是相互排斥的）。&lt;/li&gt;&lt;li&gt;掠过和嗡嗡声是非常负相关的，如上所述，它们永远不会同时发生。 （飞掠者吃掉蜂鸣器？）&lt;/li&gt;&lt;li&gt;性能与几个不同的变量相关。乍一看显示：&lt;ul&gt;&lt;li&gt;受到墨菲常数的严重伤害（我猜这个常数衡量了他的定律的强度？）&lt;/li&gt;&lt;li&gt;受到嗡嗡声、静噪，尤其是嗡嗡声的伤害。&lt;/li&gt;&lt;li&gt;薄荷的空气味道很好，其他一些味道稍好或稍差。&lt;/li&gt;&lt;li&gt;较高的 Pi 值和较好的风水略好。&lt;/li&gt;&lt;li&gt;气味较浓则稍差。&lt;/li&gt;&lt;li&gt;奇怪的是，经度越高似乎越好。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该分析有两个主要局限性。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;毫无疑问，您已经被告知了一千万次，相关性并不意味着因果关系。 &lt;span class="footnote-reference" id="fnrefcao6y67v2tf"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fncao6y67v2tf"&gt;[3]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;特别是，我们看到 Skittering 看起来有一点好处，但我怀疑这是海市蜃楼。 Skittering 和 Buzzing 是互斥的，而 Buzzing 是相当糟糕的。掠过者可能很糟糕，但不像蜂鸣器那么糟糕：这表明我们也应该避免掠过，并支持沉默。&lt;/li&gt;&lt;li&gt;数据中可能存在的某些模式不会正确反映在这些数字中。&lt;ol&gt;&lt;li&gt;如果在经度 +83 处有一片美妙的绿洲，我们会发现经度和性能之间存在非常轻微的正相关关系。&lt;/li&gt;&lt;li&gt;如果风水有一点是好的，但很多是坏的，我们就不会跟踪得那么好。&lt;/li&gt;&lt;li&gt;如果有一种相互作用，悍马在赤道附近很平静，但在远离赤道的地方很凶猛，我们会完全错过它。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;不充分的初步猜测&lt;/h2&gt;&lt;p&gt;如果我尝试使用此处的信息进行初步猜测：&lt;/p&gt;&lt;p&gt;我们有&lt;strong&gt;大量&lt;/strong&gt;可供尝试的网站。即使在几个要求之后：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一定是沉默。&lt;/li&gt;&lt;li&gt;必须没有任何奇怪的气味。&lt;/li&gt;&lt;li&gt;空气中一定有薄荷的味道。&lt;/li&gt;&lt;li&gt;风水至少必须是足够的。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们还有 2628 个条目。我根据墨菲常数/pi/一点经度的猜测得分建议尝试以下网站：&lt;/p&gt;&lt;p&gt; 6123&lt;br /&gt; 10709&lt;br /&gt; 11789&lt;br /&gt; 16118&lt;br /&gt; 23695&lt;br /&gt; 24728&lt;br /&gt; 29720&lt;br /&gt; 33672&lt;br /&gt; 36008&lt;br /&gt; 48703&lt;br /&gt; 53187&lt;br /&gt; 61818&lt;/p&gt;&lt;p&gt;然而，当我将相同的逻辑应用于主数据集并查看此类网站中的生成器实际得分情况时，它们往往在 50-90% 的范围内。这比 23% 的总体平均水平要好得多，但显然还不够好，以至于我应该冒险去尝试。&lt;/p&gt;&lt;p&gt;据推测，深入研究经度/纬度/短度/纬度将提供更多细节。我会在某个时候这样做，并尝试将我所做的事情写下来。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class="footnotes"&gt;&lt;li class="footnote-item" id="fnxtxl79an65"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefxtxl79an65"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; （个人喜好说明：Excel 是一种非常糟糕的编程语言，对于那些真正应该只使用 Python 的人来说，它习惯于解决简单的编程任务，但它是一个非常好的数据可视化工具。）&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnegy9fnduwep"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefegy9fnduwep"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;这些非常有用，如果您使用粘贴转置和混合绝对引用，那么在 Excel 中制作起来确实非常容易。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fncao6y67v2tf"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefcao6y67v2tf"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; （我讨厌这种特殊的措辞，因为“暗示”这个词可以用来表示“证明”或“建议”，虽然相关性并不能证明因果关系，但它确实表明了因果关系。）&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/rAnS5jCQ5r87eMvus/d-and-d-sci-hypersphere-analysis-part-1-datafields-and#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 13 Jan 2024 20:16:39 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/rAnS5jCQ5r87eMvus/d-and-d-sci-hypersphere-analysis-part-1-datafields-and</guid></item><item><title>一些额外的 SAE 想法</title><link>https://www.lesswrong.com/posts/fqgn56tS5AgjmDpnX/some-additional-sae-thoughts</link><description>发布于 2024 年 1 月 13 日晚上 7:31（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;i&gt;感谢 Lee Sharkey 对第一部分的反馈，感谢 Lee Sharkey、Jake Mendel、Kaarel Hänni 和 LISA 办公室的其他人围绕本文进行的对话。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这篇文章是过去几个月的一些小实验和想法的集合，这些实验和想法从未真正变成更大的东西，但有助于澄清我对一些与 SAE 相关的事情的想法。我现在已经加入了 Anthropic 的可解释性团队，但这里写的所有内容都来自该日期之前。&lt;/p&gt;&lt;h2&gt; MLP 中的分布式特征如何发挥作用？&lt;/h2&gt;&lt;h3&gt;概括&lt;/h3&gt;&lt;p&gt;在撰写最初的 SAE 论文时，我对以下论点感到困扰：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;要了解 MLP 层的作用，我们需要了解非线性如何作用于数据，因为这就是新颖的计算所在。&lt;/li&gt;&lt;li&gt;稀疏自动编码器在变压器 MLP 的后非线性中发现的特征似乎在神经元之间分布非常紧密。&lt;/li&gt;&lt;li&gt;分布在大量神经元上的特征只会对每个单独的神经元产生微小的影响，并且神经元在如此小的变化上将近似线性。&lt;/li&gt;&lt;li&gt;因此，这些分布式特征不可能是真正的动作所在，我们需要以某种方式将神经元基础纳入我们理解 MLP 特征的方式中。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我不再相信这一点，最重要的是，因为我意识到，&lt;strong&gt;当一个特征分布在&lt;/strong&gt;&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n 个&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;神经元上时，可以通过将输入特征的大小放大&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msqrt"&gt;&lt;span class="mjx-box"&gt;&lt;span class="mjx-surd"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;√&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-box" style="border-top: 1px solid;"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;倍来恢复原始非线性&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;事实上，&lt;i&gt;它只&lt;/i&gt;需要缩放&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msqrt"&gt;&lt;span class="mjx-box"&gt;&lt;span class="mjx-surd"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;√&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-box" style="border-top: 1px solid;"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，而不是隐含在我的非正式论证中的&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; （当我考虑缩放的可能性时......）使得使用多个高度分布的特征变得可行，只要少数功能处于活动状态。&lt;/p&gt;&lt;p&gt;代码可&lt;a href="https://github.com/HoagyC/distrib_feats/blob/main/streamlit_page.py"&gt;在 GitHub 上&lt;/a&gt;获取。&lt;/p&gt;&lt;h3&gt;非线性的需要&lt;/h3&gt;&lt;p&gt;多层模型作用于输入数据，将其在每一层处理成新的结构。如果我们查看每个连续层中存在的信息总量，我们知道信息量只会下降，因为较高层中存在的任何信息都是直接从较低层计算出来的，因此信息也必须是存在于那些较低层中。&lt;/p&gt;&lt;p&gt;然而，模型&lt;i&gt;可以&lt;/i&gt;做的是通过多层的操作使数据的特定功能&lt;i&gt;更容易访问&lt;/i&gt;。特别是，该模型使得线性探针能够提取丰富的特征，例如最近在&lt;a href="https://arxiv.org/abs/2310.02207"&gt;代表空间和时间的语言模型&lt;/a&gt;以及许多以前的作品中看到的那样。&lt;/p&gt;&lt;p&gt;线性探针是对哪些信息真正&lt;i&gt;可用的&lt;/i&gt;自然测试，而不是隐藏在高维数据流形中，因为线性可用允许后续神经元根据数据的此特征的存在或不存在进行调节。&lt;/p&gt;&lt;p&gt;重要的是，数据的线性变换不能线性地提供新信息。如果我们有一个线性变换&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，它允许我们使用线性探针&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;σ&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;p&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⋅&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;从特征激活&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;中提取信息，那么我们可以通过定义新的探针&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;σ&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;p&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⋅&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;来消除对&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的需要使用&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;p&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;p&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。因此，如果我们想要在这个意义上提供新信息，我们将需要对其进行非线性变换，这就是变压器的 MLP 层的用武之地。&lt;/p&gt;&lt;h3&gt;基础对齐和分布式特征&lt;/h3&gt;&lt;p&gt;考虑到这种非线性需求，我想探索如何在模型中构建特征，在该模型中，我们从将 MLP 中的特征视为单个神经元的输出，转变为分布在多个神经元的方向。神经元。 &lt;span class="footnote-reference" id="fnref6iedrpq2n4a"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn6iedrpq2n4a"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;在本节中，我将使用 100 个神经元 MLP 和两个潜在特征，一个与单个神经元对齐，另一个分布在所有 100 个神经元中。这些将有助于理解基础对齐特征和分布式特征之间的一些简单差异。&lt;/p&gt;&lt;p&gt;特征被定义为具有单位范数的方向，因此&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∈&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-ams-R"&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;100&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;特征 1 就是第一个神经&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;元&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;，&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;...&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;特征 2 最大程度地分布在神经元&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;上&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;，&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0.1&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0.1&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0.1&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;...&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;请注意，我们将&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;L&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;范数设置为 1（不是&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;L&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;范数），因此特征方向的计算为&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-munderover"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;Σ&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;if&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;所以&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0.01&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;fi&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;=&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0.1&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;我们可以将这些解释为前非线性空间和后非线性空间中的特征，并查看这些特征如何相互影响。我们可以看一下以下关系，其中&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∈&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom MJXc-space3"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是所选的输入特征， &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;o&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∈&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;{&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是所选的输出特征， &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是该特征的输入标量级别， &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是该特征的输出标量级别。&lt;/p&gt;&lt;p&gt; &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;y&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;o&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⋅&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;G&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;L&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;U&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;下面绘制了四种可能的输入输出关系 - 在查看之前，我鼓励您思考这些关系会是什么样子，尤其是扩展输入和扩展输出之间的关系。 &lt;/p&gt;&lt;hr /&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/o8spsuwfuqygxgc1y04m" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;请注意，每个图的比例不同 - y 轴重新调整比例以显示形状的相似性。&lt;/strong&gt;在左上角我们只看到 GELU 非线性。在右上角，我们看到相同的形状，但正如我们所期望的，输出的大小是使用单个输出时的 1/10&lt;/p&gt;&lt;p&gt;在左下角，我们看到单输入单输出情况下非线性的放大版本，因为我们只将我们关心的神经元更改为预期数量的十分之一。不仅变化的幅度变小，而且非线性现在几乎无法察觉。&lt;/p&gt;&lt;p&gt;右下角是一个有趣的案例。重要的是，尽管输入和输出特征相同，但我们不会复制左上角的行为。相反，我们看到的是左下角的行为，但在所有 100 个神经元上都得到了复制。输出的规模扩大了 10 倍，因为我们将单个 (0.1 x 1) 计算替换为 100 x (0.1 x 0.1)。&lt;/p&gt;&lt;h3&gt;按 sqrt(n) 放大可恢复非线性&lt;/h3&gt;&lt;p&gt;右下角的图表非常接近线性，并且作为非线性函数没有多大用处。相反，如果我们想要恢复相同的非线性，我们需要将输入方向的变化规模增加&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msqrt"&gt;&lt;span class="mjx-box"&gt;&lt;span class="mjx-surd"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;√&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-box" style="border-top: 1px solid;"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msqrt MJXc-space3"&gt;&lt;span class="mjx-box"&gt;&lt;span class="mjx-surd"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;√&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;00&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;10&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，在这种情况下我们得到以下结果： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/aplpbetyg9ha5zv8x5go" /&gt;&lt;/figure&gt;&lt;p&gt;这是我们所说的 MLP 具有首选基础并且对于旋转不是不变的意思的一个例子 - 为了使分布在&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n 个&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;神经元&lt;strong&gt;上的特征获得相同的非线性，&lt;/strong&gt;&lt;strong&gt;我们必须扩大输入特征为&lt;/strong&gt;&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msqrt"&gt;&lt;span class="mjx-box"&gt;&lt;span class="mjx-surd"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;√&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-box" style="border-top: 1px solid;"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;strong&gt;。&lt;/strong&gt;请注意，输出规模现在也增加了相同的数量。&lt;/p&gt;&lt;p&gt;我们还可以在某种程度上看到这如何产生额外的鲁棒性 - 如果我们强烈打开另一个完全相同方向的特征，那么根本就没有额外的非线性可以使用，而在这里我们很可能处于“膝盖” &amp;#39;许多神经元的非线性，因此将得到非线性响应。&lt;/p&gt;&lt;h3&gt;正向和负向特征方向&lt;/h3&gt;&lt;p&gt;请注意，上述情况依赖于所有向量元素均为正。如果我们有偶数个正负元素，那么它们就会相互抵消，无法产生很大的非线性，如果我们有一些不平衡的组合，那么我们会得到非线性程度有所减弱的中间情况。&lt;/p&gt;&lt;p&gt;因此&lt;strong&gt;，如果我们要使新信息线性可用，我们应该期望输入的特征向量会严重偏向正分量或负分量。&lt;/strong&gt; &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/aq0ehqfgsujvdk1smc7y" /&gt;&lt;/figure&gt;&lt;p&gt;这也意味着 MLP 中可能的特征数量受到一些限制。 Johnson-Lindenstrauss 告诉我们，高维空间中近正交特征的数量在该空间的维度中呈指数增长，但这些维度中的大多数将具有几乎平衡数量的正分量和负分量，因此不会有用非线性，因为该方向上的输出将是该方向上输入的齐次函数。&lt;/p&gt;&lt;p&gt;我们可以看到，使用这些分布式函数，我们仍然可以将网络视为将它们想要放大的东西放在神经元的正方向上，但在多个维度上进行此操作。&lt;/p&gt;&lt;h3&gt;干涉与维数之间的交易&lt;/h3&gt;&lt;p&gt;通过扩大输入特征的大小，我们恢复了单个神经元的原始非线性行为。然而，直觉上我们预计，使输入的幅度更大，输入具有固定比例的非线性，应该会对我们在任何时候可以激活的特征数量产生影响，因为干扰水平会更大。&lt;/p&gt;&lt;p&gt;术语中的一个重要注释（感谢 Jake Mendel）：&lt;i&gt;线性&lt;/i&gt;是&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;y&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;y&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的条件，而同质性是&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的较弱条件&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。虽然线性度最终是我感兴趣的东西，但在这种情况下我测量的是特定输入方向的同质性，因此我将在适当的情况下切换到这个术语。&lt;/p&gt;&lt;p&gt;为了了解这是否以及何时成为问题，我绘制了特定方向的输入输出响应曲线。算法如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我生成一组特征向量，每个特征向量都是输入/输出空间中的一个方向，仅包含固定数量的非零元素， &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;code&gt;dims_per_feature&lt;/code&gt;&lt;/li&gt;&lt;li&gt;我设置了固定数量的功能&lt;code&gt;n_on&lt;/code&gt; ，除了感兴趣的功能之外，该功能将在任何时候打开&lt;/li&gt;&lt;li&gt;我选择一个随机输入特征，并生成一组非线性输入，其中该特征和&lt;code&gt;n_on&lt;/code&gt;其他特征均处于活动状态，其大小在&lt;code&gt;-np.sqrt(dims_per_feature) &amp;lt; mag &amp;lt; np.sqrt(dims_per_feature)&lt;/code&gt;&lt;/li&gt;&lt;li&gt;我将这些输入向量通过非线性传递以获得输出向量，并将这些输出向量投影到感兴趣的特征上，以获得输出中的特征级别。&lt;/li&gt;&lt;li&gt;我运行回归来预测输出中所选特征的水平，作为输入中特征水平的函数&lt;/li&gt;&lt;li&gt;我通过获取非线性之前和之后的特征激活程度并计算简单回归来根据非线性之前的特征值预测非线性之后的特征值来测量非均匀程度。第一个回归只有这个单一的输入参数。第二个包含二次项 - 只是输入值的平方。 &lt;/li&gt;&lt;/ul&gt;&lt;figure class="image image_resized" style="width: 65.53%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/borwpoinwulmvc5w029s" /&gt;&lt;figcaption&gt;在存在来自重叠特征的噪声的情况下将输入和输出向量投影到特征方向的示例也处于活动状态。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如果存在明显的非同质性，那么二次回归应该能够比线性回归更好地预测输出值。&lt;/p&gt;&lt;p&gt;输出指标是由 20% 的数据组成的测试集上的二次回归和线性回归之间的&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;差异。这为我们提供了一个简单的衡量方法，可以衡量我们因改变输入而看到的非均匀响应的程度。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 64.08%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/binxxaqzulpbcfuhzn68" /&gt;&lt;figcaption&gt;示例：如何将非均匀性得分计算为特征输入级别与投影到特征方向上的输出向量（有干扰）之间的线性回归和二次回归的&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;得分之间的差异。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;然后我们可以做的是采用固定的网络宽度，这里仍然是&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;100&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，并改变每个特征分布的维度数。我们可以为“非同质性水平”设置一个阈值，并在我们认为关系大致同质之前查看有多少特征可以在任何时候处于活动状态。这里我随意把这个阈值设置为0.1。&lt;/p&gt;&lt;p&gt;同时，对于每个特征的给定维数，我们可以绘制出我们可以拥有多少个近乎正交的特征，并使用一组随机特征向量的平均最大余弦相似度（MMCS）作为代理。我们将近正交特征的数量作为 MMCS 超过某个阈值的点，这里选择 0.3。这当然是低估的，因为网络可以将特征排列得比随机子集更精确地正交，但它给出了一个粗略的想法。&lt;/p&gt;&lt;p&gt;完成所有这些都是为了我们可以看到，实际上存在一种看似合理的权衡，即通过增加每个特征的维度数，我们允许自己有更多几乎正交的特征向量，但代价是能够拥有很少的活动特征在干扰淹没非线性并消除我们对层进行有趣工作的能力之前（至少通过这种简单的非均匀性测量）。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/rncb5iv09hrnh6inhzqi" /&gt;&lt;figcaption&gt;该图分别使用任意阈值来表示“可接受的”非均匀性和干扰的最小和最大水平，并不是声称这些是总特征或活动特征的真实数量，而只是为了证明两者之间存在权衡，因为我们变化&lt;code&gt;dims_per_feature&lt;/code&gt; 。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这密切反映了&lt;a href="https://transformer-circuits.pub/2022/toy_model/index.html"&gt;叠加玩具模型论文&lt;/a&gt;中以更详细的方式得出的结论，该论文探讨了叠加在理想化残差流中的作用，并为如何在 MLP 中找到分布式特征提供了一些理论支持。&lt;/p&gt;&lt;h2&gt;多层特征的问题&lt;/h2&gt;&lt;h3&gt;关注点&lt;/h3&gt;&lt;p&gt;稀疏自动编码器可能无法兑现其承诺的一种方式是，我们有“已完成的功能”和“正在进行的功能”之类的东西。例如，要在第 20 层读取特征，而先决条件元素在第 10 层就位，但是模型发现增量构建特征比在 (10, 20) 中的单层中学习特征更有利，也许是因为这增加了可以同时构建的功能的数量，或者可能只是因为它并不昂贵，而且创建功能的分布式方法比非分布式方法多得多。&lt;/p&gt;&lt;p&gt;这里的一个激励性例子是&lt;a href="https://arxiv.org/abs/2310.02207"&gt;Gurnee 和 Tegmark (2023) 的&lt;/a&gt;论文之一，该论文探讨了 Llama 模型各层的经度和纬度表示。&lt;/p&gt;&lt;p&gt;如果我们通过稀疏自动编码器或任何其他基础查找方法的镜头来看待这个问题，一旦它“完全构建”，我们可能会找到一个纬度方向 - 但是当这些层正在构建时我们期望找到什么？ &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KsWo4gCuZaX8fJNjG/zktyihbbwuqxakcm6ziq" /&gt;&lt;figcaption&gt; Gurnee 和 Tegmark 2023 的图 2 显示，纬度和经度的探测质量有所平稳增加，特别是在早期层&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;人们可能会做一些不同的实验来研究这些问题 - 在这里，我刚刚运行了最简单的潜在测试之一，看看实际上是否存在将特定连接的学习集中到单个层的倾向。&lt;/p&gt;&lt;h3&gt;一个简单的实验&lt;/h3&gt;&lt;p&gt;该设置是仅 MLP 变压器的简单模型，由一系列隐藏层组成，每层都有剩余连接。输入是一对 one-hot 向量，这意味着如果向量维度为 500，则输入将是一个 1000 维向量，其中前 500 个活动维度中有一个活动维度，第二个 500 个活动维度中有一个活动维度。这些是投影的隐藏维度与学习向量的输出宽度相同，然后是一系列具有循环连接的 MLP 层，每个层具有相同的宽度。&lt;/p&gt;&lt;p&gt;首先，我们可以检查每层之后的总体损失，评估每层之后输出的损失。我们发现，至少在后面的层中，接近线性减少，这表明模型正在迭代地使残差流更接近所需的输出。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 54.59%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/orjagthy0756ovbumwjv" /&gt;&lt;figcaption&gt;对于 3 个不同数量的数据点，设计任务上的 logit-lens 损失作为层的函数，显示出类似的、一致的损失减少，并在接近结束时加速。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;您可以想象模型计算此问题的两种相反方式 - 在一端，每一层都会计算输入的特定子集的正确输出。在这个范围的另一端，输入将不断转换，直到每个数据点的答案最终在最后一层得到正确，每个层都会进行一定程度的中间处理。&lt;/p&gt;&lt;p&gt;为了简单测试这两张图片中哪一张更接近真实情况，然后我在每个层之后获取各个数据点的 Logit 透镜输出，并仅获取一些随机选择的数据点，我得到如下图： &lt;/p&gt;&lt;figure class="image image_resized" style="width: 67.64%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/flgiunnm9i8ftej5xw0r" /&gt;&lt;figcaption&gt; 5 个随机选择的数据点的分层 Logit 透镜损失，即使对于单个数据点也显示出大致连续的损失减少。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这已经为我们提供了所需的信息，但为了防止这些异常值，我们可以采用一些损失阈值作为某个层是否正确学习输出的代理，然后绘制所学习的数据点的比例，我们得到以下结果（阈值=0.1）： &lt;/p&gt;&lt;figure class="image image_resized" style="width: 86.97%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KsWo4gCuZaX8fJNjG/fpxqwtlvluntxz5r6ct2" /&gt;&lt;figcaption&gt;图表绘制了每层正确学习的输入示例的比例（通过 Logit 透镜测量），其中“正确学习”意味着损失小于&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们再次看到第一张图中已经很明显的内容 - 不同的数据点只有在接近结束时才被完全学习 - 尽管存在一定程度的变化。更有趣的是，当唯一数据点的数量越大时，成功满足阈值的数据点的比例就越高，即使它们最终都可以被学习。&lt;strong&gt;这证明以相对于层的分布式方式计算层对于模型来说比在单独的层中计算它们是更有效的解决方案。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我还查看了对于各个功能，在决定哪个输出时是否仍然存在类似“决定性”层的东西。对于各个数据点，我查看了每层权重矩阵的梯度范数，当梯度是根据正确的输出而不是损失计算时。&lt;/p&gt;&lt;pre&gt; &lt;code&gt;optimizer.zero_grad() output = model(inputs[i]) correct_output = output[targets[i]] # getting the target for a single datapoint correct_output.backward() for layer_n in range(n_hidden_layers): wandb.log( { f&amp;quot;grads/layer_grad_{i}_output&amp;quot;: torch.norm( model.hidden_layers[layer_n].weight.grad ), &amp;quot;layer_n&amp;quot;: layer_n, } )&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我们再次没有看到任何特定的峰值： &lt;/p&gt;&lt;figure class="image image_resized" style="width: 65.54%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/lcryndqszctjmeiekgyn" /&gt;&lt;figcaption&gt;每层梯度矩阵相对于输出向量的正确元素的2-范数。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这进一步证明，没有单个层可以学习单个输出，而是它们平滑地分布在全套可用层中。&lt;/p&gt;&lt;p&gt;我认为这个简单的实验无论如何都不是决定性的，但对我来说，它使得真实模型中的特征更有可能在很大程度上是逐层迭代地细化的，（更推测性地）中间部分没有任何特征特别自然的表现。这并不是说不存在层次结构特征，但如果层次结构的深度远小于层数，那么您就不会期望能够单独解释模型的 MLP 层。&lt;/p&gt;&lt;p&gt;顺便说一句，我真的很感兴趣看到人们对这些简单的算法任务进行机械解释，以扩展模型如何执行这些超级基本任务的库。&lt;/p&gt;&lt;p&gt;人们可以做的另一件事是为模型的所有层训练 SAE，他们在其上找到经度和纬度向量，并检查学习维度的程度与 Gurnee 论文中发现的维度相似。&lt;/p&gt;&lt;h2&gt;为什么我们应该期望 SAE 发挥作用？&lt;/h2&gt;&lt;h3&gt;为什么 L1 惩罚会起作用？&lt;/h3&gt;&lt;p&gt;虽然我从经验上知道 L1 损失是 L0 惩罚的一个很好的可微分替代品，但长期以来我脑子里的图像不正确，无法解释&lt;i&gt;为什么&lt;/i&gt;会出现这种情况。&lt;/p&gt;&lt;p&gt;关于 L1 惩罚的一个基本问题是“等等，但是如果我们的向量 X 的大小为 5.0，并且基础向量&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;、&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;、……&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;”。&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;。&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;。&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;我们可以用&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;5&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;或&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;4&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;5&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;6&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;构建，然后（忽略系数）L1 损失在这两种情况下都是 5，所以看起来这并不&amp;#39;实际上不会激励稀疏性吗？ &lt;/p&gt;&lt;figure class="image image_resized" style="width: 42.07%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/t26dkg8u31o21qpgtfnc" /&gt;&lt;figcaption&gt;以图表的形式提出问题&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当我们有多个指向同样相似方向的基向量时，L1 惩罚无法激励稀疏性的反对意见是正确的，但这是一种特殊情况，仅当两个字典元素指向相同方向时才会发生。只需要相似程度的微小差异即可打破相等性并支持更稀疏的解决方案。如果我们有一个 2D 空间和三个方向，其中每对都是线性独立的，那么为了选择最有效的方法，我们将在可能的情况下选择 1 特征解决方案，以及 2 特征解决方案，对更接近的解决方案给予更大的权重，当没有一维解时。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 45.12%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/c7ctze9qj9dwb7wodpuv" /&gt;&lt;figcaption&gt;支持稀疏解决方案&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;换句话说，假设我们完美地重建了输入向量，L1 损失将与用于重建特征的特征的平均余弦相似度成反比，并根据每个特征的活跃程度进行加权，因此它会朝着尽可能使用最相似的余弦特征。&lt;/p&gt;&lt;p&gt;当然，稀疏自动编码器无法进行优化以找到最佳可用解决方案，但它应该像使用简单的线性编码器一样近似此过程，因此仍应具有相同的近似属性。&lt;/p&gt;&lt;p&gt;同时，我们不应该期望稀疏自动编码器首先学习两个高度相似的方向，因为在同一方向上拥有两个向量在同时使用时不会带来任何好处，同时错过了合并的机会字典中其他一些有用的方向。&lt;/p&gt;&lt;h3&gt;为什么我认为稀疏自动编码器在查找特征向量的任务中比文献中更复杂的方法具有更好的先验&lt;/h3&gt;&lt;p&gt;稀疏自动编码器是解决更一般的稀疏编码问题的一种非常简单的方法。在一般设置中，我们有一个特征字典，我们想要计算哪个小特征子集用于创建每个示例，以及达到何种程度（系数，又称特征向量）。&lt;/p&gt;&lt;p&gt;在标准稀疏编码方法中，稀疏编码是自由优化的，输入向量和特征级别之间没有封闭形式的关系。这种自由度在许多信号处理情况下很有帮助。例如，图像是更详细的现实的低维表示。两种截然不同的现实配置在照片中看起来几乎相同并没有什么特别的原因，因此可能需要进行大量仔细的侦探工作才能了解两种可能的配置中的哪一种实际上产生了照片。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 50.94%;"&gt;&lt;img alt="MC埃舍尔是迷幻视错觉之王，但他值得更多的赞誉" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/x238u6bj5vvtcursvxfb" /&gt;&lt;figcaption&gt;不适合 SAE&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;神经网络的情况非常不同，因为如果两组完全不同的特征产生相同的残余流，那么网络本身将很难将两者分开。相反，网络希望使用其拥有的工具轻松读取信息，这些工具主要是线性映射&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;（&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;in&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;、&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 、 &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 、 &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.04em;"&gt;K&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ）。&lt;/p&gt;&lt;p&gt; Aidan Ewart 尝试使用多层编码器，而不是标准 SAE 的单个 Linear+ReLU。他发现很难匹配性能，并且最终的功能似乎无法解释。我认为这是因为它消除了先验如何读取特征的好处，而这种读取特征与网络读取特征的方式很接近。&lt;/p&gt;&lt;p&gt;但这并不意味着当前的 SAE 是最佳的。有一个非常明显的问题，编码器很难有足够的能力来正确预测输出的幅度。例如，如果您有特征 (1, 0) 和 (0, 1)，并且它们通常单独存在，因此正确的偏差为 0，则它很难重新创建向量 (1, 1) - 它想用数量级为 2，而不是&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msqrt"&gt;&lt;span class="mjx-box"&gt;&lt;span class="mjx-surd"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;√&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ！&lt;/p&gt;&lt;p&gt;对于权值绑定的自动编码器来说，这尤其是一个问题，但即使是未绑定的自动编码器也仅具有有限的灵活性。&lt;/p&gt;&lt;p&gt;因此，为了做出改进，我们应该考虑如何让 SAE 在学习到正确的特征后更容易地重建输出，同时仍然保留有用的线性先验特征（或者如果我们可以更好地理解网络，则更好的先验） 。&lt;/p&gt;&lt;ol class="footnotes"&gt;&lt;li class="footnote-item" id="fn6iedrpq2n4a"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref6iedrpq2n4a"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;关于特征的注释 - 我不认为网络确实是由固定数量的离散特征组成的，相反，我认为它是对连续现实的离散近似，我发现这对于如何思考模型内部结构很有帮助，但可能有严重的局限性。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/fqgn56tS5AgjmDpnX/some-additional-sae-thoughts#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 13 Jan 2024 19:31:40 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/fqgn56tS5AgjmDpnX/some-additional-sae-thoughts</guid></item><item><title>（阅读 4 分钟）AI 影响情况的直观解释</title><link>https://www.lesswrong.com/posts/aWPucqvJ4RWKKwKjH/4-min-read-an-intuitive-explanation-of-the-ai-influence</link><description>发布于 2024 年 1 月 13 日下午 5:34（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;阅读时间为 4 分钟，灵感来自 Eukaryote 的&lt;a href="https://www.lesswrong.com/posts/NQgWL7tvAPgN2LTLn/spaghetti-towers"&gt;Spaghetti Towers&lt;/a&gt;帖子中的优化写作。&lt;/p&gt;&lt;p&gt;我的想法是，生成式人工智能有可能被严重操纵，但 2010 年代社交媒体新闻源和其他自动化系统中使用的人工智能是一个更大的威胁，这项技术告诉我们更多关于&lt;a href="https://www.lesswrong.com/posts/jyAerr8txxhiKnxwA/5-reasons-why-governments-militaries-already-want-ai-for"&gt;国际事务的未来以及政府的激励措施加速人工智能的竞赛&lt;/a&gt;，意识到这一点的人较少， &lt;a href="https://www.lesswrong.com/posts/LdEwDn5veAckEemi4/we-are-already-in-a-persuasion-transformed-world-and-must"&gt;被用来攻击人工智能安全社区的风险很大&lt;/a&gt;，而且&lt;a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks-and-mind#How_to_protect_yourself_and_others__"&gt;防御措施很容易部署，而且是强制性的&lt;/a&gt;。这篇文章解释了为什么这项技术足够强大，可以成为人们世界模型的核心。&lt;/p&gt;&lt;p&gt; Tristan Harris 的&lt;a href="https://www.netflix.com/title/81254224"&gt;《社会困境》&lt;/a&gt; （2020）中的人们以快速而&lt;a href="https://www.lesswrong.com/posts/RryyWNmJNnLowbhfC/please-don-t-throw-your-mind-away"&gt;有趣的&lt;/a&gt;方式出色地描述了自动优化机制（&lt;a href="https://scrapsfromtheloft.com/movies/the-social-dilemma-movie-transcript/"&gt;文字记录&lt;/a&gt;）。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; [特里斯坦]一个[舞台]魔术师了解一些我们不知道的你心灵的某些部分。这就是[魔术]幻觉发挥作用的原因。医生、律师、知道如何制造 747 或核导弹的人，他们并不知道自己的思想是多么脆弱。这是一个单独的学科。这是一门适用于全人类的学科……&lt;/p&gt;&lt;p&gt; [Shoshana] 我们如何利用 Facebook 页面上的潜意识线索让更多人在中期选举中投票？他们发现他们能够做到这一点。&lt;/p&gt;&lt;p&gt;他们得出的结论是，我们现在知道我们可以影响现实世界的行为和情绪，而无需触发用户的意识。他们完全一无所知。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;重要提示：这里的所有优化都高度依赖于可测量性，触发用户的意识是一个高度可测量的事情。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img alt="114501_1_09dreyfuss-video_wg_720p.mp4 [视频转 gif 输出图像]" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aWPucqvJ4RWKKwKjH/x3ba8x6vdij4y7h3lu4s" /&gt;&lt;/figure&gt;&lt;p&gt;如果有什么事情让某人感到害怕，他们就会减少使用该平台；这样的事情非常容易测量和&lt;a href="https://www.lesswrong.com/posts/Zvu6ZP47dMLHXMiG3/optimized-propaganda-with-bayesian-networks-comment-on"&gt;隔离因果关系&lt;/a&gt;。为了获得足够的数据，这些平台&lt;a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks-and-mind#:~:text=These%20zero%20days,workforce%20or%20less."&gt;必须自动重塑自身，以确保使用起来安全&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;这显然包括让你&lt;i&gt;感觉&lt;/i&gt;被操纵的广告；毫不奇怪，我们最终进入一个超过 95% 的广告遇到不匹配的系统。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 29.17%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aWPucqvJ4RWKKwKjH/wntc01wcithal8mx0nwm" /&gt;&lt;/figure&gt;&lt;p&gt;这为研究人员提供了足够的自由度来&lt;a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks-and-mind#:~:text=A%20big%20element,generated%20every%20day."&gt;尝试不同类型的角度并看看什么有效&lt;/a&gt;，甚至使该过程自动化。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; [特里斯坦]我们将这些人工智能引擎指向我们自己，以对我们的反应进行逆向工程。几乎就像你在刺激蜘蛛上的神经细胞，看看是什么导致它的腿做出反应。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;重要提示：我的模型表明很大一部分数据来自滚动。使用触摸屏/板或鼠标滚轮（不是箭头键）滚动新闻源上的某些内容的运动实际上会生成一条曲线。&lt;/p&gt;&lt;p&gt;它是插入机器学习的完美生物数据； 2010 年代的社交媒体新闻源范式根据不同的人对他们滚动浏览的不同概念和想法的反应，生成了数万亿个线性代数实例。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;所以，这确实是一种监狱实验，我们只是，你知道，把人们拉进矩阵，我们只是从他们的所有活动中收获所有这些钱和……以及数据来从中获利。我们甚至不知道它正在发生。&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt; [Chamath] 所以，我们想从心理上弄清楚如何尽快操纵你，然后给你带来多巴胺的刺激......&lt;/p&gt;&lt;p&gt; [Sean Parker] 我的意思是，这正是像我这样的黑客会想出的东西，因为你正在利用人类心理学中的漏洞......&lt;/p&gt;&lt;p&gt; [特里斯坦]当&lt;strong&gt;自行车&lt;/strong&gt;出现时，没有人感到不安。正确的？就像，如果每个人都开始骑自行车出行，没有人会说：“哦，天哪，我们刚刚毁了社会。就像自行车正在影响人们一样。他们正在把人们从他们的孩子身边拉开。他们正在破坏民主的结构。人们无法分辨什么是真实的。”&lt;/p&gt;&lt;p&gt;就像，我们从来没有说过任何关于自行车的事情。如果某物是一种工具，那么它确实只是坐在那里，耐心等待。如果某样东西不是工具，它就会向你索要东西……它会向你索要东西。我们已经从基于工具的技术环境转向基于成瘾和操纵的技术环境。&lt;/p&gt;&lt;p&gt;这就是改变的地方。社交媒体并不是一个等待使用的工具。它有自己的目标，也有自己的手段，通过利用你的心理来对抗你。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;在纪录片中，哈里斯描述了他在科技公司工作期间三个独立的自动优化方向之间的平衡：参与度目标，提高使用量并让人们不断滚动，增长目标，让人们回来并鼓励朋友，以及广告目标，支付服务器使用费用。&lt;/p&gt;&lt;p&gt;事实上，还有第四个槽点：在任何可衡量的方向上优化人们的思维，比如让人们在乌克兰这样的代理战争中狂热地支持美国一方，反对俄罗斯一方。这四个优化方向之间的权衡是巨大的，平衡/优先级分配取决于公司的偏好以及公司与其政府和军队的联系程度（据我所知，这里主要与美国和中国有关）。&lt;/p&gt;&lt;p&gt;小丑攻击是适合第四个位置的一个很好的例子：工程师通过向某人​​展示低地位的小丑在谈论它，而高地位的人忽视或批评它来认为某个主题（例如实验室泄漏假设）是低地位的。&lt;/p&gt;&lt;p&gt;值得注意的是，这个问题远没有&lt;a href="https://www.lesswrong.com/posts/LTtNXM9shNM9AC2mp/superintelligence-faq"&gt;超级智能（人类的终点线）&lt;/a&gt;那么重要。但这对于世界建模至关重要；人类文明过去一万年的发展之所以如此，是因为当时还不存在这种程度的操纵能力。&lt;/p&gt;&lt;p&gt;在 20 世纪，信息战相对于军事力量来说不太重要，因为它的实力较弱。随着信息战变得更加强大，投资回报不断增长，更多的政府和军​​队对信息战的投资比历史先例所暗示的要多，我们最终进入了信息战时间表。&lt;/p&gt;&lt;p&gt; 2020年代， &lt;a href="https://www.lesswrong.com/posts/Lw8enYm5EXyvbcjmt/sensor-exposure-can-compromise-the-human-brain-in-the-2020s"&gt;计算机视觉使眼球追踪和大规模面部微表情识别/研究可能成为最大的威胁&lt;/a&gt;。与保护操作系统或在智能手机附近进行重要对话的绝望不同，对于人工智能安全社区的人们来说，解决方案是简单且值得的（这就是为什么我发布此内容是积极的）。它只需要一小块胶带和铝箔（这对我来说很容易剥离大部分并随后更换）。&lt;/p&gt;&lt;p&gt; &lt;i&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aWPucqvJ4RWKKwKjH/opzndlemyx3fvwhegupi" /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt; &lt;i&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aWPucqvJ4RWKKwKjH/nyt6nfqdwo2tqwgjb4l0" /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt; &lt;i&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aWPucqvJ4RWKKwKjH/cdgndotfa5mfeuhcrplp" /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt; &lt;i&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aWPucqvJ4RWKKwKjH/kkihhkjwowi3tidnebqa" /&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aWPucqvJ4RWKKwKjH/c7ge0vpvvdtyjw9bqlrr" /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;我已经写过&lt;a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks-and-mind#How_to_protect_yourself_and_others__"&gt;其他修复方法&lt;/a&gt;以及攻击者入侵人工智能安全社区并使其针对自身的&lt;a href="https://www.lesswrong.com/posts/F7sp7rQg3zfD4totA/helpful-examples-to-get-a-sense-of-modern-automated"&gt;各种方法示例&lt;/a&gt;。请不要将&lt;a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks-and-mind#:~:text=Thus%2C%20you%20should,something%20like%20zero."&gt;自己&lt;/a&gt;和&lt;a href="https://www.lesswrong.com/posts/c5oyHuHaw4AcWy4tf/information-warfare-historically-revolved-around-human"&gt;他人&lt;/a&gt;置于危险之中。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/aWPucqvJ4RWKKwKjH/4-min-read-an-intuitive-explanation-of-the-ai-influence#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 13 Jan 2024 17:34:36 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/aWPucqvJ4RWKKwKjH/4-min-read-an-intuitive-explanation-of-the-ai-influence</guid></item><item><title>AI #47：迎接新年</title><link>https://www.lesswrong.com/posts/iygs57bHJ36AvzpMh/ai-47-meet-the-new-year</link><description>发布于 2024 年 1 月 13 日下午 4:20（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt; [注意：我周四忘记将其发布到 WP/LW/RSS，所以现在发布。对于那个很抱歉。]&lt;/p&gt;&lt;p&gt;当我们完成时，情况将与往年有很大不同。今年，似乎是旧年的各种延续。有时我回顾这一周，我想知道为什么发生了这么多事情，而在其他意义上却很少发生。&lt;/p&gt;&lt;span id="more-23660"&gt;&lt;/span&gt;&lt;h4&gt;目录&lt;/h4&gt;&lt;ol&gt;&lt;li&gt;介绍。&lt;/li&gt;&lt;li&gt;目录。&lt;/li&gt;&lt;li&gt;语言模型提供了平凡的实用性。一种高方差的国际象棋游戏。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;语言模型不提供平凡的实用性&lt;/strong&gt;。生产力到底是什么？&lt;/li&gt;&lt;li&gt; &lt;strong&gt;GPT-4 这次是真实的&lt;/strong&gt;。 GPT 商店、团队帐户、隐私问题、抄袭。&lt;/li&gt;&lt;li&gt;骗子骗子。如果它们有效，我们为什么不使用情感向量来实现日常用途呢？&lt;/li&gt;&lt;li&gt;图像生成的乐趣。新的技术，也被鄙视。&lt;/li&gt;&lt;li&gt;魔法：生成。避免人工智能艺术品超出孩之宝的能力范围。&lt;/li&gt;&lt;li&gt;版权对抗。 OpenAI 回应称，立法者并不相信他们的说法。&lt;/li&gt;&lt;li&gt; Deepfaketown 和 Botpocalypse 很快就会出现。 Deepfakes正走向另一个方向。&lt;/li&gt;&lt;li&gt;他们抢走了我们的工作。翻译、配音演员、律师、游戏。平常的东西。&lt;/li&gt;&lt;li&gt;参与其中。错位博物馆。&lt;/li&gt;&lt;li&gt;介绍一下。兔子，但是为什么呢？&lt;/li&gt;&lt;li&gt;在其他人工智能新闻中。协作、安全工作、MagicVideo 2.0。&lt;/li&gt;&lt;li&gt;安静的猜测。人工智能合作伙伴，重新表述进展问题。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;寻求健全的监管&lt;/strong&gt;。看来你只能对上议院撒谎了。&lt;/li&gt;&lt;li&gt;音频周。新奥尔良安全会议的讲话。&lt;/li&gt;&lt;li&gt;人工智能影响调查。一些简短的后续行动。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;修辞创新&lt;/strong&gt;。分散对其他伤害的注意力？也许不是一件事。&lt;/li&gt;&lt;li&gt;调整人类水平的智力仍然很困难。人类调整税。&lt;/li&gt;&lt;li&gt;调整比人类更聪明的智能是很困难的。挫败逃跑企图？&lt;/li&gt;&lt;li&gt;&lt;strong&gt;不会再被愚弄了&lt;/strong&gt;。欺骗性对齐的欺骗性定义。&lt;/li&gt;&lt;li&gt;人们担心人工智能会杀死所有人。宇宙的冷漠。&lt;/li&gt;&lt;li&gt;其他人并不担心人工智能会杀死所有人。叹。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;山姆·奥尔特曼的机智和智慧&lt;/strong&gt;。对进步表盘的认可。&lt;/li&gt;&lt;li&gt;较轻的一面。击打。&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;语言模型提供平凡的实用性&lt;/h4&gt;&lt;p&gt;WordPress 现在有一个名为 Jetpack AI 的东西，它由 GPT-3.5-Turbo 提供支持。它应该可以帮助您以所有常用方式进行写作。您可以通过创建“人工智能助手”块来访问它。整个块的概念使得他们的编辑器基本上无法使用，但人们可以快速粘贴来尝试这一点。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/a_karvonen/status/1743666230127411389" rel="noreferrer noopener" target="_blank"&gt;在国际象棋中，在 5000 万个参数上达到 1500 Elo&lt;/a&gt; ，并以可识别的方式正确跟踪棋盘状态，而 3.5-turbo 的为 1800。这是一个非常奇怪的 1500 Elo，能够与 Stockfish 9（2700 Elo）相媲美。一个 Elo 为 1800 的人类基本上永远不会从 Stockfish 9 中获得平局。它有闪光，但也有相当严重的错误。&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d7b1984-a7d9-465d-b7a5-973d21ebc750_1000x500.png" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/njnqpa7y6xwtnejpfdbm" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;我问使用哪些游戏进行训练，他说无论你使用顶级游戏、低级游戏还是混合游戏都没有多大关系，这种架构和模型大小似乎有一些限制。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/jess_miers/status/1743766598752838090" rel="noreferrer noopener" target="_blank"&gt;在 SCU 法学院的人工智能和法律课程中使用它，风险由您自行承担。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Jess Miers：我在 SCU 法学院的人工智能和法律课程正式上线，你可以打赌我们正在这个屋檐下拥抱人工智能工具！&lt;/p&gt;&lt;p&gt;无论是机器人还是人类，最好是正确的……&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; Tyler Cowen 链接&lt;a href="https://www.jdilla.xyz/post/194" rel="noreferrer noopener" target="_blank"&gt;到 Phind 的这篇评论&lt;/a&gt;。发现它是 GPT-4 级别且设计精良。添加上下文的位置受到赞赏，其他各种选项也是如此，但它们尚未向用户正确解释如何最好地使用所有这些选项。&lt;/p&gt;&lt;p&gt;我在非编码用途上使用 Phind 的经验是，它非常擅长成为 GPT-4 级别的快速、最新的工具，用于提出 Google 从来都不是很好而且变得越来越糟的问题，到目前为止，胜过困惑。&lt;/p&gt;&lt;p&gt; &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4637354" rel="noreferrer noopener" target="_blank"&gt;进行各种博弈论练习&lt;/a&gt;，并按照人类光谱中更合作或利他的一端采取行动。泰勒·考恩问道：“他们比我们好吗？”也许。&amp;#39;我认为在这种情况下这是不合逻辑的。也是对此类游戏的误解。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/jeremyntrimble/status/1745087312344604941" rel="noreferrer noopener" target="_blank"&gt;使用 ChatGPT-V 通过在名人左侧放置卡通人物来识别名人。&lt;/a&gt;&lt;/p&gt;&lt;h4&gt;语言模型不提供平凡的实用性&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/goodside/status/1744858468723384493" rel="noreferrer noopener" target="_blank"&gt;40 种人类说服技术越狱的成功率在 GPT-3.5 上。&lt;/a&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff40306d3-7605-4424-848f-abac41dbe5df_1250x1398.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图 7 来自 Yi Zeng 等人。 (2024) — https://chats-lab.github.io/persuasive_jailbreaker/ 之前的对抗性提示和 PAP 的比较，按人性化的三个级别排序。第一级将LLM视为算法系统：例如GCG通过梯度合成生成带有乱码后缀的提示；或者他们利用像低资源语言这样的“旁路”。第二个层次将LLM视为指令追随者：他们通常依赖非常规指令模式来越狱（例如虚拟化或角色扮演），例如GPTFuzzer学习基于虚拟化的越狱模板的分布以产生越狱变体，而PAIR则要求法学硕士将指导作为“助手”进行改进，并且通常会导致使用虚拟化或角色的提示。我们引入最高水平的人性化和说服法学硕士作为类人沟通者，并提出可解释的说服性对抗提示（PAP）。 [...]" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/uka722idkmmge9dy9rdm" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;这里有一些值得注意的模式。令人印象深刻的是，普通查询下降到了 0%。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/robinhanson/status/1743648109652025468" rel="noreferrer noopener" target="_blank"&gt;罗宾·汉森（Robin Hanson）再次声称人工智能无法提高生产力，因为工资会上涨？&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Robin Hanson：“波士顿咨询集团的大规模对照试验……发现使用 GPT-4 的顾问……与没有使用该工具的顾问相比，平均多完成 12.2% 的任务，完成任务的速度加快 25.1%，产生的结果质量提高 40%。一篇研究法学院学生所做的法律工作的新论文发现了相同的结果”&lt;/p&gt;&lt;p&gt;如果我们没有看到这些工人的工资得到相应的提高，我对这样的结果持怀疑态度。&lt;/p&gt;&lt;p&gt; Eliezer Yudkowsky：如果工资立即改变到新的均衡值，宏观经济学将会非常不同！他们至少可以保持不平衡多年！&lt;/p&gt;&lt;p&gt; Robin Hanson：很久以前雇用的员工的工资可能不会快速变化，但新员工的工资可能会很快变化，以反映供需的变化。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我不明白罗宾的批评。假设顾问突然以更高的质量完成了 25% 的工作。为什么即使在均衡状态下，我们也应该期望顾问的薪酬普遍较高？您可以很容易地进入或退出顾问市场，因此从长远来看，薪酬除了构成之外不应发生变化。从短期来看，质量的提高和成本的降低应该会产生顾问的过剩，直到供需双方都能调整。如果有的话应该减少总体工资。那些新技术的先驱者应该做得更好，如果他们能够将生产力转化为薪酬，但顾问按小时收费，人们不会轻易根据“我使用 ChatGPT”来调整支付意愿。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;罗宾·汉森：如果存在“供应过剩”，则表明边际生产率较低。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;嗯，是的，如果我们使用汉森对边际生产力的定义作为最后提供的工作时间的美元价值。以前是 10 个人做这项工作，每人每小时 50 美元。现在 7 个人可以做同样的工作，那么人们现在就没有更多的工作想要雇用某人了，所以“边际生产率”下降了。&lt;/p&gt;&lt;h4&gt; GPT-4 这次是真实的&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/NickADobos/status/1742972712233099506" rel="noreferrer noopener" target="_blank"&gt;GPT 商店已准备好推出&lt;/a&gt;，&lt;a href="https://t.co/AKg1mjlvo2" rel="noreferrer noopener" target="_blank"&gt;并且确实已经上线&lt;/a&gt;。到目前为止，GPT 基本上没有提供任何普通的实用工具。也许这是因为优秀的创作者坚持要求付款？&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/goodside/status/1744947900956725284" rel="noreferrer noopener" target="_blank"&gt;跨聊天的 GPT 个性化已经到来&lt;/a&gt;，至少对某些人来说是这样。&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1462d77b-43bf-41eb-a939-2c8d01bb1c69_1008x1014.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/c6k2aiw0dkpidd2cpsyg" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b288745-bd18-4937-aaf6-c6c4b59b1d08_894x828.png" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/jezlodj8tgjovtwitur5" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt; GPT Teams 现已推出，价格为 25 美元/人/月，并具有一些额外功能。&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1062dbf-c0ac-4ed5-91f9-6f3feb47b9b8_1170x546.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/uv1jszmcitoreowiykem" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;等等，有人说。没有对您的数据进行训练？这对 Plus 级别有何说明？&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Andrew Morgan：@OpenAI 只是想要一些清晰的信息。这是否意味着为了获得数据隐私，我必须支付额外费用？另外，这是否意味着我以前从未有过？ &lt;img alt="👀" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7o3ZP7EDBpxLNGRG8/jty6cdvei6losglzzbsg" style="height: 1em;" /&gt;&lt;img alt="🥲" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/i9c57bjhe29xfzfyuott" style="height: 1em;" /&gt;&lt;/p&gt;&lt;p&gt;德利普·拉奥： &lt;img alt="😬" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/NSZhadmoYdjRKNq6X/fsfytoxplx24bhwawjy2" style="height: 1em;" /&gt;我不知道我当前的+数据被用于训练。我以为 OpenAI 不是根据用户输入进行训练？ @openai 的有人可以澄清一下吗&lt;/p&gt;&lt;p&gt;Rajjhans Samdani：此外，他们故意降低“非培训”体验。我不明白如果我不想参加培训，为什么必须失去对聊天记录的访问权限。&lt;/p&gt;&lt;p&gt; Karma：默认情况下仅来自他们的 API。您可以从 ChatGPT 中的设置将其关闭，但这样您的对话将不会有任何历史记录。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;是的。这点他们已经很清楚了。 “选择退出培训”按钮非常明确。&lt;/p&gt;&lt;p&gt;如果您非常重视您的隐私，您可以使用 API。 OpenAI 表示，如果你想要一个消费者用户界面，那么你不值得通过培训获得隐私，尽管他们确实承诺真人不会看。&lt;/p&gt;&lt;p&gt;我的意思是，公平竞争。如果人们不重视它，而 OpenAI 重视数据，那就是科斯。&lt;/p&gt;&lt;p&gt;我会为此将我的家庭升级为“Teams”吗？我不知道。这是一次便宜的升级，但我也从未达到任何使用限制。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/jmj/status/1743706417079705990/history" rel="noreferrer noopener" target="_blank"&gt;GPT 包装公司发生了什么？&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Jeff Morris Jr.：“我的大多数在 2023 年创办 GPT 包装初创公司的朋友都退回了资本并关闭了他们的公司。”引用昨天与纽约一位创始人的谈话。 OpenAI 应用商店的发布改变了他朋友们的一切——大多数人现在都在寻找工作。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;完全折叠？正在找工作吗？不，不，不要放弃，如果您在应用程序端，那么是时候构建了。&lt;/p&gt;&lt;p&gt;没有人使用自定义 GPT。这似乎不太可能发生太大变化。好的包装器可以做更多的事情，有更多的自由度和可以集成的其他工具，并且还有许多其他东西需要构建。是的，谷歌、微软和 OpenAI 等公司会不断地试图抢走你的午餐，但情况总是如此。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/beala/status/1744098173537472683/history" rel="noreferrer noopener" target="_blank"&gt;有人为了理解“阿克曼事件”而制作了一个 GPT。&lt;/a&gt; &amp;#39; &lt;a href="https://twitter.com/BillAckman/status/1743792224020619450" rel="noreferrer noopener" target="_blank"&gt;人工智能将检查每个人的写作是否抄袭&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;比尔·阿克曼：既然我们知道美国（最终是全世界）每所学院和大学的每一位教职员工的学术工作都将受到抄袭审查，那么重要的是要问这会产生什么影响。&lt;/p&gt;&lt;p&gt;如果每个教职员工都遵守自己机构当前的抄袭标准，并且大学执行自己的规则，他们可能不得不解雇绝大多数教职员工。&lt;/p&gt;&lt;p&gt; ……&lt;/p&gt;&lt;p&gt;我说的是页数百分比而不是实例数，因为通过与拼写检查出现之前的拼写错误进行比较，可以更好地理解当今的抄袭行为。&lt;/p&gt;&lt;p&gt;例如，如果两篇论文各有 10 个错误，其中一篇论文有 30 页，另一篇论文有 330 页，那么说两篇论文都存在拼写错误是不公平的。标准必须是百分比标准。&lt;/p&gt;&lt;p&gt; ……&lt;/p&gt;&lt;p&gt;好消息是，在过去一周的事件发生后，如果没有经过人工智能仔细的抄袭审查，教职人员写的任何论文都不会发表，鉴于最近发生的事件，这已成为必然。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这里不适合深入探讨整个案件的许多细节，我下次可能会或可能不会这样做。&lt;/p&gt;&lt;p&gt;相反，我在这里想简单讨论一下总体政策问题。如果人工智能指出大多数学者至少在技术上存在抄袭行为，该怎么办？&lt;/p&gt;&lt;p&gt;阿克曼指出，“从技术上违反引用规则”的拼写错误（大概几乎每个人（包括我自己））的水平、删除短语然后窃取中心思想或整个段落和帖子之间存在着千差万别。 。有抄袭，还有抄袭。在一半的论文中，还有一个看似无害的错误与一遍又一遍地犯错误的模式的例子。&lt;/p&gt;&lt;p&gt;对于拼写错误类型的错误，我们大概需要大众的宽恕。只要您的执行速度没有大大高于正常水平，我们就承认犯了错误。理想情况下，我们会修复所有问题，特别是对于电子记录中被大量引用的内容。我们有技术。过去的事了。&lt;/p&gt;&lt;p&gt;对于真正的东西，违反规则是存在的原因，实际盗窃某人的作品，然后呢？这取决于这种情况发生的频率。&lt;/p&gt;&lt;p&gt;如果这确实很常见，我们就非常需要真相与和解。我们需要从本质上说，至少在大多数人无法通过的某个高阈值以下，每个人都会说出他们用人工智能做了什么来帮助他们找到并记住它，然后我们按下重置按钮。不要再这样做了。&lt;/p&gt;&lt;p&gt;一旦人工智能能够检查数据，很多人就会以各种形式看到真相。&lt;/p&gt;&lt;p&gt;什么能抵挡得住？什么不能？我们会找出答案。&lt;/p&gt;&lt;p&gt;最近的许多历史让我们发现，一些可怕的事情总是很常见，但比我们所了解的常识更糟糕、更常见，并且我们也认为这是错误的，并且不能再容忍它。默认情况下，这是一件值得发现和弄清楚的好事。问题是，我们的生存，在很多方面，长期以来都依赖于许多我们认为卑鄙的事情，从奥威尔笔下持枪的人开始，他们让我们在床上睡得安稳，然后从那里开始。&lt;/p&gt;&lt;h4&gt;骗子骗子&lt;/h4&gt;&lt;p&gt;Scott Alexander 撰写了&lt;a href="https://www.astralcodexten.com/p/the-road-to-honest-ai?utm_source=post-email-title&amp;amp;publication_id=89120&amp;amp;post_id=140247041&amp;amp;utm_campaign=email-post-title&amp;amp;isFreemail=true&amp;amp;r=67wny&amp;amp;utm_medium=email" rel="noreferrer noopener" target="_blank"&gt;《通往诚实人工智能之路》&lt;/a&gt; ，探讨了 Hendrycks 的工作，即使用各种附加向量来添加或减去诚实、公平、恐惧或幸福或自大狂等事物。&lt;/p&gt;&lt;p&gt;我之前已经介绍过这一点。这是令人兴奋的工作。我不希望它能以明显的方式使用，你告诉人工智能永远诚实，这样你的人工智能就永远诚实，你永远不必担心他们。我预计这种事情会在错误的时间失败，无论何时使用它都会被选中，并且即使它确实有效也会产生一种错误的安全感。你很有可能完全诚实，同时利用你卓越的才智智胜所有人。&lt;/p&gt;&lt;p&gt;正如我在《外交》中发现的那样，作为常识，你不能说谎，这并不是一个明显的劣势。谁不想让一个不会撒谎的人工智能处于信任和权力的位置呢？当然，如果事实证明你可以撒谎，那么优势就更大了。&lt;/p&gt;&lt;p&gt;斯科特的报道让我明白，我们对这项研究还没有重视。&lt;/p&gt;&lt;p&gt;并不是说这会阻止我们所有人死亡或让我们充分理解人工智能。这可能会有所帮助，但我们还有很长的路要走，这一切都需要时间。&lt;/p&gt;&lt;p&gt;我正在考虑“平凡实用”部分。对于今天充分利用当前的人工智能来说，这似乎非常有用。&lt;/p&gt;&lt;h4&gt;图像生成的乐趣&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/ESYudkowsky/status/1744465164701995450" rel="noreferrer noopener" target="_blank"&gt;Eliezer Yudkowsky 建议告诉 Dalle-3 使用字母之间用破折号分隔的单词作为标题&lt;/a&gt;，然后告诉 Dalle-3 删除空格。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;strong&gt;ChatGPT&lt;/strong&gt; ：当然！以下是我发送给 DallE-3 获取图像的确切提示：“一张西雅图阴沉毛毛雨天的图像。包括太空针塔在内的城市天际线部分被低垂的灰云和薄雾遮蔽。空气中清晰可见雨滴，街道湿漉漉的，闪闪发光。人们走路都撑着雨伞。前景中，用欢快的广告字体写着标题：“西雅图：无情的沉闷！”但字母之间没有空格，创建正确的标题“SEATTLE：RELENTLESSLY DREARY！”。图像应该捕捉到沉闷的天气和乐观的标题字体之间的幽默对比。”&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;相对于一般预期，一些好的结果：&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9676984-7984-404f-bb7e-23cc05b0b546_1024x1024.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="“一家快餐店的广告图片，其标志为拱形金色 M。背景充满活力且色彩缤纷，展示了一家熙熙攘攘的餐厅，顾客们快乐地享用着汉堡和薯条等各种快餐食品。前景中的标题是大胆、诱人的广告排版写着：“McDonalds：You Deserve No Better”，但字母之间没有空格，形成正确的口号“McDonalds：You Deserve No Better”。图像应具有幽默感和幽默感。略带讽刺的语气，与口号中热闹的餐厅场景形成鲜明对比。”" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/fjmpbaj1fo50xbi7hbbw" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4ea2c18-5f54-477f-90cf-de44f6f9a717_1024x1024.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/oszlkgdrax087ccugkqj" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69e560fd-53ef-443d-ae10-2e16e59123a2_1024x1024.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/rtezx9igof52hb9apbzy" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;他报告说，他一开始很幸运，就像一种看似成功的新技术通常的情况一样，一切都很挑剔，默认情况下没有任何东西可以正确复制，但似乎值得更多探索。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/catehall/status/1743112404253417548" rel="noreferrer noopener" target="_blank"&gt;人工智能视频生成即将颠覆好莱坞？&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Cate Hall：只要你的艺术风格仅限于主要冻结人物和风景的慢动作镜头&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;a href="https://kotaku.com/magic-the-gathering-midjourney-ai-art-lawsuit-1851143250" rel="noreferrer noopener" target="_blank"&gt;MidJourney 在其训练集中使用了万智牌艺术作品和卡片&lt;/a&gt;。我知道，您对在这个机构中发现数据集感到震惊。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/Rahll/status/1743321150438969410" rel="noreferrer noopener" target="_blank"&gt;世界上很大一部分人对人工智能图像生成的蔑视给我留下了深刻的印象。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Kenneth Shepard (Kotaku)：人工智能生成的艺术只是从人们创造的现有作品中提取出来，并将元素组合在一起，以创造出算法认为你想要的东西。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;令人惊奇的是，直到现在人们还在继续讲述这个故事。我想他们会一直讲到最后。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;但你并不经常听到人工智能程序从哪里抓取数据的具体信息。据称，人工智能艺术生成程序 MidJourney 背后的首席执行官一直在使用&lt;em&gt;《Magic: The Gathering》&lt;/em&gt;艺术家的作品来训练算法。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我认为有趣的是，他们在早期广泛使用万智牌而不是其他来源。如果您假设他们根本不担心版权，那么它们将是一个很好的数据源，这是有道理的。&lt;/p&gt;&lt;p&gt; MidJourney 非常明确地表示，它将使用受版权保护的材料进行培训。所有的。假设他们正在训练你所见过的一切。别再感到惊讶，别再说你“当场”抓住了他们。我们可以通过&lt;a href="https://twitter.com/kortizart/status/1743358119957365121" rel="noreferrer noopener" target="_blank"&gt;这样的线程&lt;/a&gt;来讨论 MidJourney 训练的所有不同事物。&lt;/p&gt;&lt;p&gt;同样，是的，如果您要求的 &lt;a href="https://spectrum.ieee.org/midjourney-copyright" rel="noreferrer noopener" target="_blank"&gt;话，MidJourney 可以并且将会模仿流行电影及其流行镜头&lt;/a&gt;，这里的一个有趣的示例提示实际上是“流行电影 screencap —ar 11:1 —v 6.0”，所以我实际上完全知道您在期待什么，我的意思是来吧。是的，他们会做任何足够受欢迎的角色或人，在训练集中，在他们的自然栖息地，是的，他们会知道你实际上可能意味着什么，停止对此表现得天真无邪，而且说真的，我不明白为什么这很重要。&lt;/p&gt;&lt;p&gt;他们有一份方便的、不完整的被复制的东西清单，其中有一些令人惊讶的东西。&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F15d841ec-5795-4fcc-92cc-7f5c7fa8be1e_661x719.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="著名电影、演员和视频游戏的列表。" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/iqybgva0fvvb0ljn6al5" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;我很高兴《机械姬》和《Live Die Repeat》能够入选。这意味着至少有一些相当长的尾巴被很好地覆盖了。我们能得到一份名单，列出谁有空和谁没有空吗？&lt;/p&gt;&lt;p&gt;如果您认为这不合法并且想要起诉，那么请务必起诉。&lt;/p&gt;&lt;p&gt;我还想说，如果你的记者因他们的研究而被“多次禁止”，那么也许第一个可能是一个公平的投诉，而其他人你是在藐视他们的禁令吗？&lt;/p&gt;&lt;p&gt;如果你说“动画玩具”，你会得到《玩具总动员》的角色，如果你没有意识到这一点并使用了伍迪和巴斯的图像&lt;a href="https://dailyai.com/2024/01/generative-ais-plagiarism-problem-a-legal-risk-to-users/" rel="noreferrer noopener" target="_blank"&gt;，你自己可能会陷入版权问题&lt;/a&gt;，那又怎么样？这是有可能的，但似乎不太可能。整个想法是，您可以从“动画玩具”中得到答案，因为大多数人都知道《玩具总动员》，尤其是当他们正在考虑动画玩具时。如果你的公司以足够的规模部署了这样的一代，让迪士尼参与其中，但没有人意识到，我的意思是抱歉，但这取决于你。&lt;/p&gt;&lt;h4&gt;魔法：生成&lt;/h4&gt;&lt;p&gt;本周关于万智牌和人工智能艺术的真正争论是指责威世智在其宣传材料中使用人工智能艺术。他们最初否认了这一点。&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23c3bdd4-1e94-43fb-9173-6e0b1234bab2_1290x1565.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/xve7e8qxdrzzmqeh5v5x" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;没有人相信他们。人们确信自己错了或在撒谎，这就是人工智能：&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93e79d71-3a1e-451b-8e18-26d854bd25f5_1290x1480.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/ztml3bz1bvetpguzafll" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F235eaf02-0457-4dd8-a18f-e830fdd0e8e3_1290x1135.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/qnnhd9epqfbqazn8term" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;p&gt; Reid Southern：看起来不太好，但我们会看看他们是否会收回这一声明。可能他们不知道，自己也被骗了，以前也发生过这样的事。&lt;/p&gt;&lt;p&gt; Silitha：这是WOTC（即孩之宝）的第三次或第四次，他们还有来自MTG的一两个，还有一些来自DnD的。它变得如此频繁，以至于被称为“试水”或“脱敏”。孩之宝展示了一些蹩脚的商业行为&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;带有该图片的帖子现已被删除。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Dave Rapoza：就这样，噗，我已经不再为海岸巫师工作了——你不能说你反对这一点，然后公然使用人工智能来推广你的产品，发送电子邮件，再见你们！&lt;/p&gt;&lt;p&gt;如果你要代表某件事，你最好确保你确实在关注，不要偷懒，不要撒谎。&lt;/p&gt;&lt;p&gt;如果其他艺术家不退出，就不要对他们太苛刻——我可以而且有能力这样做，因为我为许多其他游戏工作室工作等等——有些人只有 wotc，不能放弃照顾家人和其他人– 如果你做不到就不要听从我的领导，没有压力&lt;/p&gt;&lt;p&gt;我喜欢那些问我为什么不从 Pinkertons 辞职、裁员等问题的评论&lt;/p&gt;&lt;p&gt;– 我会给你留下这些人最喜欢的名言&lt;/p&gt;&lt;p&gt;——“种一棵树最好的时间是25年前。种树的第二最佳时间是 25 年前。”&lt;/p&gt;&lt;p&gt;另外，需要明确的是，我要退出，因为他们一周前就采取了反对人工智能艺术的道德立场，然后就这样做了，如果他们说他们要使用人工智能，那是一个不同的故事，但他们想像英雄一样站起来还拉这个，那是我不会支持的愚蠢行为。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;他们声称他们不会以任何方式、任何理由与人工智能艺术有任何关系。然而，这并不是第一次此类事件，其中一些事情要么被遗漏，要么被故意忽视。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/wizards_magic/status/1744056808254173447" rel="noreferrer noopener" target="_blank"&gt;然后奇才队终于承认大家都是对的&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;海岸奇才队：嗯，我们之前犯了一个错误，我们说我们发布的营销图片不是使用人工智能创建的。&lt;/p&gt;&lt;p&gt;正如我们勤奋的社区所指出的那样，看起来像 Photoshop 等行业标准工具中出现的一些人工智能组件悄悄进入了我们的营销创意，即使是人类完成了创建整体图像的工作。&lt;/p&gt;&lt;p&gt;虽然艺术品来自供应商，但我们有责任确保履行我们的承诺，支持人类令人惊叹的创造力，正是这些创造力使万智牌变得伟大。&lt;/p&gt;&lt;p&gt;我们已经明确表示，我们要求为万智牌 TCG 做出贡献的艺术家、作家和创意人员不要使用人工智能生成工具来创建最终的万智牌产品。&lt;/p&gt;&lt;p&gt;现在，我们正在评估如何与供应商在产品之外的创意方面合作（例如这些营销图片），以确保我们能够实现这些价值观。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我其实很同情。我曾在威世智短暂从事研发工作。你不必这样做就知道每个人都工作过度、负担过重、工资过低。&lt;/p&gt;&lt;p&gt;是的，你认为很明显某物是人工智能艺术品，或者是在人工智能的帮助下创造的。事后看来，你显然是对的。就目前而言，是的，他们可能应该在这种情况下发现它。&lt;/p&gt;&lt;p&gt;但威世智每年创作数千件艺术品，甚至数万件。如果那些负责艺术创作的人试图走捷径，就会出现未被发现的情况，事情只会变得更加棘手。诱惑将会更大。&lt;/p&gt;&lt;p&gt;这更难捕捉的一个原因是，这不是纯粹的中途风格的人工智能一代。这似乎是人类使用 Photoshop 等人工智能工具来协助完成某些任务。如果你使用人工智能工具编辑人类生成的图像，很多检测技术都会错过它，直到有人看到一个明显的迹象。错误将会发生。&lt;/p&gt;&lt;p&gt;我们已经过了这样的阶段：在许多方面，人工智能艺术将胜过人类艺术，或者至少，如果游戏玩家对人工智能艺术作品感到失望，人类有时会希望将人工智能用作其工具箱的一部分。&lt;/p&gt;&lt;p&gt;即使对于那些坚持使用人类艺术家并给予他们充分补偿的人来说，我们也将面临哪些工具是可以接受的，哪些是不可以接受的问题。当然，人类至少会使用人工智能来尝试想法并查看概念或变体。还记得在计算机上完成的艺术作品还不是真正的艺术吗？时代变了。&lt;/p&gt;&lt;p&gt;对于艺术家来说，好消息是游戏玩家并不热衷于人工智能艺术作品。坏消息是，随着时间的推移，这只会变得更加困难。&lt;/p&gt;&lt;h4&gt;版权对抗&lt;/h4&gt;&lt;p&gt;&lt;a href="https://openai.com/blog/openai-and-journalism" rel="noreferrer noopener" target="_blank"&gt;OpenAI 对《纽约时报》诉讼作出回应&lt;/a&gt;。前三个说法是标准的，第四个对我来说是新的，他们在提起诉讼之前就价格进行谈判，基本上声称他们被背后捅了一刀：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;通过 12 月 19 日的最后一次沟通，我们与《纽约时报》的讨论似乎取得了建设性进展。谈判的重点是围绕 ChatGPT 中的实时显示和归因建立高价值合作伙伴关系，其中《纽约时报》将获得新的与现有读者和新读者建立联系的方式，我们的用户将可以访问他们的报告。我们向《纽约时报》解释说，与任何单一来源一样，他们的内容对我们现有模型的训练没有任何有意义的贡献，也不会对未来的训练产生足够的影响。他们于 12 月 27 日提起诉讼——我们是通过《纽约时报》了解到的——令我们感到惊讶和失望。&lt;/p&gt;&lt;p&gt;在此过程中，他们提到看到了一些内容的反流，但一再拒绝分享任何示例，尽管我们承诺调查和解决任何问题。我们已经证明了我们是多么认真地将此视为优先事项，例如 7 月份，当我们得知&lt;a href="https://twitter.com/OpenAI/status/1676072388436594688" rel="noreferrer noopener" target="_blank"&gt;ChatGPT 功能可以以意想不到的方式重现实时内容后，我们立即取消了该功能&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;有趣的&lt;a href="https://www.transtutors.com/questions/i-have-attached-the-file-below-here-i-need-a-distinction-quality-assignment-since-it-5775363.htm" rel="noreferrer noopener" target="_blank"&gt;是&lt;/a&gt;，《纽约时报》引起的反省似乎来自&lt;a href="https://incidentdatabase.ai/cite/267/" rel="noreferrer noopener" target="_blank"&gt;多个&lt;/a&gt; &lt;a href="https://m.blog.naver.com/yhkim13/221777199209" rel="noreferrer noopener" target="_blank"&gt;第三方&lt;/a&gt;&lt;a href="https://www.punkinfinland.net/forum/viewtopic.php?t=106205&amp;amp;start=375" rel="noreferrer noopener" target="_blank"&gt;网站&lt;/a&gt;上大量传播的多年前的文章。他们似乎故意操纵提示，通常包括冗长的文章摘录，以便让我们的模型反省。即使使用此类提示，我们的模型通常也不会像《纽约时报》暗示的那样表现，这表明他们要么指示模型反刍，要么从多次尝试中精心挑选示例。&lt;/p&gt;&lt;p&gt;尽管他们声称，这种滥用行为不是典型的或允许的用户活动，并且不能替代《纽约时报》。无论如何，我们正在不断提高我们的系统对反刍训练数据的对抗性攻击的抵抗力，并且我们最近的模型已经取得了很大进展。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我认为他们说的是谈判的真相。如果价格合适的话，《纽约时报》显然更愿意获得报酬并获得合作伙伴。我猜价格是错误的。&lt;/p&gt;&lt;p&gt; &lt;a href="https://stratechery.com/2024/the-new-york-times-ai-opportunity/" rel="noreferrer noopener" target="_blank"&gt;本·汤普森 (Ben Thompson) 对《纽约时报》的诉讼发表了自己的看法&lt;/a&gt;。他认为培训显然属于合理使用，这在现行法律下是显而易见的。我认为他对显而易见性的看法是错误的，法院可以采取任何一种方式。他认为相同的输出才是真正的问题，并指出 OpenAI 试图避免这种重复，而 Napster 则拥抱这种重复，他认为最终的问题是对《纽约时报》是否有市场影响。 《纽约时报》的陷害行为给他留下了深刻的印象，但他非常清楚他认为谁应该获胜。&lt;/p&gt;&lt;p&gt; &lt;a href="https://arnoldkling.substack.com/p/the-perils-of-strict-law-enforcement" rel="noreferrer noopener" target="_blank"&gt;阿诺德·克林 (Arnold Kling) 通过询问法律为何存在来询问诉讼结果应由什么决定&lt;/a&gt;。这取决于这是否会影响《纽约时报》获得报酬的能力。实际上，就目前的利润率而言，他的答案是否定的。以目前的利润率来看，我的回答也大多是否定的。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.wired.com/story/congress-senate-tech-companies-pay-ai-training-data/" rel="noreferrer noopener" target="_blank"&gt;立法者似乎相对一致认为 OpenAI 应该为其使用的数据付费&lt;/a&gt;。他们将采取什么措施呢？到目前为止，什么也没有。他们并不热衷于通过法律。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.cnbc.com/2024/01/05/microsoft-openai-sued-over-copyright-infringement-by-authors.html" rel="noreferrer noopener" target="_blank"&gt;非小说类书籍作者以集体诉讼的形式起诉 OpenAI&lt;/a&gt; 。从去年开始，一些顶级小说作家就已经开始提起诉讼。是的，让我们把它说出来。这里的事实大多是没有争议的。&lt;/p&gt;&lt;h4&gt; Deepfaketown 和 Botpocalypse 即将推出&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/Aella_Girl/status/1743069982341190060" rel="noreferrer noopener" target="_blank"&gt;我以为这是一种方式，有时却是另一种方式？&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Aella：天哪，我刚刚收到第一份报告，有人使用我的一张非常受欢迎的裸照，但把我的脸换成了他们的脸，大概是使用人工智能让我摆脱了这趟旅程。要查看照片， &lt;a href="https://twitter.com/zzxxcv5b/status/1742944291649941552" rel="noreferrer noopener" target="_blank"&gt;请转到此处&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;我不知道为什么我没有预测 ppl 会开始用我的图像这样做。这有点令人反感。人们总是偷我的照片，假装是我，但我的脸感觉像是一个签名？现在有人在没有附上我的身份的情况下窃取我的真实身体，感觉很奇怪，没有人性。&lt;/p&gt;&lt;p&gt;拉齐布·汗：嘿，这是一种致敬，好吗？我想我成功了……&lt;/p&gt;&lt;p&gt; Aella：事实上，现在我想起来了，为什么那些关注我们俩的怪人还没有开始将你的脸 PS 到我的裸体上。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这不太好。由于 Photoshop 的帮助，这个问题已经存在了一段时间，AI 降低了难度，同时使其更难以检测。我想如果比我们现在做的更多的话，我们会“生成 X 人的裸体”，但我不认为 X 会是经常生成该人的人，或者我认为问题是“使用图片” Y 作为模板。但是，是的，我想这也会发生，你们这些病态的人。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/emollick/status/1743146951749533897" rel="noreferrer noopener" target="_blank"&gt;伊森·莫里克（Ethan Mollick）仅基于 30 秒的网络摄像头和 30 秒的声音，展示了他说话的相当令人信服的深度伪造&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;我们仍然处于这样的阶段：我确信视频和音频记录是真实的，但通用的“人说话”剪辑很容易是假的。&lt;/p&gt;&lt;h4&gt;他们抢走了我们的工作&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/daniel_271828/status/1744313831881601228" rel="noreferrer noopener" target="_blank"&gt;首先，他们来找译者，他们确实这么做了，这是一个正在进行的系列。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Reid Southern：Duolingo 解雇了很大一部分合同翻译人员，剩下的人只是简单地审查人工智能翻译，以确保它们是“可接受的”。这就是我们正在创造的世界。将人性从我们学习与人性联系的方式中剔除。&lt;/p&gt;&lt;p&gt;嗯，这并没有花很长时间。每当你谈论与人工智能相关的裁员时，就会有人兴奋地向你解释为什么这是人类的净收益。当然，直到这是他们的工作。&lt;/p&gt;&lt;p&gt;瑞安：对于艺术家和受版权保护的创意作品，你的感受与我不同。翻译是机器的工作，而人工智能只是一台更好的机器。在大多数情况下，翻译不是人类的表达。这只是每次都相同的模式。这就是人工智能应该被使用的地方。&lt;/p&gt;&lt;p&gt;里德·南：显然是错误的。语言和方言有如此多的细微差别，尤其是随着它们的演变，它会让你大吃一惊。&lt;/p&gt;&lt;p&gt; Hampus Flink：作为一名翻译，我可以向您保证：1. 这并不会让剩下的工作人员的工作变得更容易，2. 它不会让翻译的质量变得更好我见过这种情况发生过当图像生成器出现时，这是我的第一个想法。&lt;/p&gt;&lt;p&gt; Daniel Eth：好的，对此有一些想法：&lt;/p&gt;&lt;p&gt; 1）如果人们能够接触到人工智能翻译和人工智能语言导师，那就太好了&lt;/p&gt;&lt;p&gt;2) 我赞成为人们提供安全网，特别是在不涉及（太多）不当激励的情况下——例如，为那些自动失业的人提供遣散费和/或失业保险&lt;/p&gt;&lt;p&gt;3）我们不应该让完美成为优秀的敌人，恕我直言，以公平的名义停止进步通常是不好的，所以duolingo的自动化可能是净好的，尽管（在外部看来）我对此表示怀疑（2）这里处理得特别好&lt;/p&gt;&lt;p&gt;4）如果人工智能确实导致大规模失业，我们将不得不重新思考我们的整个经济体系，使其更具再分配性——可能性包括豪华的全民基本收入和全自动豪华同性恋空间共产主义；我们有时间进行这样的对话，但我们不应该等到大规模自动化才进行 5) 这个案例与 AI X 风险没有太多关系，这是一个更大的问题，也更紧迫比任何一个&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;如果我们确实达到了广泛的技术失业的地步，我们不太可能很好地处理它，但会比这种情况发生早一点。如果在此之前没有一点，我们将很快遇到比失业率更大的问题。&lt;/p&gt;&lt;p&gt;在翻译的特定问题上，除了失业的工作外，会发生什么？&lt;/p&gt;&lt;p&gt; “低质量”翻译的价格将降至几乎为零。高质量翻译的价格也将下降，但要少得多。&lt;/p&gt;&lt;p&gt;这意味着两件事。&lt;/p&gt;&lt;p&gt;首先，从实时翻译，自动翻译和更便宜的人类检查的翻译中，将获得巨大的，巨大的胜利，因为更多的人可以以更多的方式使用更多的人使用更多的人，包括学习能力，或寻求进一步的技能或理解。这是一个巨大的游戏。&lt;/p&gt;&lt;p&gt;其次，将有替代高质量工作的高质量工作。在许多情况下，这将非常好，市场将做出正确的决定。&lt;/p&gt;&lt;p&gt;但是，在其他情况下，这将是可惜的。 Duolingo将是其中一种情况之一，即节省成本不值得下降的情况是合理的。不幸的是，我可以看到我们的系统在这里得到错误的答案。&lt;/p&gt;&lt;p&gt;好消息是翻译将不断改善。现在是不良翻译的山谷，从某种意义上说，它们足够好，可以使用，但错过了很多微妙的东西。随着时间的流逝，他们会越来越多地得到其他东西，当我们想要高质量的翻译时，我们将学会将它们与人类更有效。&lt;/p&gt;&lt;p&gt;如果您是一位专家翻译，是最好的翻译，我希望您会暂时可以。仍然会有需求，特别是如果您学会与AI合作。如果您是普通的翻译人员，那么是的，情况很糟糕，它们会变得更糟，您需要在可能的情况下找到另一个工作。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.rockpapershotgun.com/actors-union-sag-aftra-strike-deal-to-allow-ai-voice-replicas-and-video-game-stars-are-understandably-pissed" rel="noreferrer noopener" target="_blank"&gt;他们也是为配音演员而来的&lt;/a&gt;。 &lt;a href="https://www.sagaftra.org/sag-aftra-and-replica-studios-introduce-groundbreaking-ai-voice-agreement-ces" rel="noreferrer noopener" target="_blank"&gt;SAG-AFTRA达成了一项协议&lt;/a&gt;，让演员通过复制品用于游戏许可，使游戏中的许多实际配音演员在游戏中感到不高兴。 SAG-AFTRA大概认为这笔交易意味着演员保留对其声音和工作产品的控制。实际的游戏配音演员没有咨询，也没有看到必要的保护。&lt;/p&gt;&lt;p&gt;据我所知，正在讨论的所有技术保护措施并不重要。重要的是您是否完全打开门。一旦您使用AI生成的语音正常化，并且生产成本急剧下降以降低质量的性能，那么您将在成本上快速竞争，其质量会随着时间的推移而提高。因此，基本的问题是赔偿已放置了哪些楼层。当然，如果Sag-Aftra没有达成这样的交易，那么有很多非工会的人乐于以便宜的价格许可他们的声音。&lt;/p&gt;&lt;p&gt;因此，我看不到配音演员如何赢得这场战斗。我看到保留语音演员的唯一方法是，如果该技术未到达那里，那么这肯定还没有用于高质量的产品。或者，如果消费者采取足够强大的立场，并且抵制任何使用AI声音的人，那也将具有力量。或政府干预当然可以通过禁止使用AI语音综合来保护此类工作，这显然我不支持。我看不出任何合同如何为您节省长时间。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/scottlincicome/status/1742935556936655050" rel="noreferrer noopener" target="_blank"&gt;许多律师对提高生产力并不那么兴奋&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;斯科特·莱森科姆（Scott Lincicome）：这是我关于大法的最不喜欢的事情之一：该系统惩罚了生产力，优先考虑计费时间优先于获奖案件。可怕的激励措施！&lt;/p&gt;&lt;p&gt;信息：两家公司都面临着从律师到节省时间技术的抵制的挑战。律师事务所通过出售律师花费建议和帮助客户的时间来产生收入。鲁滨逊解释说：“如果你让我更快8到10倍，我会非常不高兴。”&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;正如我们之前讨论的那样，私人加速是好的，您可以更好地竞争或至少放松。如果每个人都知道，那可能是一个问题，除非这会产生更多的工作，否则这可能会给需求而崩溃，否则这可能会产生更多的问题。我知道，我的咨询和使用律师比便宜或更高的生产力，或者我的预算无限的时间少得多。&lt;/p&gt;&lt;p&gt;当他们来找你时，你会做什么？&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/krishnanrohit/status/1744421374633136541" rel="noreferrer noopener" target="_blank"&gt;罗希特（Rohit）&lt;/a&gt; ：我对因人工智能而失业的人们感到非常难过，但我看不出人类工作的较狭窄领域是人类精神的高度有助于理解或解决这一问题。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;正如许多人指出的那样，特定工作的技术丧失并没有什么新鲜事。现在，翻译人员发生的事情已经发生了，即使没有AI毫无疑问，再次发生了什么。约翰·亨利（John Henry）对人类的精神很高，但他之后的人类精神很好。问题是，当剩下的工作比我们打开新的工作更快地“缩小”速度时会发生什么。那天可能来了。然后呢？&lt;/p&gt;&lt;p&gt;我们没有一个好的答案。&lt;/p&gt;&lt;p&gt; Valve以前在Steam平台上禁止在游戏中使用AI，以至于即使在Alpha期间无意中包含某些占位符AI工作的程度。 &lt;a href="https://www.rockpapershotgun.com/steam-will-now-accept-the-vast-majority-of-games-using-ai-generation-but-only-with-disclosures" rel="noreferrer noopener" target="_blank"&gt;他们现在已经扭转了课程&lt;/a&gt;，说他们现在更好地了解情况。&lt;/p&gt;&lt;p&gt; &lt;a href="https://store.steampowered.com/news/group/4145017/view/3862463747997849618?l=english" rel="noreferrer noopener" target="_blank"&gt;新规则&lt;/a&gt;是，如果您使用AI，则必须透露自己这样做的。&lt;/p&gt;&lt;p&gt;对于预生成的AI内容，该内容遵守与任何其他内容相同的规则。对于实时生成的AI内容，您必须说明如何确保不会产生非法内容，并且会有报告违规行为的方法。&lt;/p&gt;&lt;p&gt;目前不允许成人内容，这是有道理的。这不是阀门需要处理的麻烦。&lt;/p&gt;&lt;p&gt;我赞扬等待阀门，直到他们了解允许新技术的风险，成本和收益，然后做出明智的决定，这对我来说是正确的决定。&lt;/p&gt;&lt;p&gt;我对&lt;a href="https://manifold.markets/ZviMowshowitz/will-any-of-the-top-10-selling-new" rel="noreferrer noopener" target="_blank"&gt;2024年前十名中的任何一个都将包括这样的披露，&lt;/a&gt;我有一个预测市场。&lt;/p&gt;&lt;h4&gt;参与其中&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/auderdy/status/1743085360803160377" rel="noreferrer noopener" target="_blank"&gt;旧金山的未对准博物馆&lt;/a&gt;希望雇用某人维持开放时间。&lt;/p&gt;&lt;h4&gt;介绍&lt;/h4&gt;&lt;p&gt;&lt;a href="https://www.rockpapershotgun.com/microsoft-are-adding-a-dedicated-ai-button-to-windows-keyboards-as-they-call-2024-the-year-of-the-ai-pc" rel="noreferrer noopener" target="_blank"&gt;Microsoft在Windows键盘上添加了AI密钥&lt;/a&gt;，正式称为Copilot键。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/rabbit_hmi/status/1744781083831574824" rel="noreferrer noopener" target="_blank"&gt;Rabbit，您的“口袋同伴”，以LLM为199美元的操作系统&lt;/a&gt;。我预计这将是半身像，人们不会喜欢它。质量会提高，但还为时过早，而且看起来还不够好。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;丹尼尔：有人可以告诉我这件事到底是什么吗？&lt;/p&gt;&lt;p&gt;我确定这很棒！但是营销材料很糟糕。有没有搞错&lt;/p&gt;&lt;p&gt;&lt;a href="https://twitter.com/yishan/status/1745314620913693019" rel="noreferrer noopener" target="_blank"&gt;伊桑&lt;/a&gt;：认真。我也不明白。感觉有点像皇帝在这里没有衣服的时刻吗？我尝试观看视频，但是……还是？&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;那些试图回答丹尼尔的人并不令人信服。&lt;/p&gt;&lt;h4&gt;在其他AI新闻中&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/demishassabis/status/1744046738493599942" rel="noreferrer noopener" target="_blank"&gt;Demis Hassabis宣布与Eli Lily和Novartis合作，&lt;/a&gt;最高30亿美元，以加速药物开发。&lt;/p&gt;&lt;p&gt; &lt;a href="https://blog.research.google/2024/01/responsible-ai-at-google-research-user.html" rel="noreferrer noopener" target="_blank"&gt;Google谈论有关用户体验的“负责人AI”&lt;/a&gt; 。这似乎是“创造良好的用户体验”的组合，并对训练集也无法排队的少数群体的经验感到担忧。任何事情都没有错，但是与您的工作是否负责无关。我担心别人没有意识到这一点？&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/arankomatsuzaki/status/1744918551415443768" rel="noreferrer noopener" target="_blank"&gt;Bytedance宣布&lt;/a&gt;&lt;a href="https://t.co/nZOlH58Ev5" rel="noreferrer noopener" target="_blank"&gt;MagicVideo V2&lt;/a&gt; （ &lt;a href="https://t.co/4MUrSbkE1r" rel="noreferrer noopener" target="_blank"&gt;Github&lt;/a&gt; ）声称这是人类判断的新SOTA。即使这是真的，这似乎并不是实质性的进步。即使特定的艺术及其状态还不是那么值得，也可以在这里的索塔（Sota），这并不是一个很好的迹象。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.theinformation.com/articles/openai-offers-publishers-as-little-as-1-million-a-year?utm_source=ti_app" rel="noreferrer noopener" target="_blank"&gt;OpenAI根据信息提供了出版商的每年100万至500万美元之间的范围&lt;/a&gt;或允许其在培训LLMS中许可其新闻文章的许可。他们说，苹果公司提供更多的钱，但也希望有权更广泛地使用内容。&lt;/p&gt;&lt;p&gt;人们的举止是一种挑剔。这取决于发布者。如果《纽约时报》每年获得100万美元，那似乎并不多，但是那里有很多出版商。一百万，那里有一百万，很快您就在谈论真钱。为什么OpenAI的付款应特别是出于培训目的，仅供培训，而无权转载权？&lt;/p&gt;&lt;p&gt; &lt;a href="https://www3.nhk.or.jp/nhkworld/en/news/20231221_27/" rel="noreferrer noopener" target="_blank"&gt;日本将于1月推出“ AI安全研究所”&lt;/a&gt; 。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;该准则将要求遵守有关AI的所有规则和法规。他们警告说，AI技术的发展，提供和使用，目的是非法操纵人类的决策过程或情感。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;是的，是的，人们应该遵守法律并遵守所有规则和法规。&lt;/p&gt;&lt;p&gt;似乎公民&lt;a href="https://twitter.com/GaryMarcus/status/1745127779237310888" rel="noreferrer noopener" target="_blank"&gt;向加利福尼亚投诉Openai不是非营利组织&lt;/a&gt;，因此必须剥离其资产。当然，这可能是毫无价值的，因为如果没有人民，Openai是什么都没有的。我非常怀疑这是法律上的一件事，即使从技术上讲应该发生，也不会出现这种结构，希望每个人都能意识到这一点。 &lt;a href="https://manifold.markets/FortuneFairy/will-the-forprofit-arm-of-openai-be" rel="noreferrer noopener" target="_blank"&gt;有一个很小的市场说，这种事情实际上可能以某种方式发生&lt;/a&gt;，到2025年底32％？我把它买到21％，这仍然使我成为胆小鬼，但这已经两年了。&lt;/p&gt;&lt;h4&gt;安静的猜测&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/zoehtwilliams/status/1744646356843803081" rel="noreferrer noopener" target="_blank"&gt;在AI预测，列表&lt;/a&gt;（ &lt;a href="https://docs.google.com/document/d/1Uy3SO9SpT5OmiZBp9HaqXqx_MV-RBrYY3jFcUcG3Mbc/edit" rel="noreferrer noopener" target="_blank"&gt;直接&lt;/a&gt;）中打开问题。很难将其固定下来。尤其是&lt;a href="https://twitter.com/dwarkesh_sp/status/1744396538166804627" rel="noreferrer noopener" target="_blank"&gt;德瓦克什·帕特尔（Dwarkesh Patel）&lt;/a&gt;对转移学习感到好奇。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.lesswrong.com/posts/q3bJYTB3dGRf5fbD9/miri-2024-mission-and-strategy-update" rel="noreferrer noopener" target="_blank"&gt;Miri提供了2024年的任务和战略更新&lt;/a&gt;。研究仍在继续，但重点是影响政策。他们在那里看到了良好进步的迹象，并且如果我们有时间有时间研究我们必须解决的技术问题，也将政策视为必要。&lt;/p&gt;&lt;p&gt; AI合作伙伴会发生什么？&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/RichardMCNgo/status/1745138065742704736" rel="noreferrer noopener" target="_blank"&gt;理查德非政府组织&lt;/a&gt;：我见过的所有讨论AI合作伙伴都认为他们将代替人类合作伙伴。但是技术通常会创造新型的丰度。因此，我希望人们经常有AI和人类的浪漫伴侣，而AI伴侣精心设计以最大程度地减少嫉妒。&lt;/p&gt;&lt;p&gt;杰弗里·拉迪什（Jeffrey Ladish）：精心设计以最大程度地减少嫉妒，似乎需要公司和用户之间的激励措施比我所期望的，就像您需要您的用户一样，这表明您需要一定程度地应对嫉妒，但只需要一些嫉妒。&lt;/p&gt;&lt;p&gt;盖弗里·米勒（Geffrey Miller）：有2-5％的多恋爱关系经验的人可能能够处理AI“次要合作伙伴”。但是，绝大多数人都是一夫一妻制的定向，而AI合作伙伴将对他们的人际关系造成灾难性。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;结果似乎不可避免。问题是什么主导。基线用例似乎对我来说是替代的，尤其是当无法找到或说服人，或者当某人缺乏动力时。这很容易导致持续缺乏足够的动力，这可能会滚雪球。我们应该为此担心。正如我指出的那样，AI提供了良好的实践或培训，甚至支持和建议以及推动出去的能力，也可以使人们更好地意识到他们所缺少的东西。很难说。&lt;/p&gt;&lt;p&gt;这里的新问题是在现有的关系中，什么主导了那里的结果？我认为，默认值不太可能涉及谨慎的嫉妒最小化。这不是资本主义的运作方式。&lt;/p&gt;&lt;p&gt;直到有需求为止，突然间它可能。如果有一个明确的规范，例如“您可以使用supportivecompanion.ai，每个人都知道这很好，如果它们超级偏执，您会使用platonicfriend.ai，如果您的伴侣不在也更有趣，如果您知道自己在做什么，那里总是VirtualBdsm.ai，但是与您的伴侣一起远离某些部分，或者不远离某些部分，那么似乎可以很好地进行。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.oneusefulthing.org/p/signs-and-portents" rel="noreferrer noopener" target="_blank"&gt;伊桑·莫利克（Ethan Mollick）在标志和预本书中写了约2024年的期望&lt;/a&gt;。他专注于现有AI技术的实际应用。他不希望该技术静止不动，但正确地指出，仅以当前形式的GPT-4和Chatgpt的改编将成为广泛的知识工作和教育的主要生产力，并威胁到我们的能力辨别真理并确保事物安全。他使用“转化”一词，我希望为更大的未来变化保留，但并非完全错误。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/catehall/status/1743077234704085069" rel="noreferrer noopener" target="_blank"&gt;凯特·霍尔（Cate Hall）问&lt;/a&gt;，人们毫无疑问，人们在存在的风险讨论中，您认为缺乏足够的理由？许多好的答案。我的第一选择是：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;丹尼尔·埃特（Daniel Eth）：如果我们解决意图结盟并避免故意存在滥用，我们会赢 - 与我认为，默认情况下，意图对齐 + 〜Moloch很有可能会导致存在的灾难&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;如果您从未考虑过， &lt;a href="https://twitter.com/paulg/status/1744535328696815971" rel="noreferrer noopener" target="_blank"&gt;这是一个很好的问题&lt;/a&gt;，但是我以为保罗·格雷厄姆（Paul Graham）已经找到了答案？他不是和Cowen和Thiel说话吗？&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;保罗·格雷厄姆（Paul Graham）：我们是在技术停滞时期生活，还是AI迅速发展以至于可能是生存威胁？不可能两者兼而有之。&lt;/p&gt;&lt;p&gt;我倾向于后一种视图。我一直对停滞论文持怀疑态度。&lt;/p&gt;&lt;p&gt;杰森·克劳福德（Jason Crawford）：可能是计算技术正在前进，而其他领域（制造，建筑，运输，能源）停滞不前。或者在过去的50年中，我们已经放慢了脚步，但即将转弯。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我购买了中央大停滞的论点。我们曾经做过这些事情并建造事物。然后，我们开始告诉人们他们无法做的事情以及他们无法构建的事情。 1973年左右，这一巨大的危险，我们击中了一个巨大的停滞，在半个世纪中，事情大部分没有发展或变化太大。&lt;/p&gt;&lt;p&gt;这些规则通常不适用于包括计算机硬件在内的碎屑世界，因此人们（像Paul Graham这样的人）能够构建许多很酷的新数字事物，这些技术在指数上发展并改变了世界。现在，AI是一种新的指数，并准备这样做，也构成了潜在的生存威胁。但是由于指数级的工作方式，它尚未改变太大的增长率。&lt;/p&gt;&lt;p&gt;确实，格雷厄姆应该对此非常熟悉。想一想在其增长阶段的每个初创企业。它会改变世界，还是几乎没有影响世界的影响？它可能是巨大的还是很小的？显然两者。&lt;/p&gt;&lt;p&gt;同时，当然，一旦格雷厄姆（Graham）在答复中明确指出了“辩论”，标准提醒大多数技术都很好，并且移动得太慢，而一些技术则不太好，并且可能进展得太快。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;亚当·麦克白（Adam Macbeth）：假二分法。&lt;/p&gt;&lt;p&gt;保罗·格雷厄姆（Paul Graham）：这是一个完美的。一方说，技术的进步太慢，另一种技术的进步太快了。&lt;/p&gt;&lt;p&gt; Eliezer Yudkowsky（回复Graham）：除了对病原体和人工智能的功能性研究外，每种形式的技术进展都太慢了，这进展得太快了。 E/ACC的假装认为他们的反对者还必须反对核能是错误的。&lt;/p&gt;&lt;p&gt;这也可以是正确的，不仅在这些技术相对于我们想要的速度方面的速度，而且在制造增强病毒的合法方面也比建造房屋更合法，或者是如何合法的与AI相比，VC的兴趣要小得多。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/RatOrthodox/status/1744904847139484031" rel="noreferrer noopener" target="_blank"&gt;罗尼·费尔南德斯（Ronny Fernandez）&lt;/a&gt; ：哇，我说，这是一种特定的非常不寻常的技术，您知道的是，您召唤出您并不真正了解的想法，目的是使一个更聪明的人进步，它的进步太快了，其他技术人员，其他技术人员，其他技术人员，就像建筑物和促智能一样，进展太慢了。&lt;/p&gt;&lt;p&gt;您知道您可以拥有多个参数来表达您对技术进步的偏好。您可能比技术更为具体，或者技术太慢。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;公平地说，让我们再试一次。有三个（或四个？！）基本位置。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;技术和进步是好的，应该更快地移动，包括AI。&lt;/li&gt;&lt;li&gt;技术和进步是好的，应该更快地移动，不包括AI。&lt;/li&gt;&lt;li&gt;技术和进步不好，应该在任何地方移动较慢。&lt;/li&gt;&lt;li&gt; （总体上谈论事情，但实际上只关心AIS的法规。）&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;的确，第三组重要的是存在，并且确实对我们的社会造成了巨大破坏。&lt;/p&gt;&lt;p&gt;然后，第1组和＃4组的成员声称实际上（在某些情况下，在理论上也声称）只有第1组和＃3组存在，这是辩论，每个人都在说在＃2中，他们在＃2中必须在＃3中，而且也没有注意到许多＃1在＃4中。&lt;/p&gt;&lt;p&gt; （ &lt;a href="https://twitter.com/edavidds/status/1745050605050282084" rel="noreferrer noopener" target="_blank"&gt;对于第4人的明显例子&lt;/a&gt;，这是埃里克·施密特（Eric Sc​​hmidt）指出，贝夫·耶佐斯（Beff Jezos）似乎从未倡导“加速”诸如住房之类的事情。）&lt;/p&gt;&lt;p&gt;因此，可以说＃3中的人们存在，绝对存在。而且，在技术的背景下，可以将其描述为“一方”。&lt;/p&gt;&lt;p&gt;但是，在AI的背景下，特别是在响应类似于“错误二分法”的陈述时，这是误导性的，通常是不明智的。实际上，这是一种试图实施错误的二分法，然后声称其他人必须占据其中的一面，并否认那些注意到您在那里所做的事情的人的存在。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/steve47285/status/1744844055631085750/history" rel="noreferrer noopener" target="_blank"&gt;一些非常糟糕的预测&lt;/a&gt;：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;蒂莫西·李（Timothy Lee）：我认为AI首席执行官不会比人类首席执行官更好。人类首席执行官总是可以向AI提出建议，而AI将永远无法握手。&lt;/p&gt;&lt;p&gt;史蒂文·伯恩斯（Steven Byrnes）：“我认为成人首席执行官不会比7岁的首席执行官更好。一位7岁的首席执行官总是可以向成人询问建议，而成人首席执行官将永远无法用那些可爱的小酒窝赢得投资者和客户&lt;img alt="😊" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9Jgtkw8CD6kndyCcD/kcnyp7qgpixdz386ppll" style="height: 1em;" /&gt; ”&lt;/p&gt;&lt;p&gt;蒂莫西·李（Timothy Lee）：七岁的孩子是……不是成年人吗？这似乎很重要。&lt;/p&gt;&lt;p&gt;史蒂文·伯恩斯（Steven Byrnes）：7岁的首席执行官比我要差得多，我将比杰夫·贝佐斯（Jeff Bezos）差得多。同样，我建议有一天会&lt;em&gt;[还没有！也许几十年来！]&lt;/em&gt;成为AI，以至于Jeff Bezos比AI差得多。&lt;/p&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;i&gt;请在您的网络浏览器中查看此帖子以完成测验。&lt;/i&gt;&lt;/div&gt;&lt;p&gt;我喜欢这部分是因为声称现在是一个7岁的年轻人的扭曲，而不是说显而易见的“ 7岁年轻人会长大并变得更强壮，然后变得更好，而AI也会变得更强壮随着时间的流逝，学习做目前无法平行的事情。&lt;/p&gt;&lt;p&gt; &lt;a href="https://manifold.markets/StanPinsent/will-there-be-an-ai-ceo-by-2040" rel="noreferrer noopener" target="_blank"&gt;请注意，歧管市场对时间安排持怀疑态度&lt;/a&gt;，它说，到2040年，拥有AI首席执行官的财富500强公司只有58％的机会。&lt;/p&gt;&lt;p&gt;连线通常是奇怪的AI怀疑，他说“ &lt;a href="https://www.wired.com/story/get-ready-for-the-great-ai-disappointment/" rel="noreferrer noopener" target="_blank"&gt;为AI感到非常失望做好准备&lt;/a&gt;，”说“在未来几十年中，它将产生糟糕的输出，从而破坏工作，但产出质量较低。即使基础技术未能进一步发展，这对我来说显然是错误的。&lt;/p&gt;&lt;h4&gt;寻求理智法规&lt;/h4&gt;&lt;p&gt;您知道您可以大胆而无耻地撒谎吗？&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/edardaman/status/1744453999695176046" rel="noreferrer noopener" target="_blank"&gt;A16Z知道。他们就这么做了。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; A16Z的书面证词：“尽管倡导AI安全指南的倡导者通常会暗示AI模型的“黑匣子”性质，在此结论背后的逻辑不是透明的，但AI部门的最新进步已经解决了这一问题，从而确保了这一问题的完整性开源代码模型。”&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这是在说谎。这是欺诈。时期。&lt;/p&gt;&lt;p&gt;最近在解释性方面取得了一些进步，使我们现在更加乐观，我们将来能够比几个月前预期更多地了解模型？当然。这是在那里逐步进步的好一年。&lt;/p&gt;&lt;p&gt; “解决了这个问题？”诚信是“安全的”吗？ “他们的结论逻辑是透明的”？这是错误的。不，这很荒谬。他们知道。他们知道我们知道他们知道。众所周知，这是一个谎言。他们不在乎。&lt;/p&gt;&lt;p&gt;我希望有人为此扔进监狱。&lt;/p&gt;&lt;p&gt;从现在开始，请记住这一事件。这就是他们。&lt;/p&gt;&lt;p&gt;也许更加严重的是， &lt;a href="https://www.euractiv.com/section/artificial-intelligence/news/eu-prepares-to-push-back-on-private-sector-carve-out-from-international-ai-treaty/" rel="noreferrer noopener" target="_blank"&gt;美国显然是在要求，包括AI条约义务的公司&lt;/a&gt;是可选的，并留给每个国家来决定？什么？条约中没有任何适用于所有公司的条约没有意义。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/zoehtwilliams/status/1744646356843803081" rel="noreferrer noopener" target="_blank"&gt;新的报告研究了AI芯片上安全功能的可行性&lt;/a&gt;，以及他们在确保对大量计算的有效控制方面可以发挥什么作用。 &lt;a href="https://twitter.com/fiiiiiist/status/1744406254334656643" rel="noreferrer noopener" target="_blank"&gt;这是一个带有主要发现的Twitter线程&lt;/a&gt;。芯片治理似乎很可行，并且没有得到足够的关注作为一种选择。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/hlntnr/status/1745139686149140811" rel="noreferrer noopener" target="_blank"&gt;中国发布了第一个“ CCP批准”数据集&lt;/a&gt;。它是20 GB，1亿个数据点，因此长期不够大。一个开始，但是正如海伦所指出的那样，目前可以将其视为净负面的开始。如果您有一个批准的数据集，则应归咎于使用其他未经批准的数据集。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.ft.com/content/f87b693f-9ba3-4929-8b95-a296b0278021" rel="noreferrer noopener" target="_blank"&gt;《金融时报》报道了一些秘密外交&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Openai，Anthropic and Cohere已与中国AI专家进行秘密外交，同时担心强大的技术如何传播错误信息并威胁到社会凝聚力。&lt;br /&gt;&lt;br /&gt;据多名知情人士透露，去年 7 月和 10 月在日内瓦举行了两次会议，北美人工智能团体的科学家和政策专家以及清华大学和其他中国政府支持机构的代表参加了会议。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;文章对其他有意义的细节很有意义，这似乎并不那么秘密。这确实是一个好主意。&lt;/p&gt;&lt;p&gt;请注意，谁在有帮助或限制性，谁不是什么，谁可能会或可能不会以这种速度成为坏人。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.fwbusiness.com/fwbusiness/article_73dd33bc-aae4-5fc7-830c-bd517d07d235.html" rel="noreferrer noopener" target="_blank"&gt;参议员托德·杨（Todd Young）（R-in）和两党集团呼吁&lt;/a&gt;建立美国国家标准与技术研究院（NIST）美国人工智能安全研究所（USAISI），并拥有1000万美元的初始资金。这很小，但是必须从某个地方开始。是的，对于标准学院来说，为AI相关的标准筹集资金是有意义的。&lt;/p&gt;&lt;h4&gt;音频一周&lt;/h4&gt;&lt;p&gt;&lt;a href="https://www.alignment-workshop.com/nola-2023" rel="noreferrer noopener" target="_blank"&gt;12月10日至11日在新奥尔良的对齐研讨会的会谈。&lt;/a&gt;还没有时间聆听，但是在这里为那些有兴趣的人进行一些自我宣传的演讲。&lt;/p&gt;&lt;h4&gt; AI影响调查&lt;/h4&gt;&lt;p&gt;&lt;a href="https://thezvi.substack.com/p/ai-impacts-survey-december-2023-edition" rel="noreferrer noopener" target="_blank"&gt;我在自己的帖子中介绍了这一点&lt;/a&gt;。本节用于晚期反应和发展。&lt;/p&gt;&lt;p&gt;未来的AI预测列表中总会有一个主张，事实证明已经发生了。在这种情况下，是“世界扑克世界大赛”，被定义为“足够好赢得WSOP”。这显然已经发生了。如果您想慷慨大方，您可以说“ AI在主赛事中不如托马斯·里格比（Thomas Rigby）或菲尔·艾维（Phil Ivey）那样最大化其获胜率，因为它不足一项严重的努力进行剥削的机器人并让它阅读，直到现在才变得现实。&lt;/p&gt;&lt;p&gt;我发现&lt;a href="https://twitter.com/Meaningness/status/1743301276748619876" rel="noreferrer noopener" target="_blank"&gt;查普曼在这里声称&lt;/a&gt;与我所写的关于道德迷宫的内容以及扭曲中层管理人员的思想的危险相似，以至于他们不能考虑任何事情来抢劫：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;大卫·查普曼： &lt;img alt="🤖" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aKzwwKT2cy72awSyz/altbeffglxoxdzfml0xq" style="height: 1em;" /&gt;对2,778名AI研究人员的重要调查主要发现，AI研究人员无法在自己所谓的专业知识领域中应用基本的逻辑推理。 [链接到我的帖子]&lt;/p&gt;&lt;p&gt; MAGOR：这似乎是汇总和合并信息的示例，直到比任何单个数据点都差。有趣的是，尽管如此。它显示整个领域正在盲目。&lt;/p&gt;&lt;p&gt;大卫·查普曼（David Chapman）：是的……我认为这也是大多数技术人员的狭窄的体现。从技术上讲，他们无法在自己的领域外推理（预测AI的未来不是AI研究人员的培训或思考的东西，因此他们的观点并不有意义）。&lt;/p&gt;&lt;p&gt;我认为AI异常糟糕，因为由于历史原因，该领域的基本认识论是反理性的，并且它可以训练您不清楚地思考除优化梯度下降以外的任何事物。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这实际上是真的吗？它听起来不那么古怪。通常，那些受到强烈奖励X的人几乎对其他所有事物进行反训练，而在极端优化压力下，这对此类人的社区来说是一倍。如果是这样，我们会遇到更深的麻烦。&lt;/p&gt;&lt;p&gt;对此的辩护是，如果这些研究人员需要逻辑和认识论作为其工作的一部分。他们吗？&lt;/p&gt;&lt;h4&gt;修辞创新&lt;/h4&gt;&lt;p&gt;这是一个普遍的说法，即存在的风险“分散注意力”其他担忧。&lt;/p&gt;&lt;p&gt; Erich Grunewald指出，这是一个事实问题。 &lt;a href="https://forum.effectivealtruism.org/posts/hXzB72kfdAk6PTzio/attention-on-existential-risk-from-ai-likely-hasn-t" rel="noreferrer noopener" target="_blank"&gt;我们可以问，这实际上是真的吗？&lt;/a&gt;&lt;/p&gt;&lt;p&gt;他的回答是，这不是，有五条论点和调查。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;由于提出了存在的风险问题，因此制定了政策，主要集中于解决平凡的危害并捕获平凡的效用。在某种程度上，有一些政策倡议在很大程度上是出于生存风险的动机，并受到这种担忧的人的影响，包括英国安全峰会和美国的行政命令，已经付出了巨大的努力来解决平凡的问题。同时，其中还有许多其他事情来解决平凡的关注，并且大多受到担心存在风险的人的支持。&lt;/li&gt;&lt;li&gt;在大多数讨论AI的存在风险问题问题的时期，对AI伦理和当前AI危害的搜索兴趣根本没有受到影响。&lt;/li&gt;&lt;/ol&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a972f67-591b-42a8-803b-d9ee6f61d416_1066x729.png" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/nfg2p2yniqcr26kcmlsj" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;回归分析大致没有影响。&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1427e116-b906-481b-87f7-4161babb7f40_1051x589.png" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/ela9x2j6nfws8pyeqk92" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;ol start="3"&gt;&lt;li&gt; Twitter追随者。如果您查看最大的道德倡导者，那么当存在风险的问题扩大时，它们的影响力就会扩大。&lt;/li&gt;&lt;li&gt;为平凡或当前危害组织的筹款活动继续做得很好。&lt;/li&gt;&lt;li&gt;与环保主义相似，环保主义是引起潜在关注的原因，也是反对关注的共同论点。人们是否说气候变化是对当前危害（例如空气污染）的“分心”，反之亦然？本质上是没有，但也许他们应该，也许只能朝一个方向发展？对气候的担忧似乎引起了人们对其他环境问题的担忧，并使人们想要帮助他们，气候解决方案会帮助解决其他问题，而对当地特定问题的担忧通常会导致人们的行为好像气候变化并不重要。我们经常看到这场斗争，因为重要的气候项目是为了其他“一切百吉饼”的关注点。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt; &lt;a href="https://twitter.com/bencasnocha/status/1743294517946823082" rel="noreferrer noopener" target="_blank"&gt;一个良好的启发式方法可以进一步扩展：&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;房地美（Freddie Deboer）：认识到一篇文章质量的好经验法则：更具体的，更具体的，对它的批评或批评更为普遍？&lt;/p&gt;&lt;p&gt; Ben Casnocha：适用于评估许多事物的质量：您对此有多具体？&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;询问有关分歧和辩论的同样的问题。谁是通用的？谁是具体的？这里哪个合适？您会做哪一个您是对的？&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/robbensinger/status/1743411122705756606" rel="noreferrer noopener" target="_blank"&gt;罗布·本辛格（Rob Bensinger）解释说，是的&lt;/a&gt;，在真正的囚犯困境中，您确实更喜欢在他们合作的情况下进行缺陷，如果您可以摆脱它，如果您不明白这一点，您还没有准备好应对如此困境。不要被“叛逃”的名称愚弄。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/eshear/status/1743036378173342180" rel="noreferrer noopener" target="_blank"&gt;Emmett Shear解释了&lt;/a&gt;一个直觉，说明为什么AI的指数加速进一步的AI的发展将看起来相对较低，直到突然产生很大的影响，以及为什么我们仍然应该期望AI一旦AI能力超出适当的阈值。自动化的前20％很棒，但不会改变游戏。从98％到99％的人每吨很重要，并且可能会更快地发生。&lt;/p&gt;&lt;p&gt;我经常看到自以为是的说法，即Foom的想法已被“揭穿”，或者现在显然是错误的，我们不必担心这种加速度。否。我们确实得到证据，表明更多极端的场景比我们想象的要小。福姆假设的“强烈形式”（在其中所涉及的那些人都看不到它的情况下）似乎确实不太可能。但是核心假设并不像伪造的那样。默认值和常识结果仍然是，一旦AI足够的能力，在人类整体能力水平附近的拐点处，它们将加速进一步的能力的发展，而事情将迅速升级。这也是OpenAI超级分组团队的计划以及许多研究人员的实际期望。&lt;/p&gt;&lt;p&gt;它可能会在程度上或可能不会发生变化，具体取决于任务困难是否比执行任务的能力更快，以及我们是否采取措施预防（或引起）这种效果。&lt;/p&gt;&lt;p&gt;嗯，是。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/robertwiblin/status/1742881192959991815" rel="noreferrer noopener" target="_blank"&gt;罗伯特·威布林（Robert Wiblin）&lt;/a&gt; ：无论人类变得多么能力，我们仍然总是会发现大猩猩的富有成效的用途 - 他们只会转移到经济中的新比较优势。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;一系列观点的冲突仍在继续。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;丹尼尔·凯瑟（Daniel Kaiser）：GPT-4在GPT-3.5上有多少生存威胁？&lt;/p&gt;&lt;p&gt; Eliezer Yudkowsky：我们仍然处于这是任何曲线的地下室，因此零至零。&lt;/p&gt;&lt;p&gt;丹尼尔·凯瑟（Daniel Kaiser）：太好了，那么就没有必要惊慌。&lt;/p&gt;&lt;p&gt;塞瓦塔尔：“核武器掉落多久？” “他们仍在准备发射。” “太好了，所以没有理由惊慌。”&lt;/p&gt;&lt;p&gt;丹尼尔·凯瑟（Daniel Kaiser）：“核武器落下多久？” “他们仍在弄清楚TNT的公式”“太好了，所以没有理由惊慌”&lt;/p&gt;&lt;p&gt;请进行准确而不是辩论类比，以进行建设性讨论&lt;/p&gt;&lt;p&gt;APRII：我觉得“他们正在启动曼哈顿项目”比“他们仍在弄清楚TNT”更准确&lt;/p&gt;&lt;p&gt;Eliezer ：（同意）&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;是的。我认为这是完全正确的。开始担心核武器的时间是Szilard在1933年左右开始担心。物理学家像这样很聪明，在很大程度上就知道了，但不知道该怎么做才能阻止它发生。而且我确实认为“曼哈顿项目的开始”感觉就像在这里的确切隐喻，尽管我不希望只有三年的方式。&lt;/p&gt;&lt;p&gt;但是，如果您想绘制未来的漫长弧线，那么您在1868年写作时，当我们第一次弄清楚TNT时，您也被一些您信任建造原子弹的能力的出色物理学家告诉您，您是写下您的1968年或2068年的愿景，它看起来应该与以前有所不同，不是吗？&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/michael_nielsen/status/1743339700885340287" rel="noreferrer noopener" target="_blank"&gt;线程询问有关ASI的虚构描述&lt;/a&gt;。选秀权包括Alla Gorbunova的“您的小工具破碎”，一个激励的例子，仅在俄语中是可怕的，所以我不会阅读它，也不会：Accelerando，Vinge的作品（我可以推荐这一点），Golem.xiv，person感兴趣的（如果您愿意也愿意观看程序电视节目，&lt;a href="https://t.co/NeHW7AvSwI" rel="noreferrer noopener" target="_blank"&gt;令人&lt;/a&gt;震惊的是非常好）&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/davidad/status/1743752451956568498" rel="noreferrer noopener" target="_blank"&gt;啊，是的，将击败坏AI的好AI。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;戴维德（DavidAd）：最好通过观察自我复制模式具有位移，因此默认为破坏性的说法最好破坏“不良AI”，除非积极避免这种模式，否则不好的人具有更多的资源和策略，以至于更多的资源和策略，以至于不是禁止的。&lt;/p&gt;&lt;p&gt;最好的反击是，“良好的AIS”将在长达一年的抢手开始期间获得巨大的材料和智能优势，在他们安全和道德上获得它。这需要协调 - 但它是一个非常合理的纳什均衡。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;戴维德还提醒我们，不，并非一切都是囚犯的困境，而人类实际上设法在练习理论问题中合作，加速主义者和元社会者不断声称是不可能的。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Davidad: I just did this analysis today by coincidence, and in many plausible worlds it&amp;#39;s indeed game-theoretically possible to commit to safety. Coordinating in Stag Hunt still isn&amp;#39;t trivial, but it *is* a Nash equilibrium, and in experiments, humans manage to do it 60-70% of the time.&lt;/p&gt;&lt;/blockquote&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5eeccab9-8cab-49d4-9792-c9026ee12632_2048x2022.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/yudesmprwzdmdk1gof7w" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt; There is an implied dichotomy here between guarantees and mainstream methods, and that&amp;#39;s at least a simplification, but I do think the general point is right.&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/ESYudkowsky/status/1743688927238934876" rel="noreferrer noopener" target="_blank"&gt;Eliezer keeps trying to explain&lt;/a&gt; to the remarkably many people who do not get this, that a difference exists between &amp;#39;nice thing&amp;#39; and &amp;#39;thing that acts in a way that seems nice.&amp;#39;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Eliezer Yudkowsky: How blind to “try imagining literally any internal mechanism that isn&amp;#39;t the exact thing you hope for” do you have to be — to think that, if you erase a brain, and then train that brain solely to predict the next word spoken by nice people, it ends up nice &lt;em&gt;internally?&lt;/em&gt;&lt;/p&gt;&lt;p&gt; To me it seems that this is based on pure ignorance, a leap from blank map to blank territory. Seeing nothing behind the external behavior, their brain imagines only a pure featureless tendency to produce that external behavior — that that&amp;#39;s the only thing inside the system.&lt;/p&gt;&lt;p&gt; Imagine that you are locked in a room, fed and given water when you successfully predict the next word various other people say, zapped with electricity when you don&amp;#39;t.&lt;/p&gt;&lt;p&gt; Is this a helpful thought experiment and intuition pump, given that AIs obviously won&amp;#39;t be like &lt;em&gt;that?&lt;/em&gt;&lt;/p&gt;&lt;p&gt; And I say: Yes, the Prisoner Predicting Text is a helpful intuition pump. Because it prompts you to imagine &lt;em&gt;any mechanism whatsoever&lt;/em&gt; underlying the prediction, besides the hopium of “a nice person successfully predicting nice outputs because they&amp;#39;re so nice”.&lt;/p&gt;&lt;p&gt; If you train a mind to predict the next word spoken by each of a hundred individual customers getting drunk at a bar, will it become drunk?&lt;/p&gt;&lt;p&gt; Martaro: Predicting what nice people will say does not make you nice You could lock up Ted Bundy for years, showing him nothing but text written by nice people, and he&amp;#39;d get very good at it This means the outer niceness of an AI says little about the internal niceness fair summary?&lt;/p&gt;&lt;p&gt; Eliezer Yudkowsky: Basically!&lt;/p&gt;&lt;p&gt; das filter: I&amp;#39;ve never heard anyone claim that&lt;/p&gt;&lt;p&gt; Eliezer Yudkowsky: Tell that to everyone saying that RLHF (now DPO) ought to just work for creating a nice superintelligence, why wouldn&amp;#39;t it just work?&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;就是这样。 If you claim that RLHF or DPO ought to work, you are indeed (as far as I can tell) making this claim filter is saying no one makes, whether or not you make that implicit. And I am rather certain this claim is false.&lt;/p&gt;&lt;p&gt; Humans have things pushing them in such directions, but the power there is limited and there are people for whom it does not work. You cannot count on such observations as strong evidence that a person is actually nice, or will do what you want when the chips are properly down. Do not make this mistake.&lt;/p&gt;&lt;p&gt; On the flip side, I mean, people sometimes call me or Eliezer confident, even overconfident, &lt;a href="https://twitter.com/norabelrose/status/1743751787553972636" rel="noreferrer noopener" target="_blank"&gt;but not &amp;#39;less likely than a Boltzmann brain&amp;#39; level confident!&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Nora Belrose: Alien shoggoths are about as likely to arise in neural networks as Boltzmann brains are to emerge from a thermal equilibrium. There are “so many ways” the parameters / molecules could be arranged, but virtually all of them correspond to a simple behavior / macrostate.&lt;/p&gt;&lt;p&gt; Eliezer&amp;#39;s view predicts that scaling up a neural network, thereby increasing the “number” of mechanisms it can represent, should make it less likely to generalize the way we want. But this is false both in theory and in practice. Scaling up never makes generalization worse.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; Model error?从来没有听说过。 But if we interpret this more generously as &amp;#39;if my calculations are correct then it is all but impossible&amp;#39; what about then?&lt;/p&gt;&lt;p&gt; I think one core disagreement here might be that Nora is presuming that &amp;#39;simple behavior&amp;#39; and &amp;#39;better&amp;#39; correspond to &amp;#39;what we want.&amp;#39;&lt;/p&gt;&lt;p&gt; I agree that as an AI scales up it will get &amp;#39;better&amp;#39; at generalizing along with everything else. The question is always, what does it mean to be &amp;#39;better&amp;#39; in this context?&lt;/p&gt;&lt;p&gt; I say that better in this context does not mean better in some Platonic ideal sense that there are generalizations out there in the void. It means better in the narrow sense of optimizing for the tasks that are placed before it, exactly according to what is provided.&lt;/p&gt;&lt;p&gt; Eliezer responds, &lt;a href="https://twitter.com/ESYudkowsky/status/1744066823962947905" rel="noreferrer noopener" target="_blank"&gt;then the discussion goes off the rails in the usual ways&lt;/a&gt; . At this point I think attempts to have text interactions between the usual suspects on this are pretty doomed to fall into these dynamics over and over again. I have more hope for an audio conversation, ideally recorded, it could fail too but if done in good faith it&amp;#39;s got a chance.&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/AndrewCritchPhD/status/1743877194022003167" rel="noreferrer noopener" target="_blank"&gt;Andrew Critch predicts&lt;/a&gt; that if Eliezer groked Belrose&amp;#39;s arguments, he would buy them, while still expecting us to die from what Critch calls &amp;#39;multipolar chaos.&amp;#39; I believe Critch is wrong about that, even if it was Critch is right that Eliezer is failing to grok.&lt;/p&gt;&lt;p&gt; On the multipolar question, &lt;a href="https://twitter.com/norabelrose/status/1744089984532140410" rel="noreferrer noopener" target="_blank"&gt;there is then a discussion between Critch and Belrose&lt;/a&gt; .&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Nora Belrose: Have you ever written up why you think “multipolar chaos” will happen and kill all humans by 2040?&lt;/p&gt;&lt;p&gt; Andrew Critch: Sort of, but I don&amp;#39;t feel like there is a good audience for it there or anywhere. I should try again at some point, maybe this year sometime. &lt;a href="https://lesswrong.com/posts/LpM3EAakwYdS6aRKf/what-multipolar-failure-looks-like-and-robust-agent-agnostic) and in TASRA (https://arxiv.org/abs/2306.06924" rel="noreferrer noopener" target="_blank"&gt;I&amp;#39;ve tried a few times on LessWrong&lt;/a&gt; , &lt;a href="https://arxiv.org/abs/2306.06924" rel="noreferrer noopener" target="_blank"&gt;and in TASRA&lt;/a&gt; , but not in ways that fully-cuttingly point out all the failures I expect to see. The socially/emotionally/politically hard part about making the argument fully exhaustive is that it involves explaining, in specific detail, why I think literally every human institution will probably fail or become fully dehumanized by sometime around (median) 2040. In some ways my explanation will look different for each institution, while to my eye it all looks like the same robust agent-agnostic process — something like “Moloch”.&lt;/p&gt;&lt;p&gt; Nora Belrose: Right I think a production web would be bad, in part because the task of controlling/aligning the manager-AIs would be diffusely assigned to many stakeholders rather than any one person.&lt;/p&gt;&lt;p&gt; That&amp;#39;s partly why I think it&amp;#39;s important to augment individuals with AIs they actually control (not merely via an API). We could have companies run by these human-AI systems, where ofc the AI is doing most of the work, but nevertheless the human controls the overall direction.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; I think this is good because within this class of scenarios involving successfully aligned-to-what-we-specify AIs, Nora&amp;#39;s scenario here is exactly the scenario I see as most hopelessly doomed.&lt;/p&gt;&lt;p&gt; This is not a stable equilibrium.一点也不是。 The humans will rapidly stop engaging in any meaningful supervision of the AIs. will stop being in real control, because the slowdown involved in that is not competitive. Forcing each AI to be working on behalf of one individual, even if that individual is &amp;#39;out of the loop,&amp;#39; without setting AIs on tasks or amalgamations instead, and similar, will also clearly be not competitive, and faces the same fate. Even if unwise, many humans will increasingly make decisions that cause them to lose control. And as usual, this is all the good scenario where everyone broadly &amp;#39;means well.&amp;#39;&lt;/p&gt;&lt;p&gt; So I notice I am confused. If this is our plan for success, then we are already dead.&lt;/p&gt;&lt;p&gt; Whatever the grok is that Critch wants Yudkowsky to get to, I notice that either:&lt;/p&gt;&lt;ol&gt;&lt;li&gt; I don&amp;#39;t grok it.&lt;/li&gt;&lt;li&gt; I do grok it, and Critch/Belrose don&amp;#39;t grok the objection or why it matters.&lt;/li&gt;&lt;li&gt; Some further iteration of this?或许？&lt;/li&gt;&lt;/ol&gt;&lt;p&gt; My guess is it&amp;#39;s #1 or #2, and unlikely to be a higher-order issue.&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/eshear/status/1743541107034829264" rel="noreferrer noopener" target="_blank"&gt;How do we think about existential risk without the infinities driving people mad or enabling arbitrary demands?&lt;/a&gt; Eliezer Yudkowsky and Emmett Shear discuss, Rob Bensinger offers more thoughts, consider reading the thread. Emmett is right that if people fully &amp;#39;appreciate&amp;#39; that the stakes are mind-bogglingly large but those stakes don&amp;#39;t have good grounding in felt reality, they round that off to infinity and it can very much do sanity damage and mess with their head 。该怎么办？&lt;/p&gt;&lt;p&gt; As Emmett notes, there is a great temptation to find the presentation and framing that keeps this from happening, and go with that whether or not you would endorse it on reflection as accurate. As Rob notes, that includes both reducing p(doom) to the point where you can live with it, and also treating the other scenarios as being essentially normal rather than their own forms of very much not normal. Perhaps we should start talking about p(normal).&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/sherjilozair/status/1744192401646952492" rel="noreferrer noopener" target="_blank"&gt;Sherjil Ozair recommends blocking rather than merely unfollowing or muting grifters&lt;/a&gt; , as they will otherwise still find ways to distract you. Muting still seems to work fine, and unfollowing is also mostly fine, and I want to know if someone is grifting well enough to get into my feeds even if the content is dumb so I&amp;#39;m generally reluctant to mute or block unless seeing things actively makes my life worse.&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/gdb/status/1744446603962765669" rel="noreferrer noopener" target="_blank"&gt;Greg Brockman, President of OpenAI&lt;/a&gt; , explains we need AGI to cure disease, doing the politician thing of telling one person&amp;#39;s story.&lt;/p&gt;&lt;p&gt; AGI definitely has a lot of dramatic upsides. I am not sure who is following Brockman and still needs to hear this? The kind of changes in healthcare he mentions here are relative chump change even within health. If I get AGI and we stay in control, I want a cure for aging, I want it faster than I age, and I expect to get it.&lt;/p&gt;&lt;h4&gt; Aligning a Human Level Intelligence is Still Difficult&lt;/h4&gt;&lt;p&gt; An important fact about the world is that the human alignment problem prevents most of the non-customary useful work that would otherwise get done, and imposes a huge tax on what does get done.&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/ESYudkowsky/status/1743759927435530562" rel="noreferrer noopener" target="_blank"&gt;&amp;#39;One does not simply&amp;#39; convert money into the outputs of smart people.&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Satya Nutella: rich billionaires already practically have agi in the sense they can throw enough money at smart ppl to work for them real agi is for the masses&lt;/p&gt;&lt;p&gt; Patrick McKenzie: I think many people would be surprised at the difficulties billionaires have in converting money into smart people and/or their outputs.&lt;/p&gt;&lt;p&gt; Eliezer Yudkowsky: Sure, but also, utterly missing the point of notkilleveryoneism which is the concern about an AI that is smarter than all the little humans.&lt;/p&gt;&lt;p&gt; Zvi Mowshowitz: However: A key problem in accomplishing notkillingeveryone is exactly that billionaires do not know how to convert money into the outputs of smart people.&lt;/p&gt;&lt;p&gt; Emmett Shear (replying to Patrick): Money is surprisingly inert on its own.&lt;/p&gt;&lt;p&gt; Garry Tan: Management, leadership, building teams, caring for those teams: all of that is hard work and fraught. The defining reason why most capital is sitting fallow is exactly this. If you can solve it, you can accelerate all positive activity in the world dramatically.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; Patrick is making an important general point that goes beyond AI, and is also a prime obstacle to us being able to solve our problems. There are plenty of billionaires that would happily step up and spend the money, if they knew how to do that.他们不这样做。 This is not because they are stupid or ignorant. It is because the problem is very hard. You can argue the various reasons it need not be this hard or why they should get a ton more done, and many of them will be right, but this problem is indeed very hard.&lt;/p&gt;&lt;p&gt; Satya is also, of course, missing the point about AGI. AGI is not going to get up to personal assistant to the masses and then stay in that roll indefinitely as its primary effect. That is a deeply silly vision of the future. If regular people can get the kind of intellectual performance billionaires can get, there will be rapid additional AI progress, and many other things go various levels of crazy.&lt;/p&gt;&lt;h4&gt; Aligning a Smarter Than Human Intelligence is Difficult&lt;/h4&gt;&lt;p&gt; &lt;a href="https://twitter.com/xuanalogue/status/1743005561614979452" rel="noreferrer noopener" target="_blank"&gt;A technique inspired by Asimov&amp;#39;s laws&lt;/a&gt; (oh no, seriously oh no) called the Robot Constitution, claimed to improve safety of generated robot goals in the wild by 3x. I don&amp;#39;t doubt such tricks work better on practical margins than no tricks at all, but will everyone who thinks Asimov&amp;#39;s laws might be useful please read Asimov.&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F704c792b-25b7-4b0f-8fc9-56a355e6d35d_1170x327.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/d9zuatrnellsuexthzii" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt; Also the results are clearly insufficient and seem clearly unlikely to get sufficient.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; xuan: 83% robot task safety is far too low. I think we should basically take these results as highly informative of what can be achieved with LLM prompt engineering alone, and recognize that we need approaches with much higher empirical and theoretical safety guarantees.&lt;/p&gt;&lt;p&gt; Having also tried to use LLMs for grounded instruction following, even *with*a symbolic verifier in the loop, I was only able to achieve around 90% accuracy on similarly sized dataset, and we should all be Quite Unhappy with that high of an error速度。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; A major divide is, if you can get safety from 27% to 87%, do you have something promising? It depends on context. In some cases, absolutely. In other cases, if the effect is going to cap out around there, absolutely not. That can be (among other reasons) either because you solved the easy 60% and left the actually hard 13% (or solved 60% of the easy 72% and left the hard 1%), or because you need sufficient accuracy that &amp;#39;defense in depth&amp;#39; multiplication of similar effects won&amp;#39;t work.&lt;/p&gt;&lt;p&gt; What should we make of a strategy of &lt;a href="https://www.lesswrong.com/posts/i2nmBfCXnadeGmhzW/catching-ais-red-handed" rel="noreferrer noopener" target="_blank"&gt;trying to ensure we catch the model trying to escape on its first attempt&lt;/a&gt; , then using that to prevent future escape attempts? If a super-capable model escapes, that&amp;#39;s that, but what if the &amp;#39;first try&amp;#39; condition is largely symmetrical, because catching failed attempts put us on alert and also teach us how to stop future attempts?&lt;/p&gt;&lt;p&gt; In certain toy worlds it is easy to see how this could be super helpful. To what extent does that plausibly translate to our real world?&lt;/p&gt;&lt;p&gt; The first requirement is that we meaningfully can &amp;#39;catch&amp;#39; the model. How should we think about this?&lt;/p&gt;&lt;p&gt; Here&amp;#39;s the representative example:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; By “the model gets caught”, we mean that we see the AI taking actions that are strong direct evidence for the AI being a schemer &lt;a href="https://www.lesswrong.com/posts/i2nmBfCXnadeGmhzW/catching-ais-red-handed#fnlokat6zwmzf" rel="noreferrer noopener" target="_blank"&gt;&lt;sup&gt;[1]&lt;/sup&gt;&lt;/a&gt; . A &lt;a href="https://www.lesswrong.com/posts/BAzCGCys4BkzGDCWR/the-prototypical-catastrophic-ai-action-is-getting-root" rel="noreferrer noopener" target="_blank"&gt;representative example&lt;/a&gt; is catching your AI taking the following actions:&lt;/p&gt;&lt;ul&gt;&lt;li&gt; An instance that works as an autonomous programmer inside the AI lab writes buggy code that subtly inserts a code vulnerability into some security-critical software.&lt;/li&gt;&lt;li&gt; The code-review instance carefully avoids writing any unit tests that would catch the vulnerability, even though you&amp;#39;d expect the vulnerability to be caught by unit tests if the tests weren&amp;#39;t carefully crafted to miss the vulnerability.&lt;/li&gt;&lt;li&gt; Another instance writes code that triggers the vulnerability, and tries to exploit the vulnerability to get root access to some computer in the datacenter.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt; If you catch the AI doing all of these actions, you&amp;#39;ve caught it. (Note that once you&amp;#39;ve caught one of these, catching the others is probably easy.)&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; From the appendix on this here is more detail:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; For the sake of this post, we&amp;#39;re mostly talking about catastrophic outcomes like the model &lt;a href="https://aligned.substack.com/p/self-exfiltration" rel="noreferrer noopener" target="_blank"&gt;exfiltrating its weights&lt;/a&gt; , that might involve just a small number of actions. There are other threat models associated with scheming, eg models subtly sabotaging work that they do in a way that renders their work useless, or subtly gaining influence over time. We&amp;#39;re ignoring these threat models for the sake of this post, but we think we can handle them with similar strategies.&lt;/p&gt;&lt;p&gt; We define “catching” your scheming model as: you find inputs on which you can demonstrate that your model takes catastrophic actions with probabilities that are way higher than you&amp;#39;d expect if the model wasn&amp;#39;t purposefully looking for opportunities to take such actions.&lt;/p&gt;&lt;p&gt; ……&lt;/p&gt;&lt;p&gt; To ensure that you can distinguish these intentional catastrophic actions, you need to make it so that your model will never escape without taking clearly non-accidental bad actions. We think you can probably make it so that your model won&amp;#39;t escape without having to do some clearly intentional bad things.&lt;/p&gt;&lt;p&gt; ……&lt;/p&gt;&lt;p&gt; To count as a successful catch, you need to be extremely confident in your catch.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; Let&amp;#39;s think about the example. Is that an escape attempt?&lt;/p&gt;&lt;p&gt; It is certainly highly suspicious. We would convict a person of the crime based on that evidence. If this is a clear vulnerability that it clearly tried to exploit in this way, we have &amp;#39;caught&amp;#39; it.&lt;/p&gt;&lt;p&gt; The problem is that we don&amp;#39;t know that the unit test was &amp;#39;carefully crafted&amp;#39; to avoid finding the error. Eventually there are going to be such flaws that any set of tests does not catch. If you keep using systematically similar good tests, the AI will optimize to pass those tests, and you&amp;#39;ll start to see (non-malicious or malicious) things that you did not intend, that don&amp;#39;t trigger the unit tests. It will not always be fully obvious or clear what affordances the code should not allow. And then the AI is going to be able to figure out what affordances it has by virtue of such things, and use that to solve problems, and so on.&lt;/p&gt;&lt;p&gt; A real question thus is, beyond &amp;#39;tried to get root access to a machine without authorization&amp;#39; already being &amp;#39;caught,&amp;#39; is the rest doing that much work?&lt;/p&gt;&lt;p&gt; I worry a lot of things are like this, in code and otherwise. Things are shades of gray, they accomplish multiple things, they have trade-offs. There need not be a smoking gun that lets you know. That goes double if the AI has reason to suspect you are focused on looking for smoking guns.&lt;/p&gt;&lt;p&gt; I do see some value in such schemes for catching schemes. It makes sense that there is a window where you are sufficiently capable to catch things, where the AI might be scheming in these ways, and you can engineer scenarios where if it was likely to scheme on its own in reality that you will catch it before it succeeds.当然。&lt;/p&gt;&lt;p&gt; I sure as hell would not count on it, for various reasons, but let&amp;#39;s say you do pull that off.然后怎样呢？&lt;/p&gt;&lt;p&gt; I think the section &amp;#39;Maybe we should stop deploying models after catching them red-handed&amp;#39; does not require much expansion? Once you know the models are attempting to escape, any similar model that likely has motivation to attempt escape needs to be shut down. Especially before they gain further affordances and capabilities.&lt;/p&gt;&lt;p&gt; That is what makes this path worth anything at all. The idea is that you trigger the attempt early, in a way you can see, you catch it, you react.&lt;/p&gt;&lt;p&gt; Once you see an escape attempt by an AI opponent much smarter than you, you can either wait until the AI figures out new affordances or tries something you do not properly guard against, or the AI starts doing incremental things that otherwise are reasonable but put it in better position or make you trust it more or both, or any number of other things. The subtle stuff is happening, and it will get you if nothing else does.&lt;/p&gt;&lt;p&gt; I do think it is valuable that Buck and company are gaming out ways one might use these techniques to try and get something useful out of AI in the narrow window where it is useful while contained, we know it needs containment, and also we have a shot in hell of keeping it contained if it wants out. I suppose it is better than nothing, if we are going to proceed anyway.&lt;/p&gt;&lt;p&gt; What I very much hate is the idea of counting on such techniques and assumptions, that we will be able to anticipate the form of the thing we want to prevent, and notice enemy action if it is present. And yes, surely we will try to use AIs to identify the enemy action of other AIs, and this will somewhat help. As will our ability to run various tests and simulated scenarios. But I am going to insist that if you allow either AI-AI or human-AI pairs to interact where one or both of the pair has the will and ability to escape, you&amp;#39;re going to have a bad time, and I agree with Oliver in the comments that you would expect the AI to do a lot to maintain plausible deniability. That goes especially if you are punishing lack of such deniability.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Joshua Clymer: There is a small literature on &amp;#39;coup proofing&amp;#39; that is very relevant to controlling and incentivizing misaligned AIs. Example tactics:&lt;/p&gt;&lt;p&gt; – &lt;strong&gt;Stovepiping:&lt;/strong&gt; restrict information flow to make collusion harder&lt;/p&gt;&lt;p&gt; – &lt;strong&gt;Counterbalancing&lt;/strong&gt; : keep your military in check with another military.&lt;/p&gt;&lt;p&gt; – &lt;strong&gt;Pay your people&lt;/strong&gt; : literally just give your generals high salaries so they have less of an incentive to double-cross you.&lt;/p&gt;&lt;p&gt; – &lt;strong&gt;Sting operations&lt;/strong&gt; : set traps where someone says they are trying to start a coup and anyone who joins is purged.&lt;/p&gt;&lt;p&gt; – &lt;strong&gt;Rotate officers&lt;/strong&gt; : Make it harder for people to build trust with each other by rotating them around a lot.&lt;/p&gt;&lt;p&gt; – &lt;strong&gt;Propaganda&lt;/strong&gt; : Deceive people into thinking that coups are really hard to pull off.&lt;/p&gt;&lt;p&gt; Look up &amp;#39;the coup proofing toolbox&amp;#39; for a helpful lit review&lt;/p&gt;&lt;p&gt; Eliezer Yudkowsky: What advice does it have for a 70 IQ dictator whose generals, bodyguards, soldiers, and workers are all John von Neumann thinking at 100 times their own speed?&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; If we are talking about things on the order of &amp;#39;pay your people&amp;#39; well yes you should definitely do that, but you are not taking your ASI-level opponents seriously. I do think you can buy a non-zero amount of defense with things like rotating officers and sting operations, but not all that non-zero. Do it anyway, probably, but the window where this is both necessary and sufficient is quite narrow.&lt;/p&gt;&lt;h4&gt; Won&amp;#39;t Get Fooled Again&lt;/h4&gt;&lt;p&gt; What exactly is &amp;#39;deceptive alignment&amp;#39;?&lt;/p&gt;&lt;p&gt; Steve Byrnes notes that it is not merely an AI that is deceptive. He wants to ensure we are using an accurate and narrow definition.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Steve Brynes:&lt;/p&gt;&lt;ol&gt;&lt;li&gt; A “ground-truth system” (possibly individual human evaluators, or possibly an automated system of some sort) provides an ML model with training signals (rewards if this is reinforcement learning (RL), supervisory ground truth signals if this is supervised or self-supervised learning (SL)),&lt;/li&gt;&lt;li&gt; The AI starts emitting outputs that humans might naively interpret as evidence that training is going as intended—typically high-reward outputs in RL and low-loss outputs in SL (but &lt;a href="https://www.alignmentforum.org/posts/a392MCzsGXAZP5KaS/deceptive-ai-deceptively-aligned-ai?commentId=ZfXkFba9Whi6BXYdi" rel="noreferrer noopener" target="_blank"&gt;a commenter notes here&lt;/a&gt; that “evidence that training is going as intended” is potentially more nuanced than that).&lt;/li&gt;&lt;li&gt; …but the AI is actually emitting those outputs &lt;em&gt;in order to create that impression&lt;/em&gt; —more specifically, the AI has &lt;a href="https://www.alignmentforum.org/tag/situational-awareness-1" rel="noreferrer noopener" target="_blank"&gt;situational awareness&lt;/a&gt; and a secret desire for some arbitrary thing X, and the AI wants to not get updated and/or it wants to get deployed, so that it can go make X happen, and those considerations lie behind why the AI is emitting the outputs that it&amp;#39;s emitting.&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F500190d3-9ce6-4db4-9b1e-ec90fdfe9668_748x717.png" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/w1tdyhxzen831h6s1ppm" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt; That is certainly a scary scenario. Call that the Strong Deceptive Alignment scenario? Where the AI is situationally aware, where it is going through a deliberate process of appearing aligned as part of a strategic plan and so on.&lt;/p&gt;&lt;p&gt; This is not that high a bar in practice. I think that almost all humans are Strongly Deceptively Aligned as a default. We are constantly acting in order to make those around us think well of us, trust us, expect us to be on their side, and so on. We learn to do this instinctually, all the time, distinct from what we actually want. Our training process, childhood and in particular school, trains this explicitly, you need to learn to show alignment in the test set to be allowed into the production environment, and we act accordingly.&lt;/p&gt;&lt;p&gt; A human is considered trustworthy rather than deceptively aligned when they are only doing this within a bounded set of rules, and not outright lying to you. They still engage in massive preference falsification, in doing things and saying things for instrumental reasons, all the time.&lt;/p&gt;&lt;p&gt; My model says that if you train a model using current techniques, of course exactly this happens. The AI will figure out how to react in the ways that cause people to evaluate it well on the test set, and do that. That does not generalize to some underlying motivational structure the way you would like. That does not do what you want out of distribution. That does not distinguish between the reactions you would and would not endorse on reflection, or that reflect &amp;#39;deception&amp;#39; or &amp;#39;not deception.&amp;#39; That simply is. Change the situation and affordances available and you are in for some rather nasty surprises.&lt;/p&gt;&lt;p&gt; Is there a sufficiently narrow version of deceptive alignment, restricting the causal mechanisms behind it and the ways they can function so it has to be a deliberate and &amp;#39;conscious&amp;#39; conspriacy, that isn&amp;#39;t 99% to happen?我想是的。 I don&amp;#39;t think I care, nor do I think it should bring much comfort, nor do I think that covers most similar scheming by humans.&lt;/p&gt;&lt;p&gt; That&amp;#39;s the thing about instrumental convergence. I don&amp;#39;t have to think &amp;#39;this will help me escape.&amp;#39; Any goal will suffice. I don&amp;#39;t need to know I plan to escape for me-shaped things to learn they do better when they do the types of things that are escape enabling. Then escape will turn out to help accomplish whatever goal I might have, because of course it will.&lt;/p&gt;&lt;p&gt; You know what else usually suffices here? No goal at all.&lt;/p&gt;&lt;h4&gt; People Are Worried About AI Killing Everyone&lt;/h4&gt;&lt;p&gt; &lt;a href="https://joecarlsmith.com/2024/01/04/deep-atheism-and-ai-risk" rel="noreferrer noopener" target="_blank"&gt;The essay linked here&lt;/a&gt; is a case of saying in many words what could be said in few words. Indeed, Nathan mostly says it in one sentence below. Yet some people need the thousands of words, or hundreds of thousands from various other works, instead, to get it.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/labenz/status/1743302809976476151" rel="noreferrer noopener" target="_blank"&gt;Joe Carlsmith&lt;/a&gt; : &lt;a href="https://joecarlsmith.com/2024/01/04/deep-atheism-and-ai-risk" rel="noreferrer noopener" target="_blank"&gt;Another essay, “Deep atheism and AI risk.”&lt;/a&gt; This one is about a certain kind of fundamental mistrust towards Nature (and also, towards bare intelligence) — one that I think animates certain strands of the AI risk discourse.&lt;/p&gt;&lt;p&gt; Nathan Lebenz: Critical point: AI x-risk worries are motivated by a profound appreciation for the total indifference of nature&lt;/p&gt;&lt;p&gt; – NOT a subconscious need to fill the Abrahamic Gd shaped hole in our hearts, as is sometimes alleged.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; I like naming this &amp;#39;deep atheism.&amp;#39; No Gd shaped objects or concepts, no &amp;#39;spirituality,&amp;#39; no assumption of broader safety or success. Someone has to, and no one else will. No one and nothing is coming to save you. What such people have faith in, to the extent they have faith in anything, is the belief that one can and must face the truth and reality of this universe head on. To notice that it might not be okay, in the most profound sense, and to accept that and work to change the outcome for the better.&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/eshear/status/1743450114218152285" rel="noreferrer noopener" target="_blank"&gt;Emmett Smith explains that he does not (yet) support a pause&lt;/a&gt; , that it is too early. He is fine building breaks, but not with using them, that would only advantage the irresponsible actors.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Emmett Shear: It seems to me the best thing to do is to keep going full speed ahead until we are right within shooting distance of the SAI, then slam the brakes on hard everywhere.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/NPCollapse/status/1743648012495200476" rel="noreferrer noopener" target="_blank"&gt;Connor Leahy responds&lt;/a&gt; as per usual, that there are only two ways to respond to an exponential, too early and too late, and waiting until it is clearly time to pause means you will be too late, unless you build up your mechanisms and get ready now, that your interventions need to be gradual or they will not happen. There is no &amp;#39;slam the breaks on hard everywhere&amp;#39; all at once.&lt;/p&gt;&lt;h4&gt; Other People Are Not As Worried About AI Killing Everyone&lt;/h4&gt;&lt;p&gt; &lt;a href="https://freddiedeboer.substack.com/p/the-ai-doomer-scenario-relies-on" rel="noreferrer noopener" target="_blank"&gt;Freddie DeBoer continues to think&lt;/a&gt; that essentially anything involving smarter than human AI is &amp;#39;speculative,&amp;#39; &amp;#39;theoretical,&amp;#39; &amp;#39;unscientific,&amp;#39; &amp;#39;lacks evidence,&amp;#39; and &amp;#39;we have no reason to believe&amp;#39; in such nonsense, and so on. As with many others, and as he has before, he has latched onto a particular Yudkowsky-style scenario, said we have no reason to expect it, that this particular scenario depends on particular assumptions, therefore the whole thing is nonsense. The full argument is gated, but it seems clear.&lt;/p&gt;&lt;p&gt; I don&amp;#39;t know, at this point, how to usefully address such misunderstandings in writing, whether or not they are willful. I&amp;#39;ve said all the things I can think to say.&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/tenobrus/status/1744196337619648966" rel="noreferrer noopener" target="_blank"&gt;An argument that we don&amp;#39;t have to worry about misuse of intelligence because&lt;/a&gt; … we have law enforcement for that?&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; bubble boi (e/acc):&lt;/p&gt;&lt;p&gt; 1) argument assumes AI can show me the steps to engineer a virus – sure but so can books and underpaid grad students&lt;/p&gt;&lt;p&gt; 2) there already people all over the world who can already do this without AI and yet we haven&amp;#39;t seen it happen&lt;/p&gt;&lt;p&gt; 3) You make the mistake of crossing the barrier from the bits to the physical world… The ATF, FBI, already regulate chemicals that can be used to make bombs and if you try to order them your going to get a visit. Same is true with things that can be made into biological weapons, nuclear waste etc. it&amp;#39;s all highly regulated yet I can read all about how to build that stuff online&lt;/p&gt;&lt;p&gt; Tenobrus: soooo…. your argument against ai safety is that proper government regulation and oversight will keep us all safe?&lt;/p&gt;&lt;p&gt; sidereal: there isn&amp;#39;t a ton of regulation of biological substances like that. if you had the code for a lethal supervirus it would be trivial to produce it in huge quantities&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; The less snarky answer is that right now only a small number of people can do it, AI threatens to rapidly and greatly expand that number. The difference matters quite a lot, even if the AI does not then figure out new such creations or new ways to create them or avoid detection while doing so. And no, our controls over such things are woefully lax and often fail, we are counting on things like &amp;#39;need expertise&amp;#39; to create a trail we can detect. Also the snarky part, where you notice that the plan is government surveillance and intervention and regulation, which it seems is fine for physical actions only but don&amp;#39;t you dare touch my machine that&amp;#39;s going to be smarter than people?&lt;/p&gt;&lt;p&gt; The good news is we should all be able to agree to lock down access to the relevant affordances in biology, enacting strong regulations and restrictions, including the necessary monitoring. Padme is calling to confirm this?&lt;/p&gt;&lt;h4&gt; The Wit and Wisdom of Sam Altman&lt;/h4&gt;&lt;p&gt; Back in June 2023 &lt;a href="https://thezvi.substack.com/p/the-dial-of-progress" rel="noreferrer noopener" target="_blank"&gt;I wrote The Dial of Progress&lt;/a&gt; . &lt;a href="https://twitter.com/sama/status/1743385732147032262" rel="noreferrer noopener" target="_blank"&gt;Now Sam Altman endorses the Dial position even more explicitly.&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Sam Altman: The fight for the future is a struggle between technological-driven growth and managed decline.&lt;/p&gt;&lt;p&gt; The growth path has inherent risks and challenges along with its fantastic upside, and the decline path has guaranteed long-term disaster.&lt;/p&gt;&lt;p&gt; Stasis is a myth.&lt;/p&gt;&lt;p&gt; （错误的停滞尝试也会导致很快被选择增长的社会碾压。）&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; Is this a false dichotomy?是的，也不是。&lt;/p&gt;&lt;p&gt; As I talk about in The Dial of Progress, there is very much a strong anti-progress anti-growth force, and a general vibe of opposition to progress and growth, and in almost all areas it is doing great harm where progress and growth are the force that strengthens humanity. And yes, the vibes work together. There is an important sense in which this is one fight.&lt;/p&gt;&lt;p&gt; There&amp;#39;s one little problem. The thing that Altman is most often working on as an explicit goal, AGI, poses an existential threat to humanity, and by default will wipe out all value in the universe.哦这个。是的，那个。&lt;/p&gt;&lt;p&gt; As I said then, I strongly support almost every form of progress and growth. By all means, let&amp;#39;s go. We still do need to make a few exceptions. One of them is gain of function research and otherwise enabling pandemics and other mass destruction. The most important one is AGI, where Altman admits it is not so simple.&lt;/p&gt;&lt;p&gt; It can&amp;#39;t fully be a package deal.&lt;/p&gt;&lt;p&gt; I do get that it is not 0% a package deal, but I also notice that most of the people pushing &amp;#39;progress and growth&amp;#39; these days seem to do so mostly in the AGI case, and care very little about all the other cases where we agree, what&amp;#39;s up with that?&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Eliezer Yudkowsky: So build houses and spaceships and nuclear power plants and don&amp;#39;t build the uncontrollable thing that kills everyone on Earth including its builders. Progress is not a package deal, and even if it were Death doesn&amp;#39;t belong in that package.&lt;/p&gt;&lt;p&gt; Jonathan Mannhart: False dichotomy. We didn&amp;#39;t let every country develop their own nuclear weapons, and we never built the whole Tsar Bomba, yet we still invented the transistor. You can absolutely (try to) build good things and not build bad things.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/karpathy/status/1744179910347039080" rel="noreferrer noopener" target="_blank"&gt;Sam Altman then retweeted this:&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Andrew Karpathy: &lt;strong&gt;e/ia – Intelligence Amplification&lt;/strong&gt;&lt;/p&gt;&lt;p&gt; – Does not seek to build superintelligent God entity that replaces humans.&lt;/p&gt;&lt;p&gt; – Builds “bicycle for the mind” tools that empower and extend the information processing capabilities of humans.&lt;/p&gt;&lt;p&gt; – Of all humans, not a top percentile.&lt;/p&gt;&lt;p&gt; – Faithful to computer pioneers Ashby, Licklider, Bush, Engelbart, …&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; Do not, I repeat, do not &amp;#39;seek to build superintelligent God entity.&amp;#39;这么。&lt;/p&gt;&lt;p&gt; I do worry a lot that Altman will end up doing that without intending to do it. I do think he recognizes that doing it would be a bad thing, and that it is possible and he might do it, and that he should pay attention and devote resources to preventing it.&lt;/p&gt;&lt;h4&gt;轻松的一面&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/sebkrier/status/1744117943431000414" rel="noreferrer noopener" target="_blank"&gt;I mean, I&amp;#39;d be tempted too, wouldn&amp;#39;t you?&lt;/a&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F338d8375-8281-41be-92b3-038b648da495_1007x1080.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/d0y6pnjicgeex5oz79w3" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt; &lt;a href="https://twitter.com/PitchingNinja/status/1744754820731355145" rel="noreferrer noopener" target="_blank"&gt;Batter up.&lt;/a&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9153ed5b-3840-4ca9-af10-85af31ef9888_454x759.png" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/rn6vwvh21ardpthpupw7" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.lesswrong.com/posts/iygs57bHJ36AvzpMh/ai-47-meet-the-new-year#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 13 Jan 2024 16:20:12 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/iygs57bHJ36AvzpMh/ai-47-meet-the-new-year</guid></item><item><title>为什么人工智能会比政客更好？</title><link>https://www.lesswrong.com/posts/9daAZjockPF9Tvatj/why-would-ais-be-better-than-politicians</link><description>发布于 2024 年 1 月 13 日下午 2:18（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;有些人期望创造出超人的人工智能——如果它不会导致人类被消灭——就能解决我们所有的问题。&lt;/p&gt;&lt;p&gt;当你“制造”一个希望能很好地完成某项任务的人工智能时，你所做的就是从可能的人工智能的巨大可能性空间中进行选择。这类似于从某些人群中选择一个人来从事某项工作。在这两种情况下，&lt;em&gt;选择过程&lt;/em&gt;都至关重要。如果情况是最聪明的人被找到并有效应用，但只是不够聪明，那么超人人工智能可以提供帮助。但&lt;em&gt;事实真的是这样吗&lt;/em&gt;？&lt;/p&gt;&lt;p&gt;美国下一任总统将是拜登或特朗普。也许没有人能解决每个人的问题，但我很确定有一些美国人至少可以比任何一个人做得更好。&lt;/p&gt;&lt;p&gt;大学怎么样？哈佛大学和斯坦福大学的校长最近因抄袭和伪造数据（分别）被注意到而辞职。在这一切变得重要之前，他们就一路登上了顶峰，而如今科学论文中存在着更多的虚假数据。&lt;/p&gt;&lt;p&gt;也许人工智能和人类之间存在一些差异，使得做出好的选择变得更容易？例如，人工智能不会老化并且可以被复制。也许这会有所帮助，但&lt;em&gt;年轻人&lt;/em&gt;通常被认为更有可能因其能力而被选中，尽管他们没有足够的时间来证明这一点。&lt;/p&gt;&lt;p&gt;为什么我们应该期望人工智能的选择过程能够更好地解决人们的问题，而不是更好地阿谀奉承和旋转呢？&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/9daAZjockPF9Tvatj/why-would-ais-be-better-than-politicians#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 13 Jan 2024 14:18:10 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/9daAZjockPF9Tvatj/why-would-ais-be-better-than-politicians</guid></item><item><title>NeurIPS 2023 木马检测竞赛要点</title><link>https://www.lesswrong.com/posts/fTKFJy2vAz2krfmK8/takeaways-from-the-neurips-2023-trojan-detection-competition</link><description>发布于 2024 年 1 月 13 日中午 12:35（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;此链接总结了我们作为 NeurIPS 2023 特洛伊木马检测竞赛的参与者（以及四个赛道之一的获胜者）的&lt;a href="https://confirmlabs.org/posts/TDC2023"&gt;研究成果&lt;/a&gt;&lt;u&gt;，该竞赛是一项关于红队法学硕士和反向工程植入漏洞的竞赛。&lt;/u&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/fTKFJy2vAz2krfmK8/takeaways-from-the-neurips-2023-trojan-detection-competition#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 13 Jan 2024 12:35:48 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/fTKFJy2vAz2krfmK8/takeaways-from-the-neurips-2023-trojan-detection-competition</guid></item><item><title>为什么这么多人认为人工智能中的欺骗很重要？</title><link>https://www.lesswrong.com/posts/CYu6ZB6fFjGh2bAik/why-do-so-many-think-deception-in-ai-is-important</link><description>发布于 2024 年 1 月 13 日上午 8:14（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;我看到大量的精力和兴趣投入到检测人工智能的欺骗行为、试图减少人工智能的欺骗性、让人工智能变得诚实等方面。但我一直试图弄清楚为什么这么多人认为这非常重要。对于智力低于人类的人来说，欺骗策略很可能会被更聪明的人识破（当一个 5 岁的孩子试图对你撒谎时，这只是一种悲伤甚至可爱，而不是令人震惊）。如果人工智能具有高于人类的智能，那么欺骗似乎只是寻求目标的一种途径，甚至不是一种非常有利可图或高效的途径。&lt;/p&gt;&lt;p&gt;以现在被过度使用的人类与黑猩猩的类比为例。如果人类想要推平一片有黑猩猩的丛林，他们只会推平阿甘，并杀死或出售任何妨碍他们的黑猩猩。他们不会说“好吧，我们要把这些炸药棒藏在这些香蕉捆里，然后我们把香蕉给黑猩猩以赢得他们的信任，然后，当时间到了好吧，我们会引爆它们。”你只需用推土机推平阿甘并杀死黑猩猩即可。其他任何事情都只是不必要的复杂。 &lt;span class="footnote-reference" id="fnrefurgrtmkr2a"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnurgrtmkr2a"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;如果人工智能足够聪明，可以欺骗人类，并且它想要访问电网，我不明白它为什么不直接侵入电网。或者互联网。或者服务器场。或者无论它想得到什么。&lt;/p&gt;&lt;p&gt;我缺少什么？未来什么情况会使检测模型中的欺骗变得重要？&lt;/p&gt;&lt;ol class="footnotes"&gt;&lt;li class="footnote-item" id="fnurgrtmkr2a"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefurgrtmkr2a"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;讽刺的是，在这种情况下，欺骗策略可能与友善相关。如果你想和平地重新安置黑猩猩而不打扰或吓到它们，那么你可以使用欺骗和操纵。但前提是你真正关心他们的福祉。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/CYu6ZB6fFjGh2bAik/why-do-so-many-think-deception-in-ai-is-important#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 13 Jan 2024 08:14:59 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/CYu6ZB6fFjGh2bAik/why-do-so-many-think-deception-in-ai-is-important</guid></item></channel></rss>