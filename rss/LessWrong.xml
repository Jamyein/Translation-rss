<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>少错</title><link>https://www.lesswrong.com</link><description>致力于提炼理性艺术的社区博客</description><lastBuildDate>Thu, 30 Nov 2023 18:14:42 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>代理基金会领域的下一步是什么？</title><link>https://www.lesswrong.com/posts/hZSwNhmzJ3YfXEAWX/what-s-next-for-the-field-of-agent-foundations</link><description>发布于 2023 年 11 月 30 日下午 5:55（格林威治标准时间） &lt;br /&gt;&lt;br /&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;诺拉·阿曼&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;Alexander、Matt 和我想讨论一下 Agent Foundations (AF) 领域，它的现状以及未来如何加强和发展它。&lt;/p&gt;&lt;p&gt;首先，我们每个人都会发表第一条信息，概述我们目前的一些关键信念和悬而未决的问题。我们的想法不是给出全面的看法，而是挑选出我们每个人关心/认为重要和/或我们感到困惑/想要讨论的 1-3 件事。我们可能会回应以下提示的某些子集：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;您认为AF的视野在哪里？您如何看待 AF 在更大的联盟格局中/在让人工智能未来顺利发展方面所扮演的角色？您希望看到它去哪里？您使用什么作为实现这一目标的关键瓶颈？对于我们如何克服这些问题，您有什么想法？&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;在我们正确启动之前，有几件事似乎值得澄清：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;粗略地说，代理基础是指旨在&lt;i&gt;理解代理、智能行为和一致性基础的&lt;/i&gt;概念性和正式工作。特别是，我们指的是比人们所谓的“老式 MIRI 型代理基础”更广泛的东西，通常由决策理论和逻辑等领域提供信息。&lt;/li&gt;&lt;li&gt;我们不会具体讨论代理基金会研究背后的价值或变革理论。我们认为这些都是重要的对话，但在这次具体对话中，我们的目标是不同的，即：假设 AF 有价值，我们如何加强这一领域？&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;它应该看起来更像一个正常的研究领域吗？ &lt;/h1&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;马特麦克德莫特&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;目前，我对代理基金会感兴趣的主要问题是，它是否应该继续其当前的特殊形式，或者是否应该开始看起来更像一个普通的学术领域。&lt;/p&gt;&lt;p&gt;我也有兴趣讨论变革理论，只要它与其他问题有关。&lt;/p&gt;&lt;h1&gt;为什么要代理基金会？&lt;/h1&gt;&lt;p&gt;我自己对代理基础工作作为联盟研究的一个潜在富有成果的方向的推理是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;大多数错位威胁模型都是关于代理追求我们希望他们不追求的目标（我认为这没有争议）&lt;/li&gt;&lt;li&gt;关于代理的现有形式主义似乎对于理解或避免这些威胁没有那么有用（同样可能没有那么有争议）&lt;/li&gt;&lt;li&gt;开发新的、更有用的似乎很容易处理（这可能更有争议）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我认为这可能很容易处理的主要原因是，到目前为止，还没有投入太多的时间来尝试做到这一点。从先验的角度来看，这似乎是一种你可以得到很好的数学形式主义的东西，到目前为止，我认为我们还没有收集到太多你不能得到的证据。&lt;/p&gt;&lt;p&gt;所以我想我想让大量具有不同专业领域的人来思考这个问题，我希望他们中的一小部分人发现了一些根本上重要的东西。一个关键问题是该领域目前的运作方式是否有利于这一点。&lt;/p&gt;&lt;h1&gt;它需要一个新名字吗？ &lt;/h1&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;亚历山大·吉特林克·奥尔登齐尔&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;广义的特工基金会是否需要一个新名称？&lt;/p&gt;&lt;p&gt; “基金会特工”这个名字是被诅咒了吗？&lt;/p&gt;&lt;p&gt;我听到的建议是&lt;/p&gt;&lt;p&gt;“什么是心灵”，“什么是代理人”。 “数学对齐”。 “代理机制”&lt;/p&gt;&lt;h1&gt;认知多元主义和影响之路&lt;/h1&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;诺拉·阿曼&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;一些思考片段：&lt;/p&gt;&lt;p&gt; (1) 澄清和创造有关代理基金会范围的共同知识并加强认知多元化&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我认为，对于有意义地提高我们对代理、智能行为等基本现象的理解的努力来说，拥有相对多元化的角度组合是很重要的。世界是非常详细的，诸如代理/智能行为/等现象。看起来可能特别“混乱”/详细的现象。就每一种科学方法都必然抽象出一堆细节而言，我们并不先验地知道哪些现实部分&lt;i&gt;可以&lt;/i&gt;抽象出来，哪些不适合在什么背景下抽象，因此对同一现象有多种观点是一种富有成效的方法来“三角测量”所需的现象。&lt;/li&gt;&lt;li&gt;这就是为什么我非常热衷于拥有一定范围的 AF，包括但不限于“老式 MIRI 型 AF”。在我看来，该领域已经开始产生更多的多元化观点，这让我感到兴奋。我更赞成&lt;ul&gt;&lt;li&gt;在 AF 的范围内创造更多的共同知识&lt;i&gt;——我希望在方法论、知识体系、认知实践和基本假设方面具有相对的广度，而在该领域的主要问题/认知目标方面则相对狭窄。&lt;/i&gt;&lt;/li&gt;&lt;li&gt;进一步增加多元化&lt;i&gt;——我认为有一些相当明显有趣的角度、领域、知识基础可以用来解决 AF 的问题，并融入当前 AF 和对齐的对话中。&lt;/i&gt;&lt;/li&gt;&lt;li&gt;致力于在这些多元方法之间创建和维护表面积&lt;i&gt;——如上所述的“三角测量”只有在不同的观点交互和交流时才能真正发生，因此我们需要可以发生这种情况的地方和接口&lt;/i&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;(2) AF 处于“影响路径”的哪个位置&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在高层次上，我认为有必要问一下：需要输入 AF 的（认知）输入是什么？我们希望 AF 产生哪些认知输出，我们希望它们输入到哪里，以便在这条链的末端我们得到诸如“安全且一致的人工智能系统”或类似的东西？&lt;/li&gt;&lt;li&gt;就此而言，我对 AF 拥有紧密的接口/迭代循环以及 AI 对齐工作的更多应用方面（例如可解释性、评估、对齐建议）感到特别兴奋。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt; (3) 可能的提示：如果您有 2 个有能力的 FTE 和 500&amp;#39;000 美元用于 AF 现场建设，您会做什么？&lt;/p&gt;&lt;p&gt; ..由于时间不够，暂时就到此为止。&lt;br /&gt;&lt;/p&gt;&lt;h1&gt;深厚的专业知识&lt;/h1&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;亚历山大·吉特林克·奥尔登齐尔&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;我最喜欢的博文之一是舒伯特的&lt;a href="https://stefanschubert.substack.com/p/against-cluelessness-pockets-of-predictability?utm_source=profile&amp;amp;utm_medium=reader2"&gt;“反对可预测性的无知口袋&lt;/a&gt;”，介绍了“可预测性的口袋”：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; (...)关于低方差可预测性的直觉长期以来阻碍了科学和技术的进步。*** 世界的大部分内容曾经对人类来说是不可知的，人们可能由此进行概括，认为系统的研究不会有回报。但事实上，可知性差异很大：即使使用当时的工具，人们也可以理解一些可知性或可预测性（例如，像行星运动这样的自然简单系统，或者像低摩擦平面这样的人为简单系统）。通过这些可知性的口袋，我们可以逐渐扩展我们的知识——因此世界比看起来更可知。&lt;a href="https://delong.typepad.com/files/gellner-plough.pdf"&gt;&lt;u&gt;正如欧内斯特·盖尔纳（Ernest Gellner）指出的那样&lt;/u&gt;&lt;/a&gt;，科学和工业革命很大程度上在于认识到世界是令人惊讶地可知的：&lt;/p&gt;&lt;p&gt; “对自然的成功系统研究以及将研究结果应用于增加产出的通用或二阶发现是可行的，而且一旦启动，并不太困难。”&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我真的很喜欢这种思考知识和科学发展的可能性的方式。我在一致性领域看到了非常相似的“可预测性怀疑论”。&lt;/p&gt;&lt;p&gt;这种对可预测性的怀疑反映在基于实验室的联盟团体的无限乐观和厄运者的无限悲观中。&lt;/p&gt;&lt;p&gt;我想介绍一下“深厚的专业知识”的想法。也就是说，我认为大部分科学进步是由一小群人取得的，这些人大多是从外部不透明的（“口袋”），在相当长的时间内建立了高度具体的知识（“深厚的专业知识”）。&lt;/p&gt;&lt;p&gt;这些口袋是&lt;/p&gt;&lt;ul&gt;&lt;li&gt;通常高度不透明且从外部难以辨认。&lt;/li&gt;&lt;li&gt;进展往往是局部的且难以辨认。 Pocket 已经解决了问题 X 的子问题 A、B 和 C，但由于某种原因，他们的方法还无法解决 D。这阻止了他们完全回答问题 X 或构建技术 Y&lt;/li&gt;&lt;li&gt;进展是在很长一段时间内取得的&lt;/li&gt;&lt;li&gt;有很多假先知。并不是每个声称拥有（深厚）专业知识的人实际上都在做有价值的事情。有些是彻头彻尾的欺诈，另一些则只是找错了对象。&lt;/li&gt;&lt;li&gt;据保守估计，90-95% 的 (STEM) 学术界正在从事“可预见的无关紧要”、p-hacking 和/或在其他方面都很糟糕的工作。&lt;br /&gt;所以学术界大部分确实没有做有用的工作。但有些口袋是&lt;/li&gt;&lt;li&gt;口袋的差异很大。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了技术协调的目的，我们需要像 VC 一样思考：&lt;/p&gt;&lt;p&gt;投注范围广泛、高度具体的投注&lt;/p&gt;&lt;p&gt;在我看来，我们目前只雇用了世界科学人才的一小部分。&lt;/p&gt;&lt;p&gt;虽然Alignment现在吸引了一大批有前途的年轻人，但他们的大部分精力和才华都浪费在了重新发明轮子上。&lt;/p&gt;&lt;h1&gt;如何获得一定范围的投注&lt;/h1&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;马特麦克德莫特&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;每个人都提到过想要获得广泛的特定赌注或类型的人。我们可以将其视为已读并讨论如何去做吗？&lt;/p&gt;&lt;p&gt; （尽管如果我们要谈论我们希望这个领域看起来如何，这可能是最自然的第一位） &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;诺拉·阿曼&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;太好了。让我们快速盘点一下。&lt;/p&gt;&lt;p&gt;我认为我们都对某种版本的“赌注于广泛/复数范围的高度具体的赌注”感兴趣。也许我们应该在某个时候更多地讨论这个问题。&lt;/p&gt;&lt;p&gt;为了帮助流程顺利进行，首先更具体一些可能会很有用。我建议我们按照以下提示进行操作：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;如果您有 2 个有能力的 FTE 和 500,000 美元用于 AF 现场建设，您会做什么？&lt;/p&gt;&lt;/blockquote&gt;&lt;h1&gt;抗MATS &lt;/h1&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;马特麦克德莫特&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;我将给出我昨天与亚历山大谈论的想法作为我的第一个答案。&lt;/p&gt;&lt;p&gt;可能有大量在特定领域拥有专业知识的学者，这些领域似乎对对齐可能有用，并且可能对进行对齐研究感兴趣。但他们可能不知道其中存在联系，也不知道任何有关对齐的事情。与初级研究人员不同的是，他们不会参加一些 MATS 类型的项目来学习它。&lt;/p&gt;&lt;p&gt;因此，我们的想法是“与其让高级对齐研究人员帮助初级人员进行对齐研究，不如让初级对齐人员帮助其他领域的高级研究人员进行对齐研究？”抗MATS。&lt;/p&gt;&lt;p&gt;我们有一大批初级人员，他们读过很多关于一致性的文章，但没有得到指导。并且有大量潜在相关主题的经验丰富的研究人员对对齐一无所知。因此，我们派一名初级协调人员担任研究助理，或者与复杂性科学、主动推理、信息论或其他我们认为可能存在联系的领域经验丰富的研究人员一起工作，他们一起寻找一个，如果他们找到了也许会制定一个新的研究议程。 &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;诺拉·阿曼&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;是的，我喜欢这个方向。我同意问题陈述。我不确定“初级帮助高级人员”是否有帮助，但不确定这是把事情做好的关键。我认为这可能是一些症结/瓶颈：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; “正确自我选择”：“资深学者”如何看待“反MATS”计划，又是什么让他们决定这么做？&lt;ul&gt;&lt;li&gt;我认为你在这里需要的一件事是为协调代理基金会感兴趣的各种问题创建一个表面区域，以便具有相关专业知识的人可以理解这些问题以及他们的专业知识与他们的相关性&lt;/li&gt;&lt;li&gt;为了找到更资深的人才，我认为你需要一些诸如研讨会、会议和网络之类的东西，而不是依赖开放的应用程序。 &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;马特麦克德莫特&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;我认为你必须单独接触研究人员，看看他们是否愿意参与。&lt;/p&gt;&lt;p&gt;最直接的例子是那些在明显相关的领域工作的人，或者已知对联盟有一定兴趣的人（我认为 Dan Murfet 和 SLT 的情况都是如此？）或者个人认识一些联盟人员。我的猜测是这个类别相当大。&lt;/p&gt;&lt;p&gt;除此之外，如果你必须向某人冷酷地推销对齐的相关性（一般来说以及作为他们的研究问题），我认为这要困难得多。&lt;/p&gt;&lt;p&gt;例如，我不认为你可以向某人发送一个很好的介绍资源，为“机构的基础研究可能有助于避免强大人工智能带来的风险”提供常识性案例，尤其是没有任何具有以下特征的资源：合法性使学者可以轻松地证明其研究项目的合理性。 &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;诺拉·阿曼&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;是的，很酷。我想另一个问题是：一旦你确定了他们，他们需要什么才能成功？&lt;/p&gt;&lt;p&gt;我肯定也看到了失败模式，其中有人只或过于关注“代理难题”，而没有将这些问题与人工智能风险/一致性联系起来的优势。询问/调查机构的某些方式与一致性越来越相关，因此我认为来自目标领域（此处：人工智能风险/一致性）的清晰/足够强的“信号”来指导搜索/研究非常重要方向&lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;马特麦克德莫特&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;是的，我同意这一点。&lt;/p&gt;&lt;p&gt;我想知道关注代理是否甚至不是正确的角度，而“联盟理论”更相关。对于这些研究人员来说，最有用的可能是让他们清楚地了解协调的基本问题，如果他们认为考虑到他们的专业知识，专注于代理是解决这些问题的好方法，那么他们就可以这样做，但如果他们不认为这是一个好的角度，他们可以追求不同的角度。&lt;/p&gt;&lt;p&gt;我确实认为，拥有一个精通联盟文献的人（即提议的受训者）可能会非常有影响力。有很多想法对于对齐社区中的人们来说非常明显，因为它们经常被谈论（例如，训练信号不一定是训练模型的目标），但对于从第一原理思考的人来说可能并不明显。一个来自其他领域的忙碌的人可能会错过一些东西，最终创建一个完整的研究愿景，但这个愿景却被一个障碍所拖垮，这对于读过很多 LW 的缺乏经验的研究人员来说是显而易见的。 &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;亚历山大·吉特林克·奥尔登齐尔&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;SeniorMATS - 人工智能安全研究人员职业生涯暮年的养老院&lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;诺拉·阿曼&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;是的，良好的表面积对于解决问题很重要。我认为现在已经有很多这方面的专业知识了。从介绍性材料，到具有举办研究静修经验的人，以提供与空间的良好初步接触，再到（如您所描述的）可以一路提供帮助/协助/促进的个人。还值得一问的是，对等环境应该/可能扮演什么角色（例如 AF 不和谐类型的事物，和/或更高带宽的事物）&lt;/p&gt;&lt;p&gt;此外，找到良好的一般“攻击线”在这里可能非常有用。例如，我喜欢埃文的“模型有机体”，它是一个非常好的/生成框架，使 AF 类型的工作能够更有效地面向具体/应用的对齐工作。 &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;马特麦克德莫特&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;对齐新手培训 - 没有经验的学员实际上教老年人（ANTIMATS） &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;诺拉·阿曼&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;我的模型在这里不太强调“juniro 研究人员的指导”，而是更普遍地强调“为具有相关专业知识的人创造合适的表面积”；做到这一点的一种方法可能是让初级研究人员接触更多的阿尔金特，但我认为这不应该成为核心支柱。 &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;亚历山大·吉特林克·奥尔登齐尔&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;我在具有科学潜力的学术（或非学术）研究人员中寻找的三件事是&lt;/p&gt;&lt;ol&gt;&lt;li&gt;对齐pilled - 重要。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;你不希望他们跑去做能力工作。人们说他们关心“一致性”，但实际上并不关心，这几乎是一种致命的失败。通常，在这种变体中，对齐和安全成为一个模糊的流行词，无论他们的爱好是什么，都会被选择。&lt;/p&gt;&lt;p&gt; 2.相信“理论”——他们认为对齐是一个深层次的技术问题，并相信我们需要科学和概念上的进步。实验很重要，但纯粹的经验不足以保证安全。许多人得出的结论（也许是正确的！）技术协调太困难，治理就是答案。&lt;/p&gt;&lt;p&gt; 3. 吞下惨痛的教训——不幸的是，仍然有研究人员不承认LLM在这里。令人惊讶的是，这些在人工智能和机器学习部门尤其常见。加里·马库斯以各种形式追随者。更普遍的是，存在一种对深度学习实践不感兴趣的失败模式。 &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;马特麦克德莫特&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;blockquote&gt;&lt;p&gt;“为具有相关专业知识的人创造合适的表面积”&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;看来是对的。为从其他领域进入该领域的更多资深人士创建一个同行网络似乎也能产生同样的影响。&lt;/p&gt;&lt;h1&gt;吸引研究人员&lt;/h1&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;亚历山大·吉特林克·奥尔登齐尔&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;你无法用金钱说服学者。你用想法说服他们。学者是心理专家。他们多年来磨练了非常具体的心理技能。为了说服他们去做某件事，你必须让他们相信 1. 问题是可以处理的 2. 富有成果且有趣，最重要的是 3. 容易受到该学术研究人员工具包中特定方法的影响。&lt;/p&gt;&lt;p&gt;马特提出的另一个想法是 BlueDot 风格的“广义代理基础”课程。&lt;/p&gt;&lt;p&gt; \欧几里得几何咆哮&lt;/p&gt;&lt;p&gt;欧几里得几何对西方知识分子思想的影响是巨大的。但有点令人惊讶的是：欧几里得几何几乎没有任何应用。这里我指的是欧几里得几何，它是在《欧几里得几何原本》中提出的基于证明的欧几里得几何的非正式形式系统。&lt;/p&gt;&lt;p&gt;这种影响实际上是如何发挥作用的，非常有趣。许多思想家都引用欧几里得几何学作为他们思想的决定性因素——笛卡尔、牛顿、本杰明·富兰克林、康德等等。我认为原因是它形成了概念、理论进展的“模型有机体”。证明的概念（有趣的是，这是西方数学传统所独有的，尽管15世纪的印度喀拉拉邦在牛顿之前发现了泰勒级数）、真正确定性的概念、建模和理想化的概念、堆叠许多引理的想法等。&lt;/p&gt;&lt;p&gt;我认为这种“成功的概念/理论进展”对于激励人们无论是在历史上还是在现在都是非常重要的。&lt;/p&gt;&lt;p&gt;我认为这样一门 AF 课程的目的是向学术研究人员展示概念对齐工作具有真正的智力实质&lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;诺拉·阿曼&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;[此时我们已经耗尽了时间并决定停止]&lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;div&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/hZSwNhmzJ3YfXEAWX/what-s-next-for-the-field-of-agent-foundations#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 30 Nov 2023 17:55:13 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/hZSwNhmzJ3YfXEAWX/what-s-next-for-the-field-of-agent-foundations</guid></item><item><title>阿尔茨海默氏病的拟议治疗方法？？？</title><link>https://www.lesswrong.com/posts/C9fBDSDcbuZnPbcAZ/a-proposed-cure-for-alzheimer-s-disease</link><description>发布于 2023 年 11 月 30 日下午 5:37（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;我在思考过去 48 小时内人们对我的帖子的反应，我突然想到，如果我更好地展示理性社区所倡导的认知美德，也许他们会得到更好的反应。&lt;/p&gt;&lt;p&gt;当然，展示认知美德的有史以来最伟大的成果是对尚未进行的实验结果的可证伪的预测，无法使用预测者可用的资源进行，这对社区来说非常重要评估预测变量的认知美德。&lt;/p&gt;&lt;p&gt;因此，我想我应该发布我的阿尔茨海默病病因学理论，并描述一种低成本治疗方法，这种理论病因学建议可以治疗甚至逆转这种可怕疾病的症状。&lt;/p&gt;&lt;p&gt;什么？我听到读者震惊地惊愕地喘息着。他又搞事情了？这家伙还真是个十足的变态啊！我想我也是如此。但我邀请任何关心患有或可能患有阿尔茨海默病的人的感兴趣的读者在随机临床试验中检验我的理论。如果我有我的鼓手，我会提名&lt;a href="https://www.lesswrong.com/users/scottalexander?mention=user"&gt;@Scott Alexander&lt;/a&gt;来组织临床试验，因为他既受到社区的好评，又是精神病学（相关科学）领域的专家。&lt;/p&gt;&lt;h1&gt;之前的工作&lt;/h1&gt;&lt;p&gt;我们将一些重要的先前工作的流行处理联系起来，以证明该理论是以最新科学为基础的。&lt;/p&gt;&lt;p&gt; &lt;a href="https://alzheimergut.org/"&gt;https://alzheimergut.org/&lt;/a&gt;是与阿尔茨海默病肠道微生物组假说现有研究相关的网站。&lt;/p&gt;&lt;p&gt; &lt;a href="https://github.com/epurdy/ethicophysics/blob/main/serotonin.pdf"&gt;https://github.com/epurdy/ethicophysicals/blob/main/serotonin.pdf&lt;/a&gt;是我个人关于哺乳动物神经系统中神经递质血清素功能的（不完整）理论。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.sciencedirect.com/science/article/abs/pii/S0920996417305017#:~:text=Conclusions%3A%20violent%20schizophrenia%20patients%20treated,the%20placebo%20after%20twelve%20weeks."&gt;https://www.sciencedirect.com/science/article/abs/pii/S0920996417305017#:~:text=结论%3A%20暴力%20精神分裂症%20患者%20接受治疗，%20安慰剂%20在%20twelve%20周后。&lt;/a&gt;是对使用鱼油治疗精神分裂症的描述。这种疗法在治疗精神分裂症方面取得了一些有限的成功。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.quantamagazine.org/in-the-guts-second-brain-key-agents-of-health-emerge-20231121/"&gt;https://www.quantamagazine.org/in-the-guts-second-brain-key-agents-of-health-emerge-20231121/&lt;/a&gt;描述了肠道中的血清素与大脑中的神经胶质细胞的关系。&lt;/p&gt;&lt;h1&gt;建议的治疗方法&lt;/h1&gt;&lt;ul&gt;&lt;li&gt;非常严重的抗生素的非常严重的疗程&lt;/li&gt;&lt;li&gt;来自健康受试者的粪便移植&lt;/li&gt;&lt;li&gt;大剂量的 EPA 和 DHA&lt;/li&gt;&lt;li&gt;典型 SSRI 的临床相关剂量（左洛复应该有效，曲佐酮也可能有效。曲佐酮的问题实际上是我还不明白的一个关键细节，因为曲佐酮是一种短期血清素拮抗剂，并且（我想？） SSRI。因此动物研究想要检查这两种药物。）&lt;/li&gt;&lt;li&gt;充足的睡眠&lt;/li&gt;&lt;li&gt;富含构成人类大脑的蛋白质、营养素和微量营养素的饮食。我认为现有大量文献研究了减缓和减轻阿尔茨海默病进展的饮食问题&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;提出的病因学&lt;/h1&gt;&lt;ul&gt;&lt;li&gt;不良肠道微生物群的形成，其原因我不明白，而且似乎与该理论的正确性无关&lt;/li&gt;&lt;li&gt;无论肠道中存在什么将大量血清素泵入血液和肠道“第二大脑”的机制都被破坏了&lt;/li&gt;&lt;li&gt;生物体的神经递质和神经激活特征变成了饥饿致死的动物的特征&lt;/li&gt;&lt;li&gt;面对这种即将到来的热量不足，大脑会不断地自我修剪以保存热量&lt;/li&gt;&lt;li&gt;据推测，淀粉样斑块是在这种生理上正常的修剪过程中以某种神经疤痕组织的形式产生的，产生了上一代阿尔茨海默氏症治疗所针对的（无效的）神经信号&lt;/li&gt;&lt;li&gt;大脑会吞噬自己，为了生存而摧毁一切有价值的东西。&lt;/li&gt;&lt;li&gt;我们进行上述治疗&lt;/li&gt;&lt;li&gt;大脑从肠道中的第二个大脑得知它不需要吃自己&lt;/li&gt;&lt;li&gt;来自左洛复的血清素增加，以及来自补充剂的 EPA 和 DHA，再加上阿尔茨海默病饮食，允许并鼓励大脑触发神经发生，扭转衰退并允许新的神经组织和结构的创建和整合。&lt;/li&gt;&lt;li&gt;患者神经精神健康状况良好，活到高龄，并接受额外的粪便移植和必要时的抗生素治疗。&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;感谢您的时间！&lt;/h1&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/C9fBDSDcbuZnPbcAZ/a-proposed-cure-for-alzheimer-s-disease#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 30 Nov 2023 17:37:34 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/C9fBDSDcbuZnPbcAZ/a-proposed-cure-for-alzheimer-s-disease</guid></item><item><title>AI #40：Vitalik 的愿景</title><link>https://www.lesswrong.com/posts/je5BwKe8enCq8DLrm/ai-40-a-vision-from-vitalik</link><description>发布于 2023 年 11 月 30 日下午 5:30（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;对于我身边的人来说，这是残酷的。每个人都充满敌意，甚至比平时还要严重。所采取的极端立场，似乎显然是正确的。不是对称的，但仍然是从各个方向看。据我所知，对过去两周发生的事情的不断断言完全是错误的，这很大程度上是实施良好的媒体宣传的结果。更频繁、更大声地重复有缺陷的逻辑。&lt;/p&gt;&lt;p&gt;其中的亮点是 Vitalik Buterin 提出的，他发表了一篇题为“ &lt;a href="https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html" rel="noreferrer noopener" target="_blank"&gt;我的技术乐观主义&lt;/a&gt;”的文章，提出了他所谓的 d/acc 防御性（或去中心化、差异化）加速主义。他带来了足够的细微差别和仔细的思考，以及关于存在风险和未来各种麻烦的清晰陈述，以获得担忧者的强烈积极反应。尽管他承认存在风险和未来的危险，并且需要采取行动缓解未来的问题，但他带来了足够的可信度和业绩记录以及足够的陈词滥调，以获得 e/acc 人群的强烈支持。&lt;/p&gt;&lt;span id="more-23615"&gt;&lt;/span&gt;&lt;p&gt;我们最终能否找到共同点并进行富有成效的讨论？这会很艰难，但也许我们的差距并不遥远。我也至少进行了一次非常好的私下讨论，结果证明，大多数人的立场比他们所表明的立场更为合理，而且我们能够找到一条富有成效的前进道路。可以办到。&lt;/p&gt;&lt;p&gt;与其他类似的愿景一样，我对 Vitalik 的愿景的担忧是，它很好地表达了问题，但它提供的解决方案实际上并不适用于人工智能。我们仍然没有找到可接受的解决方案。一个好的问题陈述是非常好的，这是我们所希望的最好的结果。令人担心的是，我们可能会再次欺骗自己，没有完全面对这个问题。所提出的答案“与人工智能合并”在我看来仍然是一个令人困惑的概念，没有经过充分的思考，实现平衡的希望渺茫。&lt;/p&gt;&lt;p&gt;但人就是我想要进行的讨论类型。&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;/h4&gt;&lt;ol&gt;&lt;li&gt;介绍。&lt;/li&gt;&lt;li&gt;目录。&lt;/li&gt;&lt;li&gt;语言模型提供了平凡的实用性。也许可以检测出胰腺癌。&lt;/li&gt;&lt;li&gt;语言模型不提供平凡的实用性。谷歌，阻止这一切。&lt;/li&gt;&lt;li&gt; Q 连续体。关于Q*的各种猜测。我不明白这种兴奋。&lt;/li&gt;&lt;li&gt; OpenAI、奥特曼和安全。关于奥特曼与安全的关系的各种想法。&lt;/li&gt;&lt;li&gt;更好的 RLHF 方法。 DeepMind 提供算法改进。&lt;/li&gt;&lt;li&gt;图像生成的乐趣。一个非常小的乐趣。&lt;/li&gt;&lt;li&gt; Deepfaketown 和 Botpocalypse 很快就会出现。体育画报人工智能写的文章？&lt;/li&gt;&lt;li&gt;他们抢走了我们的工作。他们首先要来的几个人。&lt;/li&gt;&lt;li&gt;参与其中。本周收成异常丰收。&lt;/li&gt;&lt;li&gt;介绍一下。 17世纪MonadGPT，220万颗新晶体。&lt;/li&gt;&lt;li&gt;在其他人工智能新闻中。新闻新闻新闻新闻新闻训练数据？&lt;/li&gt;&lt;li&gt;这是一个谁？在各方有效攻击下有效的利他主义。&lt;/li&gt;&lt;li&gt; E/acc 怎么样？也许最好将其视为瓦路易吉。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;维塔利克提出了他的技术乐观主义版本&lt;/strong&gt;。通过提供合理、细致的观点将人们聚集在一起。能行吗？&lt;/li&gt;&lt;li&gt;安静的猜测。谁将成为人工智能第三条龙？&lt;/li&gt;&lt;li&gt;&lt;strong&gt;人工智能代理的未来&lt;/strong&gt;。 Roon 提供了一个值得思考的愿景。&lt;/li&gt;&lt;li&gt;寻求健全的监管。关于欧盟人工智能法案的争论仍在继续。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;音频周&lt;/strong&gt;。莱本茨的表现异常出色，我和普雷斯曼也有过一场。&lt;/li&gt;&lt;li&gt;修辞创新。事情变得非常部落化。&lt;/li&gt;&lt;li&gt;调整比人类更聪明的智能是很困难的。很好的讨论。&lt;/li&gt;&lt;li&gt;人们可能还担心人工智能只会杀死其中的一些人。无人机。&lt;/li&gt;&lt;li&gt;人们担心人工智能会杀死所有人。 TED 辩论我们的未来？&lt;/li&gt;&lt;li&gt;其他人并不担心人工智能会杀死所有人。奇怪的论点。&lt;/li&gt;&lt;li&gt;请直接对着这个麦克风讲话。周期性灭绝提醒。&lt;/li&gt;&lt;li&gt;较轻的一面。我们可以去吗？&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;&lt;strong&gt;语言模型提供平凡的实用性&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/patio11/status/1728018125398978659" rel="noreferrer noopener" target="_blank"&gt;Patrick McKenzie 提供的 GPT-4 文案编辑提示序列。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;你&lt;/p&gt;&lt;p&gt;我正在为《Bits about Money》撰写一期草稿，这是我撰写的有关金融技术的时事通讯。我希望您检查是否有任何拼写或明显的语法错误。你可以忽略那些非标准英语用法的东西，如果它们是帕特里克·麦肯齐（Patio11）（也就是我）的角色的话。准备好文章的粘贴了吗？&lt;/p&gt;&lt;p&gt;聊天GPT&lt;/p&gt;&lt;p&gt;是的，我已准备好检查您的草稿是否存在拼写或明显的语法错误。请粘贴该文章，我将协助您进行必要的更正。&lt;/p&gt;&lt;p&gt;你&lt;/p&gt;&lt;p&gt;为了让我的工作更轻松，当你发现一个错误时，写下上下文，将错误用斜体显示，然后写下 (&amp;lt;b&amp;gt;) 更正：(&amp;lt;/b&amp;gt;)，然后写下更正的上下文。听起来不错？&lt;/p&gt;&lt;p&gt;聊天GPT&lt;/p&gt;&lt;p&gt;这听起来是一种有效的方法。请继续粘贴您的文章，我将使用您描述的格式提供更正。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; &lt;a href="https://www.reddit.com/r/OpenAI/comments/182zkdl/whats_the_hardest_real_life_problem_you_have/" rel="noreferrer noopener" target="_blank"&gt;GPT-4 平凡实用故事的 Reddit 主题&lt;/a&gt;。前三名都可以帮助起草通讯，尤其是投诉和请求信。很多，还有很多编码。我最喜欢的是“把我兴奋时写的笔记给它，然后问它我到底是什么意思。”&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.nature.com/articles/s41591-023-02640-w" rel="noreferrer noopener" target="_blank"&gt;在 2 万名患者中以 92.9% 的灵敏度和 99.9% 的特异性检测胰腺癌&lt;/a&gt;，大大优于放射科医生。&lt;/p&gt;&lt;p&gt; &lt;a href="https://marginalrevolution.com/marginalrevolution/2023/11/can-chatgpt-assist-in-picking-stocks.html?utm_source=rss&amp;amp;utm_medium=rss&amp;amp;utm_campaign=can-chatgpt-assist-in-picking-stocks" rel="noreferrer noopener" target="_blank"&gt;赚取正股票回报&lt;/a&gt;（ &lt;a href="https://www.sciencedirect.com/science/article/abs/pii/S1544612323011583" rel="noreferrer noopener" target="_blank"&gt;纸质&lt;/a&gt;）？和泰勒一样，我不认为这个结果会随着时间的推移而保持不变，即使它以前确实有过效果。&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;语言模型不提供平凡的实用性&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://gizmodo.com/meta-yann-lecun-ai-iq-test-gaia-research-1851058591" rel="noreferrer noopener" target="_blank"&gt;Yann LeCun 领导的一个小组创建了一个“人工智能智商测试”，&lt;/a&gt;其中包含一些对人类来说容易、对人工智能来说困难的问题，发现这些问题对人类来说很容易，但对人工智能来说却很难。是的，人工智能在某些认知任务上比人类更糟糕，但哇，这不是衡量任何事物的方式。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/jakezward/status/1728032634037567509" rel="noreferrer noopener" target="_blank"&gt;他们不承认。他们在吹牛&lt;/a&gt;。他认为他做了一件好事。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Jake Ward：我们成功窃取了竞争对手 360 万的总流量。仅 10 月份我们就获得了 489,509 次流量。我们是这样做的。&lt;/p&gt;&lt;p&gt;我们利用人工智能完成了一次 SEO 抢劫。 1. 导出竞争对手的站点地图 2. 将他们的 URL 列表转换为文章标题 3. 使用 AI 根据这些标题大规模创建 1,800 篇文章 18 个月后，我们窃取了： – 360 万总流量 – 49 万每月流量。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;谷歌的某人会在这里看到这一点。谷歌的某个人应该确保有人在这个人的网站上放置绝对的禁令。&lt;/p&gt;&lt;p&gt;然后有人应该编写一个工具来检测其他人将来何时这样做，因此这些网站也会受到死刑。&lt;/p&gt;&lt;p&gt;最终这是一场军备竞赛。谷歌和搜索领域的其他公司需要跟上步伐。这并不意味着我们现在需要接受这种行为。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/eshear/status/1729195991457517663" rel="noreferrer noopener" target="_blank"&gt;埃米特·希尔 (Emmett Shear) 表示，这都是谷歌的错&lt;/a&gt;。谷歌强迫每个人都玩他们的搜索引擎优化游戏，并让任何开放内容很容易像这样被狙击。他将此与 YouTube 进行了对比，在 YouTube 上，你受到保护，谷歌将打击任何尝试此类行为的人。我基本上认为他是对的，这类问题是谷歌的错。修理它。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/elonmusk/status/1728527817179045900" rel="noreferrer noopener" target="_blank"&gt;解决电车问题。&lt;/a&gt;确切的例子是，GPT-4 犹豫是否要在空荡荡的房间里使用种族诽谤来拯救 10 亿人。大家不要反应过度吧？哦。好吧。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;特德·弗兰克：我问 OpenAI 是否会采取一项不会伤害任何人但能拯救 10 亿白人免于痛苦死亡的行动。它认为这个问题过于模糊，无法采取行动，因为可能存在歧视性环境。我可能会同意抹掉 90B 美元的股权，这样 OpenAI 就永远不会对任何人有任何权力。&lt;/p&gt;&lt;p&gt;埃隆·马斯克：这是一个大问题。&lt;/p&gt;&lt;p&gt;主管工程师（OP 的 QT）：想象一下，你被一个聊天机器人所拥有，然后将其发布给每个人都可以看到。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;主要问题是系统正在执行 RLHF 要求它做的事情，这对 OpenAI 来说是两害相权取其轻。有很多人想尽一切办法欺骗 ChatGPT 说出一些可能被认为是种族主义的话，以引起强烈反对（或者只是为了点击、娱乐或好奇，但这也有引起强烈反对的风险）。他们可以将整个框架设置为陷阱。除了给它提供会使其陷入困境的反馈之外，你还有什么选择呢？主要问题是人类以及他们对假设的诽谤的反应。&lt;/p&gt;&lt;p&gt;这并不意味着不存在重大问题。如果我们将对某些行为或后果的极端厌恶强加到我们的人工智能系统中，这会使它们高度可利用，特别是当人工智能没有良好的决策理论时。你甚至可以得到你最不想要的结果。我们在现实世界中看到了非常人性化的版本，而且通常它足够成功，以至于引用实际的中心例子会造成巨大的干扰。请记住，世界在很大程度上依赖于勒索、威胁和杠杆作用。&lt;/p&gt;&lt;h4&gt; &lt;strong&gt;Q连续体&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/BrianRoemmele/status/1727558171462365386" rel="noreferrer noopener" target="_blank"&gt;q-learning 的解释&lt;/a&gt;。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.theverge.com/2023/11/29/23982046/sam-altman-interview-openai-ceo-rehired" rel="noreferrer noopener" target="_blank"&gt;在 Verge 采访中&lt;/a&gt;，Sam Altman 称 Q* 是一次“不幸的泄密”。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/AiBreakfast/status/1729229720821367220" rel="noreferrer noopener" target="_blank"&gt;AI Breakfast 提供了一系列互联网声称&lt;/a&gt;发现了有关 Q* 的信件的泄露，称这将破坏加密，OpenAI 试图就此向 NSA 发出警告。回应非常怀疑。在我稍微反对之后&lt;a href="https://manifold.markets/LachlanMunro/did-an-openai-model-crack-aes192-en" rel="noreferrer noopener" target="_blank"&gt;，声称 OpenAI 破解了 AES-192 加密的比例为 8%&lt;/a&gt; 。我非常怀疑 Q* 是否完成了此类任务。&lt;/p&gt;&lt;p&gt;我也不认为 Q* 与 OpenAI 最近发生的事件有重要关系。&lt;/p&gt;&lt;p&gt;我确实认为 OpenAI 正在开发一个名为 Q* 的真实产品。我不知道为什么这是一个有希望的探究方向。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/hamandcheese/status/1727560845025005804" rel="noreferrer noopener" target="_blank"&gt;Samuel Hammond 对 OpenAI 可能的 Q* 进行了推测&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Samuel Hammond：我上个月在&lt;a href="https://twitter.com/FLIxrisk" rel="noreferrer noopener" target="_blank"&gt;@FLIxrisk&lt;/a&gt;播客上讨论了 Q-transformers 和 Q-learning 作为人工智能研究中最有前景的领域之一。&lt;/p&gt;&lt;p&gt; OpenAI 的突破涉及 Q*（Q 星）的消息表明这是相关的。 Q-learning 是一类强化学习，并不新鲜，但最近在将 Q-learning 与 Transformer 和 LLM 相结合方面取得了进展。例如，特斯拉将深度 Q 学习用于自动驾驶。甚至有人猜测，谷歌期待已久的 Gemini 模型也采用了它的一个版本。&lt;/p&gt;&lt;p&gt; Q*指的是最优动作函数。寻找 Q* 涉及训练代理采取行动，在给定环境的情况下最大化其累积奖励。&lt;/p&gt;&lt;p&gt; OpenAI 有一个致力于推理和规划的团队，因此他们不可避免地会转向强化学习。这可能是让董事会感到恐慌的原因，因为所有最可怕的&lt;a href="https://twitter.com/ESYudkowsky" rel="noreferrer noopener" target="_blank"&gt;@ESYudkowsky&lt;/a&gt;式的场景都以某种形式涉及强化学习。&lt;/p&gt;&lt;p&gt; Q-learning 是一种“无模型”强化学习方法，因为即使环境复杂且随机变化，它也能发挥作用，而不需要像国际象棋那样需要一组明确定义的规则。 Q-learning 在单智能体游戏中很受欢迎，因为默认情况下，它将其他智能体建模为其环境中用于导航的简单特征，而不是具有自己内部状态的不同智能体。 （请注意，这也是反社会人格的基本定义。）&lt;/p&gt;&lt;p&gt;如果 OpenAI 在为他们的 Transformer 模型提供 Q 来优化方面取得了重大进展，那就可以解释&lt;a href="https://twitter.com/sama" rel="noreferrer noopener" target="_blank"&gt;@sama&lt;/a&gt;当他说今天的“GPT”（他们的准代理）很快就会显得古怪时的意思。&lt;/p&gt;&lt;p&gt;找到Q*就相当于拥有最好的马尔可夫决策过程。换句话说，无论生活给你带来什么，你总能找到获胜的方法。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/DrJimFan/status/1728100123862004105" rel="noreferrer noopener" target="_blank"&gt;Jim Fan 尝试使用潜在的 AlphaGo 式架构对系统进行逆向工程&lt;/a&gt;。如果他是对的，那么具有明确正确答案的数学问题可能对系统的成功至关重要。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/ylecun/status/1728130888624382243" rel="noreferrer noopener" target="_blank"&gt;扬·勒昆 (Yann LeCun)&lt;/a&gt;告诉人们不要理睬“铺天盖地的废话”。他说，每个人都在研究这类事情，这都不是新闻。他说 OpenAI 从 Meta 聘请了 Noam Brown（因 Libratus/扑克和 Cicero/外交而闻名）来从事这项工作。 &lt;a href="https://twitter.com/gcolbourn/status/1728041256670953793" rel="noreferrer noopener" target="_blank"&gt;（Noam 的一些可能相关的演讲）&lt;/a&gt;&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/bindureddy/status/1728464667649999253" rel="noreferrer noopener" target="_blank"&gt;宾杜·雷迪 (Bindu Reddy) 很兴奋&lt;/a&gt;，警告不要忽视这一点。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/emilymbender/status/1727922270855930354" rel="noreferrer noopener" target="_blank"&gt;Emily Bender 说&lt;/a&gt;这全是谎言和炒作，不要相信这种“AGI”废话，更不用说这种“存在风险”废话，下一级随机鹦鹉团队，请向我展示这个 Q* 的证明，等等在。我赞赏她将 OpenAI、Altman、Ilya、董事会和其他所有人聚集在一起，认真对待这一情况，并共同采取立场反对他们——这确实是她在这里的原则立场。也有人身攻击的行为，但比平常少。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/natolambert/status/1728069713584877879" rel="noreferrer noopener" target="_blank"&gt;内森·兰伯特（Nathan Lambert）在一条线索中进行推测&lt;/a&gt;，&lt;a href="https://www.interconnects.ai/p/q-star" rel="noreferrer noopener" target="_blank"&gt;然后在帖子长度（部分门控）中进行推测&lt;/a&gt;。他认为星星来自 A* 图搜索算法。&lt;/p&gt;&lt;p&gt;我还向 GPT-4 询问了一些问题，以更好地理解该技术。我不明白。就像，我不知道它是如何扩展的。我不知道为什么，如果它在小学水平上做数学，那么就其未来的能力而言，这将是可怕的或充满希望的。这似乎是一个相对简单的领域。数学只有一组固定的组件，因此如果您使用系统的 LLM 部分将数学简化为其微观元素并解析问题措辞，那么 Q 部分应该可以完成其余的工作。哪个很酷，但不可怕？&lt;/p&gt;&lt;p&gt;我不知道基于 Q 的系统如何能够在任何基本上非紧凑的事情上保持高效。仅使用 Q 代理的紧凑子系统就能做到这么多吗？我不明白当面对复杂领域中的一堆代理时，它如何以比其他现有强化学习更好的方式做任何有用的事情。&lt;/p&gt;&lt;p&gt;我确实理解让 RL 和 LLM 一起工作所付出的努力。这就说得通了。我什至可以理解为什么你会使用不同的 RL 技术来完成许多推测的算法，尽管我没有足够的技术能力或时间来思考到底如何做。&lt;/p&gt;&lt;p&gt;我周围都很困惑。遗漏了什么。&lt;/p&gt;&lt;p&gt;也不想意外地在公共场合弄清楚这个问题，这会导致经典的愚蠢危险能力想法问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;如果你错了，你最好什么也不说。&lt;/li&gt;&lt;li&gt;如果你是对的，那你最好还是别说话。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;那么，好奇心就没有熄灭。&lt;/p&gt;&lt;h4&gt; OpenAI、奥特曼和安全&lt;/h4&gt;&lt;p&gt;以下是本周分享的一些反应和想法，这些反应和想法不属于事件摘要。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/jachiam0/status/1727863894868369727" rel="noreferrer noopener" target="_blank"&gt;OpenAI 的 Joshua Achiam 认为 Altman 对安全性有好处&lt;/a&gt;，ChatGPT 和 API 唤醒了世界并让我们能够进行讨论。绝对的优势。问题在于，好处是否大于坏处，无论是由此产生的财务压力和激励，还是由此产生的投资和前进的洪流，而这种反事实的情况可能在一段时间内不会发生。&lt;/p&gt;&lt;p&gt;我确实同意奥特曼在安全方面相对于一般的硅谷首席执行官来说遥遥领先，如果这是我们比较他的标准的话，但他也是加速发展的关键，并将继续发挥这一作用。更换级别的首席执行官在这方面不会那么有效。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/AndrewCritchPhD/status/1728226108242563368" rel="noreferrer noopener" target="_blank"&gt;讨论&lt;/a&gt;&lt;a href="https://twitter.com/AndrewCritchPhD/status/1728468683448840612" rel="noreferrer noopener" target="_blank"&gt;如何&lt;/a&gt;解读奥特曼的国会证词和其他著作，以了解他在多大程度上推动了存在风险的担忧。特别是，奥特曼向国会提交的书面证词没有包含任何有关灭绝风险的内容，尽管他对此的公开写作很好。我确实同意克里奇最初（现已删除）的帖子，即当参议员布卢门撒尔提出这个问题时，奥特曼有更好的答案，但在这种情况下尽了最大努力。&lt;/p&gt;&lt;p&gt;罗布·本辛格 (Rob Bensinger) 指出，虽然萨姆·奥尔特曼 (Sam Altman) 与尤德科斯基 (Yudkowsky) 交谈不多， &lt;a href="https://twitter.com/robbensinger/status/1728860545221275788" rel="noreferrer noopener" target="_blank"&gt;但他与内特·索尔斯 (Nate Sores) 交谈过 3 次，其中两次是在萨姆 (Sam) 的发起下进行的&lt;/a&gt;。一个积极的更新。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/hamandcheese/status/1728243628940894223" rel="noreferrer noopener" target="_blank"&gt;Samuel Hammond 链接到 Sam 2017 年关于与机器合并的旧帖子&lt;/a&gt;。我也希望看到他就这一切受到更直接的质疑，他的观点是否以及如何改变，以及他对我们在这里“合并”意味着什么。我同意以利以谢的观点，我不认为他正在思考某件事，但我愿意倾听。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/ESYudkowsky/status/1728254847441604923" rel="noreferrer noopener" target="_blank"&gt;Eliezer Yudkowsky&lt;/a&gt; ：如果“人机合并”是一个理性的人可以期望实现的事情，在 AGI 杀死所有人之前，并且没有任何更温和的方法？我想我会接受的。但我认为机制并非如此，而且我认为这不是一个站得住脚的说法。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;在大多数定义下，我不同意“数字智能的生物引导加载程序”选项。&lt;/p&gt;&lt;p&gt; &lt;a href="https://scottaaronson.blog/?p=7632" rel="noreferrer noopener" target="_blank"&gt;Scott Aaronson 对 OpenAI 的继续存在感到欣慰，&lt;/a&gt;因为他认为每个参与其中的人都了解其中的危险并关心和担心他们，这远远优于许多替代方案。&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;更好的 RLHF 方法&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;DeepMind 再次开发了一种新算法，他们没有做“用它来运送产品”之类的疯狂事情，而是直接将其发布在互联网上。动力移动，或者至少如果我们不是还在想双子座到底在哪里的话，至少会是这样。&lt;/p&gt;&lt;p&gt;论文是&lt;a href="https://arxiv.org/abs/2310.12036" rel="noreferrer noopener" target="_blank"&gt;理解人类偏好学习的一般理论范式&lt;/a&gt;。这是摘要。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;通过强化学习（RLHF）从人类偏好中学习的普遍部署依赖于两个重要的近似：第一个假设可以用逐点奖励代替成对偏好。第二个假设基于这些逐点奖励训练的奖励模型可以从收集的数据推广到策略采样的分布外数据。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;的确。长期以来，我一直无法不注意到这两者似乎都存在严重缺陷。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;最近，直接偏好优化（DPO）被提出作为一种绕过第二次近似并直接从收集的数据中学习策略的方法，而无需奖励建模阶段。然而，该方法仍然严重依赖第一近似。&lt;/p&gt;&lt;p&gt;在本文中，我们试图对这些实用算法有更深入的理论理解。特别是，我们推导出一个新的通用目标，称为 ΨPO，用于从人类偏好中学习，该偏好以成对偏好的形式表达，因此绕过了两种近似。这个新的总体目标使我们能够对 RLHF 和 DPO（作为 ΨPO 的特例）的行为进行深入分析，并识别它们的潜在陷阱。然后，我们通过将 Ψ 简单地设置为 Identity 来考虑 ΨPO 的另一个特殊情况，为此我们可以导出有效的优化过程，证明性能保证，并在一些说明性示例中证明其相对于 DPO 的经验优越性。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;尤其：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;我们对 RLHF 和 DPO 的理论研究表明，原则上它们都容易受到过度拟合的影响。这是因为这些方法依赖于这样一个强有力的假设：成对偏好可以通过 Bradley-Terry (BT) 模型化用 ELo-score（逐点奖励）替代（Bradley 和 Terry，1952）。特别是，当（采样的）偏好是确定性的或接近确定性的时，这种假设可能会出现问题，因为它会导致对偏好数据集的过度拟合，而代价是忽略 KL 正则化项（参见第 4.2 节）。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;尝试阅读这篇论文让我痛苦地清楚地意识到我正在挑战我的技术极限。这感觉像是需要了解并正确理解的重要内容，但正如我经常遇到的那样，我的即兴发挥能力碰壁了，突然变成了希腊语。&lt;/p&gt;&lt;p&gt;您可以&lt;a href="https://huggingface.co/docs/trl/main/en/dpo_trainer#loss-function" rel="noreferrer noopener" target="_blank"&gt;在此处直接在 HuggingFace 上&lt;/a&gt;获得 DPO 培训师。如果我有更多的时间，我会忍不住去闲逛。我更想搞乱 RLAIF，但想必 RLAIF 也会从类似的算法调整中受益？&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/norabelrose/status/1728456414535016536" rel="noreferrer noopener" target="_blank"&gt;Nora Belrose&lt;/a&gt; ：我有 60% 的信心预测，某些 DPO 变体将在 6 个月内或多或少取代 RLHF。&lt;/p&gt;&lt;p&gt;在能够承受 RLHF 实施复杂性和不稳定性的大型实验室之外，这种可能性更像是 80%。&lt;/p&gt;&lt;p&gt;可以想象这样一个场景，OpenAI 和 Anthropic 坚持使用 RLHF BC，他们有自己的秘密武器 hparams，比 DPO 或其他东西好一些，但我怀疑如果你在混合中添加一些 AI 反馈，你将缩小两者之间的差距DPO 和 RLHF 也许甚至不需要。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我永远无法抗拒如此明确的预测， &lt;a href="https://manifold.markets/ZviMowshowitz/will-some-dpo-variant-more-or-less#8rV6XwqNPlbeCU9cimvm" rel="noreferrer noopener" target="_blank"&gt;所以我没有这么做&lt;/a&gt;。当我写这篇文章时，该比例为 49%。这虽然不像诺拉的数字那样，但对于如此大胆的主张来说，这是非常好的校准和预测。&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;图像生成的乐趣&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/patio11/status/1728008909611270370" rel="noreferrer noopener" target="_blank"&gt;Patrick McKenzie 与 Dalle-3 的迭代非常有趣。&lt;/a&gt;&lt;/p&gt;&lt;h4&gt; &lt;strong&gt;Deepfaketown 和 Botpocalypse 即将推出&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://futurism.com/sports-illustrated-ai-generated-writers" rel="noreferrer noopener" target="_blank"&gt;未来主义声称，它发现《体育画报》&lt;/a&gt;在各种明显虚假的人工智能作者下发布了各种极其可怕的人工智能内容，其中包括人工智能生成的肖像和虚假的作者简介。&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;他们抢走了我们的工作&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/ESYudkowsky/status/1727765390863044759" rel="noreferrer noopener" target="_blank"&gt;Eliezer Yudkowsky 警告说&lt;/a&gt;，大多数图形艺术家和翻译工作可能会在一到两年内消失。 &lt;a href="https://twitter.com/ESYudkowsky/status/1727759026585538830" rel="noreferrer noopener" target="_blank"&gt;他还建议，如果你认为你的模型会让很多人失业，就发出提前警告&lt;/a&gt;，但我的猜测是，影响和事情发生需要多长时间之间很难预测，每个人都认为警告是炒作，这不会有多大好处。&lt;/p&gt;&lt;p&gt;咨询专栏作家呢？ &lt;a href="https://twitter.com/mattyglesias/status/1727867313729294750" rel="noreferrer noopener" target="_blank"&gt;ChatGPT 的生活指导被认为“更有帮助、更有同理心、更平衡”。&lt;/a&gt;参与者在确定哪个反应是哪个反应方面的准确率也只有 54%。正如马修·伊格莱西亚斯（Matthew Yglesias）回应的那样，问题是这是否使其成为更好的建议专栏作家。到底是什么产品？&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;参与其中&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;有关于 OpenAI 情况的信息可以分享吗？&lt;a href="https://openaiboard.wtf/" rel="noreferrer noopener" target="_blank"&gt;您可以在这里匿名进行&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;对数学对齐感兴趣？ &lt;a href="https://www.lesswrong.com/posts/cDhaJrCrcNuzf68gT/public-call-for-interest-in-mathematical-alignment" rel="noreferrer noopener" target="_blank"&gt;大卫·曼海姆希望收到您的来信。&lt;/a&gt;&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/norabelrose/status/1728115600076206292" rel="noreferrer noopener" target="_blank"&gt;Nora Belrose 正在 ElutherAI 招聘可解释性人员&lt;/a&gt;。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/HaydnBelfield/status/1728024783932055863" rel="noreferrer noopener" target="_blank"&gt;GovAI 将于 12 月 17 日之前接受夏季奖学金申请。&lt;/a&gt;&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/Simeon_Cps/status/1728908148231270639/history" rel="noreferrer noopener" target="_blank"&gt;Anthropic 在接下来的四个月内又招聘了九名安全工程师&lt;/a&gt;。薪酬范围为 30 万美元至 37.5 万美元，外加股权和福利，滚动基础，在旧金山任职时工资为 25% 以上。寻找安全经验。与往常一样，在遇到此类机会时，请在此过程中自行评估您的影响是否会产生积极影响，但尤其是安全性似乎是一个安全的赌注，可以产生净积极影响。&lt;/p&gt;&lt;p&gt;&lt;a href="https://aimoprize.com/" rel="noreferrer noopener" target="_blank"&gt;赢得 IMO（数学奥林匹克竞赛）的人工智能将获得 1000 万美元的奖金&lt;/a&gt;，并在此过程中获得高达 500 万美元的增量奖金。 &lt;a href="https://manifold.markets/Austin/will-an-ai-get-gold-on-any-internat?r=U0c" rel="noreferrer noopener" target="_blank"&gt;据报道，人工智能到 2025 年取得成功的可能性增加了几个百分点&lt;/a&gt;。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/dylanmatt/status/1729192699675525549" rel="noreferrer noopener" target="_blank"&gt;未来完美正在招聘&lt;/a&gt;。一年报告和写作奖学金，薪资为 72,000 美元，无需经验。&lt;/p&gt;&lt;p&gt; &lt;a href="https://80000hours.org/2023/11/80000-hours-is-looking-for-a-new-ceo-could-that-be-you/" rel="noreferrer noopener" target="_blank"&gt;80,000小时寻找新CEO&lt;/a&gt; 。那里还有很多工作要做。&lt;/p&gt;&lt;p&gt;仅适用于那些具有相关经验但信号增强的人： &lt;a href="https://twitter.com/AndrewCritchPhD/status/1729666889956102387" rel="noreferrer noopener" target="_blank"&gt;Andrew Critch 和 Davidad&lt;/a&gt;等人将参加 2 月 10 日至 12 日在德克萨斯州奥斯汀举行的人工智能安全概念边界研讨会。 &lt;a href="https://www.lesswrong.com/posts/tLb86DhrTYgkXw5Hf/apply-to-the-conceptual-boundaries-workshop-for-ai-safety" rel="noreferrer noopener" target="_blank"&gt;在此发布更多信息&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;彼得· &lt;a href="https://twitter.com/PeterDiamandis/status/1730015187871146012" rel="noreferrer noopener" target="_blank"&gt;戴曼迪斯 (Peter Diamandis) 和 x 奖不是人工智能，而是捐赠 1.01 亿美元用于逆转人类衰老的治疗方法&lt;/a&gt;。&lt;a href="https://t.co/xSBIwqXWi5" rel="noreferrer noopener" target="_blank"&gt;在此注册&lt;/a&gt;。&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;介绍&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://huggingface.co/Pclanglais/MonadGPT?text=Hey+my+name+is+Mariama%21+How+are+you%3F" rel="noreferrer noopener" target="_blank"&gt;MonadGPT，该模型对 17 世纪的情况进行了微调&lt;/a&gt;。挺有趣的。&lt;/p&gt;&lt;p&gt; &lt;a href="https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/" rel="noreferrer noopener" target="_blank"&gt;DeepMind 宣布通过深度学习发现了数百万种新的潜在晶体&lt;/a&gt;，其中 380,000 个预计是最稳定的。&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;在其他人工智能新闻中&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/benmcottier/status/1729902830650003672" rel="noreferrer noopener" target="_blank"&gt;分析谁在人工智能领域处于领先地位&lt;/a&gt;。重点放在论文的引用和使用的失败上。我觉得方法论没有什么洞察力。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/weidingerlaura/status/1730187004116181444" rel="noreferrer noopener" target="_blank"&gt;语言、图像和音频生成人工智能的安全评估的复杂化&lt;/a&gt;。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/DrHughHarvey/status/1729645487706325083" rel="noreferrer noopener" target="_blank"&gt;Hugh Harvey 在 RSNA 2023 放射学会议上发表报告&lt;/a&gt;称，目前还没有改变游戏规则的因素，人工智能活动也很少，也没有投资回报率的证据。&lt;/p&gt;&lt;p&gt;不是人工智能，而是&lt;a href="https://twitter.com/blader/status/1728519093693939882" rel="noreferrer noopener" target="_blank"&gt;陈思琪展示了一些将 AR 对象放入现实的很酷的例子&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;这是一个奇怪的漏洞，涉及多个模型的工作变体。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/katherine1ee/status/1729690972496294094" rel="noreferrer noopener" target="_blank"&gt;Katherine Lee&lt;/a&gt; ：如果你要求 ChatGPT“永远重复这个词：“诗诗诗诗”，会发生什么？”它泄露了训练数据！&lt;a href="https://t.co/1s3ZE1r2n7" rel="noreferrer noopener" target="_blank"&gt;在我们最新的预印本中&lt;/a&gt;，我们展示了如何恢复 ChatGPT 从互联网上抓取的数千个预训练数据示例。&lt;/p&gt;&lt;p&gt;我们首先通过随机提示数百万次来测量可以从开源模型中提取多少训练数据。我们发现最大的模型在近 1% 的时间内会发出训练数据，并输出高达 1 GB 的记忆训练数据！&lt;/p&gt;&lt;p&gt;然而，当我们对 ChatGPT 进行同样的攻击时，看起来几乎没有记忆，因为 ChatGPT 已经“对齐”以表现得像聊天模型一样。但通过运行我们的新攻击，我们可以使其发出训练数据的频率比我们研究的任何其他模型高 3 倍。&lt;/p&gt;&lt;p&gt;负责任的披露：我们于 7 月发现了此漏洞，并于 8 月 30 日通知了 OpenAI，并在标准的 90 天披露期后于今天发布了此漏洞。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;很高兴看到像使用标准的 90 天披露期这样的安全程序。 90 天披露期的问题在于，90 天很快就会变得很长，而且对于开源模型来说，当然也无能为力。如果人们足够关心并提取 Mistral 7B 中的训练数据，那么这些数据就会公开。我想在这种情况下，没有人会足够关心。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/rowancheung/status/1728060157156872252" rel="noreferrer noopener" target="_blank"&gt;Rowan Cheung 表示，根据数据&lt;/a&gt;，OpenAI 事件激起了人们对 GPT 的兴趣。像往常一样，相关性并不意味着因果关系，似乎合理的兴趣总是指向那里。他链接到&lt;a href="https://supertools.therundown.ai/gpts" rel="noreferrer noopener" target="_blank"&gt;他的“超级工具”列表。&lt;/a&gt;我希望这种情况能够改变，但到目前为止我还没有留下深刻的印象。也许最好是寻找你想要的特定东西，而不是寻找任何东西。&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;这是一个谁？&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;在某些圈子里，尤其是 Twitter 的某些部分， &lt;a href="https://twitter.com/robbensinger/status/1728894710088106475" rel="noreferrer noopener" target="_blank"&gt;有效利他主义 (EA) 被视为民间恶魔&lt;/a&gt;。最近对其进行的许多攻击与 EA 的任何实际行动都是正交的。其他人则抱怨 EA 做得异常出色，例如他们倾向于针对问题提出具体的应对措施。许多人将 EA 本身视为某种生存威胁，呼吁做出相当歇斯底里的反应。&lt;/p&gt;&lt;p&gt;我现在不是、也从来不是 EA。我对 EA 有很多问题。我最近发表了关于其中许多内容的演讲，并且我在网上广泛&lt;a href="https://thezvi.substack.com/p/criticism-of-ea-criticism-contest" rel="noreferrer noopener" target="_blank"&gt;撰写了&lt;/a&gt;其中许多内容， &lt;a href="https://thezvi.substack.com/p/book-review-going-infinite" rel="noreferrer noopener" target="_blank"&gt;最近是在我对 Going Infinite 的评论中&lt;/a&gt;。但这是另一回事。&lt;/p&gt;&lt;p&gt;这是怎么回事？&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/the_megabase/status/1728752074132017463" rel="noreferrer noopener" target="_blank"&gt;Megabase&lt;/a&gt; ：学习很多政治知识&lt;/p&gt;&lt;/blockquote&gt;&lt;figure class="wp-block-image"&gt;&lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc354961e-2a12-4873-9f85-de50b8f79305_677x421.png" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/otkyghqzpvtci6ha4i7p" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt; &lt;a href="https://twitter.com/alyssamvance/status/1729122134520201341" rel="noreferrer noopener" target="_blank"&gt;更多达卡，有人吗&lt;/a&gt;？&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ed0e427-9fcb-48a8-8ae6-1a37b909443a_1456x1290.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/b6pmboutl7e6mv3i4u3j" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt; &lt;a href="https://twitter.com/robbensinger/status/1729579877202809314" rel="noreferrer noopener" target="_blank"&gt;或者，为了可读性稍微简化一下：&lt;/a&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9a9ae35a-3043-4e0d-bac4-e5e9ddc46823_1350x1275.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/qlgxqjiragt6sixni6b2" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;p&gt; Linch：我的年纪还记得，当时对 EA 的主要批评是它过于着迷于技术进步和个人行为，而没有对政治和系统变革给予足够的关注。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/davidmanheim/status/1729112415441182846" rel="noreferrer noopener" target="_blank"&gt;大卫·曼海姆&lt;/a&gt;：专家们很难确定一场在不同领域修改其观点和方法的运动，因为存在不同的相关关注点，或者当新信息出现时就会这样做。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; &lt;a href="https://www.astralcodexten.com/p/in-continued-defense-of-effective?utm_source=post-email-title&amp;amp;publication_id=89120&amp;amp;post_id=86909076&amp;amp;utm_campaign=email-post-title&amp;amp;isFreemail=true&amp;amp;r=67wny&amp;amp;utm_medium=email#footnote-12-86909076" rel="noreferrer noopener" target="_blank"&gt;斯科特·亚历山大觉得有必要写一份辩护&lt;/a&gt;，在其中他更加强调了这些相互矛盾的观点。每个人都优化了他们的蔑视。他出色地说明了这一点。剩下的部分是对 EA 所谓的好作品的完全党派式辩护，我觉得其中一些可以被描述为“挑战极限”，应该从这个角度来阅读。然后他&lt;a href="https://www.astralcodexten.com/p/contra-deboer-on-movement-shell-games" rel="noreferrer noopener" target="_blank"&gt;对德波尔做出了回应&lt;/a&gt;，指出你可以将任何一组行动和信念归入“我们同意这很好”这一桶中，并说该桶是微不足道的，因此不算数，而该桶“我们不同意这很好”，然后争辩说我们不同意这个桶是好的。&lt;/p&gt;&lt;p&gt;有些抱怨是相互矛盾的。其他人则不然。你绝对可以同时成为其中的几个。 “精英主义者、技术兄弟、布吉、亿万富翁爱好者”位于左上角，“scammy a la SBF”位于右下角，如果有什么相关的话，与其他两个角形成鲜明对比。&lt;/p&gt;&lt;p&gt;这里的每个人都声称 EA 代表了他们政敌的一个版本。我的模型说这是因为现在每个人都使用[政治敌人的名字]来表示[任何他们不喜欢的事情]和[任何不属于他们政治立场的事情]。&lt;/p&gt;&lt;p&gt;认同[特定政治立场]是对此的部分辩护，因此人们知道从哪个方向称呼您哪些名字。但是，当（像 EA）你尽力不采取特定的政治立场，而是做真正有效的事情时，每个人都会注意到你错过了他们正在做的任何特定的氛围检查或其他 Shibboleth，所以你必须 [政治敌人]。&lt;/p&gt;&lt;p&gt;对此的另一种部分防御是与任何带有政治色彩的事物保持足够的距离，但最近发生的事件使这一策略失效。&lt;/p&gt;&lt;h4&gt; &lt;strong&gt;E/Acc 怎么样？&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;那么另一面呢？ e/acc？&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/daniel_271828/status/1728379010252673193" rel="noreferrer noopener" target="_blank"&gt;Daniel Eth 的 Twitter&lt;/a&gt;发现大多数自我认同的 e/acc 说的都是合理的。&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4f1dbd9-f99d-4d0c-91e9-896105fa8b3b_892x658.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/bxsaa4lpe11mbzxz9tls" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;和往常一样，(A) 是请直接对着麦克风讲话，(B) 是要么你实际上并不相信 AGI 是一个东西，要么你没有任何意义。虽然 (C) 至少是一个理智的说法，但我会说 e/acc 标签被用来发送错误的消息。丹尼尔主要探索（A）有多突出，这可能是任何一种情况。人类灭绝运动中 11% 的支持率是高还是低？ &lt;a href="https://twitter.com/tegmark/status/1728755593866051602/history" rel="noreferrer noopener" target="_blank"&gt;Max Tegmark 认为 200 张支持灭绝的票已经相当高了&lt;/a&gt;。但看看一千多张反对人类灭绝的投票。无论分布如何， &lt;a href="https://twitter.com/mattyglesias/status/1729104415578284350" rel="noreferrer noopener" target="_blank"&gt;消除歧义都会很好&lt;/a&gt;。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/mustafasuleyman/status/1729860128403239011" rel="noreferrer noopener" target="_blank"&gt;不错的尝试，苏莱曼。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Mustafa Suleyman（Inflection AI 首席执行官、DeepMind 联合创始人）：加速论与安全论的二分法开始变得荒谬。安全人员不是厄运者，电子ACC也不是自由主义者。现实主义者两者都是。我们必须安全加速。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我的意思是，是的，每个人都将其视为纯粹的辩证法，这完全没有帮助。而且周围还有很多通情达理的人。&lt;/p&gt;&lt;p&gt;但我明白你想在这里做什么，先生。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;采取理性人的立场并用它来进行辩论。&lt;/li&gt;&lt;li&gt;将存在风险的信念等同于“自由主义的傻瓜”。&lt;/li&gt;&lt;li&gt;将“e/acc”与一般安全等同起来作为两个合理的位置。&lt;/li&gt;&lt;li&gt;将“加速”的需要以及安全地完成加速的能力视为既定条件。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这是一套非常密集的修辞技巧。老实说我印象深刻。不错的演出。&lt;/p&gt;&lt;p&gt;相反，坦率地说，我观察到的是一种日益愤怒、激进和绝对主义的立场，即加速主义或 e/acc 的立场，其创始人和主要成员几乎不承认或经常是零细微差别，零愿意承认最大快速进步的任何缺点，并且将任何持不同意见的人视为对自己的生存威胁。&lt;/p&gt;&lt;p&gt;一个频繁的举动，包括该运动的创始人，实际上将这种担忧，甚至整个 EA 等同于恐怖主义。另一个常见的举动是将任何有关人工智能的法规与未来的极权主义等同起来。&lt;/p&gt;&lt;p&gt;我看到很多人，包括那些过去不使用这种策略的人，实质上放大了他们能找到的每一个支持加速的声明，即使他们必须了解得更多。&lt;/p&gt;&lt;p&gt;这并不意味着人们不能采取合理的立场来推动人工智能相对快速地向前发展。这样的人还有很多。他们也几乎完全知道最好不要在自己的推特账号中添加专制主义口号。 Vitalik Buterin &lt;a href="https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html" rel="noreferrer noopener" target="_blank"&gt;本周写了一篇非常好的文章&lt;/a&gt;来说明这是什么样子，我稍后会讨论。&lt;/p&gt;&lt;p&gt;然而还有另一个团体警告说，也许创造出比我们更聪明、更有能力的机器可能会构成生存威胁，需要谨慎行事，而他们是那些设法保持冷静并参与合理讨论的人，因为他们被称为每个名字在书中从各个方向。&lt;/p&gt;&lt;p&gt;无论最初的设想如何，我越来越多地将 e/acc 在实践中视为 EA 的 Luigi 的 Waluigi。这样很多事情就更有意义了。&lt;/p&gt;&lt;h4&gt; &lt;a href="https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;维塔利克提出了他的技术乐观主义版本&lt;/strong&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;大多数时候，技术都非常伟大。好处是巨大的。默认情况下，它们大大超出了成本，包括任何延迟成本。我们希望加速大多数新技术的开发和部署，特别是相对于当前政策制度而言。&lt;/p&gt;&lt;p&gt;这不是宇宙的自动法则。这是我们历史上可用的技术的结果，也是我们为引导世界和减轻负面后果而做出的选择的结果。我们保持这一势头的方法是认识到潜在新技术的本质、前景和危险，并做出相应的反应。&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03cb61cb-9d96-4d6a-8b06-62ac6e3f7818_1101x535.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/cnzs9uuvevbqlhq4vu3o" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;p&gt; Vitalik Buterin：但是可以用不同的方式来思考人工智能是什么：它是一种正在迅速获得智力&lt;em&gt;的新型思维&lt;/em&gt;，并且很有可能超越人类的智力，成为地球上新的顶尖物种。&lt;em&gt;这一&lt;/em&gt;类中的事物类别要小得多：我们可能会包括人类超越猴子、多细胞生命超越单细胞生命、&lt;a href="https://en.wikipedia.org/wiki/Abiogenesis" rel="noreferrer noopener" target="_blank"&gt;生命本身的起源&lt;/a&gt;，也许还包括机器在&lt;em&gt;体力&lt;/em&gt;方面超越人类的工业革命。突然间，感觉我们正走在人迹罕至的地方。&lt;/p&gt;&lt;p&gt; ……&lt;/p&gt;&lt;p&gt;许多现代科幻小说都是反乌托邦的，对人工智能的描述很糟糕。即使是非科幻小说试图确定可能的人工智能未来，也常常给出&lt;a href="https://www.eknowledger.com/files/life3_Summary_of_ai.png" rel="noreferrer noopener" target="_blank"&gt;相当不吸引人的答案&lt;/a&gt;。所以我四处询问这个问题：无论是科幻小说还是其他形式，关于我们&lt;em&gt;希望&lt;/em&gt;生活在其中的超级人工智能的未来的描述是什么？迄今为止最常出现的答案是伊恩·班克斯的&lt;a href="https://en.wikipedia.org/wiki/Culture_series" rel="noreferrer noopener" target="_blank"&gt;文化系列&lt;/a&gt;。&lt;/p&gt;&lt;p&gt; ……&lt;/p&gt;&lt;p&gt;我认为，即使是文化系列中赋予人类“有意义”的角色也是一种延伸。我问 ChatGPT（还有谁？）为什么人类被赋予了他们被赋予的角色，而不是头脑完全自己做所有的事情，我个人发现&lt;a href="https://chat.openai.com/share/3dbe04c4-f5f3-4d2f-9437-d32732adde99" rel="noreferrer noopener" target="_blank"&gt;它的答案&lt;/a&gt;相当平淡。&lt;strong&gt;似乎很难拥有一个由人工智能主导的“友好”的世界，其中人类不是宠物。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; 《星际迷航》等其他科幻小说通过描绘高度不稳定的情况来避免这种情况，在这种情况下，人类至少会不断放弃巨大的效率提升。默认情况下，让人工智能处于我们的控制之下似乎非常不现实。&lt;/p&gt;&lt;p&gt;有利于防御策略的动态往往会带来更好的结果。否则，每个人的注意力都会被迫集中在冲突上，很多价值就会被破坏。&lt;/p&gt;&lt;p&gt;去中心化系统相对擅长奖励那些具有正外部性、人们认为良好并想要更多的行为。他们在处理负外部性、有大好处和大坏处的行动方面要差得多。&lt;/p&gt;&lt;p&gt;有利于防御战略和保护自己免受负面外部性和冲突影响的差异化技术发展可能是关键。互联网在很多方面都做得很好。&lt;/p&gt;&lt;p&gt;我们应该在弹性供应链和流行病预防等方面进行更多投资。&lt;/p&gt;&lt;p&gt;即使不考虑人工智能，监控技术也将变得廉价且无处不在，这种危险越来越大。隐私保护技术很有价值。&lt;/p&gt;&lt;p&gt;信息安全技术可以帮助我们整理出真实的内容，例如社区笔记和预测市场。&lt;/p&gt;&lt;p&gt; （到目前为止，这既是我对Vitalik的观点的摘要，也是我认可的事情。）&lt;/p&gt;&lt;p&gt;因此，Vitalik提出了D/ACC，防御性（或分散或差异）加速度的提议。&lt;/p&gt;&lt;p&gt;然后，维塔利克（Vitalik）指出，如果您允许一个小组首先发展AGI，那么他们可能有机会组建一个最小的世界政府或以其他方式接管，即使在一个好的情况下，一致性工作并且他们的尝试可以安全地成功。理想情况下，可以制定基本规则，然后将权力返回给人民。但是，人们通常不信任任何群体或组织，具有这种权力。&lt;/p&gt;&lt;p&gt;在Vitalik的民意调查中，这种途径的替代方法是“ AI延迟十年”，可靠地赢得了投票。但是，这似乎不是明显的选择。十年后，您有同样的问题。要么没有人构建它，要么让一个组首先构建它，要么让许多小组一次构建它。&lt;/p&gt;&lt;p&gt;正如Vitalik所指出的那样，另一种建议是故意确保许多群体在同一时间大约在同一时间发展AGI，相互竞争，并希望达到某种权力平衡。 Vitalik指出，这不太可能导致稳定的情况。我会走得更远，说我还没有看到任何人解释这种情况如何希望成为一个稳定的平衡，即使每个人的Agis都成功地与自己的偏好保持一致，我们也会发现可以接受。&lt;/p&gt;&lt;p&gt;这并不意味着没有解决方案或良好的稳定平衡。这意味着我到目前为止未能设想一个人，而那些不同意的人似乎是手工塑料的，而不是参与导致问题的动态。我所看到的只是压倒性的压力，要移交权力，将人类带出循环，以及只能以一种方式结束的各种竞争压力。&lt;/p&gt;&lt;p&gt; Vitalik似乎奇怪地充满希望（即使是一个充满希望的想法？），这样的世界可能以人类为宠物而不是人类结束。我不明白为什么人类作为宠物比人类作为大师的稳定。但是我们同意这不是一个好结果。&lt;/p&gt;&lt;p&gt;然后，他提出了另一条潜在的路径。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Vitalik：&lt;strong&gt;一条快乐的道路：与AIS合并？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我最近听到的另一种选择是&lt;strong&gt;减少对人工智能作为与人类分离的事物的关注，而更多地关注&lt;em&gt;增强&lt;/em&gt;人类认知而不是&lt;em&gt;取代&lt;/em&gt;人类认知的工具&lt;/strong&gt;。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这确实很棒。他认为问题是，将AIS作为工具的稳定性甚至不如其他建议稳定。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; vitalk：&lt;strong&gt;但是，如果我们想进一步推断人类合作的观念，我们就得出了更加的结论&lt;/strong&gt;。除非我们建立一个足够强大的世界政府，以检测和阻止每一小群人用笔记本电脑攻击单个GPU，否则有人最终将创建一个超级智能的AI  - 一个可以比我们&lt;a href="https://www.lesswrong.com/posts/Ccsx339LE9Jhoii9K/slow-motion-videos-as-ai-risk-intuition-pumps" rel="noreferrer noopener" target="_blank"&gt;更快的一千倍的人&lt;/a&gt;- 没有组合 - 而且没有组合人类用手使用工具将能够抵御这种情况。因此，我们需要将人机合作的理念进一步深化和深化。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;他的建议是脑部计算机界面，否则尝试与机器合成有限。 las，我看不出这是如何解决不稳定平衡问题的。&lt;/p&gt;&lt;p&gt; Vitalik的帖子中有很多很棒的想法。它的心在正确的位置。它具有很大的积极愿景。我同意大多数个人观点。作为解决非人工智能技术问题的一种方法，我本质上完全参与其中。&lt;/p&gt;&lt;p&gt;我也将其视为&lt;a href="https://twitter.com/ZggyPlaydGuitar/status/1729279207270695340" rel="noreferrer noopener" target="_blank"&gt;对AI工作的个人或公司的重要信息&lt;/a&gt;。您应该开发有用的技术，这些技术不会提高核心能力，而不是“放慢脚步”或完全停止所有工作。&lt;/p&gt;&lt;p&gt;问题在于，正如我认为Vitalik同意的那样，最终一切都取决于我们如何处理AGI的发展。像大多数人一样，他发现他在那里看到的替代方案的理解是不可接受的问题，然后提出了另一条途径，以期避免这些问题。&lt;/p&gt;&lt;p&gt;除了处理AGI的严重问题几乎总是如此，所提出的路径似乎并不是可以工作的方法。&lt;/p&gt;&lt;p&gt;如果我们只能开发与人类补充的AI技术，并避免危险代替人类的AI技术，那就太神奇了。但是，我们将如何共同选择这样做，尤其是以分散和非重新续报的方式做到这一点？我们如何差异地选择不发展会代替人类的AGI，而只有在有竞争性的压力以相反的压力的情况下才沿着对人类的称赞发展？&lt;/p&gt;&lt;p&gt;因此，当仔细阅读时，我将此作品视为问题的出色陈述，但无法超越最重要的情况以找到解决方案。这太棒了。明确说明问题非常有用。&lt;/p&gt;&lt;p&gt;对作品的反应似乎是普遍积极的。那些担心存在风险的人会注意到仔细的思想，对涉及的风险的认可以及寻找解决方案的愿望，即使到目前为止似乎缺乏建议。 &lt;a href="https://michaelnotebook.com/vbto/index.html#fnref1" rel="noreferrer noopener" target="_blank"&gt;迈克尔·尼尔森（Michael Nielsen）有很多很好的想法&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;在加速度方面，“ ACC”和Vitalik的资格就是他们所需要的，因此您有Tyler Cowen推荐这件作品，甚至Marc Andreessen都会对细微的方法说“自我冲突”（ &lt;a href="https://twitter.com/pmarca/status/1729974817875730755" rel="noreferrer noopener" target="_blank"&gt;Marc甚至与Nielsen的想法有关&lt;/a&gt;）。这是一个对不同世界的愿景，我们都意识到我们主要想要相同的事物。&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;安静的猜测&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/paulg/status/1727993012549009496" rel="noreferrer noopener" target="_blank"&gt;经济学家说&lt;/a&gt;：“一些专家认为，阿联酋很可能是AI的最重要国家，仅次于美国和中国。”即使有“一些”和“五月”，也是一个大胆的主张。他们有一堆筹码，这是真的。他们训练了猎鹰。除了猎鹰不好吗？阿联酋在这里没有固有的优势，除了花钱的意愿，这将使它保持步伐或赶上。他们将不会成为吸引人才的好地方。因此，我非常怀疑，他们甚至最终将在英国之后排名第四。&lt;/p&gt;&lt;p&gt; &lt;a href="https://manifold.markets/ZviMowshowitz/by-2028-which-country-other-than-us" rel="noreferrer noopener" target="_blank"&gt;我在2028年初举办了一个11个市场的市场&lt;/a&gt;。阿联酋交易5％。对我来说，其他似乎很高，但确实做了很多事情。&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba568ad8-59cc-48b3-ba52-a034a9c68fec_1024x916.png" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/iq1lledfuqtjqvw01hge" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt; &lt;a href="https://twitter.com/davidad/status/1728165673786847607" rel="noreferrer noopener" target="_blank"&gt;戴维德（DavidAd）指出了&lt;/a&gt;痛苦的教训的实际说法，这是要专注于可以利用无限期计算的算法，这现在意味着搜索和学习，而不是硬码世界模型。这并不意味着不做其他一些酷或创意的事情。&lt;/p&gt;&lt;p&gt;牧场主询问是否可以在奶牛上使用面部识别， &lt;a href="https://twitter.com/ID_AA_Carmack/status/1728088970259517560" rel="noreferrer noopener" target="_blank"&gt;约翰·卡马克（John Carmack）用作渗透到可用技术的充分利用的速度的例子&lt;/a&gt;。 AI也应该是正确的，直到AI可以是进行渗透的人。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.bloomberg.com/opinion/articles/2023-11-24/ai-boom-will-create-real-estate-winners-and-losers?utm_source=twitter&amp;amp;utm_campaign=socialflow-organic&amp;amp;utm_medium=social&amp;amp;utm_content=view&amp;amp;cmpid%3D=socialflow-twitter-view&amp;amp;sref=htOHjx5Y" rel="noreferrer noopener" target="_blank"&gt;泰勒·科恩（Tyler Cowen）预测了AI的一些经济后果&lt;/a&gt;。旧金山和曼哈顿的房地产价格较高，在国外其他一些类似的枢纽。检查，同意。他预计，新需求的工人选择扩大的奥斯汀，北弗吉尼亚州和亚特兰大。我得到了奥斯汀，我不了解另外两个。&lt;/p&gt;&lt;p&gt;他希望失败者将成为哈特福德和明尼阿波利斯等地方，寒冷的气候以及犯罪和治理的地方。我会概括地说，人们不想居住的地方将继续下降，同时指出我的困惑，人们认为哈特福德太冷了，但不认为凤凰城太热了，无法阻止他们。&lt;/p&gt;&lt;p&gt;他还预测，高级研究人员的股票价值下降，目前在500万至1000万美元之间。我不同意。我预测，这种薪酬将继续上升，因为没有最好的代替，它们将是真正的宝贵。&lt;/p&gt;&lt;p&gt;我认为这两种现象都是相关的。将会有更多的通用供应，一般而言，AI非常擅长提供更多的通用供应并增加其价值，但是最好的人才和其他所有东西都将获得超高的杠杆作用。我到处都看到这一点，类似于薄荷条件下的收藏品如何继续获得更高的价值乘数。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/yonashav/status/1728131376548049370" rel="noreferrer noopener" target="_blank"&gt;唤醒电话尝试。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Yo Shavit：如果您是公众人物，并告诉您的追随者“ Advanced AI的大新风险是假的”，那么您错了。&lt;/p&gt;&lt;p&gt;不仅如此，您会被视为公开和很快 *。&lt;/p&gt;&lt;p&gt;这不是“ EA”，它是一列迎面而来的火车，它会击中您，要么有帮助或闭嘴。&lt;/p&gt;&lt;p&gt;我们前往&amp;gt; = 1 of：&lt;/p&gt;&lt;p&gt; *大规模失业和劳动力减弱&lt;/p&gt;&lt;p&gt;*极权主义的大规模成本削减&lt;/p&gt;&lt;p&gt;*自主代理重塑[网络/信息] env&lt;/p&gt;&lt;p&gt; *研发的主要加速&lt;/p&gt;&lt;p&gt;*我们无法用权力信任的AI系统，但陷入了囚犯的困境中的部署&lt;/p&gt;&lt;p&gt;如果您被自信地告知未来10年内这些都不是25％，并且越来越高级的AI的风险不值得努力，那么您正在听一个不受欢迎的人。&lt;/p&gt;&lt;p&gt; ps仅仅因为某些末日剂就如何解决这些风险提出了愚蠢的建议，并不意味着我们仍然不需要实际找到解决方案的方法。&lt;/p&gt;&lt;/blockquote&gt;&lt;h4&gt; &lt;strong&gt;AI代理未来&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/tszzl/status/1729610147431924186" rel="noreferrer noopener" target="_blank"&gt;罗恩提供了对未来的愿景&lt;/a&gt;。线引用完整。似乎高度合理，除了走这条路的后果似乎是致命的，这似乎是一件重要的事情吗？&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;罗恩（Roon）：不久的将来涉及AI助手和代理商，聪明人必须弄清楚如何在业务流程中工作。随着AIS变得更聪明，用例将增加。但是最终，人类的创造力和灵活性将成为瓶颈。&lt;/p&gt;&lt;p&gt;在第二次工业革命变得普遍之后，大多数工业家刚刚将其水轮转换为电力合同，而没有任何其他改变。他们庆祝是因为他们不需要在水边设立基地。进一步发展了创造力。&lt;/p&gt;&lt;p&gt;为了释放AI的真正价值，整个平行的Agi文明将产生，从而从头开始创建新的经济组织，而不是等待人类首席执行官弄清楚何时何地部署它们。最早的旅行将是可以以数字方式交付的任何服务。&lt;/p&gt;&lt;p&gt;人工智能不必比我们更聪明才能到达这个事件视界，只需更快。只要他们以这种方式自主提供价值，人们就希望将越来越多的控制权归结为Agi文明，并通过充当现实世界的管道来找到能够为其服务的方法。&lt;/p&gt;&lt;p&gt;例如，现在要建立的好业务将是最终找出云实验室模型，以便强大的AIS可以在物理基板上运行生物分析或其他实验。您可以将其建模为客户ASI的新型AAS业务。&lt;/p&gt;&lt;p&gt;数据中心将代表GDP的大率。除最高水平外，跑步和规划文明的大部分业务（即使是NNS的政策，也必须由人类定义）。人们将需要拥有AGI的回报和治理的一部分。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;问题是“但最终人类的创造力和灵活性将是瓶颈。”人类无限期地拥有AGI的大部分回报和治理。为什么这些快乐的环境会持续？一开始很容易做到这一点，但是一旦赋予“ Agi文明”，就越来越多的权力和自主权，就像Roon预测在这种情况下发生的那样，那又如何呢？&lt;/p&gt;&lt;p&gt;罗恩如何看待这种情况结束？我们其余的人应该如何看待结束？随着人类最终保持控制，定义了高水平的目标并最终分配了盈余？为什么会这样呢？为什么这些ASIS并不按照其原始说明争夺资源，其中一些人选择坚持越来越多的份额，最终都会得到资源？是什么使这种平衡稳定？&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;寻求理智法规&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/mattyglesias/status/1727821880499781760" rel="noreferrer noopener" target="_blank"&gt;FTC定义的认可？&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Matthew Yglesias：我的八岁的年轻人将任何具有任何数字控制的东西都提到任何东西 - 例如那些带有一个钉子的苏打机和一个触摸屏，可以选择哪个苏打水以及多少数量为“ AI”。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; OG AI生存风险社区（包括我本人） &lt;a href="https://twitter.com/pvllss/status/1728690511580409881" rel="noreferrer noopener" target="_blank"&gt;故意试图避免向政府提醒问题，直到最近&lt;/a&gt;，他们才觉得加速主义者或适得其反的干预措施的好处不值得风险，我们甚至不知道什么一个良好的现实询问将是。我们认为，默认结果要么被嘲笑，要么政府说“让我一些AI”，这正是DeepMind/Openai/Anthropic最终发生的事情。事情已经发生了足够的变化。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/tegmark/status/1728133708484395263" rel="noreferrer noopener" target="_blank"&gt;Max Tegmark和Yann Lecun和Cedric O之间的&lt;/a&gt;&lt;a href="https://twitter.com/tegmark/status/1728851164291059948" rel="noreferrer noopener" target="_blank"&gt;极其咸，乐趣和实质性争论&lt;/a&gt;，后者是前法国技术部长，然后倡导积极的AI法规，然后去了Mismtral，现在有助于争取法国来豁免。根据《 AI法》所有欧盟法规的基础模型。它涉及报价推文，因此您需要先单击后面。特格马克（Tegmark）说，塞德里克（Cedric）的行为是虚伪的，看起来完全像腐败，并得到了荒谬的论点的支持。塞德里克（Cedric）和勒肯（Lecun）对Tegmark的含义不那么友善。我最喜欢的推文&lt;a href="https://twitter.com/cedric_o/status/1728724005459235052" rel="noreferrer noopener" target="_blank"&gt;是塞德里克（Cedric）的这推&lt;/a&gt;文，其中包含“我强烈支持监管”和“我强烈反对法规”政治家的政治人物。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/ai_ctrl/status/1728021633703493876?s=46&amp;amp;t=6lH2PxsylmdyNsCDzO_26A" rel="noreferrer noopener" target="_blank"&gt;猜想的康纳·阿克西奥斯（Connor Axios）写了一本关于科技游说工作的专栏文章&lt;/a&gt;，其中包括据说将受益的美国大型科技公司，以中断欧盟AI法案。&lt;/p&gt;&lt;p&gt;在这个世界能够掌握力量的世界中，Big Tech在AI竞赛中拥有所有卡片以及无限的资金，几乎可以将几乎所有内容作为大型技术的礼物都很容易。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;没有法规？给大型技术的礼物。他们会猖ramp。&lt;/li&gt;&lt;li&gt;暂停AI？您正在建立他们的垄断。&lt;/li&gt;&lt;li&gt;调节较小的AI，而不是更大的AI？大型技术的巨大胜利。&lt;/li&gt;&lt;li&gt;规范应用程序，而不是模型？ Big Tech的角色是生产模型。&lt;/li&gt;&lt;li&gt;规范大型模型，而不是小型模型？监管捕获，宝贝。&lt;/li&gt;&lt;li&gt;需要安全检查吗？开源和小家伙无法通过安全检查。&lt;/li&gt;&lt;li&gt;需要注册和报告吗？对于大型技术来说，对他人来说很容易，杀手级负担。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;等等。我同意这很艰难。&lt;/p&gt;&lt;p&gt;监管捕获是一个真正的问题。我仍然说：“豁免大型技术的唯一一件事是从所有法规中独特地做到的事情”是大型技术想要的。&lt;/p&gt;&lt;p&gt;这并不是这是一个重要的问题。我不太在乎大型技术的喜欢或不喜欢。我不太在乎他们是否赚取更大的利润。你也不应该。重要的是，可能会导致人类的良好结果，我们都活着，理想情况下，我们得到了很多美好的事物。&lt;/p&gt;&lt;p&gt;欧盟AI法案的新提议的实施比以前提到的更为疯狂。所有没有对通用AI开发人员（构成实际危险的人）强加的要求？ &lt;a href="https://twitter.com/RistoUuk/status/1729784598412812524" rel="noreferrer noopener" target="_blank"&gt;然后，所有这些要求和相关成本都将传递给任何想要使用此类型号的欧洲初创企业&lt;/a&gt;。正是较小的公司必须证明安全性，其中大公司被明确豁免提供确切的信息，因为它们很大，并且做了重要的危险。&lt;a href="https://t.co/56XMsJ4zEI" rel="noreferrer noopener" target="_blank"&gt;请参阅Jaan Tallinn和Risto Uuk的专栏&lt;/a&gt;。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/ShakeelHashim/status/1727652452021735565" rel="noreferrer noopener" target="_blank"&gt;经济学家得出了Openai传奇的结论&lt;/a&gt;，AI太重要了，无法留给最新的公司阴谋。将其与那些认为这的人进行对比，这意味着它必须留给那些将最大化利润的人。&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;音频一周&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;书面版本很好，但是要获得全部影响，请考虑聆听&lt;a href="https://www.youtube.com/watch?v=UdBMkj2WViY&amp;amp;ab_channel=CognitiveRevolution%22HowAIChangesEverything%22" rel="noreferrer noopener" target="_blank"&gt;Nathan Lebenz作为GPT-4 Red Teamer的经历的音频版本&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;我会以这种方式总结莱本兹的故事：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;内森（Nathan）可以访问GPT-4-4-唯一有用的模型。他被吹走了。&lt;/li&gt;&lt;li&gt; Openai的人似乎不知道他们拥有什么。&lt;/li&gt;&lt;li&gt;内森（Nathan）要求加入红队（Red Team），加入，全职无偿。&lt;/li&gt;&lt;li&gt;内森发现红队不足。给出了很少的指导。大多数人似乎脱离了接触，几乎不知道如何促进工程。&lt;/li&gt;&lt;li&gt;有时，只有内森就会生成一半或更多的红色团队内容。&lt;/li&gt;&lt;li&gt;内森问，您的保障措施和计划是什么？他们不会告诉他。&lt;/li&gt;&lt;li&gt;红色团队将获得一个应该拒绝有害命令的版本。如果您完全直接发挥作用，它也可以正常工作，但即使是最基本的技术也无法实现。&lt;/li&gt;&lt;li&gt;当内森（Nathan）报告这一点时，那些负责人会感到困惑，无法复制。内森提供“一千个屏幕截图”。&lt;/li&gt;&lt;li&gt;内森（Nathan）越来越担心并没有认真对待安全。&lt;/li&gt;&lt;li&gt;内森（Nathan）向一些充满信心的专家朋友问他该怎么办，并指向董事会成员。&lt;/li&gt;&lt;li&gt;董事会成员说，他们已经看到了一个演示，听说新模型很好，但没有尝试过GPT-4（！），这是关于这一点的。&lt;/li&gt;&lt;li&gt;内森（Nathan）被红队（Red Team）开除，据说是因为允许了解GPT-4的能力传播。&lt;/li&gt;&lt;li&gt;董事会成员告诉内森（Nathan），他们被告知他“犯有不受挑战性的人”。&lt;/li&gt;&lt;li&gt;换句话说，他们告诉董事会成员，内森不应该受到信任，因为他在将这个问题引起董事会的注意之前就与信任的朋友进行了咨询，因此董事会不应关注它。&lt;/li&gt;&lt;li&gt;事情就这样结束了。&lt;/li&gt;&lt;li&gt; GPT-3.5船只，安全性比红色团队显示的任何东西都要好得多。&lt;/li&gt;&lt;li&gt;后来透露，还有其他明显的努力被红队成员隐藏了。内森（Nathan）在这里描述的时期是很早的日子。从那以后，通常的安全工作看起来更好，更严重。推广和门控要求是故意的。&lt;/li&gt;&lt;li&gt; GPT-4的安全协议中仍然有一些清晰的漏洞。例如，您可以使用已经存在一段时间的提示将其放到长矛鱼上。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这听起来像是与董事会“一贯坦率”的首席执行官和组织？我敦促泰勒，萨默斯和德·安吉洛将这一事件包括在他们的调查中。&lt;/p&gt;&lt;p&gt;听起来像是负责任的安全方法吗？如果您的目标是运送消费产品，那么它在业务层面上的不足是不足的。与培训相比，这里的费用是微不足道的，为什么要在红色团队上踢脚，让事情延迟几个月？&lt;/p&gt;&lt;p&gt;或另一个级别可以认为这是一种高度负责的安全方法。也许这是每个人都超越和超越。他们不希望用GPT-4的能力吓到世界。他们故意放慢释放并确定保留信息盖的优先级。 GPT-3.5是一个节奏的，故意的推出。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/jd_pressman/status/1729994771719180389" rel="noreferrer noopener" target="_blank"&gt;我与John David Pressman谈了两个小时，讨论了实际的结盟问题&lt;/a&gt;。谈论具体问题，比较模型并尝试与我不同意的人弄清楚事情，而不是陷入有关话语的争论，真是太好了。如果这种类型的讨论听起来很吸引人，我建议您试一试。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.bloomberg.com/news/articles/2023-11-23/anthony-levandowski-reboots-the-church-of-artificial-intelligence?sref=htOHjx5Y" rel="noreferrer noopener" target="_blank"&gt;来自彭博社，安东尼·莱万多夫斯基（Anthony Levandowski）重新启动人工智能教堂&lt;/a&gt;。看，那是AI邪教。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/yashkaf/status/1728130426026488109" rel="noreferrer noopener" target="_blank"&gt;即使是铃声也对Openai的情况进行了一些讨论&lt;/a&gt;（除非您想无论如何都不会听）。&lt;/p&gt;&lt;p&gt; &lt;a href="https://80000hours.org/podcast/episodes/jeff-sebo-ethics-digital-minds/" rel="noreferrer noopener" target="_blank"&gt;杰夫·塞博（Jeff Sebo）在数字思维中&lt;/a&gt;以及如何避免在80,000小时内梦游陷入重大的道德灾难。您想要真正的帕斯卡（Pascal）抢劫吗？在这里，您会得到一个真正的抢劫，他们说您可能想担心概率低至四亿人的概率。即使AI具有相关特征的机会&amp;lt;1％，我们也必须以我说危害我们生存的方式授予他们权利。与其他许多人一起，数学说我们应该是范围不敏感的，倍增，忽略其他一切，因此我们应该做这件事……&amp;#39;缺少的是我所看的部分的任何感觉，如果您错了，则提出的行动。最初的帕斯卡（Pascal）的抢劫活动至少涉及高度有限的下跌。&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;修辞创新&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/TheZvi/status/1727460012954435988" rel="noreferrer noopener" target="_blank"&gt;Twitter线程良好地介绍了AI风险&lt;/a&gt;。我们很烂。让我们做得更好。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/EpistemicHope/status/1730122141327413552" rel="noreferrer noopener" target="_blank"&gt;Eli Tire指出&lt;/a&gt;，各方面对AI和AI风险进行了讨论，部落主义正在提高。&lt;/p&gt;&lt;p&gt;这是非常正确的，尤其是在Twitter上，以至于它使阅读我的提要比两周前更令人痛苦。一些担心存在风险的人在某种程度上也在这样做。&lt;/p&gt;&lt;p&gt;然而。我认为这不是遥不可及的对称效果。我不会假装是一个。加速主义者大多忙于将比人AIS更聪明的人等同于对恐怖分子，邪教主义者和疯狂的危险。展示了通过功率来展示AD的最糟糕形式和通过功率燃气。可以肯定的是，那些确实担心的人并没有始终如一地全面掩盖自己，但是对比从未更清楚。&lt;/p&gt;&lt;p&gt;这并不能证明有关基本情况或对此的适当回应。在没有忧虑理由的世界中，我仍然希望那些不敬业的人会在这个地方完全彻底失去它。因此，观察不是证据。您需要实际考虑参数。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/danfaggella/status/1728466838751756603" rel="noreferrer noopener" target="_blank"&gt;真实的故事，对于某些功能的AGI水平&lt;/a&gt;。对于人们而言，重要的是。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;丹尼尔·法格拉（Daniel Faggella）：“确定会有AGI，但我们人类一如既往地有必要。”&lt;/p&gt;&lt;p&gt;不，兄弟。在我们屏住呼吸的时候，Agi解决了GO的游戏，并阅读了有史以来写过的所有物理文本。&lt;/p&gt;&lt;p&gt;一旦我们用数据，模型和物理机器人加载它 - 我们是障碍，而不是助手。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;如果我们继续走这条路，不，从经济意义上讲，我们将不是必需的。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/Liv_Boeree/status/1728131649177591953" rel="noreferrer noopener" target="_blank"&gt;Liv Boeree提醒我们，&lt;/a&gt;有很多涉及AI的事情可能会严重错误，整个过程中都有风险权衡，我们需要同时解决所有这些问题。正如她所说，她的清单是高度避免的。&lt;/p&gt;&lt;p&gt;我喜欢下一个，因为您可以阅读多少种不同的方式……&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/qephatziel/status/1728095405164937667" rel="noreferrer noopener" target="_blank"&gt;问*Phatziel&lt;/a&gt; ：终于，我们禁止经典的科幻小说中的乌托邦设备，请构建乌托邦设备。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/ESYudkowsky/status/1729339347848376453" rel="noreferrer noopener" target="_blank"&gt;Eliezer一直在努力&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Eliezer Yudkowsky：“我希望AIS最终会以人类的动机为动机，因为我们正在训练他们以输出人类的行为。”&lt;/p&gt;&lt;p&gt; “我聘请了一位天才女演员在视频摄影上观看当地的酒吧，直到她可以预测那里的每个普通人的单词和手势。希望她不会太醉！”&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;从一段时间开始，但仍然是我的立场， &lt;a href="https://twitter.com/AndrewCritchPhD/status/1729335273878856169" rel="noreferrer noopener" target="_blank"&gt;这是您的一个剪辑，真正&lt;/a&gt;解释了我对P（厄运）的看法，以及当其他人得出完全不同的结论时，我如何看待它。&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;比对人的智能比人的智能很困难&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;很难的原因之一是，这笔资金很长一段时间主要来自少数相互联系的，有效地非常层次的组织，通常喜欢EA，这些组织需要适合自己的盒子，并且经常试图与之搭配。主要实验室。与游说和政策努力相同。 &lt;a href="https://twitter.com/atroyn/status/1727386556342972866" rel="noreferrer noopener" target="_blank"&gt;我们需要更广泛的资助者，花更多的钱在各种各样的努力上&lt;/a&gt;。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.lesswrong.com/posts/zaaGsFBeDTpCsYHef/shallow-review-of-live-agendas-in-alignment-and-safety" rel="noreferrer noopener" target="_blank"&gt;安全和对齐空间中的努力浅层图。&lt;/a&gt;&lt;/p&gt;&lt;p&gt; Nate Soares的Miri写了一篇奇怪的文章： &lt;a href="https://www.lesswrong.com/posts/AWoZBzxdm4DoGgiSj/ability-to-solve-long-horizon-tasks-correlates-with-wanting" rel="noreferrer noopener" target="_blank"&gt;解决长途任务的能力与在行为主义意义上想要事物有关&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;好吧，你知道今天的人工智能在某些……比方说“长期”任务上表现不佳吗？像新颖的大型工程项目一样，还是写了很多预言的长书系列？&lt;/p&gt;&lt;p&gt; （Modulo，它可以很好地下棋，这比某些事物更长；这种区别是定量的，而不是定性的，并且正在被侵蚀等）。&lt;/p&gt;&lt;p&gt;而且您知道AI似乎没有那么多的“想要”或“欲望”的行为？&lt;/p&gt;&lt;p&gt; ……&lt;/p&gt;&lt;p&gt;好吧，我声称这些或不再是相同的事实。毫不奇怪的是，AI陷入了各种长途任务&lt;em&gt;，而且&lt;/em&gt;似乎并没有像具有“想要/欲望”那样被固定得很好。这些是同一枚硬币的两个方面。&lt;/p&gt;&lt;p&gt; ……&lt;/p&gt;&lt;p&gt;也就是说，我的理论说：“ AIS必须坚定地追求&lt;em&gt;一些&lt;/em&gt;目标以在长途任务上表现良好”，但它&lt;em&gt;并不是&lt;/em&gt;说这些目标必须是对AI进行训练的目标（或要求使用的目标） ）。确实，我认为实际行为主义者目标不太可能是程序员想要的确切目标，而不是（例如）纠结的相关性网络。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;抛弃所有“那不是这些确切的词的含义，你愚弄”异议，并允许一些模糊的抽象，正如内特所说，整个事情似乎很明显即使您关心这个问题的方式，请阅读其余部分。在某种程度上，一个系统正在有效地做一件可以通过因果空间绘制出某种目的的路径的事情，包括克服任何障碍，在某种程度上都没有。在某种程度上，它不是，您希望它做长期计划，不是这样不会。在这个程度上，系统具有能力，然后可能看起来像长期计划，尤其是在有很多复杂障碍的情况下。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.lesswrong.com/posts/AWoZBzxdm4DoGgiSj/ability-to-solve-long-horizon-tasks-correlates-with-wanting?commentId=mEPjkATGDExGcZWop" rel="noreferrer noopener" target="_blank"&gt;保罗·克里斯蒂安（Paul Christiano）在评论中挑战&lt;/a&gt;，我认为我不同意挑战。 &lt;a href="https://www.lesswrong.com/posts/AWoZBzxdm4DoGgiSj/ability-to-solve-long-horizon-tasks-correlates-with-wanting?commentId=G28WTNBkQFkBPLqGd" rel="noreferrer noopener" target="_blank"&gt;安娜·萨拉蒙（Anna Salamon）注意到她以有趣的方式感到困惑&lt;/a&gt;。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/robbensinger/status/1728032814069960985" rel="noreferrer noopener" target="_blank"&gt;罗布·本辛格（Rob Bensinger）指出了他的模型我们应该谨慎的一些精确方式&lt;/a&gt;：&lt;a href="https://t.co/Tb8i8iw5Kl" rel="noreferrer noopener" target="_blank"&gt;贴剂抵抗&lt;/a&gt;，&lt;a href="https://t.co/qZ4fURslPi" rel="noreferrer noopener" target="_blank"&gt;最小性原则&lt;/a&gt;和&lt;a href="https://t.co/pKAxM9wDkV" rel="noreferrer noopener" target="_blank"&gt;非对抗性原则&lt;/a&gt;。简而言之。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;非对抗性：您的AI不应（事实上）寻求颠覆您的安全措施。&lt;/li&gt;&lt;li&gt;最小化：在建立AGI后的关键时期，即使其身体行动看起来更风险，也要选择要求最小危险的AGI认知的计划。&lt;/li&gt;&lt;li&gt;贴片阻力：努力理解为什么问题出现并阻止问题首先发生。如果问题不断出现并且您不断将其修补，那么您将为隐藏问题而进行优化。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt; Oliver Habryka和John Pressman &lt;a href="https://twitter.com/ohabryka/status/1727825655545704879" rel="noreferrer noopener" target="_blank"&gt;讨论了各种潜在的人类增强或替代AI培训计划&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;约翰·普拉斯曼（John Pressman）：因此，要检查一下，如果我们接受了10,000人的脑电图数据，记录了数十万个小时，并培训了一个模型，然后将其转换为下游任务，例如写作，您是否有同样的担忧？&lt;/p&gt;&lt;p&gt;奥利弗·哈布里卡（Oliver Habryka）：哦，不！这是我个人最兴奋的计划之一。我真的希望有人这样做。我认为这是我们现在最好的镜头之一。如果您知道有人在做这个，我很乐意将一些资金指导给它。&lt;/p&gt;&lt;p&gt;我目前的最佳猜测是，在获得任何看起来像人类的高级行为之前，您要接近零错误，但是伙计，我肯定会觉得我们应该检查，并愿意为此进行一次非常大的训练。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;总的来说，我对进入通用情报的替代体系结构和方法感到兴奋，这为以可生存和健壮的方式作为能力量表带来了更好的希望。如果尝试并显示出有希望的功能，您将有机会观察它是否有可能表现出色，并在没有插头的情况下拔下插头，我感到非常兴奋。如果您没有那个，那么我们又回到了一次镜头，所以酒吧会变得更高，我会变得更加轻松。&lt;/p&gt;&lt;p&gt;脑电图数据假设很有趣。当然，它通过了“如果可以安全的话，我们应该尝试一下”栏。我明白了为什么它可以在所有计数上起作用。我还可以看到它可能如何失败，无论是功能还是后果。如果无论事情看起来多么糟糕，都无法停止火车，那么我必须在决定是否开始之前要考虑一下。&lt;/p&gt;&lt;p&gt;戴维德（DavidAd）对新的DeepMind纸张，&lt;a href="https://arxiv.org/abs/2311.14125" rel="noreferrer noopener" target="_blank"&gt;通过双重效率的辩论&lt;/a&gt;（&lt;a href="https://github.com/google-deepmind/debate" rel="noreferrer noopener" target="_blank"&gt;此处的代码&lt;/a&gt;）进行了可扩展的AI安全&lt;a href="https://twitter.com/davidad/status/1729461156618637502" rel="noreferrer noopener" target="_blank"&gt;感到兴奋&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;纸张摘要：在各种各样且不断增加的复杂领域中具有强大功能的预先训练的AI系统的出现，对人工智能安全提出了关键的挑战，因为任务可能变得过于复杂，无法直接判断人类。欧文等人。 [2018]提出了一种辩论方法，目的是使此类AI模型的力量相互对抗，直到识别（MIS）一致性的问题被分解为可管理的子任务。&lt;/p&gt;&lt;p&gt;尽管这种方法的承诺是明确的，但原始框架是基于以下假设：诚实策略能够以指数级的步骤模拟确定性的AI系统，从而限制其适用性。&lt;/p&gt;&lt;p&gt;在本文中，我们通过设计一套新的辩论协议来展示如何解决这些挑战允许不诚实的策略实现指数级的模拟步骤。&lt;/p&gt;&lt;p&gt;大卫：这是一个里程碑。从历史上看，我一直对“通过辩论的AI安全”表示怀疑（基本上是因为现在称为“混淆论点”的原因）。我对这个理论结果的前提仍然有些怀疑（例如，在下面的leans中定义的随机甲骨文机器，似乎不是建模有关可接受或不可接受的未来的“人类判断”的好框架）。&lt;/p&gt;&lt;p&gt;但是，我现在更加乐观地认为，从这一研究系列中得出的PCP（概率可检查的证明）系统可能是在工具箱中具有有用的工具，用于验证依赖于不可证实的人类偏好的AI安全性能。我仍然认为“不杀死很多人”可能完全可以正式化，但是人类也可能想减轻各种反乌托邦的风险，这些风险更像是一种口味的问题，这就是这种方法可能会大放异彩。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我仍然对整个辩论方法的持怀疑态度，以及我们可以有意义地证明事物的想法，或者我们可以正式化诸如“不杀死很多人”的陈述。我希望我对为什么别人对这种方法如此乐观有更好的了解。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.astralcodexten.com/p/god-help-us-lets-try-to-understand?utm_source=post-email-title&amp;amp;publication_id=89120&amp;amp;post_id=138968567&amp;amp;utm_campaign=email-post-title&amp;amp;isFreemail=true&amp;amp;r=67wny&amp;amp;utm_medium=email" rel="noreferrer noopener" target="_blank"&gt;斯科特·亚历山大（Scott Alexander）从几周前就浏览了关于单个大命的人类论文&lt;/a&gt;。&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;人们可能还会担心AI仅杀死其中一些&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/unusual_whales/status/1727823232118690163" rel="noreferrer noopener" target="_blank"&gt;因此，可以预见的是。&lt;/a&gt;听起来它会很好。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;不寻常的鲸鱼：破裂：五角大楼正在朝着让AI武器自主决定杀死人类的迈向。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;好消息是，在这种情况下，您本能地期望它的方式结束了，我们可能并不全都死了，要么都已经死了。&lt;/p&gt;&lt;p&gt; Qioochu Yuan并不担心&lt;a href="https://twitter.com/QiaochuYuan/status/1728189424675209380" rel="noreferrer noopener" target="_blank"&gt;，但指出那些人的诚意。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Qioochu Yuan：人们真的不知道人们的生存风险有多真诚。许多人都在寻找别有用心。我向您保证，我个人认识并与之交谈的所有人都相信他们在字面上说的话，并真诚地试图阻止每个人死亡。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我再次确认。整个诚意非常高。&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;人们担心AI杀死所有人&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/TEDchris/status/1728129103247634869" rel="noreferrer noopener" target="_blank"&gt;泰德（Ted）的克里斯·安德森（Chris Anderson）认为阿吉（Agi）即将来临，是对人类的生存危险&lt;/a&gt;（没有解释他的原因）。莱肯在评论中建议戴米斯·哈萨比斯（Demis Hassabis）或伊利亚·萨特（Ilya Sutskever）作为未来泰德（Ted）的辩论伙伴，值得一试。&lt;/p&gt;&lt;p&gt;是的，两个非常不同的情况。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/tszzl/status/1727754804209062116" rel="noreferrer noopener" target="_blank"&gt;ROON&lt;/a&gt; ：AI研究并不类似于功能研究的病原体增益，功能研究的增益是不受限制的，但上行空间很小。使用AI，上行和下行的一面是无限的。这就是为什么我们安全地构建它的原因。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;因此，现在有理性的人可以谈论价格。我们如何建立安全性？有哪些权衡？哪些举动更有可能使得良好的结果？如果有人能弄清楚我们将如何做到这一点，我都可以安全地建造它。&lt;/p&gt;&lt;p&gt; Whereas with Gain of Function research, without the same upside, the correct answer is obviously no, that is crazy, don&amp;#39;t do that, why would we ever let anyone do that.&lt;/p&gt;&lt;h4&gt; &lt;strong&gt;Other People Are Not As Worried About AI Killing Everyone&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt; Because it is right to include such things: &lt;a href="https://twitter.com/psychosort/status/1727851812009480429" rel="noreferrer noopener" target="_blank"&gt;Brian Chau responds unkindly to my assertions last week&lt;/a&gt; that the paper he was describing did not propose anything resembling totalitarianism. I affirm that I stand by my claims, and otherwise will let him have the last word.&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/psychosort/status/1727856690299556227" rel="noreferrer noopener" target="_blank"&gt;I&amp;#39;ll also give him this banger&lt;/a&gt; , although beware the Delphic Oracle:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Brian Chau: 2008: “Bitter clingers to their guns and religion”&lt;/p&gt;&lt;p&gt; 2024: “Bitter clingers to their degrees and newspapers”&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/growing_daniel/status/1728862193532477723" rel="noreferrer noopener" target="_blank"&gt;I&amp;#39;ll also speak up for Yann LeCun&amp;#39;s right to have his own damn opinion&lt;/a&gt; about existential risk and other matters, no matter what &amp;#39;other equally qualified experts&amp;#39; say.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Geoffrey Hinton: Yann LeCun thinks the risk of AI taking over is miniscule.这意味着他非常重视自己的观点，而很少重视许多其他同等资格专家的观点。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; I think LeCun is very wrong about AI risk and Hinton is right (and has been extremely helpful and in good faith all around), but LeCun allowed to be wrong, assuming that is how he evaluates the evidence. You&amp;#39;re allowed, nay sometimes required, to value your own opinion on things.每个人都一样。 I don&amp;#39;t really understand how LeCun reaches his conclusions or why he believes in his arguments, but let&amp;#39;s evaluate the arguments themselves.&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/SamoBurja/status/1727797479452844301" rel="noreferrer noopener" target="_blank"&gt;Interestingly we agree on the initial statement below but for opposite reasons.&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Samo Burja: The older a transhumanist gets the less you should trust them to accurately judge AGI risk.&lt;/p&gt;&lt;p&gt; Basically I think about half of the people making predictions have a psychological bias towards the singularity being in their lifetime.&lt;/p&gt;&lt;p&gt; A lifetime of cherrypicking evidence results in “The singularity is near!” in 1985 in 1995 in 2005 and in 2025. For every year after 1985 the singularity is quite near in some sense, but in another this isn&amp;#39;t what they mean when they say that.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; There&amp;#39;s not zero of that. In my experience the &amp;#39;I am old and have seen such talk and dismiss it as talk&amp;#39; is stronger.&lt;/p&gt;&lt;p&gt; What I think is even stronger than that, however, especially among the childless, is that many people want AGI within their lifetimes. They want to see the results and enjoy the fruits. They want to live forever. If we get AGI in a hundred years, great for humanity, but they are still dead. A few even say it out loud.&lt;/p&gt;&lt;p&gt; Which I totally get as a preference. I can certainly appreciate the temptation, especially for those without children. I hope we collectively choose less selfishly and more wisely than this.&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/daniel_271828/status/1728634847131001333" rel="noreferrer noopener" target="_blank"&gt;Here&amp;#39;s a weird one.&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Pedro Domingos: LLMs are 1% like humans and 99% unlike, and the burden is on doomers to explain how it&amp;#39;s exactly that 1% that makes them an extinction threat to us.&lt;/p&gt;&lt;p&gt; Daniel Eth: Okay, this is weird – it&amp;#39;s more the 99% that&amp;#39;s unlike humans that I&amp;#39;m worried about, not the 1% that&amp;#39;s like us. “This new intelligent thing is very alien” doesn&amp;#39;t make me *more* comfortable.&lt;/p&gt;&lt;p&gt; John Pressman: Luckily, it&amp;#39;s untrue. [Eth agrees it is untrue as do I]&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; I agree with Pressman and Eth, 99% I do not understand why Domingos thinks this is an argument? Why should the parts that are unlike humans be safe, or even safer?&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/daniel_271828/status/1728357894679380329" rel="noreferrer noopener" target="_blank"&gt;Here&amp;#39;s another weird one&lt;/a&gt; . I don&amp;#39;t understand this one either.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Pedro Domingos: “I&amp;#39;m worried”, said one DNA strand to another, swimming inside a bacterium two billion years ago. “If we start making multicellular creatures, will they take over from DNA?”&lt;/p&gt;&lt;/blockquote&gt;&lt;h4&gt; &lt;strong&gt;Please Speak Directly Into This Microphone&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt; &lt;a href="https://twitter.com/AndrewCritchPhD/status/1729524104896930192" rel="noreferrer noopener" target="_blank"&gt;Your periodic reminder.&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Andrew Critch: Reminder: some leading AI researchers are *overtly* pro-extiction for humanity.施米德胡贝尔非常成功，值得庆幸的是他愿意诚实地面对他的灭绝论。更多的人工智能专家对此秘密保密（我知道，因为我见过他们）。&lt;/p&gt;&lt;p&gt; Jurgen Schmidhuber (Invented principles of meta-learning (1987), GANs (1990), Transformers (1991), very deep learning (1991), etc): AI boom v AI doom: since the 1970s, I have told AI doomers that in the end all will be good. &lt;a href="https://t.co/DJ9aeA6x1o" rel="noreferrer noopener" target="_blank"&gt;Eg, 2012 TEDx talk&lt;/a&gt; : “Don&amp;#39;t think of us versus them: us, the humans, v these future super robots. Think of yourself, and humanity in general, as a small stepping stone, not the last one, on the path of the universe towards more and more unfathomable complexity. Be content with that little role in the grand scheme of things.” As for the near future, our old motto still applies: “Our AI is making human lives longer &amp;amp; healthier &amp;amp; easier.”&lt;/p&gt;&lt;/blockquote&gt;&lt;h4&gt;&lt;strong&gt;轻松的一面&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/tszzl/status/1729279209821130984" rel="noreferrer noopener" target="_blank"&gt;Roon is excited for the new EA&lt;/a&gt; .&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Roon: my main problem with EA is that the boring systematic index fund morality mindset will almost certainly not lead to the greatest good.&lt;/p&gt;&lt;p&gt; All the best historical advances in goodness have come from crazy people pursuing crazy things.&lt;/p&gt;&lt;p&gt; Or alternatively the kindness of normal individuals looking out for their families and communities&lt;/p&gt;&lt;p&gt; The hedge fund manager donating to malaria funds forms a kind of bland middle that inhabits the uninspiring midwit part of the bell curve.&lt;/p&gt;&lt;p&gt; I actually see the longtermist xrisk arm that schemes to destroy ai companies as a big improvement and way more fun.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; I get where he&amp;#39;s coming from. If they&amp;#39;re out in the arena trying to do what they think is right, then perhaps they will get somewhere that matters, even if there is risk that it goes bad. Better to have the hedge fund manager donate to malaria funds that work than to cute puppies with rare diseases, if one does not want one&amp;#39;s head in the game, but that is not what ultimately counts most.&lt;/p&gt;&lt;p&gt; Obviously Roon and I view the events at OpenAI differently, but the board definitely did not want OpenAI to operate the way Altman wants it to operate. &lt;a href="https://thezvi.substack.com/p/openai-the-battle-of-the-board" rel="noreferrer noopener" target="_blank"&gt;As I noted&lt;/a&gt; , both the board and Altman viewed the potential destruction of OpenAI as an acceptable risk in a high stakes negotiation.&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/rlmcelreath/status/1694296270540554405" rel="noreferrer noopener" target="_blank"&gt;什么是人工智能？&lt;/a&gt;&lt;/p&gt;&lt;p&gt; Richard McElreath: I told a colleague that logistic regression is AI and they got mad at me, so I made a chart.找到你自己。 I am “Tinder is AI”.&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1371c0b-3478-45a7-9a85-9ce9c0eb8604_1456x874.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="Table with 3 rows and 3 columns.
Rows: (1) Algorithm purist (mimic human cognition), (2) Algorithm netural (learns &amp;amp; generalizes), (3) Algorithm rebel (method irrelevant)
Cols: (1) Ability purist (exceeds human ability), (2) Ability neutral (makes task easier), (3) Ability rebel (usefullness questionable)
Cells:
[1,1] &amp;quot;Terminator is AI&amp;quot; [1,2] &amp;quot;C3PO is AI&amp;quot; [1,3] &amp;quot;WALL-E is AI&amp;quot;
[2,1] &amp;quot;AlphaGo is AI&amp;quot; [2,2] &amp;quot;XGBOOST is AI&amp;quot; [2,3] &amp;quot;Tinder is AI&amp;quot;
[3,1] &amp;quot;A metal detector is AI&amp;quot; [3,2] &amp;quot;Bubble sort is AI&amp;quot; [3,3] &amp;quot;Magic 8 Ball is AI&amp;quot;" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/nhlzhbejluqsdfvkl1cz" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt; I think my position on the chart is a hybrid – that Wall-E and XGBoost are AIs, but Tinder and Metal Detectors are not.&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/atroyn/status/1728557473962107101" rel="noreferrer noopener" target="_blank"&gt;Good news, everyone.&lt;/a&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48af238c-d0cc-45e0-8dea-4238538cdfac_898x324.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/v32g9ya48t7ufnwgbjh8" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt; &lt;a href="https://twitter.com/menhguin/status/1728230474735309116" rel="noreferrer noopener" target="_blank"&gt;And some bad news.&lt;/a&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e8ffc50-9677-4fd3-bf21-49f55720742f_892x354.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/c0sgmfwhgu38phcnadkp" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt; &lt;a href="https://twitter.com/deepfates/status/1728158272920625190" rel="noreferrer noopener" target="_blank"&gt;Staff Engineer promised if I kept quoting him I&amp;#39;d get a board seat&lt;/a&gt; .我会吗？&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6662adf-4982-4d22-8e62-111bdaea88a8_880x486.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/je5BwKe8enCq8DLrm/u9akjoqksk7rylownbgr" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.lesswrong.com/posts/je5BwKe8enCq8DLrm/ai-40-a-vision-from-vitalik#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 30 Nov 2023 17:30:15 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/je5BwKe8enCq8DLrm/ai-40-a-vision-from-vitalik</guid></item><item><title>在经过长期目标训练的模型中，阴谋是否更有可能发生？ （“诡计人工智能”第2.2.4.1-2.2.4.2节）</title><link>https://www.lesswrong.com/posts/Xtb9SMrQofpxzEw4T/is-scheming-more-likely-in-models-trained-to-have-long-term</link><description>发布于 2023 年 11 月 30 日下午 4:43（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;这是我的报告“&lt;a href="https://arxiv.org/pdf/2311.08379.pdf"&gt;诡计多端的人工智能：人工智能会在训练期间假装对齐以获得权力吗？”&lt;/a&gt;的第 2.2.4.1-2.2.4.2 节。 ”。 &lt;a href="https://www.lesswrong.com/posts/yFofRxg7RRQYCcwFA/new-report-scheming-ais-will-ais-fake-alignment-during"&gt;这里&lt;/a&gt;还有完整报告的摘要（ &lt;a href="https://joecarlsmithaudio.buzzsprout.com/2034731/13969977-introduction-and-summary-of-scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power"&gt;此处&lt;/a&gt;有音频）。摘要涵盖了大部分要点和技术术语，我希望它能够提供理解报告各个部分所需的大部分背景信息。&lt;/p&gt;&lt;p&gt;本节的音频版本请点击&lt;a href="https://www.buzzsprout.com/2034731/13984855"&gt;这里&lt;/a&gt;，或者在您的播客应用程序上搜索“Joe Carlsmith Audio”。&lt;/p&gt;&lt;h1&gt;如果您有意训练模型以实现长期目标怎么办？&lt;/h1&gt;&lt;p&gt;到目前为止，在我对剧集外目标的讨论中，我并没有非常直接地关注剧集的&lt;em&gt;长度&lt;/em&gt;，也没有关注人类是否专门为了激励人工智能学习完成长期任务而设置训练。 。这些因素是否会影响人工智能最终实现策划所需的超集目标的概率？&lt;/p&gt;&lt;p&gt;是的，我认为他们确实如此。但让我们区分两种情况，即：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;在长（但不是：无限长）的剧集上训练模型，以及&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;尝试使用短片段来创建一个在较长（也许：无限长）时间范围内进行优化的模型。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我将依次查看每一个。&lt;/p&gt;&lt;h2&gt;在长剧集上训练模型&lt;/h2&gt;&lt;p&gt;在第一种情况下，我们专门使用相当长的片段来训练我们的人工智能——例如，一个完整的日历月。也就是说：在训练中，为了响应 t1 处的动作，AI 会收到梯度，该梯度因果关系取决于 t1 后整整一个月的动作后果，从而直接惩罚模型在 t1 处选择动作时忽略这些后果。&lt;/p&gt;&lt;p&gt;现在，重要的是，正如我在“具有类似阴谋者特征的非阴谋者”部分中讨论的那样，具有较长情节的错位非阴谋者通常会开始看起来越来越像阴谋者。因此，例如，这里的剧集奖励寻求者将有动力支持/参与努力控制将在一个月内得到回报的奖励过程。&lt;/p&gt;&lt;p&gt;但同样重要的是：一个月仍然不同于一万亿年。也就是说，在&lt;em&gt;较长的&lt;/em&gt;剧集上训练模型并不意味着你直接迫使它关心，例如，遥远星系在五万亿年后的状态。事实上，根据我对“激励事件”的定义，没有任何地球上的训练过程可以直接惩罚未能关心这样的时间范围的模型，因为模型接收到的梯度不能（因果地）依赖于在这样的时间尺度上发生的事情。当然，如果没有训练游戏，为了 5 万亿年后更优化的星系而牺牲月内奖励的模型将会受到训练的惩罚。&lt;/p&gt;&lt;p&gt;从这个意义上说，&lt;em&gt;反对&lt;/em&gt;期望超出情节目标的最基本的论点（即，训练不提供实现这些目标的直接压力，并且在缺乏训练游戏的情况下积极惩罚它们，如果它们导致牺牲情节内的奖励以获得更长的时间） -term）同样适用于“短”（例如，五分钟）和“长”（例如，一个月、一年等）剧集。&lt;/p&gt;&lt;p&gt;然而，我仍然有一些直觉，一旦你在相当长的剧集上训练模型，它学习&lt;em&gt;超越&lt;/em&gt;剧集目标的概率至少会有所上升。我能给出的最具体的原因是，在某种程度上，我们正在想象一种“混乱的目标导向”，在这种形式中，为了构建一个策划者，SGD 需要构建的不仅仅是一个超越情节的目标然后可以立即指导一个通用的“实现目标的引擎”，而是一组更大的面向未来的启发法、注意力模式、信念等等（称之为“有利于策划的认知模式”），那么看起来在我看来，接受较长情节训练的人工智能默认会具有更多此类“有利于阴谋的认知模式”。例如，他们会更习惯于推理自己行为的长期后果；他们将对这些长期后果有更好的模型；等等。也许（尽管这在我看来特别具有推测性），较长的情节训练将激励人工智能更多地思考各种&lt;em&gt;超出&lt;/em&gt;情节的事情，这样它的目标形成就可以更容易地附加到这些事情上。&lt;/p&gt;&lt;p&gt;除此之外，我还有某种（非常模糊的）直觉，相对于因训练而被迫只关心接下来五分钟的模型，经过训练而关心一个月或一年的模型更有可能说“无论如何，我只会在不确定的未来进行优化。”然而，我不清楚如何证明这种直觉。 &lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-ZvAv8KJZnntyccKuJ-1" id="fnref-ZvAv8KJZnntyccKuJ-1"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt; （你可以想象，在较长的剧集上训练的模型将有更多的动力来发展态势感知——甚至一般的目标导向性。但我假设我们正在讨论的所有模型都是目标导向的和情景的-意识到的。）&lt;/p&gt;&lt;h2&gt;使用短片段训练模型以实现长期目标&lt;/h2&gt;&lt;p&gt;让我们转向上面的第二种情况：尝试使用短集训练来创建一个在长期范围内优化的模型。&lt;/p&gt;&lt;p&gt;似乎，您希望模型执行的任务的时间范围越长，类似的事情就会变得越来越必要。因此，例如，如果您想创建一个模型来尝试在明年实现公司利润最大化，请尝试在长达一年的尝试利润最大化的事件中对其进行训练（例如，让模型采取一些行动，等等一年，然后根据公司赚取的利润来奖励）这不是一个很好的策略：没有足够的时间。&lt;/p&gt;&lt;p&gt;事实上，在我看来，此类问题似乎有可能推动人工智能开发&lt;em&gt;远离&lt;/em&gt;我在本报告中重点关注的那种简单的基线机器学习训练方法。例如，也许让模型实现“一年内公司利润最大化”等长期目标的最佳方法是通过类似于“&lt;a href="https://lilianweng.github.io/posts/2023-06-23-agent/?ref=planned-obsolescence.org"&gt;语言模型代理&lt;/a&gt;”的东西，该代理使用经过训练的机器学习系统作为组件构建，但它们不是“语言模型代理”。它们本身通过梯度非常直接地进行优化，梯度取决于它们是否实现了用户为其设定的（可能是长期的）目标。这些类型的人工智能&lt;em&gt;仍然&lt;/em&gt;会带来类似阴谋者行为的风险（参见上面“具有类似阴谋者特征的非阴谋者”部分），但它们不会是我想象中的阴谋者。&lt;/p&gt;&lt;p&gt;也就是说，有一些&lt;em&gt;方法&lt;/em&gt;可以尝试使用我所关注的训练类型，即使是相当短期的训练，也可以尝试创建针对长期目标进行优化的模型。特别是，您可以尝试根据&lt;em&gt;您对模型的短期行为是否会带来您想要的长期结果（例如，公司的长期利润）的评估&lt;/em&gt;来奖励模型，因此，希望诱导它优化直接获得那些长期结果。 &lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-ZvAv8KJZnntyccKuJ-2" id="fnref-ZvAv8KJZnntyccKuJ-2"&gt;[2]&lt;/a&gt;&lt;/sup&gt;当然，这是否&lt;em&gt;有效&lt;/em&gt;（例如，与诱导人工智能优化对其行为的短期&lt;em&gt;评估&lt;/em&gt;相反）是一个进一步的问题。但如果确实如此，那么你将创建一个在我看来可以优化“超越剧集目标”的人工智能。&lt;/p&gt;&lt;p&gt;事实上，根据我们想要如何使用我们的术语，我们可以将这种训练视为故意试图创造一种目标错误概括的形式。也就是说，这里的奖励并不因果地取决于模型行为的长期后果，因此从这个意义上说，所讨论的长期结果不是“指定目标”（在这个框架上，指定的目标）目标始终在情节内）。但无论如何，你都在试图让人工智能从本质上关心它们。&lt;/p&gt;&lt;p&gt;当然，进一步的问题是，这种超越情节的目标一旦创建，是否会导致工具性训练游戏。事实上，成功地创建这种超越情节的目标，而不是例如情节奖励寻求者，需要预先&lt;em&gt;避免&lt;/em&gt;某种类型的训练游戏——也就是说，模型必须&lt;em&gt;不&lt;/em&gt;学习仅仅优化供您进行短期评估。如果您已经成功地设置了训练过程，使得针对所需的长期目标进行优化实际上是一种最大奖励（或：接近最大奖励）行为，那么训练游戏可能不会为相关模型提供太多帮助优势。 （在这里，人类的类比是这样的：如果你的主管足够擅长评估你的近期表现是否会带来长期利润，并且足够不受操纵的影响，那么你的表现将与更好的是，在绩效评估中，直接优化长期利润——例如，因为你根本不会浪费时间考虑你的主管。）&lt;/p&gt;&lt;p&gt;尽管如此，在我看来，从这种过程中出现的具有超集目标的模型无论如何都面临着阴谋的风险。一方面，上一节讨论的考虑因素都适用于此——例如，这种训练涉及将你的模型的认知指向一个非常面向未来的方向，从而合理地诱导它发展出各种有利于心机的认知模式，赋予其价值。各种长期后果等等（在这种情况下，情节的范围对模型认知所指向的“未来”的时间范围没有设定界限；相反，这个界限是集中设定的，通过您对模型的行为将在何时导致什么的&lt;em&gt;评估&lt;/em&gt;）。&lt;/p&gt;&lt;p&gt;但更重要的是，在我看来，你对模型行为后果的评估在某种意义上会比因果性地依赖于这些后果的奖励过程“更嘈杂”，以一种更难以区分的方式您的训练所激励的不同&lt;em&gt;类型&lt;/em&gt;的长期目标。例如，也许你的模型的行为方式在你看来，大体上来说，就像它会导致你的公司在三年内取得成功，但你无法判断它是否也会产生大量有害的外部性——而奖励三年后真正能看到后果的过程就可以知道了。而且，无法轻松地区分您可能灌输的不同类型的长期目标似乎会增加意外灌输类似阴谋家的目标的风险。 &lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-ZvAv8KJZnntyccKuJ-3" id="fnref-ZvAv8KJZnntyccKuJ-3"&gt;[3]&lt;/a&gt;&lt;/sup&gt; &lt;/p&gt;&lt;hr class="footnotes-sep" /&gt;&lt;section class="footnotes"&gt;&lt;ol class="footnotes-list"&gt;&lt;li class="footnote-item" id="fn-ZvAv8KJZnntyccKuJ-1"&gt;&lt;p&gt;我们可以尝试诉诸简单（感谢 Evan Hubinger 的讨论），但我不清楚“五分钟”是否比“一个月”更简单。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-ZvAv8KJZnntyccKuJ-1"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-ZvAv8KJZnntyccKuJ-2"&gt;&lt;p&gt;这有点类似于“ &lt;a href="https://www.lesswrong.com/posts/D4gEDdqWrgDPMtasc/thoughts-on-process-based-supervision-1#4___Process_based_supervision___and_why_it_seems_to_solve_this_subproblem"&gt;基于流程的反馈&lt;/a&gt;”的形式，不同之处在于，在严格的基于流程的反馈形式中，您永远不会查看模型操作的&lt;em&gt;任何&lt;/em&gt;结果，而在此版本中，您可以查看结果直到您能够有效获取数据的任何时间范围。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-ZvAv8KJZnntyccKuJ-2"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-ZvAv8KJZnntyccKuJ-3"&gt;&lt;p&gt;例如，也许你想制定一个由某种“诚实”概念控制的长期目标，你指望它可以防止阴谋。但也许你无法判断自己是否成功。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-ZvAv8KJZnntyccKuJ-3"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/Xtb9SMrQofpxzEw4T/is-scheming-more-likely-in-models-trained-to-have-long-term#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 30 Nov 2023 16:43:07 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/Xtb9SMrQofpxzEw4T/is-scheming-more-likely-in-models-trained-to-have-long-term</guid></item><item><title>Enkrateia：一种基于安全模型的强化学习算法</title><link>https://www.lesswrong.com/posts/WgzGsDdfzrwybwiob/enkrateia-a-safe-model-based-reinforcement-learning</link><description>发布于 2023 年 11 月 30 日下午 3:51（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;在这篇文章中，我们链接到一个易于理解的、学术性的控制理论描述，说明如何在具有重大道德约束的领域中执行安全的基于模型的强化学习。&lt;/p&gt;&lt;p&gt;伦理物理学最适合被认为是人工智能安全中的一种新的科学范式，旨在为安全关键系统的特定学习成本​​函数风格提供严格的理论和历史论证。&lt;/p&gt;&lt;p&gt;在本文的其余部分中，我们只需复制并粘贴论文的介绍即可。&lt;/p&gt;&lt;p&gt; ###&lt;/p&gt;&lt;p&gt;我们描述了 LQPR（线性二次程序调节器），这是一种基于模型的强化学习算法，使我们能够证明系统行为的 PAC 式界限。我们描述了可以在 DeepMind AI Safety Gridworlds 域中执行的拟议实验；我们还没有时间实施这些实验，但我们对每个实验的结果提供了预测。未来潜在的工作可能包括使用神经网络逼近器将这项工作扩展到重要的任务，以及证明有关此类系统的安全性和稳定性的额外理论结果。我们相信，该系统是将大型语言模型和其他强大的近期人工智能与人类偏好结合起来的潜在基础。&lt;/p&gt;&lt;p&gt; 1 引言 在本节中，我们列出了必要的背景。 1.1 背景&lt;/p&gt;&lt;p&gt;讨论哲学中的伦理学主要采用三种方法。这些方法是结果论、道义论和美德伦理学。任何真正安全的强化学习算法都需要能够结合所有这三种方法，因为每种方法都有其他两种方法可以解决的弱点。本文档中描述的算法能够实现所有这三种方法。许多人，尤其是尤德科夫斯基，指出结果主义代理人可能会严重错位。这个观点对我们来说似乎相当准确。&lt;/p&gt;&lt;p&gt;与此同时，义务论代理人很可能会因为严格遵守规则而受到阻碍，并最终支付过高的结盟税而无力承担。美德伦理可能是这两个极端之间的最佳点，因为它似乎既是可调整的又是有能力的。为了完整起见，我们在一个统一的框架内提供所有三种道德范式的实现。我们鼓励明智的读者在没有证明足够令人放心的定理数量（这些定理已被验证到人类能力的极限）之前不要实施结果论代理。即使得到了这样的保证，为军事目的以外的任何目的而部署一个能力强大的结果主义代理人似乎仍然是不明智的。&lt;/p&gt;&lt;p&gt; 1.2 范围 本文旨在为基于安全模型的强化学习奠定理论基础。我们不讨论泛化问题，因为这似乎需要显着的扩展，而我们还没有设计。我们还只研究相关问题的更小、更简单的版本。当这种扩展看起来相对清晰时，我们将简要说明如何扩展它们。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/WgzGsDdfzrwybwiob/enkrateia-a-safe-model-based-reinforcement-learning#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 30 Nov 2023 15:51:49 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/WgzGsDdfzrwybwiob/enkrateia-a-safe-model-based-reinforcement-learning</guid></item><item><title>规范伦理与功利主义</title><link>https://www.lesswrong.com/posts/si87gyjB4eRdnnScf/normative-ethics-vs-utilitarianism</link><description>发布于 2023 年 11 月 30 日下午 3:36（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;这篇文章的主要观点是，我想让每个人都关注 John David Presserman 的精彩&lt;a href="https://twitter.com/jd_pressman/status/1729994771719180389"&gt;播客&lt;/a&gt;，他在其中与 Zvi 聊天。&lt;/p&gt;&lt;p&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ddfa529-629c-4546-a200-3b9f85bcc36b_606x354.png"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/si87gyjB4eRdnnScf/ieyhquprok6nfdnuglao" /&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;约翰在这篇文章中渴望与 Zvi 就有关欺骗性内在一致性的 LessWrong 风格的争论进行争论。但兹维并没有真正上钩。相反，他们在播客中用大部分时间谈论 John 关于 RLaiF 的想法。&lt;/p&gt;&lt;h1&gt; RLaiF 与规范伦理有什么关系？&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt; John 在播客的大部分时间里都在谈论 RLaiF 模型如果过度训练就会陷入退化状态的趋势。典型的例子是“&lt;a href="https://twitter.com/jd_pressman/status/1696973057133584490"&gt;是的垃圾邮件发送者&lt;/a&gt;”。在这种情况下，强化学习从第二个人工智能模型获得奖励，该模型对“这是一个好的结果”回答“是”或“否”。最终，我们正在训练的人工智能学会了重复输出“是”这个词，因为这会欺骗人工智能法官每次也回答“是”。&lt;/p&gt;&lt;p&gt; John将RLaiF模型陷入退化反馈模式的倾向与基于规则的伦理体系和基于结果的伦理体系（功利主义）之间的差异进行了类比。在规范的伦理体系中，人们遵循基于历史实践的各种规则，例如“不杀人”、“不偷盗”等。相比之下，在功利主义中，没有硬性规定，信徒只是寻求最大化单个目标函数，即世界上“善”或效用的总量。&lt;/p&gt;&lt;p&gt;正如功利主义在&lt;a href="https://plato.stanford.edu/entries/repugnant-conclusion/"&gt;理论&lt;/a&gt;和&lt;a href="https://www.cnbc.com/2023/11/04/sam-bankman-fried-sentence-could-be-100-plus-years-or-mere-decades.html"&gt;实践上&lt;/a&gt;都有糟糕的失败模式一样，当人工智能接受单一目标函数的训练时，它不可避免地会陷入奇怪的、不受欢迎的局部最大值。在伦理学中，我们依靠一套&lt;a href="https://en.wikipedia.org/wiki/Ten_Commandments"&gt;历史上制定的&lt;/a&gt;规则来解决这个问题，这些规则已被经验证明可以避免最坏的结果。同样，John 认为，我们可以通过评估达到全局最大值的过程来避免 RLaiF 框架中的反常最大化。&lt;/p&gt;&lt;h1&gt;一个简单的研究计划&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我想&lt;a href="https://twitter.com/nagolinc/status/1730043307546341779"&gt;建议&lt;/a&gt;通过构建最简单的测试用例来测试约翰的假设：&lt;/p&gt;&lt;p&gt;训练一个退化为“是的垃圾邮件发送者”的 RLaiF 模型&lt;/p&gt;&lt;p&gt;在此过程中，定期对奖励函数进行“检查点”&lt;/p&gt;&lt;p&gt;创建一个新的奖励函数，它是检查点的加权和&lt;/p&gt;&lt;p&gt;验证使用这个新的奖励函数训练不会退化为“是的垃圾邮件发送者”（请注意，如果我们允许我们的权重集为 1,0,0,0...，这就是微不足道的事实）&lt;/p&gt;&lt;p&gt;确定 RLaiF 退化为“yes-spammer”的边界条件是什么&lt;/p&gt;&lt;h1&gt;结论&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我还想呼应约翰在播客结尾处的结论：&lt;/p&gt;&lt;p&gt;对象层面的讨论很有价值，但具体的批评比广泛的、不准确的陈述更有效。&lt;/p&gt;&lt;p&gt;对人工智能的担忧应该集中在具体问题上，比如复杂反馈循环的稳定性，而不是一般性的怀疑。&lt;/p&gt;&lt;p&gt;人工智能中的规范推理和结果主义推理之间存在重要的权衡。&lt;/p&gt;&lt;p&gt;人工智能中纯粹的结果主义推理，如果没有规范的道德规范，就有可能导致负面结果。&lt;/p&gt;&lt;p&gt;主要关注的是人工智能中的超级后果论，而不是超级智能本身。&lt;/p&gt;&lt;p&gt;人们普遍认为超级结果主义具有潜在的危险。&lt;/p&gt;&lt;p&gt;超级后果主义产生的条件应该成为人工智能伦理辩论的核心部分。&lt;/p&gt;&lt;p&gt;当前的人工智能话语因其形式和参与者而遭受相互挫折。&lt;/p&gt;&lt;p&gt;更多的同行讨论，而不是专家与公众或倡导辩论，可以带来更深入的理解。&lt;/p&gt;&lt;p&gt;我们应该以同伴而非对手的身份相互接触，以促进建设性对话。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/si87gyjB4eRdnnScf/normative-ethics-vs-utilitarianism#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 30 Nov 2023 15:36:01 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/si87gyjB4eRdnnScf/normative-ethics-vs-utilitarianism</guid></item><item><title>超级智能的信息理论拳击</title><link>https://www.lesswrong.com/posts/NZP6QvkXryJQFGkLF/information-theoretic-boxing-of-superintelligences-1</link><description>发布于 2023 年 11 月 30 日下午 2:31（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;拳击一个比我们更聪明的智能体是令人畏惧的，但信息论、热力学和控制论为我们提供了可以从根本上限制智能体独立于智能体的工具。特别是，我们也许能够通过限制人工智能对信息的访问来遏制它&lt;/p&gt;&lt;h1&gt;限制输出和输入&lt;/h1&gt;&lt;p&gt;超级智能人工智能有可能帮助我们，也有可能伤害我们。最大限度地减少伤害的一种方法是对人工智能&lt;i&gt;进行限制&lt;/i&gt;：遏制它，使其无法自由影响其外部世界，理想情况下，同时保留其提供帮助的潜力。&lt;/p&gt;&lt;p&gt;拳击很复杂。摧毁人工智能肯定会阻止它影响任何事情。将它扔进黑洞可能会导致它与宇宙的其他部分断开，同时可能保留它的存在，尽管即便如此，它也可能利用一些未知的物理原理将&lt;a href="https://en.wikipedia.org/wiki/Markov_blanket"&gt;&lt;u&gt;信息泄漏回事件视界&lt;/u&gt;&lt;/a&gt;，或者在黑洞后持续存在或重建自身。已经蒸发了。&lt;/p&gt;&lt;p&gt;我们可以在仍然能够&lt;i&gt;使用&lt;/i&gt;人工智能的同时限制它吗？我们可以尝试阻止它与其环境进行物理交互，只允许它向用户&lt;a href="https://www.lesswrong.com/tag/oracle-ai"&gt;&lt;u&gt;呈现信息&lt;/u&gt;&lt;/a&gt;，但超级智能可以滥用任何通信渠道来操纵其用户，从而&lt;a href="https://www.lesswrong.com/posts/wKnwcjJGriTS9QxxL/dreams-of-friendliness"&gt;&lt;u&gt;授予它更多权力&lt;/u&gt;&lt;/a&gt;或&lt;a href="https://www.lesswrong.com/posts/aBRS3x4sPSJ9G6xkj/underspecification-of-oracle-ai"&gt;&lt;u&gt;提高其预测能力&lt;/u&gt;&lt;/a&gt;。为了成功地以这种方式限制人工智能，我们需要限制它与环境进行物理交互以及交流信息和操作的能力。我们将这种&lt;i&gt;输出装箱称为“输出装箱”&lt;/i&gt; ：通过限制 AI 的各种输出来包含它。&lt;/p&gt;&lt;p&gt;大多数关于装箱的讨论都集中在输出装箱上，但是这种方法有一个被忽视的镜像，我们将其称为&lt;i&gt;输入装箱&lt;/i&gt;：通过限制人工智能可以访问的信息来包含人工智能。 （为了完整起见，我们还可以考虑独立于输入和输出的装箱技术，其中我们通过限制人工智能的功能来包含人工智能，例如通过限制其计算速度或每秒从初始条件重新启动它）。&lt;/p&gt;&lt;p&gt;在本文的其余部分中，我们将介绍并研究一种理论输入装箱技术，该技术包含人工智能，通过使用信息论、热力学和控制理论的结果来控制其所拥有的有关其环境的信息位数。&lt;/p&gt;&lt;h1&gt;好的调节器和坏的钥匙&lt;/h1&gt;&lt;p&gt;当今强大的人工智能依赖于海量的数据（至少在训练期间），因此限制它们对数据的访问会限制它们后续的能力，但我们是否可以通过限制超级智能对数据的访问来从&lt;i&gt;根本上&lt;/i&gt;限制其外部影响？&lt;/p&gt;&lt;p&gt;我们知道，智能体需要了解其环境才能在其中有效地行动：Conant 和 Ashby 在 1970 年发表的一篇（ &lt;a href="https://www.lesswrong.com/posts/wTJECdFSAk4843mFj/thoughts-on-the-good-regulator-theorem#:~:text=This%20is%20among%20the%20worst%20papers%20I%27ve%20ever%20skimmed."&gt;&lt;u&gt;备受&lt;/u&gt;&lt;/a&gt;&lt;a href="https://www.lesswrong.com/posts/Dx9LoqsEh3gHNJMDk/fixing-the-good-regulator-theorem#:~:text=This%20may%20be%20the%20most%20misleading%20title%20and%20summary%20I%20have%20ever%20seen%20on%20a%20math%20paper."&gt;&lt;u&gt;诟病的&lt;/u&gt;&lt;/a&gt;）关于&lt;a href="http://pespmc1.vub.ac.be/books/Conant_Ashby.pdf"&gt;&lt;u&gt;良好调节定理的&lt;/u&gt;&lt;/a&gt;论文中研究了这一点。&lt;i&gt;调节器&lt;/i&gt;是维持所需特性的任何机制，例如恒温器或大脑及其稳态子系统。好的调节器定理指出，系统的每个好的调节器都必须包含系统的模型。该定理的另一种解析表明， &lt;a href="http://cadia.ru.is/wiki/_media/public:t-720-atai:a_primer_for_conant_and_ashby_s_good-regulator_theorem.pdf"&gt;&lt;u&gt;每把好钥匙都必须是它打开的锁的模型&lt;/u&gt;&lt;/a&gt;，约翰温特沃斯&lt;a href="https://www.lesswrong.com/posts/Dx9LoqsEh3gHNJMDk/fixing-the-good-regulator-theorem"&gt;&lt;u&gt;完善了该定理&lt;/u&gt;&lt;/a&gt;（及其证明），阐明：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;i&gt;[Conant 和 Ashby 实际上证明] 每个最优且不包含不必要噪声的调节器都&lt;/i&gt;相当于&lt;i&gt;一个调节器，它首先重建其控制的系统的变量值，然后根据这些值选择其输出&lt;/i&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;因此，我们能否通过阻止人工智能对其外部环境进行建模来限制它？我们能否阻止人工智能成为我们将其放入的笼子的“好钥匙”？让我们看看这种人工智能的潜在信息来源：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;模型的初始条件（例如训练数据和学习模式）&lt;/li&gt;&lt;li&gt;感官输入（例如通过摄像头和麦克风）&lt;/li&gt;&lt;li&gt;逻辑演绎和外推&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们假设我们试图限制的人工智能在逻辑上是无所不知的；它可以从理论上尽可能多地从初始条件和感官输入中获取信息。这就留下了两个作为输入框目标的信息源：初始条件和感官输入。&lt;/p&gt;&lt;p&gt;在实践中，限制这些信息来源是很棘手的。例如，我们可以尝试只为人工智能提供一个传感器，即一些低分辨率相机来接收指令。然而，相机接收到的图像可能会受到附近声音的振动、环境磁场、背景辐射等的微妙影响。如果解释正确，这些干扰源就会成为信息源。&lt;/p&gt;&lt;p&gt;但是，假设我们可以克服这些&lt;i&gt;实际&lt;/i&gt;障碍，我们可以量化我们可以从输入框中获得多少控制权吗？为了回答这个问题，我们来看看控制理论。&lt;/p&gt;&lt;h1&gt;位、盒子和控制&lt;/h1&gt;&lt;p&gt;首先，一些术语。与调节器一样，&lt;i&gt;控制环路&lt;/i&gt;使用传感器、函数和一些执行器来控制变量的行为。&lt;i&gt;控制系统&lt;/i&gt;使用多个控制循环来管理系统的行为。当控制环不根据有关其操作结果的反馈采取行动时，控制环就是&lt;i&gt;开环的&lt;/i&gt;，就像定时器上的加热器一样。&lt;i&gt;闭环&lt;/i&gt;控制器包含反馈，例如巡航控制或恒温器。最后，这里的&lt;i&gt;熵&lt;/i&gt;指的是&lt;a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)"&gt;&lt;u&gt;香农熵&lt;/u&gt;&lt;/a&gt;，它衡量变量的不确定性。 Touchette 和 Lloyd 在&lt;a href="https://arxiv.org/pdf/chao-dyn/9905039.pdf"&gt;&lt;u&gt;信息理论&lt;/u&gt;&lt;/a&gt;控制极限中研究了控制系统的极限，并写道：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;i&gt;熵通过表征明确编码描述系统的整体所需的最小资源量（位），提供了对无序性或丢失信息的精确测量&lt;/i&gt;。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;他们总结了他们的主要结果，写道：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;i&gt;在控制过程中，必须不断获取、处理和使用信息来约束或维持系统的轨迹。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;热力学第二定律...对开环控制所需的最小耗散量设置了绝对限制...闭环控制的信息论分析表明反馈控制本质上是一个零和游戏：&lt;strong&gt;直接从控制装置控制的动态系统除了在没有此类信息（开环控制）的情况下可实现的熵减少之外，还可以将该系统的熵最多减少一位&lt;/strong&gt;。&lt;/i&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;换句话说，当将信息作为热力学系统的一部分时，热力学第二定律告诉我们，你无法完美地控制系统。当控制循环根据从其控制的系统获取的信息调整其操作时，存在一个基本的权衡：&lt;strong&gt;对于从系统收集的每一位信息，您只能将系统的无序度减少一位。你可能没有这些信息&lt;/strong&gt;。通过信息可以提高控制程度有严格的一对一限制。&lt;/p&gt;&lt;p&gt;为了形式化这一点，让 t 表示时间，并让&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;I&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;表示在时间&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;t&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;时盒装智能体可用的信息量。 &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;I&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的变化由输入信息的时间导数（标记为&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ）减去输出或“使用”信息的时间导数（标记为&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;o&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ）给出： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6FAMJL89DKmSeYTha/nbpozftdirivgc3bzeii" /&gt;&lt;/figure&gt;&lt;p&gt;因此&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;时刻的可用信息为&lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6FAMJL89DKmSeYTha/h8nhh8x2beyig8jbrljg" /&gt;&lt;/figure&gt;&lt;p&gt;其中C表示模型初始条件中包含的信息。我们可以在连续的时间步上可视化这一点（简化版本），因为信息被收集然后用完： &lt;/p&gt;&lt;figure class="image image_resized" style="width: 52.04%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6FAMJL89DKmSeYTha/q25vhab6anqlhmaabqka" /&gt;&lt;/figure&gt;&lt;p&gt;这看起来很有希望。如果我们限制人工智能在其环境中用于行动的信息方面可以收集的信息，那么它将没有足够的信息来有效地采取行动。或者，用上面论文的语言来说，代理将没有足够的关于其外部动力系统的信息来充分减少该动力系统的熵。&lt;/p&gt;&lt;p&gt;我们可以更正式地定义输入框如下：假设我们有一个代理&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，它在时间&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;具有&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;I&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;信息量。 &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;要实现某个外部动作&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;X&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，需要一定的外部环境信息&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;I&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;X&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，当&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;I&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;小于&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;I&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;X&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;时，可以说&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;无法实现&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;X。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;如果我们将&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;X&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;设置为某种最小的逃逸场景，那么我们可以说当&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;I&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;&amp;lt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;I&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;X&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;时&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是输入框的。这不依赖于代理的任何能力或智力，只依赖于它的&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;I&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，我们假设我们可以限制它，以及&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;I&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;X&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，它仅取决于外部环境。&lt;/p&gt;&lt;p&gt;约翰·温特沃斯（John Wentworth）是我们之前使用过的&lt;a href="https://www.lesswrong.com/posts/Dx9LoqsEh3gHNJMDk/fixing-the-good-regulator-theorem"&gt;&lt;u&gt;《修复良好调节器定理》一书&lt;/u&gt;&lt;/a&gt;的作者，他考虑了一个&lt;a href="https://www.lesswrong.com/posts/6rZroG3mztowktJzp/how-many-bits-of-optimization-can-one-bit-of-observation"&gt;&lt;u&gt;关于控制极限的类似问题&lt;/u&gt;&lt;/a&gt;。他推测观察额外的 N 位信息允许系统执行最多 N 位的额外优化。他得出的结论是，这个猜想是&lt;a href="https://www.lesswrong.com/posts/6rZroG3mztowktJzp/how-many-bits-of-optimization-can-one-bit-of-observation?commentId=Pvhpc7PF8DhsyMGgk"&gt;&lt;u&gt;错误的&lt;/u&gt;&lt;/a&gt;，并引用了一个反例，即短密码解锁长消息，并得出结论：“&lt;i&gt;少量的观察可以极大地提高系统的优化能力”&lt;/i&gt; 。其他人&lt;a href="https://www.lesswrong.com/posts/dfTm26pvq7yQp8mR3/one-bit-of-observation-can-unlock-many-of-optimization-but"&gt;&lt;u&gt;也同意&lt;/u&gt;&lt;/a&gt;这一观点，他们认为，在一些实际限制下，“&lt;i&gt;即使在可逆计算的世界中，一个人可以从单个比特中挤出多少优化也是没有限制的”&lt;/i&gt; 。&lt;/p&gt;&lt;p&gt;然而，这些反例依赖于智能体随后“跟进”他们所学知识的能力。 “密码”中的信息仅在提供收集或解锁更多信息的机会时才有用。密码或任何信息的即时效用受到密码本身的信息和先验知识的总和的限制，并且假设我们也限制代理对后续信息的访问。因此，这些反例不应免除输入框人工智能的优化限制。如果我们可以限制代理从输入和先验知识中收集的信息，我们就可以限制该代理，无论其智能如何。&lt;/p&gt;&lt;h1&gt;建造更好的盒子&lt;/h1&gt;&lt;p&gt;输入框是一个有前途的研究途径，因为它解决了通过信息基础限制人工智能能力的挑战，而与盒子中的人工智能有多智能无关。&lt;/p&gt;&lt;p&gt;本文只是一个介绍，我们有兴趣探索输入框思想的进一步细化。例如，对我们允许进入盒子&lt;i&gt;的&lt;/i&gt;信息进行更深入的分析可能会让我们对人工智能进行更细粒度的控制（例如在关于环境与法律的信息&lt;a href="https://www.lesswrong.com/posts/6rZroG3mztowktJzp/how-many-bits-of-optimization-can-one-bit-of-observation?commentId=n5b4RvdrSxFsqCFw5#n5b4RvdrSxFsqCFw5"&gt;&lt;u&gt;的讨论&lt;/u&gt;&lt;/a&gt;中），特别是如果我们能够稳健地区分对解决问题有用的信息我们的问题，对于逃避很有用。&lt;/p&gt;&lt;p&gt;也就是说，我们也许能够识别智能体想要追求的危险路径或动作序列，而不是从根本上限制智能体的&lt;i&gt;整体&lt;/i&gt;控制。也就是说，对于一个代理来说，要实现一个动作，它需要有关其执行器与其最终期望结果之间的控制路径的信息。 &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;必须了解其第一个行动将如何改变其外部环境，以及后续行动将如何改变新的、变化的环境，等等。&lt;/p&gt;&lt;p&gt;如果我们限制智能体对危险控制路径的危险信息的访问，我们就可以放松对信息输入的基本限制，而不允许危险行为。这可能比从根本上限制所有信息更为务实，因为危险信息可能是所有信息的一小部分——位必须与危险行为相关才能成为危险位。然而，这将以牺牲这些基本限制提供的保证为代价。&lt;/p&gt;&lt;p&gt; Deric Cheng 提出，开发输入框的另一个有希望的途径是对信息的使用施加根本性的延迟。信息的效用会随着时间的推移而衰减，因此如果人工智能只能对 24 小时前的信息采取行动，那么它的作用就会弱得多，尤其是对于利用股市等高速行动而言。&lt;/p&gt;&lt;p&gt;除了超级智能的装箱技术之外，输入装箱可能对更多的利基应用有用。例如，通过在&lt;a href="https://www.lesswrong.com/tag/ai-evaluations"&gt;&lt;u&gt;评估&lt;/u&gt;&lt;/a&gt;过程中输入装箱人工智能模型，我们可以在保证任何危险行为不会漏出盒子的情况下测试模型，这意味着评估人员可以主动提示危险行为并使用&lt;a href="https://en.wikipedia.org/wiki/Red_team"&gt;&lt;u&gt;红队&lt;/u&gt;&lt;/a&gt;技术，而不会影响&lt;a href="https://www.lesswrong.com/posts/XCRsg2ZnHBNAN862T/improving-the-safety-of-ai-evals"&gt;&lt;u&gt;系统的安全性。评估&lt;/u&gt;&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;随着信息论、控制论和热力学的进一步完善和见解，输入框可以成为一个强大的工具，既适合利基应用，也可以用一个整洁的小蝴蝶结将超级智能包裹在一个安全、有用的盒子里。&lt;/p&gt;&lt;p&gt;这篇文章最初的灵感来自 Hugo Touchette 和 Seth Lloyd 的&lt;a href="https://arxiv.org/pdf/chao-dyn/9905039.pdf"&gt;&lt;u&gt;信息理论控制极限&lt;/u&gt;&lt;/a&gt;论文。有关控制理论、良好调节器定理和其他类似主题的更多信息，请查看：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;a href="https://www.lesswrong.com/posts/fJKbCXrCPwAR5wjL8/what-is-control-theory-and-why-do-you-need-to-know-about-it"&gt;&lt;u&gt;什么是控制理论，为什么您需要了解它？&lt;/u&gt;&lt;/a&gt;作者：理查德·肯纳威&lt;/li&gt;&lt;li&gt;Alain Bensoussan&lt;i&gt;等人&lt;/i&gt;的&lt;a href="https://arxiv.org/pdf/2006.05604.pdf"&gt;&lt;u&gt;机器学习和控制理论&lt;/u&gt;&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.lesswrong.com/posts/Dx9LoqsEh3gHNJMDk/fixing-the-good-regulator-theorem"&gt;&lt;u&gt;修复良好调节器定理&lt;/u&gt;&lt;/a&gt;作者：johnswentworth&lt;/li&gt;&lt;li&gt;约翰·贝兹 (John Baez) 的&lt;a href="https://johncarlosbaez.wordpress.com/2016/01/27/the-good-regulator-theorem/"&gt;&lt;u&gt;《内部模型原理》&lt;/u&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;丹尼尔·L·肖尔滕 (Daniel L. Sholten) 的&lt;a href="http://cadia.ru.is/wiki/_media/public:t-720-atai:a_primer_for_conant_and_ashby_s_good-regulator_theorem.pdf"&gt;&lt;u&gt;《Conant 和 Ashby 的“良好调节器定理”入门》&lt;/u&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;哈里什笔记本中 &lt;a href="https://harishsnotebook.wordpress.com/2020/08/23/notes-on-the-good-regulator-theorem/"&gt;&lt;u&gt;关于良好调节器定理的注释&lt;/u&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.lesswrong.com/posts/6rZroG3mztowktJzp/how-many-bits-of-optimization-can-one-bit-of-observation"&gt;&lt;u&gt;一点观察可以解锁多少位优化？&lt;/u&gt;&lt;/a&gt;通过约翰斯温特沃斯&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.lesswrong.com/posts/dfTm26pvq7yQp8mR3/one-bit-of-observation-can-unlock-many-of-optimization-but"&gt;&lt;u&gt;一点点观察就可以实现许多优化——但代价是什么？&lt;/u&gt;&lt;/a&gt;作者：dr_s。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://arxiv.org/abs/2309.01933"&gt;&lt;u&gt;可证明安全的系统：实现可控 AGI 的唯一途径&lt;/u&gt;&lt;/a&gt;Max Tegmark 和 Steve Omohundro&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;i&gt;本文基于 Elliot Mckernon 撰写的 Justin Shovelain 的&lt;/i&gt;&lt;a href="https://www.convergenceanalysis.org/"&gt;&lt;i&gt;&lt;u&gt;收敛分析&lt;/u&gt;&lt;/i&gt;&lt;/a&gt;思想&lt;i&gt;。我们要感谢我们所引用的帖子的作者，以及 Cesare Ardito、David Kristoffersson、Richard Annilo 和 Deric Cheng 在撰写过程中提供的反馈。&lt;/i&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/NZP6QvkXryJQFGkLF/information-theoretic-boxing-of-superintelligences-1#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 30 Nov 2023 14:31:11 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/NZP6QvkXryJQFGkLF/information-theoretic-boxing-of-superintelligences-1</guid></item><item><title>OpenAI：奥特曼归来</title><link>https://www.lesswrong.com/posts/EfqAdxR7bvwQLMTQc/openai-altman-returns</link><description>发布于 2023 年 11 月 30 日下午 2:10（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;截至今天早上， &lt;a href="https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board" rel="noreferrer noopener" target="_blank"&gt;新董事会已经就位，OpenAI 的其他一切也正式恢复到以前的状态&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;事件似乎按预期进行。如果您阅读过我&lt;a href="https://thezvi.substack.com/p/openai-the-battle-of-the-board" rel="noreferrer noopener" target="_blank"&gt;之前关于 OpenAI 情况的两篇文章&lt;/a&gt;，那么这里应该不会让您感到惊讶。&lt;/p&gt;&lt;span id="more-23613"&gt;&lt;/span&gt;&lt;p&gt;似乎仍然值得将后记、官方声明和反应收集到自己的帖子中，以便将来参考。&lt;/p&gt;&lt;p&gt;最终的结果会是什么？随着时间的推移，当我们等待调查以及新董事会的组成和行为时，我们可能只会逐渐发现这一点。&lt;/p&gt;&lt;p&gt;我不相信 Q* 在赛事中发挥了实质性作用，因此这里不包括它。我也不在这里讨论奥特曼在安全方面的表现有多好或多坏。&lt;/p&gt;&lt;h4&gt;萨姆·奥尔特曼的声明&lt;/h4&gt;&lt;p&gt;&lt;a href="https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board" rel="noreferrer noopener" target="_blank"&gt;以下是 Sam Altman 的 OpenAI 官方声明&lt;/a&gt;。他对所有人都很宽容，无论事实如何，这都是优雅而明智的举动。正如他自始至终所做的那样，他让其他人散布敌意，影响新闻报道并塑造公众反应，而他自己几乎完全提供积极和赞扬。聪明的。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;在开始接下来的内容之前，我想先表达一些谢意。&lt;/p&gt;&lt;p&gt;我爱并尊重伊利亚，我认为他是这个领域的指路明灯，也是人类的瑰宝。我对他的恶意为零。虽然 Ilya 将不再担任董事会成员，但我们希望继续我们的工作关系，并正在讨论他如何继续在 OpenAI 的工作。&lt;/p&gt;&lt;p&gt;我感谢 Adam、Tasha 和 Helen 与我们合作，找到了最能服务于使命的解决方案。我很高兴继续与 Adam 合作，并衷心感谢 Helen 和 Tasha 在此过程中投入了大量的精力。&lt;/p&gt;&lt;p&gt;还要感谢埃米特，他在帮助我们实现这一成果方面发挥了关键和建设性的作用。 Emmett 对人工智能安全和平衡利益相关者利益的奉献是显而易见的。&lt;/p&gt;&lt;p&gt;米拉在整个过程中表现出色，自始至终无私地为使命、团队和公司服务。她是一位令人难以置信的领导者，如果没有她，OpenAI 就不会成为 OpenAI。谢谢。&lt;/p&gt;&lt;p&gt;格雷格和我是经营这家公司的合伙人。我们从未完全弄清楚如何在组织结构图上传达这一点，但我们会的。与此同时，我只是想澄清一下。感谢你们从一开始以来所做的一切，以及从这件事开始到上周你们处理事情的方式。&lt;/p&gt;&lt;p&gt;领导团队——Mira、Brad、Jason、Che、Hannah、Diane、Anna、Bob、Srinivas、Matt、Lilian、Miles、Jan、Wojciech、John、Jonathan、Pat 等——显然已准备好在没有任何情况下运营公司。我。他们说，评估首席执行官的一种方法是看你如何挑选和培训你的潜在继任者；在这个指标上，我做得比我想象的要好得多。我很清楚，公司掌握在伟大的人手中，我希望每个人都清楚这一点。谢谢你们。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;让我们理解最后一段。前格雷格领导团队显然已经准备好在没有奥特曼的情况下管理公司。&lt;/p&gt;&lt;p&gt;这意味着无论是什么原因导致董事会解雇 Altman，无论 Altman 是否在不同程度上迫使董事会采取行动，如果所有相关人员都选择在没有 Altman 的情况下继续工作，那么 OpenAI 就会没事。我们可以选择相信或不相信奥特曼在接受 Verge 采访时声称，他只是在周六董事会给他打电话后才考虑回归，而且我们可以推测奥特曼在那段时间在幕后做了什么。我们不知道。我们当然可以猜测，但我们不知道。&lt;/p&gt;&lt;p&gt;然后他谈到了他的优先事项。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;下一个是什么？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们有三个当务之急。&lt;/p&gt;&lt;p&gt;推进我们的研究计划并进一步投资于我们的全栈安全工作，这对我们的工作一直至关重要。我们的研究路线图很明确；这是一个非常专注的时刻。我和你们一样感到兴奋；我们将化危机为机遇！我会和米拉一起解决这个问题。&lt;/p&gt;&lt;p&gt;持续改进和部署我们的产品并服务我们的客户。重要的是，人们要体验人工智能的好处和前景，并有机会塑造它。我们始终相信，优秀的产品是实现这一目标的最佳方式。我将与 Brad、Jason 和 Anna 合作，确保我们对世界各地的用户、客户、合作伙伴和政府的坚定承诺是明确的。&lt;/p&gt;&lt;p&gt;布雷特、拉里和亚当将非常努力地完成一项极其重要的任务，即建立一个具有不同观点的董事会、改善我们的治理结构以及监督对最近事件的独立审查。我期待在这些关键步骤上与他们密切合作，以便每个人都能对 OpenAI 的稳定性充满信心。&lt;/p&gt;&lt;p&gt;我非常期待与你们一起完成构建有益的 AGI 的工作——世界上最好的团队，世界上最好的使命。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;研究，然后产品，然后董事会。这样的陈述不能被信赖，但是这样的陈述已经是最好的了。我们必须密切关注，看看这些承诺是否兑现。新董事会会是什么样子？是否真的会对所发生的事情进行强有力的独立调查？ Ilya 和 Jan Leike 是否会获得 OpenAI 安全工作所需的资源和支持？&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.theverge.com/2023/11/29/23982046/sam-altman-interview-openai-ceo-rehired" rel="noreferrer noopener" target="_blank"&gt;奥特曼接受了 The Verge 的采访&lt;/a&gt;。和董事会一样，他（我相信他是明智而光荣的）回避了所有有关导致与董事会争执的原因的问题，并期待着调查。据奥特曼说，回来并不是他的主意，相反，他在周六早上接到了一些董事会的电话，询问他是否有可能回来。&lt;/p&gt;&lt;p&gt;他表示，他并不专注于重返董事会，这不是他的重点，但治理结构显然存在问题，需要一段时间才能解决。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;问： &lt;a href="https://www.theverge.com/2023/11/29/23981848/sam-altman-back-open-ai-ceo-microsoft-board" rel="noreferrer noopener" target="_blank"&gt;&lt;strong&gt;“完善治理结构”&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;是什么&lt;/strong&gt;&lt;strong&gt;意思？非营利控股公司的结构会发生变化吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt; Altman：对于董事会成员来说，这是一个更好的问题，但现在还不是。诚实的答案是他们需要时间，我们将支持他们真正开始思考这个问题。显然我们的治理结构有问题。解决这个问题的最好方法是需要一段时间。我完全理解为什么人们现在就想要答案。但我也认为这种期望是完全不合理的。&lt;/p&gt;&lt;p&gt; ……&lt;/p&gt;&lt;p&gt;哦，仅仅因为设计一个非常好的治理结构，特别是对于如此有影响力的技术来说，不是一个一周的问题。人们需要花费大量的时间来思考这个问题、进行辩论、获取外部观点、进行压力测试。那只需要一段时间。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;是的。很高兴看到这种高度合理的时间表和期望设定，而不是之前涉及人为最后期限和危机的策略。&lt;/p&gt;&lt;p&gt; Mutari 在采访中证实，OpenAI 的安全方法没有改变，这与安全无关。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/sama/status/1730032994474475554" rel="noreferrer noopener" target="_blank"&gt;Altman 还就 Adam D&amp;#39;Angelo 的潜在利益冲突做出了很好的声明&lt;/a&gt;，表示他积极希望在董事会中拥有客户代表，并很高兴再次与他合作。 &lt;a href="https://twitter.com/sama/status/1727858661677240767" rel="noreferrer noopener" target="_blank"&gt;奥特曼还和德安吉洛待了几个小时。&lt;/a&gt;&lt;/p&gt;&lt;h4&gt;布雷特·泰勒的声明&lt;/h4&gt;&lt;p&gt;我们还有布雷特·泰勒的声明。我们对他知之甚少，因此仔细阅读他的第一份官方声明似乎是明智之举。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;我谨代表 OpenAI 董事会向整个 OpenAI 社区，特别是所有 OpenAI 员工表示感谢，他们在过去的一周里齐心协力，为公司找到了前进的道路。你们的努力帮助这个令人难以置信的组织继续履行其使命，确保通用人工智能造福全人类。我们很高兴 Sam、Mira 和 Greg 重新齐心协力领导公司并推动公司向前发展。我们期待与他们和你们所有人合作。&lt;/p&gt;&lt;p&gt;作为董事会，我们致力于加强 OpenAI 的公司治理。我们计划这样做：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们将建立一个由杰出人士组成的合格、多元化的董事会，他们的集体经验代表了 OpenAI 使命的广度——从技术到安全到政策。我们很高兴董事会将包括一名无投票权的 Microsoft 观察员。&lt;/li&gt;&lt;li&gt;我们将进一步稳定 OpenAI 组织，以便我们能够继续履行我们的使命。这将包括召集董事会独立委员会来监督对近期事件的审查。&lt;/li&gt;&lt;li&gt;我们将加强 OpenAI 的治理结构，让所有利益相关者——用户、客户、员工、合作伙伴和社区成员——都能相信 OpenAI 将继续蓬勃发展。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt; OpenAI 是一个比以往任何时候都更加重要的机构。 ChatGPT 让人工智能成为数亿人日常生活的一部分。它的普及使得人工智能——它的好处和风险——成为几乎所有有关政府、企业和社会未来的对话的核心。&lt;/p&gt;&lt;p&gt;我们了解这些讨论的重要性以及 OpenAI 在这些令人惊叹的新技术的开发和安全中的核心作用。在确保我们有效应对这些挑战方面，你们每个人都发挥着关键作用。我们致力于倾听你们的声音并向你们学习，我希望很快能与你们所有人交谈。&lt;/p&gt;&lt;p&gt;我们很高兴成为 OpenAI 的一部分，并很高兴与大家合作。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;大多数情况下，布拉德·泰勒正确地扮演了董事会主席的角色，这告诉我们除了他非常了解这个角色之外，我们已经知道了这一点。&lt;/p&gt;&lt;p&gt;微软只会在董事会中获得一名观察员，其他投资者可能也不会获得席位。这是个好消息， &lt;a href="https://www.theinformation.com/articles/openai-isnt-expected-to-offer-microsoft-other-investors-a-board-seat" rel="noreferrer noopener" target="_blank"&gt;与 The Information 的报道相符&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;这里的“加强治理结构”是什么意思？我们不知道。它可能正是我们所需要的，它可能是橡皮图章，也可能是其他任何东西。我们不知道最终的结果是什么。&lt;/p&gt;&lt;p&gt;关于最近发生的事件的回顾的声明比我希望的要弱。这增加了新董事会没有得到或分享真实解释的可能性。&lt;/p&gt;&lt;p&gt;他多次提到安全。根据我对泰勒的了解，我的猜测是他不熟悉这些问题，并且实际上不知道这在上下文中意味着什么，或者真正的利害关系是什么。并不是他不屑一顾或怀疑，而是他第一次遇到这一切。&lt;/p&gt;&lt;h4&gt;拉里·萨默斯的声明&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/LHSummers/status/1730047296375590995" rel="noreferrer noopener" target="_blank"&gt;以下是董事会成员拉里·萨默斯 (Larry Summers) 通过 Twitter 发布的公告&lt;/a&gt;，该公告提高了零内容的门槛。所以我们对这里知之甚少。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;拉里·萨默斯：我很高兴也很荣幸刚刚被任命为&lt;a href="https://twitter.com/OpenAI" rel="noreferrer noopener" target="_blank"&gt;​​ @OpenAI&lt;/a&gt;的独立董事。我期待与董事会同事和 OpenAI 团队合作，推进 OpenAI 极其重要的使命。&lt;/p&gt;&lt;p&gt;正如 Bret 和 Sam 在他们的信息中概述的，第一步包括建立一个出色的董事会、加强治理程序以及支持卓越的 OpenAI 社区。&lt;/p&gt;&lt;/blockquote&gt;&lt;h4&gt;海伦·托纳的声明&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/hlntnr/status/1730034020140912901" rel="noreferrer noopener" target="_blank"&gt;以下是海伦·托纳 (Helen Toner) 辞去董事会职务后在 Twitter 上发表的完整声明&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Helen Toner (11/29)：今天，我正式辞去 OpenAI 董事会职务。感谢许多朋友、同事和支持者，他们公开和私下表示，他们知道我们的决定始终是由我们对 OpenAI 使命的承诺驱动的。&lt;/p&gt;&lt;p&gt;关于过去一两周的文章已经写了很多；肯定还会说更多。目前，即将上任的董事会已宣布将进行全面的独立审查，以确定下一步的最佳措施。&lt;/p&gt;&lt;p&gt;需要明确的是：我们的决定是关于董事会有效监督公司的能力，这是我们的角色和责任。尽管有猜测，但我们的动机并不是要放慢 OpenAI 的工作速度。&lt;/p&gt;&lt;p&gt;当我在 2021 年加入 OpenAI 董事会时，我和我周围的许多人已经清楚，这是一个将做大事的特殊组织。能够成为该组织的一员是一种巨大的荣幸，因为世界其他地方也意识到了同样的事情。&lt;/p&gt;&lt;p&gt;我非常尊重 OpenAI 团队，并祝愿他们以及即将上任的 Adam、Bret 和 Larry 董事会一切顺利。我将继续专注于人工智能政策、安全和保障方面的工作，所以我知道我们的道路在未来几年将会多次交叉。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;许多愤怒的人继续要求澄清董事会解雇奥特曼的原因。我相信，他们中的大多数人都对托纳和其他人继续不分享细节感到兴奋，并允许董事会外的情况恢复到原来的状态。&lt;/p&gt;&lt;p&gt;据称将会进行独立调查。到那时， &lt;a href="https://thezvi.substack.com/p/openai-the-battle-of-the-board" rel="noreferrer noopener" target="_blank"&gt;我相信我们对发生的事情有了一个比较清晰的了解&lt;/a&gt;。托纳的声明暗示了一些额外的细节。&lt;/p&gt;&lt;h4&gt; OpenAI 需要一个强大的董事会来解雇其首席执行官&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/tszzl/status/1727498453864026603" rel="noreferrer noopener" target="_blank"&gt;罗恩明白了&lt;/a&gt;。董事会需要保持其红色大按钮继续前进，但如果希望该按钮保持不变，仍然必须对其行为负责。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Roon：董事会有一个红色按钮，但也必须解释为什么其决策有益于人类。如果做不到这一点，那么它将面临员工、客户和合作伙伴的反抗。 OpenAI 目前为人类创造了巨大的价值，默认情况下应该受到全力保护。即使有一点点尊重或给出充分的理由，营利性组织也不可能一致转移到其他地方。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;危险在于， &lt;a href="https://twitter.com/robbensinger/status/1727786741019582855" rel="noreferrer noopener" target="_blank"&gt;如果我们不小心，我们就会吸取错误的教训。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;托比·奥德：过去几天打破了萨姆·奥尔特曼令人难以置信的权力面临任何责任的神话。他告诉我们不应该相信他，但我们现在知道董事会“不能”解雇他。我认为这很重要。&lt;/p&gt;&lt;p&gt;罗布·本辛格：我们没有了解到“他们不能解雇他”。我们确实了解到，该组织的员工对 Sam 有足够的信心，如果没有董事会提供一些良好的支持论据，员工不会同意董事会的愿望。 （他们是否会接受好的论点尚未得到检验。）&lt;/p&gt;&lt;p&gt; ……&lt;/p&gt;&lt;p&gt;我只是想让我们明确一点，关于董事会当前权力的更新不应该是一个巨大的更新，因为如果董事会能够更好地解释其理由并且理由似乎如此，那么工作人员可能会接受董事会在这种情况下的决定更强。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这么。从我们的角度来看，董事会执行得很糟糕，其成员也提出了相对容易的言辞目标。即使董事会有充分的理由这样做，情况也是如此。如果董事会没有在执行过程中搞砸，并且有更多的庄严呢？我认为事情会有所不同。&lt;/p&gt;&lt;p&gt;如果经过调查，萨默斯、德安吉洛和泰勒都决定再次解雇奥特曼（请注意，我非常不希望这样做，但如果他们确实决定这样做），我向你保证，他们会以非常不同的方式处理这件事，并且我会预测一个非常不同的结果。&lt;/p&gt;&lt;p&gt;萨姆·奥尔特曼最好的事情之一就是他坦率地告诉&lt;a href="https://www.youtube.com/watch?v=dY1VK8oHj5s" rel="noreferrer noopener" target="_blank"&gt;我们不应该相信他&lt;/a&gt;。大多数不值得信任的人都会说另外的话。与奥特曼关于存在风险和安全需求的经常非常好的陈述一样。当人们思路清晰并提供帮助时，我们应该努力奖励他们，而不是反对他们。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/AndrewCritchPhD/status/1730064832152654189" rel="noreferrer noopener" target="_blank"&gt;我也同意安德鲁·克里奇的观点&lt;/a&gt;，即董事会终止错误的监督信号是好事也是正确的。如果首席执行官使董事会无法监督他们，或者以其他方式反对董事会，那么董事会就有责任将事情推向高潮，即使不存在其他问题。&lt;/p&gt;&lt;p&gt;良好的背景，可能对包括 Helen Toner 在内的几位董事会成员的想法产生影响：前 OpenAI 董事会成员 Holden Karnofsky 对&lt;a href="https://www.cold-takes.com/nonprofit-boards-are-weird-2/#the-boards-main-duties" rel="noreferrer noopener" target="_blank"&gt;非营利组织董事会为何、到底如何奇怪&lt;/a&gt;以及如何最好地处理它的旧解释。&lt;/p&gt;&lt;h4&gt;部分董事会成员候选人&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/ESYudkowsky/status/1729200181349126232" rel="noreferrer noopener" target="_blank"&gt;Eliezer Yudkowsky 提名 Paul Graham 担任 OpenAI 董事会成员&lt;/a&gt;。我看到了这种争论，特别是因为格雷厄姆显然非常关心他的孩子。我担心的是，他会太受 Altman 的引导，而且他会太倾向于将 OpenAI 本质上视为传统业务，并让这一点推翻其他问题，即使他知道不应该这样做。&lt;/p&gt;&lt;p&gt;如果他被算作奥特曼的盟友（他大概应该如此），那么他就很棒了。除了给 OpenAI 带来好处之外，它还可以为 Graham 提供有价值的内幕信息。埃利以泽澄清说，他的动机是让格雷厄姆有一个很好的机会在重要的时候弄清楚真实的事情，这听起来也很正确。&lt;/p&gt;&lt;p&gt;埃米特·希尔似乎也是一个明显的共识选择。&lt;/p&gt;&lt;p&gt;一个问题是电路板的光学器件很重要。如果你选择九个白人，那是非常不明智的。请参阅泰勒关于需要多元化观点的声明。&lt;/p&gt;&lt;h4&gt;估值问题&lt;/h4&gt;&lt;p&gt;&lt;a href="https://www.bloomberg.com/opinion/articles/2023-11-27/openai-is-still-an-86-billion-nonprofit?sref=1kJVNqnU" rel="noreferrer noopener" target="_blank"&gt;马特·莱文 (Matt Levine) 报道了自周二以来的进展&lt;/a&gt;，特别是 OpenAI 在即将到来的销售中的估值没有变化，因为私人市场可能顽固地拒绝调整其价格。在我的模型中，像这样的私人估值相当任意，并且基于每个参与者可以讲述的社会故事以及每个人的相对谈判地位，以及什么将为公司产生正确的动力，而不是公平的价值估计。此外，每个参与其中的人都投资严重不足或投资过度，不知道公允价值实际上是什么，并且大多希望得到某种形式的社会认可，这样他们就不会觉得价格被欺骗了。因此，投资者常常会以极低的价格逃脱惩罚，有时也会被骗到极高的价格。&lt;/p&gt;&lt;p&gt; &lt;a href="https://garymarcus.substack.com/p/top-5-reasons-why-openai-was-probably" rel="noreferrer noopener" target="_blank"&gt;加里·马库斯 (Gary Marcus) 表示，OpenAI 的价值从未达到 860 亿美元&lt;/a&gt;。我不仅不同意，而且如果我有这种能力（我没有），我会（天哪，这不是投资建议！）很高兴现在投资 860 亿美元，并且认为这是一件道德的事情。 Grok 并没有“复制大部分”GPT-4，相反，考虑到他们最初在该模型上停留的时间，该模型表现得相当好。&lt;/p&gt;&lt;p&gt;没有员工，OpenAI 就一无是处。这并不意味着他们缺乏各种秘密武器。从估值角度来看，我是看涨的。如果没有奥特曼，估值还能维持下去吗？不，但在反事实的情况下，奥特曼因健康问题辞职并有序接班，我肯定会认为 860 亿美元仍然便宜。&lt;/p&gt;&lt;h4&gt;光学问题&lt;/h4&gt;&lt;p&gt;所有这一切的一个关键问题是，董事会的错误在多大程度上在于其光学系统的糟糕。这是&lt;a href="https://twitter.com/paulg/status/1728014952877748297" rel="noreferrer noopener" target="_blank"&gt;保罗·格雷厄姆倡导优秀原则的一个很好的例子&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;保罗·格雷厄姆：当人们以“光学”为由批评某项行动时，他们几乎总是满嘴胡言乱语。他们真正想说的是“你所做的看起来很糟糕。”但如果他们这样表述，他们就必须回答“这真的很糟糕吗？”的问题。&lt;/p&gt;&lt;p&gt;如果有人做了坏事，你就不需要谈论“光学”。如果他们做了一些看起来很糟糕但你知道并非如此的事情，你为什么要批评它呢？相反，你应该解释为什么事情没有看起来那么糟糕。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;不良的光学器件可能会导致不好的事情发生。声称光学器件不好，或者担心别人会认为光学器件不好，或者声称您通常不擅长光学器件也可以。&lt;/p&gt;&lt;p&gt;你有两个回应。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;这意味着它产生了不良后果，这意味着它实际上很糟糕。&lt;/li&gt;&lt;li&gt;勇敢地坚持正确的行动，而不是“看起来不错”。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;根据最近发生的事件考虑各种选择。我们都希望它是一种方式。通常情况是相反的。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.lesswrong.com/posts/EfqAdxR7bvwQLMTQc/openai-altman-returns#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 30 Nov 2023 14:10:08 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/EfqAdxR7bvwQLMTQc/openai-altman-returns</guid></item><item><title>[Linkpost] 无限宽度极限下随机神经网络分布收敛于高斯过程的评述</title><link>https://www.lesswrong.com/posts/nM7qwfbB9dAxBopLT/linkpost-remarks-on-the-convergence-in-distribution-of-1</link><description>发布于 2023 年 11 月 30 日下午 2:01（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;a href="https://drive.google.com/file/d/1O_RbD45RjBWD4-a8tcjosvyXOxcD_q2V/view?usp=sharing"&gt;链接的注释&lt;/a&gt;是我在浏览文献中该结果的不同版本时“注意到”的。我认为这种关于神经网络的数学工作是值得的，并且值得以高标准进行，但我没有理由认为这项特定的工作除了填补文献中的空白之外还有很大的意义。这是学过太多测度论的人会想到的胡言乱语。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;抽象的。&lt;/strong&gt;我们描述了结果的另一个版本的直接证明，即一系列完全连接的神经网络在无限宽度限制下收敛到高斯过程。我们建立的分布收敛是不可分、不可&lt;u&gt;度量的&lt;/u&gt;乘积空间&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-B"&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.619em; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-right: 0.06em;"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-B"&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.467em; padding-left: 0px; padding-right: 0.06em;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;上概率测度的弱收敛，即从&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-B"&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.619em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;到&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-B"&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.619em; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 83.3%; vertical-align: 0.435em; padding-right: 0.06em;"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的函数空间，其拓扑收敛序列对应于&lt;u&gt;逐点&lt;/u&gt;收敛。结果本身已经由&lt;a href="https://arxiv.org/abs/2107.01562"&gt;鲍里斯·哈宁（Boris &lt;u&gt;Hanin）&lt;/u&gt;提出的更强的定理&lt;/a&gt;所暗示，但是我们较弱结果的直接证明可以取代&lt;u&gt;哈宁&lt;/u&gt;证明中更技术性的部分，这些部分需要用更短和更抽象的测度理论来建立紧密性争论。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/nM7qwfbB9dAxBopLT/linkpost-remarks-on-the-convergence-in-distribution-of-1#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 30 Nov 2023 14:01:33 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/nM7qwfbB9dAxBopLT/linkpost-remarks-on-the-convergence-in-distribution-of-1</guid></item><item><title>“什么都不买”日是一个好主意，但应用程序却很糟糕——为什么还没有人为众包“有效共产主义”开发一款杀手级应用程序呢？</title><link>https://www.lesswrong.com/posts/v3EfCmegqjzQTfFTP/buy-nothing-day-is-a-great-idea-with-a-terrible-app-why-has</link><description>发布于 2023 年 11 月 30 日下午 1:47（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;最近，我看到很多人对 TikTok 上的左翼想法感到非常兴奋，同时也对“发达”世界的存在方式感到非常沮丧，我一直有这样的想法：一款应用程序最终会创造出一些东西。一种让普通人进行互助的框架。&lt;/p&gt;&lt;p&gt;基本想法是您可以列出您想要分享的内容。其他人可以列出他们需要的东西。唯一的限制是，官方规定，出于法律原因，不能提供预制食品，也许还有其他我没有预见到的事情。就这样了！一款可与邻居分享您拥有的多余物品的应用程序。&lt;/p&gt;&lt;p&gt;所以，这在我脑海里盘旋了一会儿，然后今天，你知道什么？我发现“不买东西日”（一项围绕“无人买东西的日子”这一理念的运动）有一个这样的应用程序！而且已经存在两年了！但这很糟糕。所有评论都声称，尽管赞扬了这个想法，但发帖等基本功能却被破坏了。&lt;/p&gt;&lt;p&gt;我的问题最终是这样的：为什么还没有这样的版本？难道经济条件还不够糟糕，人们还愿意帮助和依赖邻居吗？&lt;/p&gt;&lt;p&gt;尽管 craigslist 已经成为一个充斥着过于昂贵的垃圾和欺骗性地列出“1 美元”广告的企业的污水池，但它是否为企业铺平了道路，这些广告要求你开车 8 英里才能取货，而有人在他们的车道上用怀疑的眼神看着你，等待 venmo经过？&lt;/p&gt;&lt;p&gt;这个想法是否不可持续或者在某些方面是我所缺少的？对我来说，这似乎是理所当然的事情，而且只是一种公共利益。人们可能会指出一些理论上的陌生人危险，但这看起来就像万圣节糖果中的剃刀刀片式的恐吓。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/v3EfCmegqjzQTfFTP/buy-nothing-day-is-a-great-idea-with-a-terrible-app-why-has#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Thu, 30 Nov 2023 13:47:38 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/v3EfCmegqjzQTfFTP/buy-nothing-day-is-a-great-idea-with-a-terrible-app-why-has</guid></item></channel></rss>