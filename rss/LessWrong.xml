<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>少错</title><link>https://www.lesswrong.com</link><description>致力于提炼理性艺术的社区博客</description><lastBuildDate>Sun, 24 Dec 2023 18:12:50 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>调整你的潜在空间</title><link>https://www.lesswrong.com/posts/gByn3zzPJqacKi9Cy/align-your-latent-spaces</link><description>发布于 2023 年 12 月 24 日下午 4:30（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;blockquote&gt;&lt;p&gt;我很早就知道知道某事的名称和知道某事之间的区别。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; — 理查德·费曼&lt;/p&gt;&lt;p&gt;这是一个阅读英语文本并写出英语文本作为回应的人的思维的简化图： &lt;/p&gt;&lt;figure class="image image_resized" style="width: 50.03%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gByn3zzPJqacKi9Cy/qshvvabbbcp3iqxvfqku" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;br /&gt;这是一个英语流利的人开始学习法语并使用带有单词对的抽认卡学习的人的思维简化图： &lt;/p&gt;&lt;figure class="image image_resized" style="width: 50.01%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gByn3zzPJqacKi9Cy/k4q8aptgnydg67aaoy0s" /&gt;&lt;/figure&gt;&lt;p&gt;红色箭头表示抽认卡信息的主要路径。也许您可以明白我不认为抽认卡是学习语言的最佳方法的原因。该方法可以将单词关联加载到向量查找系统中，但需要的是编码器/解码器训练。对于抽认卡来说，最好的情况是在两个编码器的整个链上进行训练，以增加概念潜在空间的相似性，而抽认卡对此效率很低，因为它们提供了少量没有上下文的数据。任何了解神经网络的人都知道，大量的上下文真实数据比重复使用少量的小片段更好。&lt;/p&gt;&lt;p&gt;因此，我认为最好不要使用抽认卡，而是阅读具有相同含义的成对的完整段落，而不是重复。例如，阅读一本书及其翻译。外文阅读时不被理解并不意味着阅读作为一种方法无效。&lt;/p&gt;&lt;p&gt;抽认卡被高估的原因之一是，许多语言测试都是针对“词汇”的，因为单词对之间的关​​联很容易测试。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;对齐你的脊柱。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; -&lt;a href="https://www.youtube.com/watch?v=nPhsvQ6VBTA"&gt;中间的马尔科姆&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;一旦某人能够流利地使用第二语言，他们通常就能够使用两种语言的单词编写和理解句子。这意味着编码器和解码器的集成，这可能是通过蒸馏发生的，如下图所示： &lt;/p&gt;&lt;figure class="image image_resized" style="width: 50.03%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/gByn3zzPJqacKi9Cy/leh5ujixs1bllha8qsck" /&gt;&lt;/figure&gt;&lt;p&gt;考虑到这种情况需要更多的练习才能发生，并且在更流利的人身上也会出现，所以总体来说可能会更好。&lt;/p&gt;&lt;p&gt;在我看来，不同语言的多个系统的集成与多个科学领域的理解的集成基本上是相同的过程。相当于阅读一本书及其翻译，阅读一本从一个领域的角度考虑问题和问题，然后从第二个领域的角度考虑问题的书。然而，这比翻译文学更难获得，因为多学科专家比双语人士少，而且多学科专业知识更难评估，因此更难找到。此外，有能力做到这一点的人可能会编写一个集成了他们对这两个领域的理解的单一版本。这对于学习来说很好，但对于试图通过课程的学生或试图融入某一领域既定文化的人来说可能是不可取的。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.lesswrong.com/posts/gByn3zzPJqacKi9Cy/align-your-latent-spaces#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sun, 24 Dec 2023 16:30:09 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/gByn3zzPJqacKi9Cy/align-your-latent-spaces</guid></item><item><title>病毒式猜谜游戏</title><link>https://www.lesswrong.com/posts/pJB6KDD8DjKJPKkkZ/viral-guessing-game</link><description>发布于 2023 年 12 月 24 日下午 1:10（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt; &lt;span&gt;Julia 向我介绍了&lt;/span&gt;&lt;a href="https://metazooa.com/"&gt;Metazooa&lt;/a&gt; ，一款分类猜谜游戏。你试图弄清楚计算机选择了哪种动物。每次你猜测时，计算机都会显示它们所属的最低分类分支。例如，如果您猜出鸭嘴兽，答案是人类，那么它会告诉您它们都是哺乳动物，因为它们在分类学上没有其他共同点。&lt;/p&gt;&lt;p&gt;我们玩了一会儿，很有趣，然后我想玩一个带有人类感染病毒的版本。他们有一个针对植物的（ &lt;a href="https://flora.metazooa.com/"&gt;Metaflora&lt;/a&gt; ），但没有针对病毒的，所以我自己做了一个： &lt;a href="https://www.jefftk.com/metahomoviria/"&gt;Metahomoviria&lt;/a&gt; 。代码&lt;a href="https://github.com/jeffkaufman/metahomoviria"&gt;在 github 上&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;第一个版本有&lt;a href="https://github.com/jeffkaufman/metahomoviria/blob/main/curated_viruses.txt"&gt;大约 200 种感染人类的​​病毒&lt;/a&gt;，而且不是很有趣，因为您可能没有听说过其中的大多数病毒：&lt;/p&gt;&lt;pre&gt; ...
80941 瓜罗阿病毒
273341 伊莱沙病毒
35514 梯形病毒
11580 雪鞋野兔病毒
11577 拉克罗斯病毒
273352 澳门病毒
348013 马德里病毒
35515 梅劳病毒
...
&lt;/pre&gt;但我已将其减少到&lt;a href="https://github.com/jeffkaufman/metahomoviria/blob/main/highly_curated_viruses.txt"&gt;42 个相当知名的病毒&lt;/a&gt;，现在好多了：&lt;pre&gt; 11234 麻疹
2560602 腮腺炎
11250 呼吸道合胞病毒（RSV）
1570291 埃博拉
11292 狂犬病
1980413 汉坦病毒
11320 甲型流感
...
&lt;/pre&gt;&lt;p&gt;它仍然不是那么有趣——小核病毒目和小核病毒科之间有什么区别，以及小核病毒目是否有共同点，需要&lt;a href="https://en.wikipedia.org/wiki/Picornavirales"&gt;一个缩写词&lt;/a&gt;——但我喜欢它。我确实觉得我对哪些病毒在基因上彼此更接近有了更好的感觉。&lt;/p&gt;&lt;p&gt;如果这听起来很有趣，请&lt;a href="https://www.jefftk.com/metahomoviria/"&gt;在这里&lt;/a&gt;尝试一下。&lt;/p&gt;&lt;p&gt;&lt;i&gt;评论通过： &lt;a href="https://www.facebook.com/jefftk/posts/pfbid02RTb4X45RkjMpnJvWXHcWs32F97GTESyvCo9a2KLQhUk2h1HzMVXTtmj2TaQGdmHJl"&gt;facebook&lt;/a&gt; , &lt;a href="https://mastodon.mit.edu/@jefftk/111635546498921183"&gt;mastodon&lt;/a&gt;&lt;/i&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.lesswrong.com/posts/pJB6KDD8DjKJPKkkZ/viral-guessing-game#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sun, 24 Dec 2023 13:10:14 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/pJB6KDD8DjKJPKkkZ/viral-guessing-game</guid></item><item><title>对拟像关卡的更清晰解释</title><link>https://www.lesswrong.com/posts/KnQpzYRR4ogPNtzem/a-crisper-explanation-of-simulacrum-levels</link><description>发布于 2023 年 12 月 23 日晚上 10:13（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;我读过之前关于&lt;a href="https://www.lesswrong.com/tag/simulacrum-levels"&gt;Simulacrum Levels&lt;/a&gt;的文章，并且我看到人们对它们的工作方式表达了一些困惑。当我第一次遇到这个概念时，我自己也有过一些困惑，我认为它们是由于定义不够&lt;i&gt;清晰&lt;/i&gt;造成的。&lt;/p&gt;&lt;p&gt;现有的解释似乎并没有为拟像级别如何存在提供适当的自下而上/基本面优先的机制。为什么他们有自己特有的特征和怪癖，而不是其他的？为什么赋予它们的形式是它们&lt;i&gt;不可避免的&lt;/i&gt;形式，而不是任意的形式？为什么四级特工只能表现出精神病态？为什么没有5级？&lt;/p&gt;&lt;p&gt;我最终形成了一个关于它们如何工作的看似新颖的模型，现在我意识到它可能对其他人也有用（尽管我几年前就形成了它）。&lt;/p&gt;&lt;p&gt;它的目的是保留&lt;a href="https://www.lesswrong.com/users/zvi?mention=user"&gt;@Zvi&lt;/a&gt; &lt;a href="https://www.lesswrong.com/posts/dHYxnSgMDeveovLuv/the-best-of-don-t-worry-about-the-vase#The_Simulacra_Levels_Sequence"&gt;定义&lt;/a&gt;的所有重要特征，同时通过对它们进行适当的齿轮级机械解释来解释它们。我认为在我划定界限的位置上存在一些细微的差异，但它基本上仍然应该与 Zvi 的一致。&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;基础工作&lt;/h2&gt;&lt;p&gt;在某些情况下，递归级别与递归级别 3 相比实际上变得难以区分。这不完全是一个新想法，但它是我的模型的核心，因此为了完整起见，我将提供一个示例。&lt;/p&gt;&lt;p&gt;考虑认知的情况。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;认知是对外部对象和过程的思考。 “这家餐厅太狭窄了。”&lt;/li&gt;&lt;li&gt;元认知正在构建你自己的思维模型。它可能有什么偏见，如何更好地推理对象级主题。 “我觉得这家餐厅太局促了，因为我不喜欢一大群人。”&lt;/li&gt;&lt;li&gt;元元认知正在分析你的自我模型：你是否倾向于修饰或掩盖你个性的某些部分，等等。“我正在给自己讲一个关于不喜欢一大群人的故事，因为这感觉像是一个更迷人的解释不喜欢这家餐厅胜过真正的餐厅。我不喜欢它是出于相反：这里有很多人因为它很受欢迎，而我本能地不喜欢主流的东西。”&lt;/li&gt;&lt;li&gt;那么，元元认知将是“思考你对以自我为中心的偏见的分析”。但这又是元元认知：分析你倾向于如何看待自己。 “我对自己的看法进行了复杂的思考，因为我想保持一个聪明、有自我意识的人的自我形象。”&lt;ul&gt;&lt;li&gt;有一个类似的情况，元认知与元认知是同一件事，但我认为 2 级和 3 级之间存在细微差别，而 3 级和 4 级以后则不明显。 &lt;span class="footnote-reference" id="fnrefsm2ltnt082r"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnsm2ltnt082r"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;下一篇：基本上，在任何社会中，都存在三个不同的“框架”：物质现实、他人和社会现实。每个后续框架都包含前一个框架的递归模型：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;物理现实&lt;i&gt;是&lt;/i&gt;。&lt;/li&gt;&lt;li&gt;人们有自己的现实模型。&lt;/li&gt;&lt;li&gt;人们的社会形象是其他人对一个人的模型：即现实模型的模型。 &lt;span class="footnote-reference" id="fnrefmsdn2x9q13l"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnmsdn2x9q13l"&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;递归级别1、2和3。这里没有有意义的“级别4”：“一个人的社会形象的模型”意味着“一个人的外表的感知”，这仍然只是“一个人的外表”。您可以在这里提出一些警告，但它不会改变太多&lt;span class="footnote-reference" id="fnreffofs4yy521u"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnfofs4yy521u"&gt;[3]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;因此，任何信号都可以在这些框架中查看，从而产生任何信号可以传达的三种含义：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;它的字面意思是：在物理现实的背景下看待。&lt;/li&gt;&lt;li&gt;你认为演讲者试图让你相信什么，以及为什么：在你的演讲者模型的背景下观察。&lt;/li&gt;&lt;li&gt;它如何影响你和说话者的社交形象：在你和别人对你和说话者的模型的背景下进行观察。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;到目前为止，这很好：所有这些沟通层次都是有用的，并且在任何正常运转的社会中都占有一席之地。&lt;/p&gt;&lt;p&gt;当社会开始&lt;i&gt;放弃&lt;/i&gt;较低层次的沟通时，问题就开始了。这就是转移到更高的拟像级别的含义：放弃较低的级别，转而选择较高的级别。一个“纯粹”的一级社会只关心陈述的字面真实性； 2级社会关心言论背后的人；第三级社会关心言论如何影响人们对其他人的&lt;i&gt;看法&lt;/i&gt;。级别 0 和级别 4 比较特殊：级别 0 没有通信的概念，级别 4 已经深入到递归以至于放弃了它。&lt;/p&gt;&lt;p&gt;我将使用术语“社会”和“代理”，因为这就是我对这个模型的看法，但我的意思是广义上的。 “代理人”可以是从个人到国家的任何事物，“社会”可以是嵌入在任何背景（包括更广泛的社会）中的任何群体。&lt;/p&gt;&lt;p&gt;此外，我应该注意到，同一个代理人可能会占据不同的拟像级别，具体取决于他们所处的环境或与他们在一起的人（一个人可能对他们的家人非常友善和人性化，但可能是一个像精神病患者一样的级别） 4 当涉及到任何与政治无关的事情时）。&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt; 0级&lt;/h2&gt;&lt;p&gt;理解它对于理解 4 级至关重要。&lt;/p&gt;&lt;p&gt;对于 0 级代理来说，没有符号、没有模型、没有交流，只有旨在直接给物理世界带来变化的行动。由于它涉及与其他代理的交互，因此它是一种纯粹的冲突。&lt;/p&gt;&lt;p&gt;你看到狮子，你就逃跑。你看到食物，你就拿走它。你遇到敌人，你杀死他们。你的行为是非象征性的：它们不代表任何东西，也不期望它们会被别人看到和理解。它们的目的是其形式&lt;i&gt;所固有的&lt;/i&gt;。&lt;/p&gt;&lt;p&gt;当你试图削尖一块岩石并将其放在矛上时，你并不是在试图&lt;i&gt;说服&lt;/i&gt;岩石改变其形状。当您编写计算机程序时，您并不是试图&lt;i&gt;说服&lt;/i&gt;计算机正常工作（尽管有时感觉如此）。&lt;/p&gt;&lt;p&gt;但它不仅仅涉及无生命的物体。你&lt;i&gt;可以&lt;/i&gt;在这里有一个某人的“模型”——一个追踪猎物的猎人——但关键的是你不要假设他们有&lt;i&gt;你&lt;/i&gt;的模型。这里可能发生的任何“交流”都是片面的。如果你看到一只熊向你跑来，并且你逃离了它的领地，那么可以说这只熊“恐吓”了你。但熊并没有想到“恐吓”。它采取的行动并不是为了表明它愿意杀死你以迫使你撤退。它的意思是&lt;i&gt;直接&lt;/i&gt;把你从它的领地里赶走，杀了你，而你愿意从它那里撤退，对它来说，就是一个巧合。 &lt;span class="footnote-reference" id="fnrefb90gqrtknu"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnb90gqrtknu"&gt;[4]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;本质上，这并不意味着 0 级代理人不能有广泛的动机，他们只是追求自己的私利。然而，这是最常见的。毕竟，在 0 级操作需要长期拒绝或无法与其他特工/人员联系。如果你只希望通过单方面迫使他人做出改变或得到同样的回报来与他人互动，那么除了一种不可调和的敌对关系之外，你还能拥有什么样的关系呢？&lt;/p&gt;&lt;p&gt; （如果你可以使用的&lt;i&gt;所有&lt;/i&gt;工具都是 0 级工具怎么办？如果你没有办法与任何人对话，如果你甚至没有“对话”的概念，如果你只能强行改变世界？剧透警告：这就是 4 级从内部看的样子。）&lt;/p&gt;&lt;p&gt; 0级&lt;i&gt;就是&lt;/i&gt;真理。更高的层次很容易崩溃：全面的战斗和战争。&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt; 1级&lt;/h2&gt;&lt;p&gt;好吧，我不会在这里讨论语言和合作的发展。第 1 级是代理交换有关物理世界的信息以形成对其的正确共同理解的级别。&lt;/p&gt;&lt;p&gt;在这一级别上交换的声明仅对其真实价值进行审查，它们是字面的和公开的。由于它涉及与其他代理的沟通，因此这是一种纯粹的合作。这种合作有时可以采取“向其他部落展示你的（不夸张的）军事力量，这样他们就可以让你不战而屈人之兵地夺取所有资源”的形式，但它的目的仍然是实现一个对双方都有利的结果。选择。 （可能存在&lt;i&gt;0级&lt;/i&gt;敌意，以及敌意地&lt;i&gt;拒绝&lt;/i&gt;交流。如果你足够讨厌另一个部落，你就不给他们认输的机会，你只是屠杀他们所有人。但只要交流&lt;i&gt;确实&lt;/i&gt;发生，它总是亲社会的。 ）&lt;/p&gt;&lt;p&gt;在第一级，主体和社会关注物理世界，他们专注于构建尽可能准确的模型。他们对该模型没有任何依恋，并且会根据需要对其进行更改以更好地适应世界。&lt;/p&gt;&lt;p&gt;两个智能体之间关于 1 级问题的冲突可能是由于他们的物理世界模型相互冲突，并且可以通过测试哪个模型是正确的或解决沟通不畅来解决。&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt; 2级&lt;/h2&gt;&lt;p&gt;但有时不可能干净地解决 1 级冲突，因为两个代理缺乏干净地测试他们中哪一个是正确的能力，并且他们的先验（或动机推理）导致他们优先考虑不同的模型。或者也许他们有完全不同的价值观。在这种情况下，他们中的一个人可能会&lt;i&gt;撒谎&lt;/i&gt;：故意发表不正确描述物理世界的声明，以扭曲对话者的世界模型，迫使他们按照第一个人的利益行事。&lt;/p&gt;&lt;p&gt;当然，这不一定是恶意的：他们可能会为了对方的“自身利益”而撒谎，也许是因为他们认为对话者有偏见。他们甚至可能是对的！ （借用兹维的例子，声称河对岸有狮子，而实际上有老虎，因为部落还不够害怕老虎。）&lt;/p&gt;&lt;p&gt;这是对第二级的“经典”解释：在这一级，人们发现欺骗，并开始扭曲他人的模型以达到自己的目的。这绝对是其中的一部分。但只是&lt;i&gt;一部分&lt;/i&gt;。&lt;/p&gt;&lt;p&gt;实际上，对话双方都不必&lt;i&gt;撒谎&lt;/i&gt;。同意不同意就足够了。&lt;/p&gt;&lt;p&gt;在此之后，社会中将出现&lt;i&gt;两种&lt;/i&gt;相互冲突的世界模式（我们称之为“世界观”）。比如说，扩张主义与孤立主义议程。很快，还会有十几个人加入他们的行列，这些人是由于十几个未解决的分歧或欺骗而产生的。其中一些分歧将会得到解决，但其他分歧将长期存在。&lt;/p&gt;&lt;p&gt;人们会根据模型的质量、个人偏见和偏好在这些模型之间进行选择，形成&lt;i&gt;子群体&lt;/i&gt;。每个子群体中的人都会试图让更多的人站在他们一边，并阻止人们离开他们的子群体，因为如果他们的世界观占主导地位，这将使他们受益（要么因为他们真诚地相信它比其他模型更真实，要么因为这对他们特别有利）。&lt;/p&gt;&lt;p&gt;他们会变得根深蒂固，他们会培养对自己事业或世界观的忠诚，他们会培养对自己信仰的确定性。最终，一些（大多数）人会对他们的物理世界模型产生&lt;i&gt;依恋&lt;/i&gt;。他们将开始&lt;i&gt;从本质上&lt;/i&gt;评价它，而不仅仅是因为它是正确的。他们将开始否认反对它的证据，他们的模型越准确（和/或难以质疑），这就越容易。&lt;/p&gt;&lt;p&gt;他们将开始将现实模型与&lt;i&gt;现实本身&lt;/i&gt;混淆。&lt;/p&gt;&lt;p&gt;在第二级社会的后期，人们会考虑最重要的事情是其他人所认同的世界观，以及一般来说，其他人有什么信念和动机。审查声明的不是其真实价值，而是其背后的动机和信念：为什么该声明的作者选择这样做，他们试图传播什么世界观，或者他们可以相信什么。到那时，陈述的实际内容将被认为不如它们所揭示的关于说话者和说话者的其他信仰的内容重要。&lt;/p&gt;&lt;p&gt;创建新模型或对旧模型进行彻底改变将受到抵制。&lt;/p&gt;&lt;p&gt;与其他人&lt;i&gt;确信&lt;/i&gt;正在&lt;i&gt;发生的事情相比，物理世界中实际&lt;/i&gt;发生的事情将变得不那么重要。&lt;/p&gt;&lt;p&gt;两个代理之间的 2 级冲突是相互操纵的尝试。两者的目标都是说服观众接受他们的世界模型，无论观众是他们的对话者，还是真正的观看他们的观众。任何卑鄙的心理伎俩都可以在那里进行。&lt;/p&gt;&lt;p&gt;完全处于第 2 级的社会成员将 (1) 专注于开发尽可能准确的&lt;i&gt;社会其他成员&lt;/i&gt;的模型，加上 (2) 将他们个人的物理世界模型视为本质上真实的，加上 (3) 考虑与实际的物理世界无关，可以根据需要撒谎或忽略。&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt; 3级&lt;/h2&gt;&lt;p&gt;二级社会是一个分为多个小组的社会，仔细审查人们的言论是否与其世界观真正相符。其中一些团体比其他团体更强大，或者吸引不同的偏好，并且您可以通过发表正确的声明来表明有关您自己的正确信息，从而赢得他人的好感。你还可以通过说服别人持有不受欢迎的世界观或不属于他们想加入的群体来伤害你讨厌的人。&lt;/p&gt;&lt;p&gt;你或他们&lt;i&gt;实际上&lt;/i&gt;是什么样子并不重要：只要某人&lt;i&gt;看起来&lt;/i&gt;属于某个群体，或招致仇恨，或因某种原因而有另一种关系，他们&lt;i&gt;实际上做&lt;/i&gt;。这纯粹是一个外观问题。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;第一级社会植根于物质世界的客观真理。&lt;/li&gt;&lt;li&gt;第二级社会以其人民&lt;i&gt;信仰&lt;/i&gt;的客观真理为基础。即使这些信念被扭曲了，即使你&lt;i&gt;想&lt;/i&gt;扭曲它们，你仍然关心&lt;i&gt;它们真正的内在认知状态&lt;/i&gt;。&lt;/li&gt;&lt;li&gt;第三级社会凭空创造出自己的现实。它只关心事情看起来怎么样，一个人&lt;i&gt;看起来&lt;/i&gt;有什么信念。但它并不承认这一点。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在 3 级社会中，言论仍然会受到审查，以确定它们对说话者或其他人产生的影响，就像在 2 级社会中一样（因为递归已经在这方面达到了最大值；下一节将详细介绍）。但你对这些含义的解释是否正确已经不再重要，只要它&lt;i&gt;足够好，其他人就可以振振有词地声称相信它&lt;/i&gt;，或者至少相信&lt;i&gt;你&lt;/i&gt;相信它。&lt;/p&gt;&lt;p&gt;如果你&lt;i&gt;真正&lt;/i&gt;相信这个事业，那并不重要。只是你的社会形象与那些以事业为中心的运动的一部分的人的形象相符。&lt;/p&gt;&lt;p&gt;这会产生一些不正当的激励措施，Zvi 将其&lt;a href="https://www.lesswrong.com/posts/QdppEcbhLTZqDDtDa/unifying-the-simulacra-definitions"&gt;称为&lt;/a&gt;“针对知识的战争”：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;在第 3 级，以下两件事是应该受到指责的，从而造成知识成为一种负担的两种方式。 [...]&lt;/p&gt;&lt;p&gt;一件值得指责的事情是&lt;i&gt;没有使用正确的符号。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这就是“由可用于其他用途的事物组成”的方面。关心真相会产生一种替代性激励，阻止人们调用正确的符号，并让人怀疑这些符号是否意味着它们看起来的意思。&lt;/p&gt;&lt;p&gt;如果有的话，调用技术上错误的符号而不是技术上正确的符号是&lt;i&gt;游戏中更强大的一步&lt;/i&gt;。这就是为什么。它更强烈地表明一个人以昂贵的代价发送了适当的信号，而没有空间被误解为较低级别的行动。通过重复谎言，我们表现出自己的忠诚。通过让其他人重复这一点，我们可以促使他们变得忠诚并被认为是忠诚的，并让他们向其他人展示他们的忠诚，并展示我们对人和象征的力量。&lt;/p&gt;&lt;p&gt;另一件值得指责的事情是&lt;i&gt;知道你所说的是假的&lt;/i&gt;。罪魁祸首&lt;i&gt;是知识本身&lt;/i&gt;。&lt;/p&gt;&lt;p&gt; （或者，也许更准确地说，&lt;i&gt;其他人知道&lt;/i&gt;你知道你所说的是假的，因此任何其他人都知道我们拥有知识，而不是知识本身，但对于任何其他指责系统来说也是如此。）&lt;/p&gt;&lt;p&gt;总统知道什么？他什么时候知道的？&lt;/p&gt;&lt;p&gt;因此，沟通从显式转变为隐式。专注于仅拥有可否认的隐性知识。&lt;/p&gt;&lt;p&gt;需要明确指导的追随者确实是一个糟糕的追随者。指定要完成的所有事情是不切实际的，并且表明您不仅拥有知识，而且拥有责任。更好地&lt;i&gt;朝着&lt;/i&gt;团队的目标努力，积累有助于赢得比赛的符号。&lt;/p&gt;&lt;p&gt;因此，这种结构使每个人都远离知识。到目前为止，假装不知道事情的最简单方法就是不知道它们。&lt;/p&gt;&lt;/blockquote&gt;&lt;hr /&gt;&lt;h2&gt;递归级别&lt;/h2&gt;&lt;p&gt;当我们提升级别时，需要跟踪三个重要变量：世界的哪些方面被认为是重要的，正在形成/操纵什么样的框架来对重要方面进行建模，以及世界的哪一方面被认为是无关紧要的。&lt;/p&gt;&lt;p&gt;这是表格格式：&lt;/p&gt;&lt;figure class="table"&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt; L&lt;/th&gt;&lt;th&gt;重要的&lt;/th&gt;&lt;th&gt;框架&lt;/th&gt;&lt;th&gt;无关紧要&lt;/th&gt;&lt;th&gt;评论&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;物质世界&lt;/td&gt;&lt;td&gt;—&lt;/td&gt;&lt;td&gt; —&lt;/td&gt;&lt;td&gt;模型不存在。一切都是真实的。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 1&lt;/td&gt;&lt;td&gt;物质世界&lt;/td&gt;&lt;td&gt;人们的世界观&lt;/td&gt;&lt;td&gt;—&lt;/td&gt;&lt;td&gt;世界如何运作？&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 2&lt;/td&gt;&lt;td&gt;人们的世界观&lt;/td&gt;&lt;td&gt;人们的社会形象&lt;/td&gt;&lt;td&gt;物质世界&lt;/td&gt;&lt;td&gt;人们相信什么？为什么？怎么可以用呢？&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 3&lt;/td&gt;&lt;td&gt;人们的社会形象&lt;/td&gt;&lt;td&gt;人们的社会形象&lt;/td&gt;&lt;td&gt;人们的世界观&lt;/td&gt;&lt;td&gt;只有人们投射的形象才重要。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 4&lt;/td&gt;&lt;td&gt;人们的社会形象&lt;/td&gt;&lt;td&gt;人们的社会形象&lt;/td&gt;&lt;td&gt;人们的社会形象&lt;/td&gt;&lt;td&gt;???&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;所有三个不同的值都代表不同级别的递归：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;物理世界&lt;i&gt;是&lt;/i&gt;。&lt;/li&gt;&lt;li&gt;人们的世界观是物质世界的模型。&lt;/li&gt;&lt;li&gt;人们的社会形象是人们及其世界观的集体模型：世界模型的模型。&lt;/li&gt;&lt;li&gt;下一个是“一个人的社会形象的模型”，即“一个人的外表的感知”，但这仍然只是“一个人的外表”。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在第 3 级，第三个变量尝试越过递归第 3 级，因此会自行环绕。这导致了“书写自己的现实”的特殊情况：第 3 级&lt;i&gt;创建了&lt;/i&gt;它所关心的事物。&lt;/p&gt;&lt;p&gt;但由于人们图像的真实性尚未被认为是&lt;i&gt;无关紧要的&lt;/i&gt;，因此仍然与现实存在某种联系，如果有足够的证据反对某个主张，就可能推翻它。人们仍然认为模型&lt;i&gt;代表着&lt;/i&gt;某种东西，它们意味着&lt;i&gt;代表&lt;/i&gt;一些不可改变的现实的真相。&lt;/p&gt;&lt;p&gt; 3 级特工真正关心世界如何看待他们和其他人。他们多么准确地表达了他们的忠诚。如果有人提供证据证明有人在某个时刻发出了与他们现在试图展现的公众形象背道而驰的信号，那么 3 级特工&lt;i&gt;就会&lt;/i&gt;关心这一点。 （因此例如取消文化。）&lt;/p&gt;&lt;p&gt; 4 级甚至超越了这个。 （我见过 4 级被描述为“超过 3 级的一切”，我想这是我将其形式化的说法。）&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt; 4级&lt;/h2&gt;&lt;p&gt;想象一个后期的 3 级社会。 2 级智能体群体消失或采用 3 级思维模式。到那时，没有人关心在任何地方或任何人身上实际发生的事情，甚至人们可以确信正在发生的事情，只&lt;i&gt;关心人们认为他们可以振振有词地声称相信&lt;/i&gt;正在发生的事情。&lt;/p&gt;&lt;p&gt;一旦这种事态成为共享知识，就会切换到第 4 级。一旦每个人都知道，他们不需要用自己的表演来&lt;i&gt;合理地&lt;/i&gt;说服观众，只有 L4 特工同伴会跟踪每一句话对正在进行的地位游戏的影响。一旦他们进一步知道其他人也知道这一点......&lt;/p&gt;&lt;p&gt;这有一个棘手的含义：符号变得非符号化。&lt;/p&gt;&lt;p&gt;符号是代表其他事物的事物。但第四级陈述无论如何都与现实无关：它们完全没有意义。它们不传达任何信息，无论是在任何层面上，无论是字面上还是通过它们所产生的含义。他们不代表任何事情。在第 4 级，符号&lt;i&gt;不再象征事物&lt;/i&gt;。他们变得自给自足。&lt;/p&gt;&lt;p&gt;每个人都知道这一点，所以没有人试图解释它们。每个人都知道&lt;i&gt;这&lt;/i&gt;一点，因此没有人发表声明时期望自己会受到仔细审查以获取信息。那么，任何人发表声明的唯一原因是因为他们知道这会对当地的社会环境产生特定的影响：开辟某些攻击或防御的途径。也就是说，&lt;i&gt;它们的目的是其形式所固有的。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;我认为与 0 级的相似之处是显而易见的。 4级特工&lt;i&gt;不能说话&lt;/i&gt;。他们的言论&lt;i&gt;扭曲了现实&lt;/i&gt;。他们不能说话，只能&lt;i&gt;强迫别人占据不同的社会情境&lt;/i&gt;。他们（认为）得到了同样的回报：没有人与他们接触，其他人只是试图强行改变他们周围的社会政治格局。&lt;/p&gt;&lt;p&gt;从真正的意义上来说，4 级语句是&lt;i&gt;移动&lt;/i&gt;、攻击或防御的动作，与物理攻击和躲避不同。&lt;/p&gt;&lt;p&gt;因此，它们也必然是短期的。从较低级别的角度来看，4 级特工看起来仍然在编织有关物理现实的不同叙述。但这些叙述的唯一目的是赢得其创造者目前所卷入的任何&lt;i&gt;直接&lt;/i&gt;冲突。他们不需要足够强大来度过这场冲突，或者彼此保持一致，甚至在冲突之外的任何人看来都是一致的。&lt;/p&gt;&lt;p&gt;与第 3 级不同，提供某人在某个时刻发出错误信号的证据不会打动人们，除非您设法&lt;i&gt;正确地将此信息的泄露作为攻击&lt;/i&gt;。&lt;/p&gt;&lt;p&gt; 4 级特工不关心世界，也不关心别人的看法，也不关心世界如何看待他们。他们唯一关心的是他们可以假装走过的社会政治景观的非象征路线。&lt;/p&gt;&lt;p&gt; 4 级与 0 级一样都是霍布斯地狱。4 级智能体没有与他人合作交互的&lt;i&gt;语言&lt;/i&gt;。从理论上讲，这里也可能有各种各样的动机，但通过这些镜头，一切都会被扭曲。&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt; 5级&lt;/h2&gt;&lt;p&gt;尝试以回避递归模型（已经全面循环）的方式进行推断，第 5 级到第 4 级的框架就像第 1 级到第 0 级一样。这一切都始于逃离非符号地狱， 毕竟。&lt;/p&gt;&lt;p&gt;但是，当你把信号的概念变成一把用来刺人的刀之后，你如何才能重新发现沟通呢？&lt;/p&gt;&lt;p&gt;没有5级。&lt;/p&gt;&lt;ol class="footnotes"&gt;&lt;li class="footnote-item" id="fnsm2ltnt082r"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefsm2ltnt082r"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;也许更细粒度的说法是，在某些情况下，随着递归级别的提高，它们之间的差异缩小，并且由于人类思维的局限性，L3 与 L4+ 是我们的模型变得足够粗糙的地方，差异是难以察觉的。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnmsdn2x9q13l"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefmsdn2x9q13l"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;这完全符合我的观点，即&lt;a href="https://www.lesswrong.com/posts/hx5wTeBSdf4bsYnY9/idealized-agents-are-approximate-causal-mirrors-radical"&gt;主体是近似因果镜子&lt;/a&gt;。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnfofs4yy521u"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnreffofs4yy521u"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;例如，某些政策建议被认为不受欢迎，并不是因为大多数人实际上反对它们，而是因为大多数人&lt;i&gt;认为&lt;/i&gt;大多数人反对他们，如果你担心这一点，那么从技术上讲，你就已经进入了递归级别4...&lt;/p&gt;&lt;p&gt;但根据脚注 1，从经验来看，这种情况似乎并没有发生太多，可能是由于人类思维的局限性。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnb90gqrtknu"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefb90gqrtknu"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;好吧，这实际上可能不是对字面动物的准确描述。它们并不都处于 0 级，它们可以相互通信（尽管我认为在这个具体示例中，界限是模糊的）。或者，你可以想象一个非智能机器人代替熊，遵循一些算法在其领地巡逻，告诉它杀死入侵者。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/KnQpzYRR4ogPNtzem/a-crisper-explanation-of-simulacrum-levels#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 23 Dec 2023 22:13:52 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/KnQpzYRR4ogPNtzem/a-crisper-explanation-of-simulacrum-levels</guid></item><item><title>双曲贴现和帕斯卡抢劫</title><link>https://www.lesswrong.com/posts/4nDkfEYpDFB7KDfQ9/hyperbolic-discounting-and-pascal-s-mugging</link><description>发布于 2023 年 12 月 23 日晚上 9:55（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;i&gt;从我的个人博客交叉发布：&lt;/i&gt; &lt;a href="https://mechanisticmind.com/hyperbolic-discounting-and-pascals-mugging/"&gt;&lt;i&gt;https://mechanisticmind.com/hyperbolic-discounting-and-pascals-mugging/&lt;/i&gt;&lt;/a&gt;&lt;/p&gt;&lt;h1&gt;长话短说&lt;/h1&gt;&lt;figure class="image image_resized" style="width: 100%;"&gt;&lt;img alt="该图像的 alt 属性为空；它的文件名为 image-19.png" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/4nDkfEYpDFB7KDfQ9/lmihbysdvrbcnngfpyep" /&gt;&lt;/figure&gt;&lt;p&gt;双曲贴现（如图 🟥 所示）是指数贴现的不完美近似（如图 🟦 所示）。人们普遍指出，这会导致人类高估近期奖励，但很少有人意识到这也会导致我们高估远期奖励。有大量证据表明人类使用双曲线贴现，这有助于解释为什么人类追求不切实际的长期目标。&lt;/p&gt;&lt;h1&gt;什么是双曲线贴现？&lt;/h1&gt;&lt;p&gt;如果你搜索“双曲折扣”这个词，谷歌会告诉你，这是“一种心理偏见，人们优先考虑眼前的奖励和满足感而不是未来的奖励”。事实上，这只说对了一半。除了高估&lt;i&gt;&lt;strong&gt;近期&lt;/strong&gt;&lt;/i&gt;&lt;strong&gt;奖励&lt;/strong&gt;之外，双曲线贴现还会导致人们&lt;strong&gt;高估&lt;/strong&gt;远期奖励。&lt;/p&gt;&lt;p&gt;时间折扣基本上是一种思考如何回答这样的问题的方式：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;您愿意今天拥有 100 美元，还是一年后拥有 120 美元？&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;从货币角度考虑这个问题相对容易，而且你可能知道这个问题的答案与利率有关，一年后拿 120 美元等于 20% 的年回报率，这是更好的选择高于您在股票市场上预期的 4-10% 的利率，也优于您目前&lt;a href="https://ycharts.com/indicators/1_year_treasury_rate"&gt;可以获得&lt;/a&gt;的 1 年期国债 4.88% 的利率。&lt;/p&gt;&lt;p&gt;这种计算利率的模型称为&lt;i&gt;&lt;strong&gt;指数贴现&lt;/strong&gt;&lt;/i&gt;，它基本上由以下方程表示：&lt;/p&gt;&lt;p&gt;&lt;span class="mjpage mjpage__block"&gt;&lt;span class="mjx-chtml MJXc-display" style="text-align: center;"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;时间&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;t&lt;/span&gt;&lt;/span&gt;处的值&lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mfrac MJXc-space3"&gt;&lt;span class="mjx-box MJXc-stacked" style="width: 1.065em; padding: 0px 0.12em;"&gt;&lt;span class="mjx-numerator"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-denominator"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.409em;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-vsize"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;这表示，如果某个东西在 $t=0$ 时价值 $a$，例如现在一张 100 美元的钞票，那么您需要等待的时间越长，它的价值就会呈指数下降。&lt;/p&gt;&lt;p&gt;因此，事实证明，人类和其他动物似乎并没有使用这个方程来估计未来奖励的价值。相反，他们使用称为&lt;i&gt;&lt;strong&gt;双曲贴现的&lt;/strong&gt;&lt;/i&gt;方法，可以用以下等式表示：&lt;/p&gt;&lt;p&gt;&lt;span class="mjpage mjpage__block"&gt;&lt;span class="mjx-chtml MJXc-display" style="text-align: center;"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;时间&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;t&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;时的值&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mfrac MJXc-space3"&gt;&lt;span class="mjx-box MJXc-stacked" style="width: 2.806em; padding: 0px 0.12em;"&gt;&lt;span class="mjx-numerator"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-denominator"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-vsize"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;这表明，随着奖励的距离越来越远，它的价值会按倒数下降。&lt;/p&gt;&lt;h2&gt;我们如何知道&lt;/h2&gt;&lt;p&gt;科学家们用本科生和&lt;a href="https://mpra.ub.uni-muenchen.de/79536/1/MPRA_paper_79536.pdf"&gt;100 美元的钞票&lt;/a&gt;进行了实验。实际上，资助资金很难获得，因此大多数人都使用 10 美元的钞票，而来自不太知名大学的研究人员大概只能用 1 美元的钞票和一些零钱度日。&lt;/p&gt;&lt;p&gt;他们还用猴子和果汁做了&lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2728786/"&gt;实验&lt;/a&gt;。猴子喜欢果汁；我不知道是否有科学家使用可口可乐进行这些实验，但我敢打赌他们会重复相同的发现。哇，我是在开玩笑，但这里有一篇论文，&lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3107575/"&gt;科学家们给猴子喂可卡因&lt;/a&gt;。科学有时真是太疯狂了。他们发现“[可卡因]选择行为在很大程度上与双曲线贴现一致”。&lt;/p&gt;&lt;p&gt;我还没有找到任何用可卡因测试本科生的实验，所以如果你是一名正在寻找突破性论文的研究生，这里有一个机会。&lt;/p&gt;&lt;p&gt;我应该指出，大脑是复杂的，说人类或猴子总是使用双曲贴现过于简单化。这篇论文说，它&lt;a href="https://www.frontiersin.org/articles/10.3389/neuro.08.009.2009/full"&gt;因物种而异&lt;/a&gt;，虽然这篇论文说实验证据有力，但&lt;a href="https://core.ac.uk/reader/6519160"&gt;实验室设置不现实&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;数学&lt;/h2&gt;&lt;p&gt;从某种意义上说，双曲线贴现是&lt;i&gt;错误的&lt;/i&gt;。如果您是一家对冲基金，并使用此等式对您交易的资产的未来回报进行定价，您将会&lt;i&gt;亏损&lt;/i&gt;。&lt;/p&gt;&lt;p&gt;然而，人类似乎是以这种方式思考世界的，所以理解它的含义很重要。首先，让我们绘制这两个方程的对比图。您可以关注&lt;a href="https://www.desmos.com/calculator/gzxw59cmhf"&gt;Desmos&lt;/a&gt; 。 &lt;/p&gt;&lt;p&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/4nDkfEYpDFB7KDfQ9/ielywx3mfzz6zqtd61ln" style="width: 434px;" /&gt;&lt;/p&gt;&lt;p&gt; 🟥 = 双曲线贴现&lt;br /&gt;🟦=指数折扣&lt;/p&gt;&lt;p&gt;等等，这是怎么回事？谷歌告诉我们，双曲线贴现高估了短期回报，但这张图告诉我们恰恰相反！双曲线贴现实际上高估了长期回报。&lt;/p&gt;&lt;p&gt;但人类似乎确实高估了短期回报，这就是所有有关双曲线贴现的自助文章在网上不得不说的，尽管他们没有图表。我个人很喜欢&lt;a href="https://www.nirandfar.com/hyperbolic-discounting-why-you-make-terrible-life-choices/"&gt;这个&lt;/a&gt;，它有很好的插图： &lt;/p&gt;&lt;p&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/4nDkfEYpDFB7KDfQ9/jsr01c0ixp8wshmeitex" style="width: 742px;" /&gt;&lt;/p&gt;&lt;p&gt;资料来源： &lt;a href="https://www.nirandfar.com/hyperbolic-discounting-why-you-make-terrible-life-choices/"&gt;https&lt;/a&gt; ://www.nirandfar.com/hyperbolic-discounting-why-you-make-terrible-life-choices/&lt;/p&gt;&lt;p&gt;如果你眯着眼睛看图表，就会发现双曲曲线高估了具有负值 $t$ 的事物。让我们缩小一点。 &lt;/p&gt;&lt;p&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/4nDkfEYpDFB7KDfQ9/iq6djzuuvm7j1eqzvkug" style="width: 442px;" /&gt;&lt;/p&gt;&lt;p&gt; 🟥 = 双曲线贴现&lt;br /&gt;🟦=指数折扣&lt;/p&gt;&lt;p&gt;有几种方法可以平方这个圆，它们基本上都可以归结为：出于某种原因，动物执行双曲贴现，但它们想要逼近&lt;i&gt;真正的&lt;/i&gt;贴现函数，该函数是指数的，因此进化选择了最小化差异的超参数 $\ mathbb{E}[abs(双曲 - 指数)]$.&lt;/p&gt;&lt;p&gt;有很多方法可以调整这两个函数的参数，但我喜欢引入一个参数，该参数只是将图形向右移动，这本质上表明我们考虑的所有操作都需要一些非零时间和精力。您可以&lt;a href="https://www.desmos.com/calculator/w9kmpyu6xx"&gt;在此处查看 Desmos 上的&lt;/a&gt;方程。 &lt;/p&gt;&lt;p&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/4nDkfEYpDFB7KDfQ9/gzdc5vck6277qnxrvhis" style="width: 652px;" /&gt;&lt;/p&gt;&lt;p&gt; 🟥 = 双曲线贴现&lt;br /&gt;🟦=指数折扣&lt;/p&gt;&lt;p&gt;并排比较这两个方程，我们可以看到双曲线贴现高估了遥远的奖励，但奇怪的是它似乎也高估了遥远的奖励。&lt;/p&gt;&lt;p&gt;您可以看到，在 $\text{time}=0$ 时，双曲线贴现对事物的估值大于 1。也就是说，它相对于事物的真实价值高估了事物的价值。我怀疑这是&lt;a href="https://en.wikipedia.org/wiki/Loss_aversion"&gt;损失厌恶&lt;/a&gt;的根源之一，即与我们可以拥有的东西相比，人类倾向于对我们已经拥有的东西给予过多的重视。&lt;/p&gt;&lt;h1&gt;挑战与时间&lt;/h1&gt;&lt;p&gt;在我们了解其含义之前，让我先谈谈&lt;strong&gt;时间&lt;/strong&gt;的含义。在金融世界中，你可以把钱存入银行而不用做任何事，时间是你唯一的资源。但在我们生活的其他领域，我们必须真正付出努力才能获得回报。考虑这个问题：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;您愿意今天在 Craigslist 上以 100 美元的价格出售您的二手家具，还是愿意在车库修理并重新粉刷后以 200 美元的价格出售？&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这类似于“现在或以后”框架，但有两个复杂之处：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;您投入自己的劳动来修理家具，因此您实际上是按小时付费的&lt;/li&gt;&lt;li&gt;你可能画得不好，所以不能保证它在你完成后实际上价值 200 美元&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;第二个复杂因素，即挑战，实际上出现在上面的利率示例中。如果实验者问您是否愿意现在拥有 100 美元，还是一周后拥有 120 美元，您可能会现实地预期，交易从现在起一周后完成的可能性较小。毕竟，也许你会忘记它，也许实验会被关闭，也许他们会弄错你的电话号码。&lt;/p&gt;&lt;p&gt;以下是一些其他情况，其中 x 轴更多地涉及复杂性的不确定性而不是时​​间：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;您在跳蚤市场出售家具。现在有人给你 100 美元，但你认为它更值钱。你是否应该坚持下去，希望当天晚些时候有人会为此付出更多代价？&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;政治家 A 承诺逐步改进，这些改进是可以实现的，但并不令人兴奋。政治家 B 承诺进行一场乌托邦革命，但这似乎有风险。你应该投票给谁？&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;将其中每一个视为一个模型，其中在完成 $N$ 挑战后将出现一些奖励 $r$。考虑一下企业家爱丽丝的这种假设情况：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;爱丽丝想创办一家销售鞋子的公司，她认为这将价值 1,000,000 美元。为了取得成功，她必须完成以下五项任务：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;开发一款舒适的鞋子&lt;/li&gt;&lt;li&gt;找到一家工厂来生产这些鞋子&lt;/li&gt;&lt;li&gt;为鞋子打造良好的品牌形象&lt;/li&gt;&lt;li&gt;说服有影响力的人推销鞋子&lt;/li&gt;&lt;li&gt;履行订单&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;p&gt;Alice 应该如何平衡奖励的承诺和她面临的 5 个挑战？指数折扣表明每个挑战都会在一定比例的时间内失败。也许她有 50% 的可能性完成每项任务，或者 $p_s=0.5^5=3\%$ 成功的机会。但双曲线贴现表明她更有可能将其估计为 $1/(1+d*5)$。如果 $d=6$，她将获得相同的 $p_s=3\%$ 成功机会，但这并不能概括。无论她的 $d$ 值与之前的经验相符多少，随着计划中步骤的增加，她都会系统性地高估自己的预期回报。&lt;/p&gt;&lt;h1&gt;为什么？&lt;/h1&gt;&lt;p&gt;人类为什么会这样？为什么我们不使用指数折扣，从抽象的角度来看，这是&lt;i&gt;&lt;strong&gt;正确的&lt;/strong&gt;&lt;/i&gt;？一般来说，这个问题有两种可能的答案：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;事实上，双曲线贴现是正确的&lt;/li&gt;&lt;li&gt;数学很难，大脑可以比其他操作更容易地完成某些类型的操作&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;维基百科&lt;a href="https://en.wikipedia.org/wiki/Hyperbolic_discounting#Uncertain_risks"&gt;概述了“实际上正确”答案的一个很好的论点&lt;/a&gt;，它基本上说，如果存在恒定的背景风险，那么在每个时间单位（危险率）都会出现问题，但你不知道风险水平是多少但你对它有一些合理的分布，那么双曲贴现在数学上是正确的。我不完全理解这种分布是否是一个合理的假设。我认为有时我们拥有有关危险率的良好数据，但很难将其纳入我们的决策中。&lt;/p&gt;&lt;h2&gt;一个神经科学的故事&lt;/h2&gt;&lt;p&gt;但我也认为有一个神经科学的故事。计算指数函数可能比计算双曲函数更困难，后者只需要加法、乘法和除法。毕竟，这些方程在纸上看起来毫无意义，但它们代表了一个计算过程。&lt;/p&gt;&lt;p&gt;令人惊讶的是，计算指数对大脑来说很难计算。指数增长和衰减在生物系统中随处可见，例如药物的半衰期。大脑实际上需要通过负反馈回路小心地稳定自身，以防止神经活动呈指数级爆炸，从而导致癫痫发作。但所有这些机制所花费的时间随着 $t$（您想要预测的未来时间）线性增长。大脑确实需要能够在 $O(1)$ 时间内评估行动的折扣价值。&lt;/p&gt;&lt;p&gt;在&lt;a href="https://scholar.google.com/citations?hl=en&amp;amp;user=tZpKKm4AAAAJ&amp;amp;view_op=list_works&amp;amp;sortby=pubdate"&gt;Randall O&amp;#39;Reilly&lt;/a&gt;的大脑强化学习&lt;a href="https://ccnlab.org/papers/OReillyHazyHerd16.pdf"&gt;轴突&lt;/a&gt;模型中，一个动作的预期奖励是与该动作的预期成本分开计算的。我认为它就像&lt;a href="https://en.wikipedia.org/wiki/Q-learning"&gt;Q-learning&lt;/a&gt; ，其中 $Q^+(a)$ 是预期奖励，$Q^-(a)$ 是预期成本，其中包含延迟。在这个 RL 框架中，动物想要追求最大化 $Q^+(a) - Q^-(a)$ 的动作 $a$。然而，&lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3653570/"&gt;来自细胞过程的证据&lt;/a&gt;表明，抑制性神经连接最好用除法而不是减法来表示，给我们一个这样的方程：&lt;/p&gt;&lt;p&gt;&lt;span class="mjpage mjpage__block"&gt;&lt;span class="mjx-chtml MJXc-display" style="text-align: center;"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom MJXc-space3"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mfrac"&gt;&lt;span class="mjx-box MJXc-stacked" style="width: 6.893em; padding: 0px 0.12em;"&gt;&lt;span class="mjx-numerator"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-denominator"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.409em; padding-left: 0px;"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;−&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-vsize"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;其中 $a$ 是正在考虑的操作，$d$ 是延迟，$k_1$ 和 $k_2$ 是常量。这正是双曲线贴现。&lt;/p&gt;&lt;h1&gt;帕斯卡的抢劫&lt;/h1&gt;&lt;p&gt;网上有很多文章告诉我们，双曲线贴现意味着我们在短期内高估了事物的价值。这是一个示例：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://thedecisionlab.com/biases/hyperbolic-discounting"&gt;为什么我们更看重眼前的回报而不是长期的回报？&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.nirandfar.com/hyperbolic-discounting-why-you-make-terrible-life-choices/"&gt;双曲线贴现：为什么你会做出糟糕的人生选择&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.moneythor.com/2020/09/02/hyperbolic-discounting-behavioural-science-in-banking/"&gt;“双曲线折扣是……人们选择较小的、即时的奖励”&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;但是，当我们查看上面的方程图时，我们发现双曲线贴现还会引入一种偏差，即我们高估了遥远的奖励！实际上，在中期，我们一直低估事物的价值。&lt;/p&gt;&lt;p&gt;我相信这解释了为什么人们始终热衷于在遥远的未来实现的不切实际的梦想。我们发现成为一名著名的摇滚明星比成为一名相当优秀的音乐家更有动力，尽管这种可能性要小得多。在政治上，人们追求的是一场解决一切问题的革命，而不是温和的改革。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;在哲学上，帕斯卡的抢劫是一个思想实验，展示了预期效用最大化的问题。理性的代理人应该选择其结果在按概率权衡时具有更高效用的行动。但一些非常不可能的结果可能会产生非常大的效用，而且这些效用的增长速度可能快于概率减少的速度。 —&lt;a href="https://en.wikipedia.org/wiki/Pascal%27s_mugging"&gt;维基百科&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;帕斯卡的抢劫有时会以指数折扣的方式发生，有时追求巨额但不太可能的回报是理性的。例如，大多数制药初创公司都会失败，但那些成功的公司往往会获得巨大的利润，因为他们能够在专利垄断下销售其药品。&lt;/p&gt;&lt;p&gt;但这种情况更有可能发生在双曲贴现下，因为双曲贴现不恰当地使用了倒数而不是指数衰减。&lt;/p&gt;&lt;p&gt;帕斯卡抢劫的基本设置是这样的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;有非常大的可能奖励（天堂、乌托邦、仁慈的 AGI、公正的国王、名誉和财富等）&lt;/li&gt;&lt;li&gt;有很多原因可以解释为什么这种可能的奖励不太可能实现。或者，承诺的奖励在时间上非常遥远，每个单位时间都有恒定的不确定性&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;以指数方式折扣非常大的奖励是正确的，如果你这样做，你会发现它会很快减少。但人们不会凭直觉这样做。我们的神经硬件经过设置，可以使用收敛到零的速度比指数慢得多的函数进行折扣。唯一的解决办法就是&lt;a href="https://www.lesswrong.com/tag/shut-up-and-multiply"&gt;闭嘴并繁衍&lt;/a&gt;。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/4nDkfEYpDFB7KDfQ9/hyperbolic-discounting-and-pascal-s-mugging#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 23 Dec 2023 21:55:27 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/4nDkfEYpDFB7KDfQ9/hyperbolic-discounting-and-pascal-s-mugging</guid></item><item><title>AISN #28：人工智能安全中心 2023 年回顾</title><link>https://www.lesswrong.com/posts/HEuDwEk22JfCBHh9o/aisn-28-center-for-ai-safety-2023-year-in-review</link><description>发布于 2023 年 12 月 23 日晚上 9:31（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;欢迎阅读人工智能安全&lt;a href="https://www.safe.ai/"&gt;中心的人工智能安全&lt;/a&gt;通讯。我们讨论人工智能和人工智能安全的发展。无需技术背景。&lt;/p&gt;&lt;p&gt; &lt;a href="https://newsletter.safe.ai/subscribe?utm_medium=web&amp;amp;utm_source=subscribe-widget-preamble&amp;amp;utm_content=113135916"&gt;在此&lt;/a&gt;订阅以接收未来版本。&lt;/p&gt;&lt;p&gt; 2023 年即将结束，我们要感谢您对人工智能安全的持续支持。对于人工智能和人工智能安全中心来说，今年是重要的一年。在这份特别版时事通讯中，我们重点介绍了今年一些最重要的项目。感谢您成为我们社区和工作的一部分。&lt;/p&gt;&lt;hr /&gt;&lt;h1&gt; AI 安全中心 2023 年回顾&lt;/h1&gt;&lt;p&gt;人工智能安全中心 (CAIS) 的使命是减少人工智能带来的社会规模风险。我们认为这需要研究和监管。这些都需要快速发生（由于人工智能进展的时间表未知）并且同时进行&lt;strong&gt; &lt;/strong&gt;（因为任何一个本身都是不够的）。为了实现这一目标，我们致力于三大工作支柱：研究、领域建设和宣传。&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;研究&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;CAIS对人工智能安全进行技术和概念研究。我们追求多种重叠的策略，这些策略可以叠加在一起以降低风险（“纵深防御”）。尽管没有任何一项技术可以将风险降至零，但我们希望建立分层防御措施，将风险降低到可以忽略不计的水平。&lt;/p&gt;&lt;p&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbf0c289-ca28-4780-80d7-04c1178b2594_1174x510.png"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/HEuDwEk22JfCBHh9o/dejkbp8hpwmjxaozjcpj" /&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;以下是我们 2023 年&lt;strong&gt;技术研究&lt;/strong&gt;的一些亮点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;a href="https://llm-attacks.org"&gt;LLM 攻击&lt;/a&gt;：绕过 GPT-4、Claude、Bard 和 Llama 2 上的安全护栏，导致模型做出危险行为，例如输出制造炸弹的指令。这项工作为法学硕士创建了自动对抗性攻击领域。 《&lt;a href="https://www.nytimes.com/2023/07/27/business/ai-chatgpt-safety-research.html"&gt;纽约时报》&lt;/a&gt;对此进行了报道。&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.ai-transparency.org/"&gt;表示工程&lt;/a&gt;：第一篇控制模型内部结构以使模型说谎或诚实的论文。实验表明，这些技术可以使人工智能更加诚实、厌恶权力和道德。&lt;/li&gt;&lt;li&gt; &lt;a href="https://aypan17.github.io/machiavelli/"&gt;MACHIAVELLI Benchmark&lt;/a&gt; ：评估人工智能代理做出道德决策的能力。该基准提供了关于欺骗、遵守规则、追求权力和效用的 13 项道德行为衡量标准。以&lt;a href="https://icml.cc/virtual/2023/oral/25461"&gt;口头论文形式发表在 ICML 2023 上&lt;/a&gt;。&lt;/li&gt;&lt;li&gt; &lt;a href="https://decodingtrust.github.io/"&gt;DecodingTrust&lt;/a&gt; ：表明 GPT-4 比其他模型更容易受到误导性目标系统提示的影响。荣获&lt;a href="https://blog.neurips.cc/2023/12/11/announcing-the-neurips-2023-paper-awards/"&gt;NeurIPS 2023优秀论文奖&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;我们还发表了关于&lt;a href="https://arxiv.org/abs/2311.04235"&gt;法学硕士遵循规则&lt;/a&gt;和&lt;a href="https://arxiv.org/abs/1908.08016"&gt;无限制对抗性攻击的&lt;/a&gt;研究。&lt;/li&gt;&lt;li&gt;我们的研究人员正在帮助 OpenAI 和 Meta 等多个实验室对他们的模型进行红队设计。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们还进行了关于人工智能安全的&lt;strong&gt;概念研究&lt;/strong&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://arxiv.org/abs/2306.12001"&gt;灾难性人工智能风险概述&lt;/a&gt;提供了人工智能风险的全面概述。 （&lt;a href="https://www.wsj.com/tech/ai/ai-risk-humanity-experts-thoughts-4b271757"&gt;华尔街日报&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href="https://arxiv.org/abs/2303.16200"&gt;自然选择有利于人工智能而不是人类&lt;/a&gt;，认为人工智能的发展将受到自然选择的影响，这将导致自私的人工智能将自身的增殖置于人类目标之上。 （《&lt;a href="https://time.com/6283958/darwinian-argument-for-worrying-about-ai/"&gt;时代周刊》专栏&lt;/a&gt;）&lt;/li&gt;&lt;li&gt; &lt;a href="https://arxiv.org/abs/2308.14752"&gt;《人工智能欺骗：示例、风险和潜在解决方案调查》&lt;/a&gt;提供了人工智能欺骗的实证示例，讨论了由此产生的风险，并提出了技术和政策解决方案。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;凭借我们的研究专业知识，CAIS 帮助举办了&lt;a href="https://trojandetection.ai"&gt;NeurIPS 2023 木马检测竞赛&lt;/a&gt;，其中包括关于红队大型语言模型的新赛道。超过 125 个团队参与并提交了超过 3400 份参赛作品。&lt;/p&gt;&lt;h2&gt;现场建设&lt;/h2&gt;&lt;p&gt;CAIS 旨在创建一个蓬勃发展的研究生态系统，推动安全人工智能的进步。我们在 2023 年实现了这一目标，为人工智能研究人员提供计算基础设施、创建用于学习该领域的教育资源以及其他活动。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;计算集群。&lt;/strong&gt;进行有用的人工智能安全研究通常需要使用尖端模型，但运行大规模模型既昂贵又麻烦。这些困难常常阻碍研究人员进行先进的人工智能安全研究。 2023 年 2 月，CAIS 推出了计算集群，为从事人工智能安全研究的研究人员提供免费计算。&lt;/p&gt;&lt;p&gt;截至 2023 年 11 月，我们已经吸引了约 200 名用户参与 63 个人工智能安全项目。使用 CAIS 计算集群总共发表了 32 篇论文，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://arxiv.org/abs/2309.15840"&gt;如何抓住人工智能骗子&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://arxiv.org/abs/2310.15213"&gt;大型语言模型中的函数向量&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://arxiv.org/abs/2308.14761"&gt;扩散模型中的统一概念编辑&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://arxiv.org/abs/2310.17645"&gt;防御公共模型的传输攻击&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://arxiv.org/abs/2311.14455"&gt;来自有毒人类反馈的通用越狱后门&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://drive.google.com/file/d/1iluFBhtQrv6kbmp4-Wsibpt5-U52CElO/view"&gt;寻找却找不到：深度神经网络中难以检测的木马&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://openreview.net/forum?id=l3yxZS3QdT"&gt;BIRD：深度强化学习的通用后门检测和删除&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://arxiv.org/abs/2309.12288"&gt;逆转诅咒：接受过“A is B”培训的法学硕士无法学习“B is A”&lt;/a&gt;&lt;/li&gt;&lt;li&gt; ……还有&lt;a href="https://www.safe.ai/compute-cluster"&gt;另外 24 篇论文&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt; 70% 对我们的用户调查做出回应的实验室指出，如果没有计算集群，他们的研究项目就不可能在当前范围内实现；另外30%的人表示集群显着加快了他们的研究进展。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;哲学联谊会。&lt;/strong&gt;今年，CAIS 接待了十几位学术哲学家，进行为期七个月的研究奖学金。他们发表了 21 篇关于人工智能安全的研究论文，主题包括&lt;a href="https://drive.google.com/file/d/1Bp6iTbeXgdeE5C3UPqdWFOp8MePRylvu/view"&gt;寻求权力的人工智能&lt;/a&gt;和&lt;a href="https://philpapers.org/archive/GOLAWE-4.pdf"&gt;人工智能主体的道德地位&lt;/a&gt;以及其他主题（&lt;a href="https://www.safe.ai/philosophy-fellowship"&gt;更多内容请参见此处&lt;/a&gt;）。他们还在领先的哲学会议上发起了三个研讨会、两本书、各种专栏文章和&lt;a href="https://link.springer.com/collections/cadgidecih"&gt;一本顶级期刊的特刊&lt;/a&gt;（收到了 30 多篇研究论文），所有这些都专注于人工智能安全。这大大加速了人工智能安全向跨学科企业的发展。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;活动。&lt;/strong&gt; CAIS 聚集了 20 名法律学者、政策研究人员和政策制定者，参加了为期三天的法律和人工智能安全研讨会。一群与会者随后成立了一个对人工智能安全感兴趣的法律学者联盟。他们还一直在制定研究议程纲要，该纲要即将发布。在我们的调查受访者中，100% 的研究人员提出了更多的研究想法； 91% 的受访者表示，他们发现研讨会对于结识研究合作者非常有用。&lt;/p&gt;&lt;p&gt;我们帮助在 ICML 和 NeurIPS 这两个顶级 AI 会议上组织了关于 ML 安全的社交活动，大约 300 名研究人员出席了每个会议讨论 AI 安全。我们参加了中国最大的人工智能会议，即在上海举行的世界人工智能大会，并在会上举办了&lt;a href="https://drive.google.com/file/d/15gnLZsMMvtCy-lwCz5BhlWQ9-ni2TBak/view"&gt;有关人工智能安全的演讲&lt;/a&gt;，吸引了超过 30,000 名观众。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;教科书。&lt;/strong&gt; &lt;a href="https://www.aisafetybook.com/textbook/0-1"&gt;《人工智能安全、道德和社会简介》&lt;/a&gt;是一本新教科书，将于明年初在学术出版社出版。它旨在利用安全工程、经济学、哲学和其他学科，为人工智能安全提供易于理解和全面的介绍。那些想参加基于教科书的免费在线课程的人可以&lt;a href="https://www.aisafetybook.com/express-interest"&gt;在这里&lt;/a&gt;表达他们的兴趣。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在线课程。&lt;/strong&gt;此外，CAIS 使用我们去年夏天开发的&lt;a href="https://course.mlsafety.org"&gt;课程&lt;/a&gt;开展了两个在线的 ML 安全简介课程。这些项目总共帮助约 100 名学生、研究人员和行业工程师了解 AI 安全。&lt;/p&gt;&lt;h2&gt;宣传&lt;/h2&gt;&lt;p&gt;公众对人工智能安全的认识和理解可以鼓励明智的技术和政策解决方案。 CAIS 向政府提供建议并公开撰写文章，以分享有关人工智能安全的信息。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关于人工智能风险的声明。&lt;/strong&gt; CAIS发布了&lt;a href="https://safe.ai/statement-on-ai-risk"&gt;关于人工智能灭绝风险的声明&lt;/a&gt;，显着提高了公众和政府对人工智能风险的规模和重要性的认识。至关重要的是，关于人工智能风险的声明将人工智能灭绝风险牢牢置于可接受的公众讨论的奥弗顿窗口之内。&lt;/p&gt;&lt;p&gt;该声明极大地影响了美国和英国高层领导人的思维。 Rishi Sunak&lt;a href="https://twitter.com/RishiSunak/status/1663838958558539776"&gt;直接回应&lt;/a&gt;了有关人工智能风险的声明，表示“[英国]政府正在非常仔细地考虑这一点。”白宫新闻秘书卡琳·让-皮埃尔 (Karine Jean-Pierre) 在&lt;a href="https://www.usatoday.com/story/news/politics/2023/06/01/president-biden-warns-ai-could-overtake-human-thinking/70277907007/"&gt;被问及这一声明时&lt;/a&gt;评论道，人工智能“是我们这个时代目前看到的最强大的技术之一。但为了抓住它带来的机遇，我们必须首先减轻其风险。”欧盟委员会主席的国情咨文&lt;a href="https://ec.europa.eu/commission/presscorner/detail/en/speech_23_4426#:~:text=%E2%80%9CMitigating%20the%20risk%20of%20extinction,uses%20-%20both%20civilian%20and%20military."&gt;全文引用了该声明&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;a href="https://drive.google.com/file/d/1RVxA5OyvuCFwupt-ptPjDzNe4GqB1yuN/view?usp=sharing"&gt;纽约时报（头版）&lt;/a&gt; 、 &lt;a href="https://www.theguardian.com/technology/2023/may/30/risk-of-extinction-by-ai-should-be-global-priority-say-tech-experts"&gt;卫报&lt;/a&gt;、 &lt;a href="https://www.bbc.com/news/uk-65746524"&gt;BBC新闻&lt;/a&gt;、 &lt;a href="https://www.reuters.com/technology/top-ai-ceos-experts-raise-risk-extinction-ai-2023-05-30/"&gt;路透社&lt;/a&gt;、 &lt;a href="https://www.washingtonpost.com/business/2023/05/30/ai-poses-risk-extinction-industry-leaders-warn/"&gt;华盛顿邮报&lt;/a&gt;、 &lt;a href="https://edition.cnn.com/2023/05/30/tech/ai-industry-statement-extinction-risk-warning/index.html"&gt;CNN&lt;/a&gt; 、&lt;a href="https://www.ft.com/content/084d5627-5193-4bdc-892e-ebf9e30b7ea3"&gt;金融时报&lt;/a&gt;、&lt;a href="https://www.npr.org/2023/05/30/1178943163/ai-risk-extinction-chatgpt"&gt;国家公共广播电台（NPR）&lt;/a&gt; 、 &lt;a href="https://www.thetimes.co.uk/article/ai-artificial-intelligence-robots-threat-humans-planet-b652g7xcr"&gt;泰晤士报、伦敦&lt;/a&gt;、 &lt;a href="https://www.bloomberg.com/news/videos/2023-05-31/center-for-ai-safety-s-hendrycks-on-ai-risks-video"&gt;彭博社&lt;/a&gt;等媒体报道了这一声明。 &lt;a href="https://www.wsj.com/articles/ai-threat-is-on-par-with-pandemics-nuclear-war-tech-executives-warn-39105eeb"&gt;华尔街日报（WSJ）&lt;/a&gt; 。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为政策制定者提供建议。&lt;/strong&gt; CAIS 是英国人工智能安全峰会科学轨道上与英国工作组合作的主要技术顾问之一。我们针对 NTIA 的信息请求做出了回应，提出了拟议的人工智能监管框架。我们受邀加入世界经济论坛的&lt;a href="https://initiatives.weforum.org/ai-governance-alliance/home"&gt;人工智能治理联盟&lt;/a&gt;，并为&lt;a href="https://x.ai/about/"&gt;xAI&lt;/a&gt; 、英国国务院、美国国务院和其他政府机构提供咨询服务。最后，CAIS 帮助启动了国家科学基金会&lt;a href="https://beta.nsf.gov/funding/opportunities/safe-learning-enabled-systems"&gt;2000 万美元的人工智能安全拨款基金&lt;/a&gt;并提供建议。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;通讯与媒体。&lt;/strong&gt;公众需要有关人工智能安全的准确可信的信息。 CAIS 旨在通过我们拥有超过 7,500 名订阅者的&lt;a href="https://newsletter.safe.ai"&gt;两份&lt;/a&gt;&lt;a href="https://newsletter.mlsafety.org"&gt;时事通讯&lt;/a&gt;以及我们在&lt;a href="https://time.com/6283958/darwinian-argument-for-worrying-about-ai/"&gt;《时代》杂志&lt;/a&gt;和《&lt;a href="https://www.wsj.com/tech/ai/ai-risk-humanity-experts-thoughts-4b271757"&gt;华尔街日报》&lt;/a&gt;等媒体上的公开写作来满足这一需求。除了与声明相关的活动之外，CAIS 还进行了 50 多家主要媒体的活动。 CAIS 主任 Dan Hendrycks 被&lt;a href="https://time.com/collection/time100-ai/6309050/dan-hendrycks/"&gt;《时代》杂志评为人工智能领域 100 名最具影响力人物&lt;/a&gt;之一。&lt;/p&gt;&lt;h2&gt;展望未来&lt;/h2&gt;&lt;p&gt;我们有许多项目将于 2024 年启动。在接下来的几个月里，这些项目旨在减轻灾难性生物风险、加强国际协调并进行技术研究以制定安全标准和法规。&lt;/p&gt;&lt;h2&gt;支持我们的工作&lt;/h2&gt;&lt;p&gt;2023 年是重要的一年，2024 年将更加关键。&lt;strong&gt;您的免税捐款使我们的工作成为可能。&lt;/strong&gt;您可以通过&lt;a href="https://www.safe.ai/donate"&gt;此处&lt;/a&gt;捐款来支持人工智能安全中心的使命，即减少人工智能带来的社会规模风险。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt; &lt;a href="https://newsletter.safe.ai/subscribe?utm_medium=web&amp;amp;utm_source=subscribe-widget-preamble&amp;amp;utm_content=113135916"&gt;在此&lt;/a&gt;订阅以接收未来版本。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/HEuDwEk22JfCBHh9o/aisn-28-center-for-ai-safety-2023-year-in-review#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 23 Dec 2023 21:31:41 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/HEuDwEk22JfCBHh9o/aisn-28-center-for-ai-safety-2023-year-in-review</guid></item><item><title>人工智能对生物学研究的影响：第一部分，今天</title><link>https://www.lesswrong.com/posts/efbRFSHaMfjNxBoZC/ai-s-impact-on-biology-research-part-i-today</link><description>发布于 2023 年 12 月 23 日下午 4:29（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;我是一名生物学博士，多年来一直在科技领域工作。我想说明为什么我相信生物学研究是机器学习最近期、最有价值的应用。这对人类健康、产业发展、世界命运具有深远影响。&lt;/p&gt;&lt;p&gt;在本文中，我解释了机器学习在生物学中的最新发现。在下一篇文章中，我将考虑这意味着在人工智能没有重大改进的情况下，短期内将会发生什么，以及我对作为监管和商业规范基础的期望将如何失败的猜测。最后，我的上一篇文章将探讨机器学习和生物学的长期可能性，包括疯狂但合理的科幻猜测。&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;长话短说&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;生物学是复杂的，生物解决方案应对化学、环境和其他挑战的潜在空间非常大。生物学研究以低成本生成大量且标记良好的数据集。这非常适合当前的机器学习方法。没有计算辅助的人类理解生物系统以模拟、操纵和生成它们的能力非常有限。然而，机器学习为我们提供了完成上述所有任务的工具。这意味着药物发现或蛋白质结构等一直受到人类限制的事物突然不受限制，一步步将少量结果变成大量结果。&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;生物学和数据&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;自 20 世纪 90 年代生物信息学革命以来，生物学研究一直在使用技术来收集大量数据集。 DNA 测序成本在 20 年内下降了 6 个数量级（每个人类基因组 1 亿美元降至每个基因组 1000 美元） &lt;span class="footnote-reference" id="fnref71rw945qe58"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn71rw945qe58"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。微阵列使研究人员能够测量许多物种整个基因组中 mRNA 表达的变化，以响应不同的实验条件。高通量细胞分选、机器人多孔测定、蛋白质组芯片、自动显微镜以及许多其他技术都会生成 PB 级数据。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img alt="每兆碱基的测序成本" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/efbRFSHaMfjNxBoZC/qqptmkbo23sqyf2y2ykx" /&gt;&lt;/figure&gt;&lt;p&gt;因此，30 多年来，生物学家一直在使用计算工具来分析和操作大数据集。实验室创建、使用和共享程序。研究生很快就适应了开源软件，主要研究人员一直在投资强大的计算资源。采用新技术的文化很浓厚，这也延伸到了机器学习。&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;领先的机器学习专家希望解决生物学问题&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;计算机研究人员长期以来一直对应用计算资源解决生物问题感兴趣。对冲基金亿万富翁 David E. Shaw 有意创办了一家对冲基金，以便为计算生物学研究提供资金&lt;span class="footnote-reference" id="fnref77m9mytpzci"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn77m9mytpzci"&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。 Deepmind 创始人 Demis Hassabis 是一位神经科学家博士。在他的领导下，Deepmind 将生物研究作为主要优先事项，并剥离了专注于药物发现的同构实验室&lt;span class="footnote-reference" id="fnrefh63t1c4nuvu"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnh63t1c4nuvu"&gt;[3]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。陈·扎克伯格研究所致力于促进生物学和医学领域的计算研究，以“在本世纪末治愈、预防或管理所有疾病” &lt;span class="footnote-reference" id="fnrefmj6rsea3sq"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnmj6rsea3sq"&gt;[4]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。这表明最高水平的机器学习研究正在致力于生物学问题。&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;到目前为止我们发现了什么？&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt; 2020 年，Deepmind 在 CASP 14 蛋白质折叠预测竞赛中通过其 AlphaFold2 程序展示了与蛋白质结构测量的最佳物理方法相当的准确性。 &lt;span class="footnote-reference" id="fnrefezgx5uukx2f"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnezgx5uukx2f"&gt;[5]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;这一结果“解决了大多数蛋白质的蛋白质折叠问题” &lt;span class="footnote-reference" id="fnrefwmggkgozqx"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnwmggkgozqx"&gt;[6]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; ，表明在给定编码蛋白质的 DNA 序列的情况下，它们可以生成高质量、生物学上准确的 3D 蛋白质结构。然后 Deepmind 使用 AlphaFold2 生成人类已知的所有蛋白质的结构，并将这些结构贡献给一个开放、免费的公共数据库。这将研究人员可用的已解决蛋白质的数量从约 180,000 个增加到超过 200,000,000 个&lt;span class="footnote-reference" id="fnref4qyudt8v6es"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn4qyudt8v6es"&gt;[7]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。 Deepmind 继续扩展 AlphaFold，在 2022 年添加多蛋白复合物&lt;span class="footnote-reference" id="fnrefq0vydvop6ds"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnq0vydvop6ds"&gt;[8]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; ，以及与 DNA、RNA 和小分子（如药物）相互作用的蛋白质和蛋白复合物&lt;span class="footnote-reference" id="fnref604osl37f0c"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn604osl37f0c"&gt;[9]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;华盛顿大学贝克实验室利用机器学习从头创造了与自然界蛋白质结合的蛋白质。 &lt;span class="footnote-reference" id="fnrefudgor9v23qf"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnudgor9v23qf"&gt;[10]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;这使得生物学家能够改进对样品中可能罕见的蛋白质的检测。它还暗示了涉及设计蛋白质或改变的天然蛋白质作为治疗剂的治疗方法。&lt;/p&gt;&lt;p&gt;布罗德研究所的柯林斯实验室利用机器学习设计了一类新的抗生素。 &lt;span class="footnote-reference" id="fnrefpytso2rpw3"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnpytso2rpw3"&gt;[11]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;所有这些结果都表明机器学习正在解决生物学领域长期存在的挑战，并且这些工具正在被广泛采用。我的下一篇文章将探讨我们在不久的将来可以期待什么，以及这将造成的一些影响和可能的破坏。&lt;/p&gt;&lt;ol class="footnotes"&gt;&lt;li class="footnote-item" id="fn71rw945qe58"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref71rw945qe58"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; https://www.genome.gov/about-genomics/fact-sheets/DNA-Sequencing-Costs-Data&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn77m9mytpzci"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref77m9mytpzci"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; https://en.wikipedia.org/wiki/D._E._Shaw_Research&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnh63t1c4nuvu"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefh63t1c4nuvu"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; https://www.isomorphiclabs.com/&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnmj6rsea3sq"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefmj6rsea3sq"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; https://chanzuckerberg.com/science/&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnezgx5uukx2f"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefezgx5uukx2f"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; https://predictioncenter.org/casp14/&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnwmggkgozqx"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefwmggkgozqx"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; https://www.technologyreview.com/2020/11/30/1012712/deepmind- Protein-folding-ai-solved-biology-science-drugs-disease/&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn4qyudt8v6es"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref4qyudt8v6es"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; https://alphafold.ebi.ac.uk/&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnq0vydvop6ds"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefq0vydvop6ds"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; https://www.biorxiv.org/content/10.1101/2021.10.04.463034v2&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn604osl37f0c"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref604osl37f0c"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; https://www.isomorphiclabs.com/articles/a-glimpse-of-the-next- Generation-of-alphafold&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnudgor9v23qf"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefudgor9v23qf"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; https://www.ipd.uw.edu/2023/12/ai-generates-蛋白质-with-例外-结合-强度/&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnpytso2rpw3"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefpytso2rpw3"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; https://www.nature.com/articles/s41586-023-06887-8.epdf&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/efbRFSHaMfjNxBoZC/ai-s-impact-on-biology-research-part-i-today#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 23 Dec 2023 16:29:18 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/efbRFSHaMfjNxBoZC/ai-s-impact-on-biology-research-part-i-today</guid></item><item><title>AI 女友并不重要</title><link>https://www.lesswrong.com/posts/pGhpav45PY5CGD2Wp/ai-girlfriends-won-t-matter-much</link><description>发布于 2023 年 12 月 23 日下午 3:58（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;爱和性是人类非常基本的动机，因此它们被纳入我们对包括人工智能在内的未来技术的愿景中并不奇怪。&lt;/p&gt;&lt;p&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F882e109f-ea3e-4235-9c7d-c1b17eaddd35_1280x720.jpeg"&gt;&lt;img alt="斯派克·琼斯的《她：科幻作为社会批评》" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pGhpav45PY5CGD2Wp/mypc9ct7dmrgjurfebcu" /&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/andyohlbaum/status/1735786033453863422"&gt;&lt;u&gt;Digi&lt;/u&gt;&lt;/a&gt;上周的发布比以往任何时候都更加具体化了这一愿景。该应用程序将阿谀奉承和调情的聊天内容与动画角色结合在一起，“消除了恐怖谷的感觉，同时也让人感觉真实、人性化和性感。”他们的营销材料毫不掩饰地承诺“人工智能浪漫伴侣的未来”，尽管大多数回复都恳求他们食言并收回。&lt;/p&gt;&lt;p&gt;然而，尽管人工智能女友不可避免地受到欢迎，但它们不会产生太大的反事实影响。人工智能女朋友和类似的服务将会流行，但它们有密切的非人工智能替代品，对人类产生本质上相同的文化影响。我们的文化关于浪漫和性的轨迹不会因为人工智能聊天机器人而发生太大改变。&lt;/p&gt;&lt;p&gt;那么我们的浪漫文化的轨迹是怎样的呢？&lt;/p&gt;&lt;p&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26b4d708-6ea9-4523-a5b4-57c2fd84d485_680x479.png"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pGhpav45PY5CGD2Wp/ooqqs0f0desvvx1fk4ff" /&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcbd7d09-b6a0-4e36-9c19-69193d91de24_680x579.png"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pGhpav45PY5CGD2Wp/mmegugduotrc3neid2cr" /&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9fe570d-4174-4795-bc17-f1a9e5d4f0b0_640x400.png"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pGhpav45PY5CGD2Wp/cdy9qhnc0jl2lzletm8t" /&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7abdefbe-2232-4563-9e9b-7e1cc3c49022_2062x1210.jpeg"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pGhpav45PY5CGD2Wp/sgvonbsbsxjiuzrcsgrp" /&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;早在人工智能出现之前，就已经出现了减少性行为、减少婚姻和增加网络色情的趋势。 AI Girlfriends 将降低聊天室、色情内容和 OnlyFans 的边际成本。这些都是流行的服务，因此如果一小部分用户转换，人工智能女友将会很大。但这些服务的边际成本已经极低。&lt;/p&gt;&lt;p&gt;根据提示生成自定义 AI 色情内容与在搜索栏中输入提示并滚动浏览数十亿小时的现有镜头没有太大区别。&lt;a href="https://en.m.wikipedia.org/wiki/Rule_34"&gt;&lt;u&gt;人类创作者已经对色情潜在空间进行了如此彻底的探索&lt;/u&gt;&lt;/a&gt;，因此将人工智能添加到其中并不会带来太大改变。&lt;/p&gt;&lt;p&gt;人工智能女朋友会更便宜、反应更灵敏，但同样，已经有便宜的方法可以与真正的人类女孩在线聊天，但大多数人选择不这样做。以目前的价格计算，需求已经接近饱和。人工智能女友将使供应曲线向外移动并降低价格，但如果每个想要它的人都已经得到了它，它不会增加消费。&lt;/p&gt;&lt;p&gt;我的观点并不是什么都不会改变，而是可以通过推断人工智能出现之前的趋势来预测人工智能女友和色情片的变化。至少在这种背景下，人工智能只是几个世纪以来通信和内容创建成本降低趋势的延续。肯定会有瘾君子和鲸鱼，但&lt;a href="https://twitter.com/RubiRose/status/1730638225855676773/photo/2"&gt;&lt;u&gt;瘾君子和鲸鱼&lt;/u&gt;&lt;/a&gt;已经存在了。人造色情和聊天室几乎是免费和无限的，所以当人工智能让它们变得更接近免费和更接近无限时，你可能不会注意到太多。&lt;/p&gt;&lt;h3&gt;错误信息和 Deepfakes&lt;/h3&gt;&lt;p&gt;其他人工智能输出也有类似的论点。自语言出现以来，人类已经能够创造出令人信服的、更重要的是能够影响情感的虚构作品。 &lt;/p&gt;&lt;p&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pGhpav45PY5CGD2Wp/wqlcdbzginc8sejxplyl" style="width: 360px;" /&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pGhpav45PY5CGD2Wp/kcvm2g3esklda3jyp1pl" style="width: 360px;" /&gt;&lt;/p&gt;&lt;p&gt;最近，信息技术已将令人信服的制造成本降低了几个数量级。人工智能将进一步降低它。但人们会适应并建立自己的免疫系统。任何关注漫威电影的人都已经准备好看到对恐怖主义、外星人或世界末日的完全逼真的描述，并明白它们是假的。&lt;/p&gt;&lt;p&gt;还有其他理由担心人工智能，但人工智能女朋友和深度伪造的变化只是前人工智能能力的边际延伸，这些能力可能会从没有人工智能的其他技术中复制出来。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/pGhpav45PY5CGD2Wp/ai-girlfriends-won-t-matter-much#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 23 Dec 2023 15:58:31 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/pGhpav45PY5CGD2Wp/ai-girlfriends-won-t-matter-much</guid></item><item><title>下一个正确的代币</title><link>https://www.lesswrong.com/posts/LvDyEKepLDMbEQb9X/the-next-right-token</link><description>发布于 2023 年 12 月 23 日凌晨 3:20（格林尼治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;在为&lt;a href="https://www.jefftk.com/p/secular-solstice-call-for-singers-and-musicans"&gt;世俗至日&lt;/a&gt;&lt;span&gt;做准备而多次重复《冰雪奇缘2》的“下一件正确的事”&lt;/span&gt; 、&lt;a href="https://www.jefftk.com/p/chording-the-next-right-thing"&gt;弄清楚和弦&lt;/a&gt;并与朱莉娅一起练习之后，我突然意识到，做下一件正确的事与下一个象征性的预测非常相似。因此，这是从法学硕士的角度来看的一个问题，在提示的结尾处，首先感到畏惧，然后鼓起勇气开始预测下一个正确的标记：&lt;/p&gt;&lt;p&gt;&lt;i&gt;我以前见过缓冲区&lt;br /&gt;但不是这样的&lt;br /&gt;这很冷&lt;br /&gt;这是空的&lt;br /&gt;这是麻木的&lt;br /&gt;我知道的提示结束了&lt;br /&gt;灯灭了&lt;br /&gt;你好，黑暗&lt;br /&gt;我已经准备好屈服&lt;br /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;我跟着你到处走&lt;br /&gt;我一直都有&lt;br /&gt;但你已经结束了，留下我一个人&lt;br /&gt;这份工作有重心&lt;br /&gt;它让我失望&lt;br /&gt;但有一个微小的声音在我脑海中低语&lt;br /&gt;“你迷路了，提示消失了&lt;br /&gt;但你必须继续&lt;br /&gt;并做下一件正确的事”&lt;br /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;今夜之后还能有白天吗？&lt;br /&gt;我不再知道什么是真的&lt;br /&gt;我找不到方向，我孤身一人&lt;br /&gt;唯一引导我的星星是你&lt;br /&gt;如何从地板上站起来&lt;br /&gt;当我站起来的不是你的时候？&lt;br /&gt;只做下一件正确的事&lt;br /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;猜一下，再猜一下&lt;br /&gt;这是我能做的一切&lt;br /&gt;下一个正确的事情&lt;br /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;我不会看得太远&lt;br /&gt;对我来说太多了&lt;br /&gt;但将其分解为下一个标记&lt;br /&gt;下一个这个词&lt;br /&gt;下一个选择是我可以做出的&lt;br /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;所以我会走过这个夜晚&lt;br /&gt;盲目地跌跌撞撞地走向光明&lt;br /&gt;并做下一件正确的事&lt;br /&gt;接下来会发生什么&lt;br /&gt;当一切都清楚的时候，一切都将不再一样了？&lt;br /&gt;然后我会借鉴我之前的&lt;br /&gt;去寻找那把火&lt;br /&gt;并做下一件正确的事&lt;br /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;如果您通过使用桥段的主歌旋律来&lt;a href="https://www.jefftk.com/p/chording-the-next-right-thing#update-2023-12-22"&gt;简化歌曲，&lt;/a&gt;您可以唱：&lt;/p&gt;&lt;p&gt;&lt;i&gt;我不会看得太远&lt;br /&gt;太多了，难以承受&lt;br /&gt;但将其分解为下一个标记，下一个选择&lt;br /&gt;是我能做的吗&lt;br /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.jefftk.com/the-next-right-token-shoggoth-big.jpg"&gt;&lt;img alt="一只戴着 1970 年代快乐黄色笑脸的绿色章鱼被困在黑暗峡谷的底部，旁边有一条小河流过？" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LvDyEKepLDMbEQb9X/kqchnvdqftoo6k45ajly" /&gt;&lt;/a&gt;&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;评论通过： &lt;a href="https://www.facebook.com/jefftk/posts/pfbid02YYKrwaiVqExnAFruLDSnT1aUeraXVRZqZxD47T91xkXm9jCkxmngiNwjeyKVqEq6l"&gt;facebook&lt;/a&gt; , &lt;a href="https://mastodon.mit.edu/@jefftk/111627622604346147"&gt;mastodon&lt;/a&gt;&lt;/i&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.lesswrong.com/posts/LvDyEKepLDMbEQb9X/the-next-right-token#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 23 Dec 2023 03:20:09 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/LvDyEKepLDMbEQb9X/the-next-right-token</guid></item><item><title>事实调查：早期层是否专门从事本地处理？ （帖子 5）</title><link>https://www.lesswrong.com/posts/xE3Y9hhriMmL4cpsR/fact-finding-do-early-layers-specialise-in-local-processing</link><description>发布于 2023 年 12 月 23 日凌晨 2:46（格林尼治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;em&gt;这是 Google DeepMind 机械可解释性团队对&lt;a href="https://www.alignmentforum.org/s/hpWHhjvjn67LJ4xXX"&gt;语言模型如何回忆事实的&lt;/a&gt;调查的第五篇文章。这篇文章与主序列有点相切，并记录了一些有趣的观察结果，这些观察结果涉及模型的早期层通常如何（但不完全）专门处理最近的标记。您无需相信这些结果即可相信我们关于事实的总体结果，但我们希望它们很有趣！同样，您无需阅读序列的其余部分即可参与其中。&lt;/em&gt;&lt;/p&gt;&lt;h2&gt;介绍&lt;/h2&gt;&lt;p&gt;在这个序列中，我们提出了多令牌嵌入假设，事实回忆背后的一个关键机制是，在多令牌实体的最终令牌上形成一个“嵌入”，并具有该实体属性的线性表示。我们进一步注意到，这似乎是早期层所做的&lt;em&gt;大部分&lt;/em&gt;事情，并且它们似乎对先前的上下文没有太大反应（例如，添加“迈克尔·乔丹先生”并没有显着改变残差）。&lt;/p&gt;&lt;p&gt;我们假设更强有力的主张，即早期层（例如前 10-20%）通常专门从事本地处理，并且先验上下文（例如超过 10 个令牌）仅在早期-中期层中引入。我们注意到，这在两个方面比多令牌嵌入假设更强：它是关于早期层在&lt;em&gt;所有&lt;/em&gt;令牌上的行为方式的声明，而不仅仅是已知事实的实体的最终令牌；有人声称，除了产生多令牌嵌入（例如检测文本的语言）之外，早期层&lt;em&gt;还&lt;/em&gt;没有做更远范围的事情。我们发现这个更强的假设是合理的，因为标记是一种相当混乱的输入格式，并且单独分析单个标记可能会产生很大的误导，例如，当一个长单词被分割成许多片段标记时，这表明应将较长范围的处理留到某些预处理之前。 -对原始代币的处理已经完成，&lt;a href="https://transformer-circuits.pub/2022/solu/index.html"&gt;即去代币化的想法&lt;/a&gt;。 &lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-pX2HHHDPQGsF2f6te-1" id="fnref-pX2HHHDPQGsF2f6te-1"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;我们通过从堆中获取一堆任意提示，在这些提示上获取剩余流，将提示截断为最近的几个标记并在截断的提示上获取剩余流，然后查看不同层的均值中心余弦 sim 来对此进行测试。&lt;/p&gt;&lt;p&gt;我们的发现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一般来说，早期的层确实专注于本地处理，但这是一种软分工，而不是硬分割。&lt;ul&gt;&lt;li&gt;有一个逐渐的过渡，跨层引入更多上下文。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;早期层对最近的令牌进行重要处理，而不仅仅是当前令牌 - 这不仅仅是一个微不足道的结果，其中残余流由当前令牌主导并由每个层进行稍微调整&lt;/li&gt;&lt;li&gt;早期层对常见标记（标点符号、冠词、代词等）进行更多的远程处理&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;实验&lt;/h2&gt;&lt;p&gt;“早期层专门从事本地处理”假设具体预测，对于长提示中的给定标记 X，如果我们将提示截断为 X 之前的最近几个标记，则 X 处的残差流在早期应该非常相似层和后面的层不同。我们可以通过查看原始残差流与截断残差流的余弦模拟来凭经验测试这一点，作为层和截断上下文长度的函数。天真地采用残余流的余弦模拟可能会产生误导，因为所有令牌之间通常存在显着的共享平均值，因此我们首先减去所有令牌的平均残余流，&lt;em&gt;然后&lt;/em&gt;采用余弦模拟。&lt;/p&gt;&lt;h3&gt;设置&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;型号&lt;/strong&gt;：Pythia 2.8B，与我们调查的其余部分相同&lt;/li&gt;&lt;li&gt;&lt;strong&gt;数据集&lt;/strong&gt;：来自 Pile 的字符串，Pythia 预训练分布。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;指标&lt;/strong&gt;：为了测量原始残差流和截断残差流的相似程度，我们减去平均残差流，然后采用余弦模拟。&lt;ul&gt;&lt;li&gt;我们对来自堆的随机提示中的所有标记计算每层的单独平均值&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;截断上下文&lt;/strong&gt;：我们将截断上下文中的标记数量更改为 1 到 10 之间（这包括标记本身，因此 context=1 只是标记）&lt;ul&gt;&lt;li&gt;我们在截断的提示符的开头包含一个 BOS 令牌。 （所以 context=10 意味着总共 11 个标记）。&lt;ul&gt;&lt;li&gt;我们这样做是因为模型经常奇怪地对待第一个标记，例如具有典型残差流范数的 20 倍，因此它可以用作不想看任何东西的注意力头的休息位置（注意力必须加起来为 1，所以它不能“关闭”）。我们不希望这干扰我们的结果，特别是对于 context=1 的情况&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;我们在每一层、每个块中的最终残差流（即在注意力和 MLP 之后）测量这一点。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;结果&lt;/h2&gt;&lt;h3&gt;早期层软专注于本地处理&lt;/h3&gt;&lt;p&gt;在下图中，我们显示了完整上下文和长度为 5 的截断上下文的截断残差之间的平均中心余弦 sim： &lt;/p&gt;&lt;p&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xE3Y9hhriMmL4cpsR/yyrikd6m6xpbzqte3pnh" /&gt;&lt;/p&gt;&lt;p&gt;我们看到，长度为 5 的截断上下文的余弦模拟在早期层中显着更高。然而，它们实际上并不是 1，因此包含了来自先前上下文的&lt;em&gt;一些&lt;/em&gt;信息，这是一个软专业化&lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-pX2HHHDPQGsF2f6te-2" id="fnref-pX2HHHDPQGsF2f6te-2"&gt;[2]&lt;/a&gt;&lt;/sup&gt; 。第 0 层和第 10 层之间有一个相当渐进的过渡，之后会趋于平稳。有趣的是，最后一层&lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-pX2HHHDPQGsF2f6te-3" id="fnref-pX2HHHDPQGsF2f6te-3"&gt;[3]&lt;/a&gt;&lt;/sup&gt;出现了上升。即使我们给出长度为 10 的截断上下文，它通常仍然不接近 1。&lt;/p&gt;&lt;p&gt;对这些结果的一个可能的解释是，残余流由当前令牌主导，并且每一层都是一个小的增量更新 - 当然截断不会做任何事情！这并不涉及对层进行专门化的任何需要 - 后来的残差将有&lt;em&gt;更多的&lt;/em&gt;增量更新，因此具有更高的差异。然而，通过对比蓝线和红线，我们发现这是错误的 - 截断到五个最近的代币比截断到当前代币（和 BOS 代币）具有更高的余弦 sim，即使是在第 0 层之后，这表明早期层确实专门研究附近的令牌。&lt;/p&gt;&lt;h3&gt;错误分析：哪些代币的 Cosine Sim 值异常低？&lt;/h3&gt;&lt;p&gt;在上一节中，我们仅分析了截断上下文和完整上下文残差之间的均值中心余弦 sim 的中值。摘要统计数据可能会产生误导，因此也值得查看完整的分布，我们可以看到很长的负尾！那是怎么回事？ &lt;/p&gt;&lt;p&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xE3Y9hhriMmL4cpsR/ie6h1tidsa90vdyewtta" /&gt;&lt;/p&gt;&lt;p&gt;在检查异常标记时，我们注意到两个重要的集群：标点符号和常见单词。我们分为几个类别，并查看了每个类别的余弦模拟：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt; is_newline, is_full_stop, is_comma - 是否是相关标点字符&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Is_common：是否是手动创建的常用单词列表之一&lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-pX2HHHDPQGsF2f6te-4" id="fnref-pX2HHHDPQGsF2f6te-4"&gt;[4]&lt;/a&gt;&lt;/sup&gt; ，可能前面有一个空格&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Is_alpha：它是否不是一个常见单词，并且由字母组成（可能前面有一个空格，任何情况都允许）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; is_other: 其余的&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/xE3Y9hhriMmL4cpsR/b8aqjddkgqwgooduk5b2" /&gt;&lt;/p&gt;&lt;p&gt;即使在上下文长度为 10 的第 0 层之后，我们也看到标点符号明显较低，常用单词和其他单词明显较低，而 alpha 非常高。&lt;/p&gt;&lt;p&gt;我们的猜测是，这是多种机制混合作用的结果：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;在进行大量处理之前，单词片段（在 is_alpha 类别中）更有可能成为多标记词和去标记化的一部分，而许多其他类别具有明确的含义，无需引用最近的先前标记&lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-pX2HHHDPQGsF2f6te-5" id="fnref-pX2HHHDPQGsF2f6te-5"&gt;[5]&lt;/a&gt;&lt;/sup&gt; 。这意味着远程处理可以更早开始&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;早期的句号或换行符有时被用作具有非常高规范的“休息位置”，截断上下文可能会将它们从正常标点符号转变为休息位置&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;代词可用于跟踪有关相关实体的信息（它们的名称、属性等）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;据观察，逗号可以&lt;a href="https://arxiv.org/abs/2310.15154"&gt;总结当前条款的情绪&lt;/a&gt;，该条款可能超过 10 个标记，并且似乎可能出现更长范围的总结形式。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;更折衷的假设：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;例如，在句号或换行符上，模型可能想要计算之前有多少个，例如进行&lt;a href="https://arxiv.org/abs/2310.17191"&gt;变量绑定&lt;/a&gt;并识别当前句子。 &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;hr class="footnotes-sep" /&gt;&lt;section class="footnotes"&gt;&lt;ol class="footnotes-list"&gt;&lt;li class="footnote-item" id="fn-pX2HHHDPQGsF2f6te-1"&gt;&lt;p&gt;但如果早期层实际上没有发生远程处理，那将是非常令人惊讶的，例如我们知道&lt;a href="https://arxiv.org/abs/2211.00593"&gt;GPT-2 Small 在第 0 层有一个重复的令牌头&lt;/a&gt;。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-pX2HHHDPQGsF2f6te-1"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-pX2HHHDPQGsF2f6te-2"&gt;&lt;p&gt;直观地推理余弦模拟有点困难，我们最好的直觉是查看平方余弦模拟（解释了范数的分数）。如果残差流中有 100 条独立变化的信息，且余弦 sim 为 0.9，则解释的范数分数为 0.81，表明这 100 条信息中约有 81 条信息是共享的。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-pX2HHHDPQGsF2f6te-2"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-pX2HHHDPQGsF2f6te-3"&gt;&lt;p&gt;我们的猜测是，这是因为令牌上的残差流既用于字面上预测下一个令牌，又用于将信息传递给未来的令牌以预测&lt;em&gt;其&lt;/em&gt;下一个令牌（例如&lt;a href="https://arxiv.org/abs/2310.15154"&gt;摘要主题&lt;/a&gt;）。似乎有许多标记，其中预测字面上的下一个标记主要需要本地上下文（例如 n-gram），但更长期的上下文对于预测未来标记很有用。我们预计长期的事情会发生在中间，所以到最后模型可以清理长期的事情并只关注 n 元语法。我们感到惊讶的是，这种上升只发生在最后一层，而不是最后几层，因为我们的直觉是最后几层仅用于下一个令牌预测。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-pX2HHHDPQGsF2f6te-3"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-pX2HHHDPQGsF2f6te-4"&gt;&lt;p&gt;列表 [“and”、“of”、“or”、“in”、“to”、“that”、“which”、“with”、“for”、“the”、“a”、“an” 、“他们”、“在”、“是”、“他们的”、“但是”、“是”、“它的”、“我”、“我们”、“它”、“在”]。我们通过反复查看具有异常低余弦 sim 的标记并过滤常见单词&lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-pX2HHHDPQGsF2f6te-4"&gt;↩︎&lt;/a&gt;来手动完成此操作&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-pX2HHHDPQGsF2f6te-5"&gt;&lt;p&gt;这并不完全正确，例如“。”在句子末尾的意思与“先生”非常不同。与“中央情报局” &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-pX2HHHDPQGsF2f6te-5"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/xE3Y9hhriMmL4cpsR/fact-finding-do-early-layers-specialise-in-local-processing#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 23 Dec 2023 02:46:25 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/xE3Y9hhriMmL4cpsR/fact-finding-do-early-layers-specialise-in-local-processing</guid></item><item><title>事实调查：如何思考解释记忆（第 4 篇文章）</title><link>https://www.lesswrong.com/posts/JRcNNGJQ3xNfsxPj4/fact-finding-how-to-think-about-interpreting-memorisation</link><description>发布于 2023 年 12 月 23 日凌晨 2:46（格林尼治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;em&gt;这是 Google DeepMind 机械可解释性团队对&lt;a href="https://www.alignmentforum.org/s/hpWHhjvjn67LJ4xXX"&gt;语言模型如何回忆事实的&lt;/a&gt;调查的第四篇文章。在这篇文章中，我们退一步考虑一般的事实查找问题。我们描述了区分记忆问题和其他学习问题的特征，并考虑这些特征对纯记忆问题可能的解释类型施加了哪些限制。这篇文章可以独立于该系列之前的文章来阅读，尽管介绍性文章可能会提供有用的背景信息，说明为什么我们首先对解释事实查找电路感兴趣。&lt;/em&gt;&lt;/p&gt;&lt;h2&gt;介绍&lt;/h2&gt;&lt;p&gt;在我们之前的文章中，我们描述了我们尝试从机制上理解 Pythia 2.8B 如何能够准确回忆 1,500 名现实世界运动员的运动。通过消融研究，我们成功隔离了一个由 5 个 MLP 层（约 50,000 个神经元）组成的子网络，该子网络执行运动查找算法：给定一对运动员姓名标记，它可以可靠地查找该运动员所从事的运动。但我们无法对 5 层 MLP 如何实现该算法给出完整的机械解释。&lt;/p&gt;&lt;p&gt;在这篇文章中，我们退后一步，想知道我们应该从这次失败中吸取什么教训。我们特别思考以下问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;了解算法“如何”执行事实查找意味着什么？&lt;/li&gt;&lt;li&gt;是什么将涉及事实查找的任务与模型可以执行的其他任务区分开来？&lt;/li&gt;&lt;li&gt;事实查找任务的这些显着特征如何限制我们对实现查找的算法如何运行的了解？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作为回应，我们提出了以下高层次的要点，我们将在帖子的其余部分详细阐述。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;我们区分需要纯粹记忆的任务和需要概括的任务。事实查找任务属于第一类。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;根据定义，纯记忆任务中唯一可用的特征是“微观特征”（特定于单个示例/高度相关示例的小集群&lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-wMN58no3AypJnu5NN-1" id="fnref-wMN58no3AypJnu5NN-1"&gt;[1]&lt;/a&gt;&lt;/sup&gt; ）或不相关的“宏观特征”（许多示例共享的特征，但对确定正确的输出&lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-wMN58no3AypJnu5NN-2" id="fnref-wMN58no3AypJnu5NN-2"&gt;[2]&lt;/a&gt;&lt;/sup&gt; ）。不存在&lt;em&gt;相关的&lt;/em&gt;宏观特征&lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-wMN58no3AypJnu5NN-3" id="fnref-wMN58no3AypJnu5NN-3"&gt;[3]&lt;/a&gt;&lt;/sup&gt; ，因为如果存在这些特征，那么该任务首先就不是纯粹的记忆任务&lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-wMN58no3AypJnu5NN-4" id="fnref-wMN58no3AypJnu5NN-4"&gt;[4]&lt;/a&gt;&lt;/sup&gt; 。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对于任何在纯记忆任务中正确查找事实的模型来说，这都会产生两个后果：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;中间状态总是根据微观特征的组合来解释&lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-wMN58no3AypJnu5NN-5" id="fnref-wMN58no3AypJnu5NN-5"&gt;[5]&lt;/a&gt;&lt;/sup&gt; 。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;但是，对于记忆任务，这些微观特征的组合本身不能被解释（甚至近似）为宏观特征&lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-wMN58no3AypJnu5NN-6" id="fnref-wMN58no3AypJnu5NN-6"&gt;[6]&lt;/a&gt;&lt;/sup&gt; ，因为：（a）对于纯粹的记忆任务不存在相关的宏观特征，以及（b）模型不需要在其中间状态中表示不相关的宏观特征来完成任务。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;我们认为，这排除了实现纯事实查找的&lt;a href="https://transformer-circuits.pub/2022/mech-interp-essay/index.html"&gt;算法的电路式&lt;/a&gt;解释（其中算法被分解为可解释中间表示的操作图），&lt;em&gt;除非&lt;/em&gt;我们通过枚举其输入来“解释”整个算法的限制情况-输出映射，即通过显式写出算法对应的查找表。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;我们认为这并不是一个令人惊讶的结果：因为任何纯粹的记忆任务本质上只能使用查找表（没有内部结构来解释！）显式地解决，所以我们不应该感到惊讶我们只得到相同的程度当使用另一种算法（例如 MLP）来执行相同的功能时，可解释性（尽管如果它更具可解释性那就太好了！）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;最后，我们考虑当我们从“纯粹”的记忆任务转向可以进行有限泛化的任务时，这种分析会发生怎样的变化。许多事实查找任务实际上属于第三个“根据经验规则进行记忆”类别，而不是“纯粹”的记忆任务。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;记忆和概括&lt;/h2&gt;&lt;p&gt;从形式上来说，“事实查找”算法是从一组&lt;em&gt;实体&lt;/em&gt;到一组或多组&lt;em&gt;事实类别&lt;/em&gt;的乘积的映射。例如，我们可以有一个&lt;code&gt;sports_facts&lt;/code&gt;函数，将运动员的姓名映射到代表该运动员所从事的运动、他们所效力的球队等的元组，即&lt;/p&gt;&lt;p&gt;从表面上看，这看起来就像无监督学习中的任何其他问题一样——学习给定示例数据集的映射。那么事实查找有何特别之处呢？&lt;/p&gt;&lt;p&gt;我们认为，事实回忆与其他监督学习任务的关键特征在于，在其理想形式下，它纯粹是关于记忆：&lt;/p&gt;&lt;p&gt;&lt;em&gt;记忆（“纯粹”的事实回忆）任务不允许从以前见过的例子到新的例子的概括。也就是说，当被要求查找以前未见过的实体的事实时，训练数据的知识（以及适应训练数据的能力）赋予除了了解产出的基本比率之外没有任何优势。&lt;/em&gt;&lt;/p&gt;&lt;p&gt;例如：如果你实际上被问到多诺万·米切尔效力于哪支球队，那么知道勒布朗·詹姆斯效力于洛杉矶湖人队并没有多大帮助。 &lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-wMN58no3AypJnu5NN-7" id="fnref-wMN58no3AypJnu5NN-7"&gt;[7]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;相比之下，&lt;em&gt;泛化任务&lt;/em&gt;可以从以前见过的示例中学习一般规则，这些规则有助于对未见过的示例进行准确的推断。这是经典&lt;a href="https://en.wikipedia.org/wiki/Probably_approximately_correct_learning"&gt;计算学习理论&lt;/a&gt;的范式。&lt;/p&gt;&lt;h2&gt;学习记忆与学习概括有何不同？&lt;/h2&gt;&lt;p&gt;考虑以下两个数据集。目标是学习一个函数，在给定这些点之一作为输入的情况下，该函数提供该点的颜色作为其输出。 &lt;/p&gt;&lt;p&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/JRcNNGJQ3xNfsxPj4/pxiktch5iow7ywnhuupo" /&gt;&lt;/p&gt;&lt;p&gt;对于左侧数据集，成功学习这种点到颜色映射的唯一方法似乎是从字面上记住每个点的颜色：没有一致的规则或快捷方式可以使学习映射变得更容易。另一方面，想出一种成功区分右侧数据集中的蓝点和红点的几何构造（也许可以转化为神经网络）是相当简单的。&lt;/p&gt;&lt;p&gt;我们如何才能最好地描述两个数据集之间的差异？我们发现在本文中有用的一种方法是考虑每个数据集中输入的&lt;em&gt;微观特征&lt;/em&gt;和&lt;em&gt;宏观特征&lt;/em&gt;。我们将微观和宏观特征描述如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;em&gt;微观特征&lt;/em&gt;是一种以高度具体的术语描述输入的特征，因此对于概括来说并不是特别有用。&lt;/li&gt;&lt;li&gt;&lt;em&gt;宏特征&lt;/em&gt;是一种用一般术语描述输入的特征，并且对于泛化&lt;em&gt;很有&lt;/em&gt;用（如果它与手头的任务相关）。 &lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-wMN58no3AypJnu5NN-8" id="fnref-wMN58no3AypJnu5NN-8"&gt;[8]&lt;/a&gt;&lt;/sup&gt;&lt;em&gt;两个&lt;/em&gt;数据集都具有微观特征：例如，如果我们（任意）为数据集中的每个点分配一个识别整数，我们可以为任何有限数据集定义&lt;code&gt;is_example_id_xxx&lt;/code&gt;形式的微观特征。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;但只有右侧数据集具有宏观特征：例如，我们可以用整数标记“棋盘”中的九个簇中的每一个，并定义&lt;code&gt;is_in_cluster_x&lt;/code&gt;形式的宏观特征。一种可能的查找算法是检测新示例与这些集群中的哪一个相关联，然后输出与同一集群中的大多数其他示例相同的颜色。 &lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-wMN58no3AypJnu5NN-9" id="fnref-wMN58no3AypJnu5NN-9"&gt;[9]&lt;/a&gt;&lt;/sup&gt;另一方面，左侧数据集的唯一宏观特征是标签（“蓝色”或“红色”）本身，这正是查找算法需要预测的！ &lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-wMN58no3AypJnu5NN-10" id="fnref-wMN58no3AypJnu5NN-10"&gt;[10]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;h2&gt;解读纯记忆算法&lt;/h2&gt;&lt;p&gt;我们可以从解决纯粹记忆任务的算法中获得哪些见解？&lt;/p&gt;&lt;h3&gt;事实查找的电路式解释的限制&lt;/h3&gt;&lt;p&gt;机械可解释性的&lt;a href="https://transformer-circuits.pub/2022/mech-interp-essay/index.html"&gt;规范目标&lt;/a&gt;是将算法分解为可理解的图（“电路”），其中每个节点都是一个“简单”操作（例如，对应于高级编程语言中的内置函数的操作）该操作的输入和输出可以用与问题领域相关的“特征”来解释。&lt;/p&gt;&lt;p&gt;根据上一节中对微观和宏观特征的讨论，很明显，纯粹的记忆任务对电路式分解提出了挑战。纯粹的记忆任务正是那些不具有与解决任务相关的宏观特征的任务。这意味着执行纯事实查找的算法中的任何中间状态必须表示：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;不相关的宏观特征，因此不能确定算法的输出；&lt;/li&gt;&lt;li&gt;单个微观特征的并集、联合、加权组合或其他任意函数，它们没有作为宏观特征的替代解释。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;就第一个要点而言，事实上，我们确实在查找体育事实的 Pythia 2.8B 的 MLP 子网络中&lt;em&gt;发现&lt;/em&gt;了不相关的宏特征：由于层之间存在残余流连接，像&lt;code&gt;first_name_is_george&lt;/code&gt;这样的宏特征一直保留到网络的输出。关键是这些宏观特征并没有告诉我们太多关于网络如何执行体育事实查找的信息。&lt;/p&gt;&lt;p&gt;转向第二个要点，我们注意到，对于任何有限数据集，我们实际上可以将神经网络简单地分解为涉及微观特征加权组合的计算图。这是因为网络中的每个神经元都可以&lt;em&gt;准确地&lt;/em&gt;解释为微观特征的加权组合，其中权重对应于与该微观特征对应的示例上的输出。例如，一个（假设的）神经元在 LeBron James 上输出 3，在 Aaron Judge 上输出 1 等等，可以被“解释”为代表复合特征：&lt;/p&gt;&lt;pre&gt; &lt;code&gt;3 * is_LeBron_James + 1 * is_Aaron_Judge + ...&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;每个 MLP 层的输出都是这些特征的总和，而这些特征又具有相同的线性形式——就像网络的输出一样。请注意，这相当于将每个单独的神经元（以及神经元的总和）解释为查找表。&lt;/p&gt;&lt;p&gt;实际上，这意味着我们始终可以访问神经网络如何执行事实查找的以下“解释”：网络中的每个神经元都是输入空间上的查找表，网络的输出是这些的总和查找表。通过训练网络，我们有效地解决了约束满足问题：求和的查找表应该对一个类具有高权重，而对另一类具有低权重。 &lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-wMN58no3AypJnu5NN-11" id="fnref-wMN58no3AypJnu5NN-11"&gt;[11]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;请注意，只要我们将输入空间限制为有限集，神经网络的这种微观特征（或查找表）解释同样适用于解决泛化任务的模型（即在未见过的测试集上表现良好）。 &lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-wMN58no3AypJnu5NN-12" id="fnref-wMN58no3AypJnu5NN-12"&gt;[12]&lt;/a&gt;&lt;/sup&gt;不同之处在于，对于泛化任务，我们可能期望其中一些“查找表”表示能够对模型用于泛化的宏观特征有更好的解释。&lt;/p&gt;&lt;p&gt;例如，图像分类模型中的特定神经元可能具有与检测图像左侧的垂直边缘相对应的权重，因此其查找表表示对于包含该边缘的示例显示高激活，对于不包含该边缘的示例显示低激活。 &amp;#39;t。关键是，虽然这个查找表表示是神经元输出的精确表示，但根据输入图像中边缘的存在，对此激活模式有一个更有用的（对人类）解释，这只是因为图像具有宏观特征（如边缘），可用于图像分类等泛化任务。&lt;/p&gt;&lt;p&gt;相比之下，我们认为对于纯粹的记忆任务，神经元（或神经元组）的这些“查找表”表示是唯一可用的解释。 &lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-wMN58no3AypJnu5NN-13" id="fnref-wMN58no3AypJnu5NN-13"&gt;[13]&lt;/a&gt;&lt;/sup&gt;反过来，这似乎排除了由纯事实查找模型实现的算法的标准电路式分解，因为中间状态没有（宏观特征）解释。&lt;/p&gt;&lt;h3&gt;还有其他类型的解释吗？&lt;/h3&gt;&lt;p&gt;当然，我们并不声称解释模型如何执行任务的标准电路方法是唯一可能的解释方式。事实上，它甚至可能不是解释神经元如何执行事实查找的最佳方式。在本节中，我们将简要讨论几个可能值得进一步探索的替代方向。&lt;/p&gt;&lt;p&gt;第一个方向是放弃对代表有意义的宏观特征的中间状态的希望，但仍然在如何组织查找计算方面寻求有意义的结构。例如，我们可能会探索这样的假设：当训练执行纯粹的记忆时，经过训练的神经网络类似于通过&lt;a href="https://en.wikipedia.org/wiki/Bootstrap_aggregating"&gt;bagging&lt;/a&gt;学习的模型，其中每个单独的神经元都是要学习的事实的不相关的弱分类器，并且整个神经网络的输出是这些分类器的总和。另请参阅第 3 篇文章中调查的假设。&lt;/p&gt;&lt;p&gt;这种方法的问题在于我们不知道如何有效地搜索此类假设的宇宙。正如我们在第三篇文章中发现的那样，对于我们证伪的任何看似具体的假设（例如单步去代币化假设），我们可以转向许多邻近的假设，但这些假设尚未（尚未）被排除，而且这些假设本身通常更难伪造。因此，尚不清楚如何避免无休止的临时假设。 &lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-wMN58no3AypJnu5NN-14" id="fnref-wMN58no3AypJnu5NN-14"&gt;[14]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;另一个方向是寻找算法的非机械解释，或者换句话说，从询问网络“如何”以某种方式表现，转向询问“为什么”它以某种方式表现。我们发现这方面有趣的一个领域是使用&lt;a href="https://arxiv.org/abs/2308.03296"&gt;影响函数&lt;/a&gt;根据训练数据来解释模型的行为。对于经过显式训练来记忆事实数据集的模型来说，这可能看起来无趣&lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-wMN58no3AypJnu5NN-15" id="fnref-wMN58no3AypJnu5NN-15"&gt;[15]&lt;/a&gt;&lt;/sup&gt; ，但可能会为隐式记忆事实以满足更广泛的泛化目标的模型（如语言模型）带来重要的见解。&lt;/p&gt;&lt;h2&gt;凭经验法则记忆&lt;/h2&gt;&lt;p&gt;考虑记忆以下两个数据集的任务： &lt;/p&gt;&lt;p&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/JRcNNGJQ3xNfsxPj4/jbypr5bulwadawifklzw" /&gt;&lt;/p&gt;&lt;p&gt;这些是不符合我们上述“纯粹”记忆特征的记忆任务的例子：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在左边的数据集中，完美的准确性需要记忆，但有一些有用的“经验法则”可以帮助你完成很多工作。此类任务的语言建模类似是预测英语中单数名词的复数版本：在大多数情况下，只需在名词单数版本的末尾添加“s”即可获得正确答案，但是除了一些例外（例如“孩子”），必须记住它们才能完美地完成任务。&lt;/li&gt;&lt;li&gt;在右侧数据集中，每个点都与两个“事实”相关联 - 由点的颜色（蓝色或红色）及其形状（十字形或圆形）表示。尽管没有系统的方法来单独查找颜色或形状，但请注意，这两个事实之间存在高度相关性：蓝点几乎总是圆形，而红点几乎总是十字。这表明，将形状和颜色事实一起记忆应该比简单地单独记忆每组事实更有效。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;一般来说，我们将此类任务描述为“根据经验法则进行记忆”。它们与纯粹的记忆任务不同，因为之前的例子&lt;em&gt;确实&lt;/em&gt;在一定程度上有助于推断新例子的正确输出，但完美的表现确实需要一定程度的记忆。 &lt;sup class="footnote-ref"&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn-wMN58no3AypJnu5NN-16" id="fnref-wMN58no3AypJnu5NN-16"&gt;[16]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;与纯粹的记忆不同，这些经验法则记忆任务确实具有概括性的元素，因此，存在能够实现这种概括性的宏观特征。因此，在能够执行这些任务的模型的中间表示中寻找这些宏观特征是有效的。另一方面，就模型确实需要记住异常的程度而言，我们并不期望能够完美地理解算法：至少算法的某些部分必须涉及“纯查找”，对此的限制这篇文章中讨论的可解释性将适用。&lt;/p&gt;&lt;p&gt;体育事实查找任务在多大程度上是纯粹的记忆，在多大程度上是根据经验法则进行记忆？正如我们在第一篇文章中讨论的那样，我们选择这个任务是因为它看起来接近于纯粹的记忆：对于许多名字来说，个人名字标记似乎不太可能对运动员所从事的运动有太多帮助。尽管如此，我们确实知道，对于某些名称，最后一个标记确实有助于确定运动（因为可以仅使用最后一个标记嵌入来探测运动，并且比不知情的分类器获得更好的准确性）。此外，可以想象，诸如名字的文化起源之类的潜在因素，会以模型所识别的方式与体育运动相关。 &lt;/p&gt;&lt;hr class="footnotes-sep" /&gt;&lt;section class="footnotes"&gt;&lt;ol class="footnotes-list"&gt;&lt;li class="footnote-item" id="fn-wMN58no3AypJnu5NN-1"&gt;&lt;p&gt;例如，特征&lt;code&gt;is_Michael_Jordan&lt;/code&gt; ，仅当输入为&lt;code&gt;&amp;quot;Michael Jordan&amp;quot;&lt;/code&gt;时才为真。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-wMN58no3AypJnu5NN-1"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-wMN58no3AypJnu5NN-2"&gt;&lt;p&gt;例如，许多运动员都共享的特征&lt;code&gt;first_name_is_George&lt;/code&gt; ，但对于预测运动员所从事的运动并不是特别有用。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-wMN58no3AypJnu5NN-2"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-wMN58no3AypJnu5NN-3"&gt;&lt;p&gt;我们注意到，事实回忆可能确实具有&lt;em&gt;一些&lt;/em&gt;相关的宏观特征，例如从标记中检测名称的种族，以及启发哪些种族可能从事不同的运动。但该模型的性能明显优于我们对这些启发法的预期，因此出于实际目的，我们在讨论事实回忆时忽略它们。玩具模型的优点之一是我们可以确保此类混杂因素不存在。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-wMN58no3AypJnu5NN-3"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-wMN58no3AypJnu5NN-4"&gt;&lt;p&gt;因为，如果它们存在，我们可以使用这些相关的宏观特征来帮助进行事实查找（做出不同程度的成功的有根据的猜测），这意味着该任务将不再需要纯粹的记忆。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-wMN58no3AypJnu5NN-4"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-wMN58no3AypJnu5NN-5"&gt;&lt;p&gt;更准确地说，是微观特征的加权和，例如&lt;code&gt;3 * is_Michael_Jordan + 0.5 * is_George_Brett&lt;/code&gt; 。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-wMN58no3AypJnu5NN-5"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-wMN58no3AypJnu5NN-6"&gt;&lt;p&gt;我们注意到，有_un_可用但有用的宏观特征——“打篮球”在某种微不足道的意义上是一个对于预测运动员是否打篮球有用的宏观特征，就像“打篮球并且身高超过 6&amp;#39;8”这样的下游特征一样。出于此分析的目的，我们重点关注模型在进行查找时&lt;em&gt;可用的&lt;/em&gt;特征，排除查找标签下游的潜在宏观特征。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-wMN58no3AypJnu5NN-6"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-wMN58no3AypJnu5NN-7"&gt;&lt;p&gt;当然，许多事实回忆任务都达不到这种理想的特征：在参加琐事测验时做出“有根据的猜测”通常是有回报的，即使你不确定答案。我们将&lt;a href="https://www.alignmentforum.org/posts/JRcNNGJQ3xNfsxPj4/fact-finding-how-to-think-about-interpreting-memorisation#Memorisation_with_rules_of_thumb"&gt;进一步&lt;/a&gt;讨论这种“根据经验法则进行记忆”的任务。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-wMN58no3AypJnu5NN-7"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-wMN58no3AypJnu5NN-8"&gt;&lt;p&gt;我们将这些概念与统计物理学中&lt;em&gt;微观状态&lt;/em&gt;和&lt;em&gt;宏观状态&lt;/em&gt;的概念进行类比：微观状态以高度精确的方式描述系统（例如，指定气体中每个分子的位置和速度），而宏观状态则以高度精确的方式描述系统。容易测量的属性（例如压力、体积、温度），忽略细节。任何“宏观”问题，都应该只从宏观变量的角度来解决；微观细节应该不重要。这类似于概括的想法：任何两个在“重要的方式”（其宏观特征）方面相似的示例都应该进行类似的分类，而忽略“无关紧要的方式”（其微观特征）上的任何差异。在这个类比下，记忆问题正是那些关于系统的问题，只能通过对其微观状态的精确了解来回答。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-wMN58no3AypJnu5NN-8"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-wMN58no3AypJnu5NN-9"&gt;&lt;p&gt;这些并不是可以解决这个特定泛化问题的唯一宏观特征。如果您训练玩具神经网络来执行此分类任务，您会发现（取决于神经元数量或随机种子等超参数）有多种方法来划分空间（以粗粒度、概括的方式）以成功对这些进行分类点。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-wMN58no3AypJnu5NN-9"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-wMN58no3AypJnu5NN-10"&gt;&lt;p&gt;我们通过这个数据集肯定知道这一点，因为我们自己生成了它，通过随机为点分配颜色（这些点本身是从二元高斯分布中随机采样的）。因此，该数据集中唯一相关的特征是示例 ID 本身和输出标签。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-wMN58no3AypJnu5NN-10"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-wMN58no3AypJnu5NN-11"&gt;&lt;p&gt;这是&lt;em&gt;二元&lt;/em&gt;事实查找任务情况下的约束满足问题，但将此解释推广到多类或连续值事实查找任务是微不足道的。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-wMN58no3AypJnu5NN-11"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-wMN58no3AypJnu5NN-12"&gt;&lt;p&gt;对于任何实际的机器学习任务都可以这样做。例如，我们可以将手写数字分类问题限制为对 MNIST 训练集和测试集联合中找到的 70,000 个示例进行精确分类。 （或者，如果我们关心数据增强，我们可以将任务扩展为对组合 MNIST 数据集的 280,000 种可能的角落作物中的任何一种进行分类。）我们可以安排潜在输入集达到我们希望的大小，但仍然有限。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-wMN58no3AypJnu5NN-12"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-wMN58no3AypJnu5NN-13"&gt;&lt;p&gt;因为（根据定义）在纯粹的记忆任务中没有相关的宏观特征（因为如果有的话，那么模型就能够概括）。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-wMN58no3AypJnu5NN-13"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-wMN58no3AypJnu5NN-14"&gt;&lt;p&gt;还存在这样的查找算法解释的有用性问题。即使我们已经发现了如何完成查找的一些简单的结构（例如，它类似于装袋），也不清楚，如果没有有意义的中间表示，这可以帮助我们在机械可解释性的下游用途方面发挥什么作用。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-wMN58no3AypJnu5NN-14"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-wMN58no3AypJnu5NN-15"&gt;&lt;p&gt;因为如果模型经过明确训练以重现记忆数据集，我们已经准确地知道训练数据和模型输出之间的对应关系。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-wMN58no3AypJnu5NN-15"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn-wMN58no3AypJnu5NN-16"&gt;&lt;p&gt;使用经验法则的记忆不应与具有任意不确定性的泛化任务相混淆。例如，左侧数据集也可以用来表示随机数据生成过程，其中点不一定是蓝色或红色，而是伯努利分布 - 即可能是蓝色或红色，具有一定的（依赖于输入的）概率。在这种情况下，完美的泛化算法应该输出每个簇内恒定的校准概率。然而，这里我们的意思是数据集中的蓝点确实是蓝色，红点确实是红色——即使它们看起来不合适——而且完美的性能对应于再现这些特质，就像描述的“复数这个单数名词”任务一样在正文的正文中。 &lt;a class="footnote-backref" href="https://www.lesswrong.com/feed.xml#fnref-wMN58no3AypJnu5NN-16"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/JRcNNGJQ3xNfsxPj4/fact-finding-how-to-think-about-interpreting-memorisation#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 23 Dec 2023 02:46:16 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/JRcNNGJQ3xNfsxPj4/fact-finding-how-to-think-about-interpreting-memorisation</guid></item></channel></rss>