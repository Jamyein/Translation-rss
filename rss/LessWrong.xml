<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>少错</title><link>https://www.lesswrong.com</link><description>致力于提炼理性艺术的社区博客</description><lastBuildDate>Tue, 05 Dec 2023 12:21:21 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>与我的学生的苏格拉底式对话</title><link>https://www.lesswrong.com/posts/TtdJt78mgGiDubnAM/a-socratic-dialogue-with-my-student</link><description>发布于 2023 年 12 月 5 日上午 9:31（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;这是我和我的学生诺姆之间的对话。经他许可，以编辑形式转载。评论时，请考虑他是一个青少年。其中许多想法对他来说都是&lt;a href="https://xkcd.com/1053/"&gt;新的&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;怎样才能招到学生呢？你偷了它们。他以前的老师是一位马克思主义者。我在辩论中彻底摧毁了他以前的老师，以至于他放弃了她的教诲，现在转而听我的。&lt;/p&gt;&lt;p&gt;我认为这段对话展示了良好的教学技巧。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我让诺姆来判断什么是合理的、什么是有道理的、什么是“证据”。在诺姆出生之前，我参加了我的第一次辩论比赛。这个障碍稍微缩小了差距。&lt;/li&gt;&lt;li&gt;我提出一系列问题，而不只是说“ &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是真的”。这使得&lt;a href="https://www.lesswrong.com/posts/NMoLJuDJEms7Ku9XS/guessing-the-teacher-s-password"&gt;密码猜测&lt;/a&gt;变得不可能。他是在下棋，不是在&lt;i&gt;危险边缘！&lt;/i&gt;&lt;/li&gt;&lt;li&gt;我避免告诉诺姆我的信仰，除非他明确询问。这对诺姆来说更有趣，因为没有人喜欢未经请求的讲道。这也更有说服力，因为结论感觉像是他的结论。&lt;/li&gt;&lt;li&gt;当诺姆改变话题时，我立即退缩了。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;我知道你反对免除学生贷款债务。你能告诉我为什么吗？我这样做是为了一场演讲和辩论比赛。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;你&lt;a href="https://www.youtube.com/watch?v=o_wNNjfCG1E&amp;amp;t=4s"&gt;以前不相信&lt;/a&gt;支持救济的论点吗？当然，重复曾经说服你的论点并不困难。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;我不知道我现在是否有足够的研究来与像你这样的人辩论。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;你并不是想说服我。你正试图说服&lt;a href="https://www.youtube.com/watch?v=xuaHRN7UhRo"&gt;&lt;i&gt;他们&lt;/i&gt;&lt;/a&gt;。利用他们的偏见、非理性、部落主义和无知。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;我还必须安抚评委们。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;我就是这么说的。&lt;/p&gt;&lt;hr /&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;我正在努力寻找一个关于学生贷款减免的好论据。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;但是你以前不是很赞同吗？当然，你可以重复曾经说服你的糟糕论点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;这些都是道德争论，没有任何经济理解。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;没关系。你的听众可能是经济文盲。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;不知何故，我认为我们作为赞成免除所有学生贷款债务的一方赢得了一次胜利。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;干得好。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;谢谢。&lt;/p&gt;&lt;hr /&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;你听说过“有效利他主义”吗？您可能会喜欢他们推出的一些东西。它往往具有道德一致性和经济素养（与主要的民主共和党、社会主义等政治纲领不同）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;不，但我会调查一下。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;你可能不同意。但我预计它的智力稳健性会让你耳目一新。&lt;/p&gt;&lt;hr /&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;这是否意味着我自杀然后将我所有的器官捐献给需要它们的人是道德的？我想，除非我能在不自杀的情况下拯救更多的生命。也许更好的论点是自杀，让某人卖掉我所有的身体部位，然后用这笔钱购买疟疾网，送给生活在非洲的人们。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;你可以在不自杀的情况下拯救更多生命。而且，我想不出有哪个 EA 曾为此案自杀过。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;可能是因为我们直觉上认为自杀是错误的。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;不要因为肾脏的事情而分心。基本思想如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;美国政府需要花费 10,000,000 美元才能挽救一个美国人的生命。&lt;/li&gt;&lt;li&gt;在非洲，通过公共卫生措施挽救一条生命需要 5,000 美元。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这就是我上个月为非洲公共卫生措施捐赠 20 美元的原因。它的作用相当于美国联邦政府花费的 40,000 美元。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;是的，确实如此。在美国靠什么拯救生命？&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;基本的想法是你应该计算数字。&lt;/p&gt;&lt;figure class="media"&gt;&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;我认为这对钱有用，但我不知道它是否可以完全应用于所有事情。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;为什么不呢？具体例子。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;嗯，这取决于你是否认为人类应该拥有受保护的权利。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;这不是一个具体的例子。您的主张可能适用于什么现实世界的决定？请明确点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;一位医生有5名病人需要器官移植，否则他们就会死。有一名完全健康的人因接受小手术而处于麻醉状态。如果我们仔细计算一下数字，医生应该杀死那个人才能挽救五个人的生命。如果你认为人类有权利，那就是不道德的。如果你认为人类不会，那就不会了。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;正确。这显然是不道德的。但人权并不是医生不应该谋杀病人的唯一原因。你能想到一种实用主义的吗？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;医生会失去执照，然后他们就会失业。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;如果没有许可证要求怎么办？比如在战区。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;患者将来也许能够挽救生命。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt; 5 个器官接受者也可以。另一个原因。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;我不确定。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;没有人会去看他们认为会谋杀他们的医生。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;如果是战区，那么可能没有其他选择。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;公平。您熟悉“义务论伦理学”这个词吗？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;是的。任何有最好意图的事情都是如此。那是对的吗？我可能已经忘记了。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;没有。这不是最好的意图。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;好的。之后怎么样了？&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;义务论伦理遵循“不要杀死你的病人”这样的良好规则。 EA 相信要处理数字，但它们通常不会违反义务论限制。当我捐20美元时，我捐的是我自己的钱。我没有偷它。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;好的。让我想想我是否发现任何缺陷。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;慢慢来。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;如果你遵循我认为好的规则，并且你帮助了最多的人，那么我不可能反对。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;那是 EA。但不仅仅是人。他们的素食主义者数量远远超过了应有的比例。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;好的。稍微不相关的问题：您对素食主义者有何看法？&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;我已经几个月没吃肉了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;这对你来说是环境问题还是对杀害动物的道德反对？还是健康？&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;对我的健康可能会产生负面影响。环境影响对我来说无关紧要。我不在乎杀死动物。如果你能找到一个符合道德来源的汉堡，那么我很乐意吃它。问题是，我们的动物产品默认来自工厂化农场，那是人间地狱。 [更正：我在家人的感恩节晚餐上吃了一些肉汁。]&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;这对我来说很有趣，我不一定不同意你的推理。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;我尽量不将我的信仰和价值观强加给别人。这就是为什么直到你问我才提到这一点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;如果你说折磨动物是错误的，那么杀死动物不也是不道德的吗？&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;动物干净的死亡几乎没有什么痛苦，特别是与漫长而美好的生命相比。我正在努力减少痛苦，同时遵守义务论限制。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;你认为道德考虑的重要性应该与事物的先进程度成正比吗？抱歉，如果我措辞不好。现在已经是深夜了，我正在等待电源恢复，这样我就可以做剩下的作业了。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;我知道你的意思。答案=是。如果我必须在拯救两只牛和一个人之间做出选择，那么人类是显而易见的选择。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;好的。我同意你的看法。&lt;/p&gt;&lt;hr /&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;辩论进行得怎么样？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;你的假设是非常正确的，即法官们都是经济文盲。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;lsusr：&lt;/strong&gt;哈哈哈哈哈哈&lt;/p&gt;&lt;hr /&gt;&lt;p&gt;&lt;strong&gt;Lsusr：&lt;/strong&gt;你喜欢吗？我觉得你很喜欢辩论锦标赛。干得好，能够与校队的孩子们竞争。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;是的。非常有趣。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;我也喜欢高中辩论。我做了3-4年。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;尝试捍卫错误的立场很有趣，因为这很困难。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;如果你的信念是错误的（所以你认为这是正确的立场）怎么办？那很难吗？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;我知道不是在这个问题上，因为正如你所说，这就像争论天空是否是蓝色的。但对于其他一些诸如“美国应该在&amp;lt;地方&amp;gt;部署更多军队”之类的问题，很难看出什么是正确的。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;出去吧。直视。准确地告诉我你看到的是什么颜色。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;现在是黑色的。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;通常，辩论比赛决议的定义（故意）如此模糊，以至于它们可能是正确的，也可能是错误的，这取决于它们的解释方式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;据我所知，无论你如何解释，这个都是错误的。我认为“全部”这个词几乎让人无法辩护。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;美国联邦政府应免除所有联邦学生贷款债务。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;假设民主国家的每个人（错误地）都支持学生贷款减免。民选政府是否应该尊重人民的意愿？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;是的，因为如果他们不这样做，就会开创一个不服从人民的危险先例。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;那么你所要做的就是表明绝大多数美国选民支持贷款减免。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;比起 3.4% 的通胀率，我更担心这种影响。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;不用担心。绝大多数美国选民支持愚蠢得多的政策。美国的通胀率应该是多少？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;我的直觉是 0%，但有一些我不知道的经济小事表明一个国家应该有&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;程度的通货膨胀。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;这是我制作的一个长达一小时的 YouTube 视频，试图传达这个问题的复杂性。 【我就是右边那个戴面具的人。】&lt;/p&gt;&lt;figure class="media"&gt;&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/figure&gt;&lt;p&gt;为什么它应该为零？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;我认为，我在经济知识方面的差距正在显现，但当一种货币尽可能值钱时，这不是很好吗？而且，我的力量现在又恢复了。所以我要做作业然后去睡觉。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;如果你希望货币尽可能值钱，那么我们应该有负通胀率。晚安！保证充足的睡眠。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;噢，你说得对。我把这归咎于“凌晨2点”。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Lsusr：&lt;/strong&gt;不。你的问题并不愚蠢。这很难。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;诺姆：&lt;/strong&gt;我想我应该记住数字可能会下降。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;lsusr：&lt;/strong&gt; 🤑&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/TtdJt78mgGiDubnAM/a-socratic-dialogue-with-my-student#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Tue, 05 Dec 2023 09:31:05 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/TtdJt78mgGiDubnAM/a-socratic-dialogue-with-my-student</guid></item><item><title>对齐的神经不确定性估计</title><link>https://www.lesswrong.com/posts/79eegMp3EBs8ptFqa/neural-uncertainty-estimation-for-alignment</link><description>发布于 2023 年 12 月 5 日上午 8:01（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;介绍&lt;/h2&gt;&lt;p&gt;假设您已经构建了一些人类价值观的人工智能模型。你输入一个情况，它就会给出一个良好度评级。您可能想问：“此优度评级的误差线是多少？”除了了解误差线之外，不确定性估计在人工智能内部也很有用：指导主动学习&lt;span class="footnote-reference" id="fnref80ywo0pbl8r"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn80ywo0pbl8r"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 、纠正&lt;a href="https://www.lesswrong.com/posts/5gQLrJr2yhPzMCcni/the-optimizer-s-curse-and-how-to-beat-it"&gt;优化器的诅咒&lt;/a&gt;&lt;span class="footnote-reference" id="fnrefq23duy4ut0g"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnq23duy4ut0g"&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;或进行分布外检测&lt;span class="footnote-reference" id="fnref3dij2j9svj8"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn3dij2j9svj8"&gt;[3]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;我最近出于一个&lt;a href="https://www.lesswrong.com/s/aJvgWxkCBWpHpXti4/p/nA3n2vfCy3ffnjapw"&gt;喜欢的原因&lt;/a&gt;进入了神经网络（NN）的不确定性估计文献：我认为这对于量化人工智能潜在特征的有效性域的对齐很有用。如果我们&lt;a href="https://www.lesswrong.com/posts/w4aeAFzSAguvqA5qu/how-to-go-from-interpretability-to-alignment-just-retarget"&gt;将人工智能指向其世界模型中的某个概念&lt;/a&gt;，那么对该概念的实现进行优化可能会因为将该概念推到其有效范围之外而出错。&lt;/p&gt;&lt;p&gt;但现在就先把对齐的想法放在你的后口袋里吧。这篇文章主要是对不确定性估计文献的调查，其中夹杂着我自己的看法。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;贝叶斯神经网络图片&lt;/h2&gt;&lt;p&gt;贝叶斯神经网络图是几乎所有神经网络不确定性估计方法的鼻祖，因此从这里开始是合适的。&lt;/p&gt;&lt;p&gt;图片很简单。您从参数的先验分布开始。您的训练数据就是证据，在对其进行训练后，您将获得更新的参数分布。给定输入，您可以通过贝叶斯神经网络传播输入来计算输出的分布。&lt;/p&gt;&lt;p&gt;这一切都是非常正确且无关紧要的（“当然，让我更新模型&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;所有&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;参数&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;上&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;万亿&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;维&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;联合&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;分布&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;”），除了&lt;i&gt;实际训练神经网络确实有点就这样工作&lt;/i&gt;。&lt;i&gt; &lt;/i&gt;如果您使用对数似然损失和 L2 正则化，并且您的参数先验是高斯分布，则最小化损失的参数将位于贝叶斯神经网络所具有的分布的峰值&lt;span class="footnote-reference" id="fnreffo4svcpvxs"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnfo4svcpvxs"&gt;[4]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; &lt;span class="footnote-reference" id="fnrefcogdul3x2xj"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fncogdul3x2xj"&gt;[5]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;这是因为损失景观和参数不确定性之间存在桥梁。 &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;贝叶斯&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;规则&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;表示&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;P&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;（&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;参数&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mspace" style="width: 0.278em; height: 0px;"&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mspace" style="width: 0.278em; height: 0px;"&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;数据&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;集&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;P&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;(&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;参数&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;⋅&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;P&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;(&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;数据&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;集&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mtext MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mspace" style="width: 0.278em; height: 0px;"&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mspace" style="width: 0.278em; height: 0px;"&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;参数&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;）&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;/&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;P&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;（&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;数据&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;集&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;）&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;。&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;_&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;这里&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;P&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;参数&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mspace" style="width: 0.278em; height: 0px;"&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mspace" style="width: 0.278em; height: 0px;"&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;数据&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;集&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;是&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;要&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;估计&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;后&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;验&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;分布&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;，&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;P&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;(&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;参数&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;s&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⋅&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;P&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;数据&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;集&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mtext MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mspace" style="width: 0.278em; height: 0px;"&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mspace" style="width: 0.278em; height: 0px;"&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;参数&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;s&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;是&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;损失&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;指数&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;[&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;6&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;]&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="footnote-reference" id="fnrefamk58pvab4"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnamk58pvab4"&gt;_&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;这适用于物理隐喻，例如“参数的分布是位于损失盆地底部的玻尔兹曼分布”。&lt;/p&gt;&lt;p&gt;根据经验，通过假装遵循贝叶斯神经网络图来计算神经网络的不确定性效果非常好，以至于一篇关于集成方法的好论文&lt;span class="footnote-reference" id="fnreflpb1b2qcoen"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnlpb1b2qcoen"&gt;[7]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;将其称为“基本事实”。当然，要在这里实际计算任何东西，你必须进行近似，如果你进行快速而肮脏的近似（例如假装你可以从 Hessian 找到损失盆地的形状），你会得到不好的结果&lt;span class="footnote-reference" id="fnrefd9jz9mfml"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnd9jz9mfml"&gt;[8]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; ，但人们正在做这些天，蒙特卡罗方法变得很聪明&lt;span class="footnote-reference" id="fnrefbct5kii2m07"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnbct5kii2m07"&gt;[9]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; ，他们发现贝叶斯神经网络计算的更好近似可以得到更好的结果。&lt;/p&gt;&lt;p&gt;但对损失景观进行蒙特卡罗遍历的成本很高。对于大规模应用的技术，它必须只对运行模型的成本施加很小的乘数，并且如果您希望它变得普遍，那么它施加的成本必须非常小。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;合奏团&lt;/h2&gt;&lt;p&gt;解决不确定性的一种完全不同的方法是集成&lt;span class="footnote-reference" id="fnrefen0yeoqzg0k"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnen0yeoqzg0k"&gt;[10]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。只需训练十几个模型，询问他们的建议，并估计传播的不确定性。所有事情的数十倍成本乘数都很陡峭，但如果您经常查询模型，它比损失情况的蒙特卡洛估计便宜。&lt;/p&gt;&lt;p&gt;集成在理论上很简单。您不需要假装模型经过训练可以收敛，不需要专门针对预测损失进行训练，甚至不需要固定的架构。您只需选择一些想要分散不确定性的模型分布并进行采样。&lt;/p&gt;&lt;p&gt;你可以用合奏做一些聪明的事情。通过计算集成如何适应贝叶斯神经网络图片，您会了解到改变正则化的零点可能是个好主意，否则您将在模型的泛化方式中得到虚假相关性&lt;span class="footnote-reference" id="fnreflpb1b2qcoen"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnlpb1b2qcoen"&gt;[7]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。您可以拆分数据集并训练单独的较小模型，然后巧妙地聚合这些模型（类似于&lt;a href="https://www.kaggle.com/code/prashant111/bagging-vs-boosting"&gt;装袋和提升&lt;/a&gt;），以降低集成的计算溢价&lt;span class="footnote-reference" id="fnrefen0yeoqzg0k"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnen0yeoqzg0k"&gt;[10]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。这些论文中暗示，聪明的集成技巧在更大的尺度上并不那么重要，但目前还不清楚收益是否完全为零。&lt;/p&gt;&lt;p&gt;集成的一个棘手部分是，如果一枚硬币正面朝上的概率为 51%，并且您已训练神经网络以获得正确答案，那么集成中的每个成员都会预测正面。正确答案并不不确定，因此您的团队表示不存在不确定性。如果您希望不确定性度量包含环境中的熵，则必须训练神经网络来估计该熵，这在很大程度上放弃了使用非预测损失的自由。&lt;/p&gt;&lt;p&gt;解释时的类似关注适用于在模型的潜在特征上使用集成，尽管我在文献中没有看到人们这样做。假设您训练了十几个模型，并用有关狗的数据探测它们，为每个模型找到一个“狗向量”。您可以对它们的大小和方差进行标准化，然后使用集合的方差作为“狗向量的不确定性”。这并不是关于狗的完全不确定性，因为它没有衡量人工智能模型中关于狗的不确定性，这只是不同模型根据特定探测方法的内部表示的传播。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;关于任意不确定性的注释&lt;/h2&gt;&lt;p&gt;文献中很大一部分文字是关于任意不确定性和认知不确定性之间的区别&lt;span class="footnote-reference" id="fnrefxqxuuw1xe2"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnxqxuuw1xe2"&gt;[11]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。当我说集成会告诉你由于建模选择而导致的输出的不确定性时，这就是我必须谈论的区别，但不会告诉你人工智能内部对环境的不确定性。在不确定性估计文献中，由于模型方差而产生的不确定性被称为“认知性”，而人工智能环境模型内部的不确定性被称为“随意性”。 &lt;span class="footnote-reference" id="fnref2jiolbj6tn8"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn2jiolbj6tn8"&gt;[12]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;在大数据限制下，认知不确定性相对于任意不确定性变得很小（除非你故意将模型推入高度认知不确定性的情况）。有些论文忘记了这一点，做了一些愚蠢的事情，使他们的认知不确定性估计更大，因为他们认为这应该是总的不确定性，这就是为什么其他论文必须用章节来讨论这种区别。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;添加噪声，由于某种原因通常会丢失&lt;/h2&gt;&lt;p&gt;如果您想要不确定性估计，您可以将随机噪声添加到神经网络的中间激活中。如果输出对噪声更敏感，则不确定性更大，如果输出不太敏感，则不确定性更小&lt;span class="footnote-reference" id="fnrefud7l8eu73jk"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnud7l8eu73jk"&gt;[13]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。有一些自然的启发式论证可以解释为什么这是有意义的&lt;span class="footnote-reference" id="fnreflgnhfp0m35e"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnlgnhfp0m35e"&gt;[14]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; ，并且通过更多的工作，您可以尝试将其与贝叶斯神经网络图和损失景观的蒙特卡洛估计联系起来。&lt;/p&gt;&lt;p&gt;或者，您可以忽略抽象参数并使用 dropout 作为随机噪声分布&lt;span class="footnote-reference" id="fnrefhfox6k7gfev"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnhfox6k7gfev"&gt;[15]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;哦，当然，人们给出了理由，但我认为这里的第一印象是正确的，添加 dropout 然后采样在理论上是愚蠢的。但在实验上，它的效果很好，人们一直在谈论它&lt;span class="footnote-reference" id="fnref0hl862nst9f9"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn0hl862nst9f9"&gt;[16]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; &lt;span class="footnote-reference" id="fnrefu11lguv41wc"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnu11lguv41wc"&gt;[17]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; &lt;span class="footnote-reference" id="fnrefhzxdsrsco9g"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnhzxdsrsco9g"&gt;[18]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; ，而且它不需要你做任何额外的训练。&lt;/p&gt;&lt;p&gt;为什么它起作用的一个谜题可能是，在具有一些噪声样本的数据集上训练的网络将学会输出一个包罗万象的先验以响应噪声&lt;span class="footnote-reference" id="fnreffqljh5j8ipf"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnfqljh5j8ipf"&gt;[19]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。我怀疑 dropout 是足够大的噪音，它将网络推向这个先验，这有助于过度自信。&lt;/p&gt;&lt;p&gt;我希望人们对更小的、非丢失的噪声进行更多的比较&lt;span class="footnote-reference" id="fnrefvl2ahm3user"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnvl2ahm3user"&gt;[20]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。这在理论上似乎更合理，尽管当翻译回贝叶斯术语时，将噪声注入内部层似乎对应于有趣但不寻常的噪声分布。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;校准&lt;/h2&gt;&lt;p&gt;文献&lt;span class="footnote-reference" id="fnref0hl862nst9f9"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn0hl862nst9f9"&gt;[16]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;的很大一部分是人们只是试图获取神经网络的输出并对它们应用简单的函数来获得不确定性估计。我将简要地对待他们。&lt;/p&gt;&lt;p&gt;第 0 级只是按面值获取 NN 输出。当数据较多且参数不确定性较小时，神经网络的直接预测可以很好地估计不确定性。例如，基础 GPT-4 在分配给下一个标记的概率分布中得到了很好的校准，包括当这些下一个标记是以前从未见过的测试问题的答案时&lt;span class="footnote-reference" id="fnrefzkojoz799ka"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnzkojoz799ka"&gt;[21]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。即使是非分布，这也比什么都没有好——正如我上面提到的，如果神经网络的训练集包含意外数据，那么它们确实会学会不确定意外数据&lt;span class="footnote-reference" id="fnreffqljh5j8ipf"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnfqljh5j8ipf"&gt;[19]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; ，尽管它们仍然倾向于过度自信。&lt;/p&gt;&lt;p&gt;随着模型的泛化能力越来越强，我预计它们的输出能够在更大的领域得到很好的校准。相反，对于在有限数据上训练小型模型的应用程序，您将需要一种不同的方法来估计不确定性。&lt;/p&gt;&lt;p&gt;通常人们会尝试比第 0 级更奇特一些，并做一些事情，比如调整 softmax 函数的参数，以最大限度地提高对保留验证集的校准&lt;span class="footnote-reference" id="fnrefnglt70rybd9"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnnglt70rybd9"&gt;[22]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。这也很容易与其他方法结合作为最终校准步骤&lt;span class="footnote-reference" id="fnrefgx8tqfun0w"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fngx8tqfun0w"&gt;[23]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;如果您有分布外 (OOD) 数据样本，您还可以做更奇特的事情，例如同时进行 OOD 检测和校准&lt;span class="footnote-reference" id="fnreftmgq2x5m6t"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fntmgq2x5m6t"&gt;[24]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。或者，如果您有 OOD 数据样本并且是频率论者，则可以进行保形预测&lt;span class="footnote-reference" id="fnrefg3rtbqm4247"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fng3rtbqm4247"&gt;[25]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;校准的一个卖点是您可以对任何经过训练的模型执行此操作。但如果您愿意放弃这一点并干预训练，就有一些方法可以改进模型的校准。这可能看起来像使用额外的正则化&lt;span class="footnote-reference" id="fnrefqbdlqupa3x"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnqbdlqupa3x"&gt;[26]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;或对比示例&lt;span class="footnote-reference" id="fnref2qfcvdqkx2y"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn2qfcvdqkx2y"&gt;[27]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;进行训练。这些也在一定程度上提高了 OOD 泛化能力，对抗性训练也是如此&lt;span class="footnote-reference" id="fnrefazba93s687"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnazba93s687"&gt;[28]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;最终，网络输出的校准似乎并没有达到我想要的不确定性估计方法的效果。其一，它不会估计潜在特征的不确定性，而是与您拥有数据的输出的不确定性有关。&lt;/p&gt;&lt;p&gt;另一方面，它&lt;a href="https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation"&gt;缺乏搜索的鲁棒性&lt;/a&gt;&lt;span class="footnote-reference" id="fnrefv1gf6chx43"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnv1gf6chx43"&gt;[29]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。确实，所有其他不确定性估计方法在优化时也应该容易受到对抗性示例的影响（部分原因是对抗性示例是特征，而不是错误&lt;span class="footnote-reference" id="fnrefa3kc8qjhdn6"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fna3kc8qjhdn6"&gt;[30]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; ），但是当网络输出及其不确定性估计是相同的时，对良好输出的本地搜索应该&lt;i&gt;特别&lt;/i&gt;有效地找到奇怪的意想不到的最佳值&lt;span class="footnote-reference" id="fnref28983dpfjdp"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn28983dpfjdp"&gt;[31]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;训练高阶模型&lt;/h2&gt;&lt;p&gt;校准的另一面。首先让你的神经网络为你提供更好的不确定性估计。&lt;/p&gt;&lt;p&gt;如果您想获得二阶不确定性的估计，请训练神经网络以输出&lt;a href="https://en.wikipedia.org/wiki/Dirichlet_distribution#Occurrence_and_applications"&gt;狄利克雷分布&lt;/a&gt;的参数，而不是进行正常分类&lt;span class="footnote-reference" id="fnrefkm10b29by7c"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnkm10b29by7c"&gt;[32]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; &lt;span class="footnote-reference" id="fnrefhfc8x4hav0b"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnhfc8x4hav0b"&gt;[33]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。或者，如果您正在进行回归，请训练神经网络以输出答案的分布参数&lt;span class="footnote-reference" id="fnrefen0yeoqzg0k"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnen0yeoqzg0k"&gt;[10]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。或者，如果您拥有法学硕士并且每个问题都是钉子，请训练您的法学硕士用语言表达不确定性&lt;span class="footnote-reference" id="fnrefffdudph3qus"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnffdudph3qus"&gt;[34]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; &lt;span class="footnote-reference" id="fnrefadsp4hkxuk"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnadsp4hkxuk"&gt;[35]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;表达不确定性的训练模型存在一个微妙的问题：不存在适当的二阶损失函数&lt;span class="footnote-reference" id="fnrefxuwhb9ieyh"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnxuwhb9ieyh"&gt;[36]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。这意味着仅从数据点出发，很难准确地训练模型来给出概率分布 - 您可以创建损失函数来尝试做到这一点，但只要您只监督正确答案是什么，而不监督正确答案是什么。正确的概率分布是，通过损失最小化得到的概率分布将会有偏差。&lt;/p&gt;&lt;p&gt;贝叶斯方法，或者至少是贝叶斯理论框架，在这里会很有用。您不需要适当的损失函数来进行贝叶斯更新。但还没有人写下该应用程序的贝叶斯神经网络图的类似物。&lt;/p&gt;&lt;p&gt;理论上也不清楚如何整合我们可以获得的有关概率分布的其他类型的监督数据。例如，人为噪声的例子可以给出直接的监督信号，表明正确的概率分布是高熵的。或者，我们可以通过询问“我期望我对正确答案的估计随着更多数据而改变多少？”来学习分布。它的监督分布在整个数据集中，因此绕过了没有适当评分规则的证明 - 但我们可以以公正的方式做到这一点吗？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;比较方法&lt;/h2&gt;&lt;p&gt;那么，哪个是最好的？&lt;/p&gt;&lt;p&gt;目前，它正在训练一个整体。但训练高阶模型具有尚未开发的潜力。&lt;/p&gt;&lt;p&gt;情况尚不清楚，因为比较是在玩具问题上进行的，文献很少并且并不总是重复，比较很困难，因为每种方法都有十几种变体，而且不同的论文有时会评估完全不同的指标。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img alt="该图显示了一些神经网络曲线与不同方法生成的误差条的拟合情况。" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/xptyd74vj7qmuirlgkdq" /&gt;&lt;figcaption&gt;来自&lt;a href="https://www.lesswrong.com/posts/79eegMp3EBs8ptFqa/neural-uncertainty-estimation-for-alignment#fnlpb1b2qcoen"&gt;参考文献。 7&lt;/a&gt; .玩具曲线拟合问题的不确定性估计方法比较。&lt;br /&gt;&lt;br /&gt; Ground Truth 是一个贝叶斯神经网络，Hamiltonian MC 是它的一个很好的蒙特卡洛近似，变分推理是它的一个廉价近似，MC Dropout 根据 dropout 后的方差估计不确定性，而我们的方法是一个具有奇特初始化的集成。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个数字是一个不错的直觉泵。它在玩具曲线拟合任务（只有&lt;span class="footnote-reference" id="fnreflpb1b2qcoen"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnlpb1b2qcoen"&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;个数据点的回归问题）上比较了不确定性估计方法（尽管它明显错过了校准和高阶建模），每种方法都使用 ReLU 与 Sigmoid。我认为这个数字的一​​些定性印象是概括性的。&lt;/p&gt;&lt;p&gt;印象笔记：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;贝叶斯神经网络、蒙特卡洛近似和集成方法都做出了类似的预测。&lt;/li&gt;&lt;li&gt;架构对于泛化属性来说非常重要，在某种程度上使这些方法看起来过于自信。 （整合不同的架构将是一个好的开始，但没有人这样做。）&lt;/li&gt;&lt;li&gt; Dropout 和变分推理近似在数据点附近的置信度都低于集成簇，但在分布之外的置信度更高。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在对 CIFAR-10 或 LSTM 语言模型&lt;span class="footnote-reference" id="fnrefhzxdsrsco9g"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnhzxdsrsco9g"&gt;[18]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;或医学 MRI 数据&lt;span class="footnote-reference" id="fnrefu11lguv41wc"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnu11lguv41wc"&gt;[17]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;进行更彻底的比较（现在包括校准）时，集成似乎是最好的方法。但老实说，我提到的所有方法都非常接近，在复杂任务上，dropout 比玩具模型所建议的更有竞争力，而变分推理在 MNIST 上表现得令人惊讶。&lt;/p&gt;&lt;p&gt;高阶建模出现在较少的比较中。但这是参考文献中的一个数字。 31 其中模型在 MNIST 上进行训练，然后在&lt;a href="https://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html"&gt;非 MNIST&lt;/a&gt;上进行测试&lt;span class="footnote-reference" id="fnrefkm10b29by7c"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnkm10b29by7c"&gt;[32]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。学习分类输出上的狄利克雷分布（EDL 虚线）与包的其余部分不同，就像包与原始模型输出（蓝色 L2 线）的不同一样： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img alt="该图显示高阶建模给出了分布的高熵猜测。" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/79eegMp3EBs8ptFqa/iyp8dpi29scplwjsybyy" /&gt;&lt;figcaption&gt;来自&lt;a href="https://www.lesswrong.com/posts/79eegMp3EBs8ptFqa/neural-uncertainty-estimation-for-alignment#fnkm10b29by7c"&gt;参考文献。 32&lt;/a&gt; . OOD 数据集上输出熵的积分直方图（或累积分布）。训练是在 MNIST 上进行的，但测试是在&lt;a href="https://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html"&gt;非 MNIST&lt;/a&gt;上进行的，因此具有更高的高熵概率是好的。&lt;br /&gt;&lt;br /&gt; EDL 是他们的狄利克雷分布模型，L2 是原始模型输出，DeepEnsemble 是一个集成，FFLU 不清楚但可能是贝叶斯 NN 近似，Dropout 是 dropout，FFG 是贝叶斯 NN 方法，MNFG 是变分推理近似。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当显示 OOD 数据时，这是一种非常令人印象深刻的不确定能力。是的，在分布上（在 MNIST 上）它具有正常的准确性。显然，学习何时不确定就是获取一些其他方法无法获取的信息。&lt;/p&gt;&lt;p&gt;但如此不确定真的正确吗？假设您正在对数字进行分类，这就是您所知道的，然后有人输入字符“B”。这肯定是8，对吧？或者也许是一个被压在一起的 13，如果你能想到这个想法的话。但它肯定不是 2。既然你知道这一点，那么在这里返回最大熵分布将是一个错误。但这似乎正是狄利克雷分布模型倾向于做的事情。&lt;/p&gt;&lt;p&gt;我希望高阶模型与论文中其他所有内容之间的不同行为是因为这些方法具有不同的背景假设，如果我们知道我们在做什么，我们可以在适当的时候灵活地使用不同的假设。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;我未来想从事这个领域的工作&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;更大的尺度&lt;ul&gt;&lt;li&gt;对 Transformer 语言模型的不确定性估计进行基准测试。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;搜索的鲁棒性&lt;ul&gt;&lt;li&gt;看看认知不确定性对对抗性例子有何影响。&lt;/li&gt;&lt;li&gt;分析找到新的对抗性例子来欺骗不确定性估计和原始指​​标是多么容易。检查这些例子对人类来说是否自然。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;非压差噪声&lt;ul&gt;&lt;li&gt;当您向神经网络添加噪声时，改进采样的理论。&lt;/li&gt;&lt;li&gt;对不同类型的噪声进行相互比较和其他方法的基准测试。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;合奏带来更多聪明的事情&lt;ul&gt;&lt;li&gt;测试改变架构的集成。&lt;/li&gt;&lt;li&gt;测试正在探索“相同”潜在特征的集合。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;更好的高阶模型&lt;ul&gt;&lt;li&gt;发展神经网络学习二阶分布的贝叶斯视角。&lt;/li&gt;&lt;li&gt;通过尝试转化理论和修补信号（例如预测未来更新），为高阶模型开发更好的训练方法。&lt;/li&gt;&lt;li&gt;弄清楚如何使用高阶建模来获得不同背景假设的不确定性。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;更好的比较&lt;ul&gt;&lt;li&gt;更系统地比较校准和 Brier 评分。&lt;/li&gt;&lt;li&gt;对决策问题进行基准测试，为分布数据之外的“良好行为”提供具体标准。&lt;/li&gt;&lt;li&gt;开发包含“自然”分布泛化的标记数据集，我们可以将其类比为现实世界中模型完成的 OOD 泛化。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;更多协同效应&lt;ul&gt;&lt;li&gt;通过将多种方法结合在一起，可以获得更好的结果。校准太容易与一切结合起来，尽管它仍然是一个好主意，但这不算新闻。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果这些论文确实存在而我错过了，请告诉我。如果他们不这样做，并且其中一个项目听起来像是您想做的事情，请联系我 - 我很乐意聊天。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;与一致性、结论的相关性&lt;/h2&gt;&lt;p&gt;文献与对齐的相关性不如我的预期，但这主要是因为我的期望被混淆了。我对某种“人类价值观的不确定性”感兴趣，它不同于文献中的“任意”或“认知”不确定性。&lt;/p&gt;&lt;p&gt;任意不确定性是从数据中得知的，但我们没有人类价值观的真实标签。或者，如果模型中有一些与人类价值观相关的潜在特征，我们不仅仅想了解该特征在某些训练集上的方差。&lt;/p&gt;&lt;p&gt;认知不确定性更接近，但正如文献中所使用的那样，它实际上是关于某些输出或特征对于训练目标的有用程度。在训练过程中收敛到相同答案的模型越多，认知不确定性就越小。但相对于我想要的，这感觉好像缺少一些关于首先使用什么训练程序或特征检测程序的不确定性&lt;span class="footnote-reference" id="fnrefmyfeye042z"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnmyfeye042z"&gt;[37]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;正确的训练/特征检测程序的不确定性偏离了“有一个基本事实答案，不确定性是与该答案的预期偏差”的通常范式。为了保持一致，我认为图片应该更像是通信——我们试图通过架构和数据向人工智能传达一些信息，而人工智能应该对如何解释它有不确定性。&lt;/p&gt;&lt;p&gt;构建这种关于人类价值观的不确定性是相当棘手的——我什至还不知道我想从中得到什么！也许如果我们更清楚地理解我们想要什么，我们就可以用更标准的不确定性来构建它。例如，我们可以设计一个人工智能可以玩的“游戏”，激励对人类概念的不同解释，这样游戏中的任意和认知不确定性就可以充分捕捉到我们希望人工智能对人类价值观具有的不确定性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;这篇文章部分写于&lt;/i&gt;&lt;a href="https://www.mitalignment.org/"&gt;&lt;i&gt;MAIA&lt;/i&gt;&lt;/a&gt; &lt;i&gt;。谢谢玛雅！还有贾斯蒂斯·米尔斯（Justis Mills）进行编辑，以及波士顿的各种人士进行对话。&lt;/i&gt;&lt;/p&gt;&lt;ol class="footnotes"&gt;&lt;li class="footnote-item" id="fn80ywo0pbl8r"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref80ywo0pbl8r"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;主动学习文献调查。&lt;i&gt;伯尔·塞特尔斯&lt;/i&gt;(2010) &lt;a href="https://burrsettles.com/pub/settles.activelearning.pdf"&gt;https://burrsetles.com/pub/settles.activelearning.pdf&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnq23duy4ut0g"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefq23duy4ut0g"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;优化器的诅咒：决策分析中的怀疑主义和决策后惊喜。&lt;i&gt;詹姆斯·E·史密斯、罗伯特·L·温克勒&lt;/i&gt;(2006) &lt;a href="https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1050.0451"&gt;https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1050.0451&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn3dij2j9svj8"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref3dij2j9svj8"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;用于检测神经网络中错误分类和分布外示例的基线。&lt;i&gt;丹·亨德里克斯、凯文·金佩尔&lt;/i&gt;(2016) &lt;a href="https://arxiv.org/abs/1610.02136"&gt;https://arxiv.org/abs/1610.02136&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnfo4svcpvxs"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnreffo4svcpvxs"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;使用贝叶斯统计进行神经网络不确定性评估并应用于遥感。 &lt;i&gt;F. Aires、C. Prigent、WB Rossow&lt;/i&gt; (2004)&lt;/p&gt;&lt;p&gt;第 1 部分：网络权重&lt;a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004173"&gt;https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004173&lt;/a&gt;&lt;/p&gt;&lt;p&gt;第 2 部分：输出错误&lt;a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004174"&gt;https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004174&lt;/a&gt;&lt;/p&gt;&lt;p&gt;第 3 部分：网络雅可比矩阵&lt;a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004175"&gt;https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003JD004175&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fncogdul3x2xj"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefcogdul3x2xj"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;深度学习中不确定性估计的通用框架。&lt;i&gt;安东尼奥·洛奎西奥、马蒂亚·塞古、大卫·斯卡拉穆扎&lt;/i&gt;(2020) &lt;a href="https://www.zora.uzh.ch/id/eprint/197704/1/RAL20_Loquercio.pdf"&gt;https://www.zora.uzh.ch/id/eprint/197704/1/RAL20_Loquercio.pdf&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnamk58pvab4"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefamk58pvab4"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;如果&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;P&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;(&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;参数&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;是&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;高斯&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;分布&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;（&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;指数&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;L2&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;正&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;则&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;化），并且您的损失是&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;对&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;数&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;损失&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;因此&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;P&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;数据&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;集&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mspace" style="width: 0.278em; height: 0px;"&gt;&lt;/span&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mspace" style="width: 0.278em; height: 0px;"&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;参数&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;s&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;是&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;它&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;指数&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;。&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;_&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnlpb1b2qcoen"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnreflpb1b2qcoen"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;神经网络的不确定性：近似贝叶斯集成。&lt;i&gt;蒂姆·皮尔斯、菲利克斯·莱布弗里德、亚历山德拉·布林特鲁普、穆罕默德·扎基、安迪·尼利&lt;/i&gt;(2020) &lt;a href="http://proceedings.mlr.press/v108/pearce20a/pearce20a.pdf"&gt;http://proceedings.mlr.press/v108/pearce20a/pearce20a.pdf&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnd9jz9mfml"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefd9jz9mfml"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;最明显的问题是 Hessian 矩阵的奇点。但在短长度尺度上，损失情况也可能会很复杂，使得低阶近似有时会失败。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnbct5kii2m07"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefbct5kii2m07"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;面向神经网络的校准和可扩展的不确定性表示。&lt;i&gt;纳比尔·西达特、克里斯托弗·卡南&lt;/i&gt;(2019) &lt;a href="https://arxiv.org/abs/1911.00104"&gt;https://arxiv.org/abs/1911.00104&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnen0yeoqzg0k"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefen0yeoqzg0k"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;使用深度集成的简单且可扩展的预测不确定性估计。 &lt;i&gt;Balaji Lakshminarayanan、Alexander Pritzel、Charles Blundell&lt;/i&gt; (2017) &lt;a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/9ef2ed4b7fd2c810847ffa5fa85bce38-Paper.pdf"&gt;https://proceedings.neurips.cc/paper_files/paper/2017/file/9ef2ed4b7fd2c810847ffa5fa85bce38-Paper.pdf&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnxqxuuw1xe2"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefxqxuuw1xe2"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;计算机视觉的贝叶斯深度学习需要哪些不确定性？&lt;i&gt;亚历克斯·肯德尔，亚林·加尔&lt;/i&gt;(2017) &lt;a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/2650d6089a6d640c5e85b2b88265dc2b-Paper.pdf"&gt;https://proceedings.neurips.cc/paper_files/paper/2017/file/2650d6089a6d640c5e85b2b88265dc2b-Paper.pdf&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn2jiolbj6tn8"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref2jiolbj6tn8"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;源自希腊语，意思是“关于知识”和“关于赌博”。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnud7l8eu73jk"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefud7l8eu73jk"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; 2 如何仅在给定模型权重的情况下判断你的输入是否不符合分布， &lt;i&gt;dkirmani&lt;/i&gt; (2023) &lt;a href="https://www.lesswrong.com/posts/tvLi8CyvvSHrfte4P/how-2-tell-if-ur-input-is-out-of-distribution-given-only"&gt;https://www.lesswrong.com/posts/tvLi8CyvvSHrfte4P/how-2-tell-if-ur-input-is-out-of -仅给定分布&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnlgnhfp0m35e"&gt;&lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnreflgnhfp0m35e"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;现实世界中存在噪声，因此，如果小的输入噪声极大地改变了您的答案，您就不应该对此充满信心。相反，在表现良好的输入上，神经网络学会对噪声具有鲁棒性。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnhfox6k7gfev"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefhfox6k7gfev"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;密集回归的免训练不确定性估计：灵敏度作为替代。&lt;i&gt;卢米、王浩、田永龙、何浩、Nir Shavit&lt;/i&gt; (2022) &lt;a href="https://arxiv.org/abs/1910.04858"&gt;https://arxiv.org/abs/1910.04858&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn0hl862nst9f9"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref0hl862nst9f9"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;深度神经网络不确定性调查。&lt;i&gt;雅各布·高利科斯基等人。&lt;/i&gt; (2021) &lt;a href="https://arxiv.org/abs/2107.03342"&gt;https://arxiv.org/abs/2107.03342&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnu11lguv41wc"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefu11lguv41wc"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;估计心脏 MRI 分割神经网络的不确定性：一项基准研究。&lt;i&gt;马修·吴、富民·郭、Labonny Biswas、Steffen E. Petersen、Stefan K. Piechnik、Stefan Neubauer、Graham Wright&lt;/i&gt; (2023) &lt;a href="https://ieeexplore.ieee.org/abstract/document/10002847"&gt;https://ieeexplore.ieee.org/abstract/document/10002847&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnhzxdsrsco9g"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefhzxdsrsco9g"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;你能相信你的模型的不确定性吗？评估数据集变化下的预测不确定性。 &lt;i&gt;Yaniv Ovadia、Emily Fertig、Jie Ren、Zachary Nado、D Sculley、Sebastian Nowozin、Joshua V. Dillon、Balaji Lakshminarayanan、Jasper Snoek&lt;/i&gt; (2019) &lt;a href="https://arxiv.org/abs/1906.02530"&gt;https://arxiv.org/abs/1906.02530&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnfqljh5j8ipf"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnreffqljh5j8ipf"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;深度神经网络倾向于进行可预测的推断。&lt;i&gt;凯蒂·康、阿姆里斯·塞特勒、克莱尔·汤姆林、谢尔盖·莱文&lt;/i&gt;(2023) &lt;a href="https://arxiv.org/abs/2310.00873"&gt;https://arxiv.org/abs/2310.00873&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnvl2ahm3user"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefvl2ahm3user"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;对于分布外检测来说似乎更常见，例如增强神经网络中分布外图像检测的可靠性。&lt;i&gt;梁世宇、李亦轩、R.Srikant&lt;/i&gt; (2020) &lt;a href="https://arxiv.org/abs/1706.02690"&gt;https://arxiv.org/abs/1706.02690&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnzkojoz799ka"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefzkojoz799ka"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; GPT-4 技术报告。 &lt;i&gt;OpenAI&lt;/i&gt; (2023) &lt;a href="https://openai.com/research/gpt-4"&gt;https://openai.com/research/gpt-4&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnnglt70rybd9"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefnglt70rybd9"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; Mix-n-Match：深度学习中不确定性校准的集成和组合方法。&lt;i&gt;张继泽、Bhavya Kailkhura、T. Yong-Jin Han&lt;/i&gt; (2020) &lt;a href="https://arxiv.org/abs/2003.07329"&gt;https://arxiv.org/abs/2003.07329&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fngx8tqfun0w"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefgx8tqfun0w"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;不确定性量化和深度集成。&lt;i&gt;拉胡尔·拉哈曼、亚历山大·H·蒂埃里&lt;/i&gt;(2020) &lt;a href="https://arxiv.org/abs/2007.08792"&gt;https://arxiv.org/abs/2007.08792&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fntmgq2x5m6t"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnreftmgq2x5m6t"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;在分布外数据集上校准深度神经网络分类器。&lt;i&gt;邵志辉、杨建一、任少雷&lt;/i&gt;(2020) &lt;a href="https://arxiv.org/abs/2006.08914"&gt;https://arxiv.org/abs/2006.08914&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fng3rtbqm4247"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefg3rtbqm4247"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;归纳共形预测：神经网络的理论与应用。&lt;i&gt;哈里斯·帕帕佐普洛斯&lt;/i&gt;(2008) &lt;a href="https://www.intechopen.com/chapters/5294"&gt;https://www.intechopen.com/chapters/5294&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnqbdlqupa3x"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefqbdlqupa3x"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;通过 Logit 归一化缓解神经网络过度自信。&lt;i&gt;魏洪欣、谢仁春子、程浩、冯雷、安博、李一轩&lt;/i&gt;(2022) &lt;a href="https://proceedings.mlr.press/v162/wei22d/wei22d.pdf"&gt;https://proceedings.mlr.press/v162/wei22d/wei22d.pdf&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn2qfcvdqkx2y"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref2qfcvdqkx2y"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;使用噪声对比先验对深度神经网络进行可靠的不确定性估计。 &lt;i&gt;Danijar Hafner、Dustin Tran、Timothy Lillicrap、Alex Irpan、James Davidson&lt;/i&gt; (2018) &lt;a href="https://openreview.net/forum?id=HkgxasA5Ym"&gt;https://openreview.net/forum?id=HkgxasA5Ym&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnazba93s687"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefazba93s687"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;通过对抗性训练和预训练改进 OOD 泛化。&lt;i&gt;易明阳、侯鲁、孙家成、尚立峰、蒋欣、刘群、马志明&lt;/i&gt;(2021) &lt;a href="http://proceedings.mlr.press/v139/yi21a/yi21a.pdf"&gt;http://proceedings.mlr.press/v139/yi21a/yi21a.pdf&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnv1gf6chx43"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefv1gf6chx43"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; SolidGoldMagikarp（加上，提示生成）。&lt;i&gt;杰西卡·朗贝罗、马修·沃特金斯&lt;/i&gt;(2023)&lt;i&gt; &lt;/i&gt;&lt;a href="https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation"&gt;https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt- Generation&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fna3kc8qjhdn6"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefa3kc8qjhdn6"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;对抗性例子不是错误，而是特征。&lt;i&gt;安德鲁·伊利亚斯等人。&lt;/i&gt; （2019） &lt;a href="https://arxiv.org/abs/1905.02175"&gt;https://arxiv.org/abs/1905.02175&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn28983dpfjdp"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref28983dpfjdp"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;如果我们使用生成而不是搜索来构建良好的输出，则可以回避优化不稳健的问题。或者在强化学习环境中，如果我们使用策略预测器将我们保持在系统的有效性范围内。但这是昂贵的，有时容易受到以不同速率泛化的能力的影响。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnkm10b29by7c"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefkm10b29by7c"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;用于量化分类不确定性的证据深度学习。&lt;i&gt;穆拉特·森索伊、兰斯·卡普兰、梅利赫·坎德米尔&lt;/i&gt;(2018) &lt;a href="https://arxiv.org/abs/1806.01768"&gt;https://arxiv.org/abs/1806.01768&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnhfc8x4hav0b"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefhfc8x4hav0b"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;使用狄利克雷深度神经网络识别域外对象。&lt;i&gt;艾哈迈德·哈曼、弗兰克·博纳伦斯、赛义德·E·戈巴迪、克里斯托夫·斯蒂勒&lt;/i&gt;(2023) &lt;a href="https://openaccess.thecvf.com/content/ICCV2023W/UnCV/papers/Hammam_Identifying_Out-of-Domain_Objects_with_Dirichlet_Deep_Neural_Networks_ICCVW_2023_paper.pdf"&gt;https://openaccess.thecvf.com/content/ICCV2023W/UnCV/papers/Hammam_Identifying_Out-of-Domain_Objects_with_Dirichlet_Deep_Neural_Networks_ICCVW_2023_paper.pdf&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnffdudph3qus"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefffdudph3qus"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;教学模型用言语表达不确定性。&lt;i&gt;斯蒂芬妮·林、雅各布·希尔顿、欧文·埃文斯&lt;/i&gt;(2023) &lt;a href="https://openreview.net/forum?id=8s8K2UZGTZ"&gt;https://openreview.net/forum?id=8s8K2UZGTZ&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnadsp4hkxuk"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefadsp4hkxuk"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;直接从 GPT-3 中导出概率。&lt;i&gt;努诺·森佩雷&lt;/i&gt;(2023) &lt;a href="https://forum.effectivealtruism.org/posts/aGmhi4uvAJptY8TA7/straightforwardly-eliciting-probabilities-from-gpt-3#Fine_tune_the_model_on_good_worked_examples_of_forecasting_reasoning"&gt;https://forum. effectivealtruism.org/posts/aGmhi4uvAJptY8TA7/straightforwardly-eliciting-probabilities-from-gpt-3#Fine_tune_the_model_on_good_worked_examples_of_forecasting_reasoning&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnxuwhb9ieyh"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefxuwhb9ieyh"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;关于认知不确定性量化的二阶评分规则。&lt;i&gt;维克托·本格斯、艾克·胡勒迈尔、威廉·韦格曼&lt;/i&gt;(2023) &lt;a href="https://arxiv.org/abs/2301.12736"&gt;https://arxiv.org/abs/2301.12736&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnmyfeye042z"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefmyfeye042z"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;我可能还会提到关于使用什么抽象或使用什么推理程序的不确定性。但这些似乎是培训的下游。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/79eegMp3EBs8ptFqa/neural-uncertainty-estimation-for-alignment#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Tue, 05 Dec 2023 08:01:32 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/79eegMp3EBs8ptFqa/neural-uncertainty-estimation-for-alignment</guid></item><item><title>分析历史灾难发生率</title><link>https://www.lesswrong.com/posts/SgYz4YPKridWXJSE6/analyzing-the-historical-rate-of-catastrophes</link><description>发布于 2023 年 12 月 5 日上午 6:30（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;为了传达风险，我们经常求助于故事。核武器让人想起相互毁灭、带有红色按钮的公文包和核冬天的故事。气候变化让人想起极端天气、海平面上升淹没城市和农作物歉收的故事。新冠疫情之后的流行病几乎不需要想象力，但以前却是&lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/Contagion_(2011_film)?ref=bounded-regret.ghost.io"&gt;《传染病》&lt;/a&gt;&lt;/em&gt;等电影的主题。&lt;/p&gt;&lt;p&gt;故事非常适合传达具体的风险（我自己&lt;a href="https://bounded-regret.ghost.io/gpt-2030-and-catastrophic-drives-four-vignettes/"&gt;最近就人工智能风险做了这件事&lt;/a&gt;），但它们不是预测未来的好方法。这是因为大多数故事都过于具体，不可能发生。更重要的是，故事往往具有简短、简单的因果链，而现实则复杂且具有多种因果关系。&lt;/p&gt;&lt;p&gt;大多数有竞争力的预测者不是使用故事，而是通过查看历史&lt;a href="https://forecasting.quarto.pub/book/base-rates.html?ref=bounded-regret.ghost.io"&gt;参考类别&lt;/a&gt;来开始预测。这非常有效，而且也很有意义：历史通过以实际发生的事件为基础，使我们摆脱了讲故事的偏见。虽然历史是通过叙述来过滤的，但好的历史将与现实的复杂性相抗衡，我们可以通过基于原始数字来进一步剥离叙述。 &lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn1"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;在这篇文章中，我将使用参考课程来了解当今社会面临的最大风险。我将通过考虑历史灾难​​的两个不同参考类来做到这一点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;导致全球大部分人口死亡的事件（&lt;a href="https://www.lesswrong.com/feed.xml#historical-causes-of-human-population-loss"&gt;第 1 节&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;物种灭绝，特别是大规模灭绝事件（&lt;a href="https://www.lesswrong.com/feed.xml#species-extinctions"&gt;第 2 节&lt;/a&gt;）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过查看这些参考课程，我们学到了两件事。首先，它为我们提供了不同灾难的罕见程度的数值估计。如果我们将灾难定义为十年内导致全球 1% 人口死亡的事件，那么自 1500 年以来，已经发生了 11 起此类灾难，每年发生的基准率为 2%。如果我们提高杀死 10% 人口的标准，基本死亡率就会下降一个数量级，降至 0.2%。&lt;/p&gt;&lt;p&gt;历史也为我们提供了定性的见解。例如，上一段中的灾难都是流行病、战争或饥荒。此外，许多事件都是多重原因造成的——最严重的流行病发生在人口已经因饥荒而虚弱的时候，而许多流行病和饥荒是由于气候变化或政治动荡而加剧的。物种灭绝也是多因素造成的，常见的罪魁祸首是气候变化、自然灾害、入侵物种和人类。&lt;/p&gt;&lt;p&gt;反对使用历史基本利率的一个论点是，现在与过去如此不同（例如由于技术），以至于基本利率毫无意义。虽然当今世界确实与过去不同，但基本利率可以通过澄清实际上的新内容来帮助加剧而不是忽视这些差异。例如，仅仅技术的存在并不能让我们远远高于基本速度，因为历史上已经开发了许多技术，但没有一项技术造成了上述意义上的灾难。相反，我们应该寻找与灾难的历史驱动因素具有共同特征的技术：流行病、饥荒、战争、政治动荡、气候变化、自然灾害、入侵物种和人类。&lt;/p&gt;&lt;p&gt;我详细分析了这些驱动程序（&lt;a href="https://www.lesswrong.com/feed.xml#takeaways-for-modern-catastrophes-and-for-ai"&gt;第 3 节&lt;/a&gt;），发现它们分为几个核心组：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全球或区域规模的自然事件（饥荒、气候变化、自然灾害）&lt;/li&gt;&lt;li&gt;新型、高度适应、自我复制的生物体（流行病、新型病原体和捕食者、入侵物种）&lt;/li&gt;&lt;li&gt;协调一致的人类群体寻求资源、土地或权力（战争、政治动荡、过度狩猎和栖息地破坏导致的灭绝）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这个列表是有道理的——要产生全球影响，某件事要么应该从全球范围开始（大型自然事件），要么有办法到达那里（自我复制、协调）。&lt;/p&gt;&lt;p&gt;从这个角度来看，21世纪灾难的可能驱动因素是什么？从上面的列表中可以明显看出一些答案——流行病、气候变化和重大战争仍然是严重的威胁。与上一次重大饥荒发生在 1961 年相比，饥荒的威胁不那么明显，但为饥荒做好准备可能仍需谨慎。政治动荡虽然本身不​​是灾难性的，但却为其他灾难的发生创造了条件。&lt;/p&gt;&lt;p&gt;谈到新技术，工程病原体是危险的，因为它们是新型的自我复制器，&lt;a href="https://en.wikipedia.org/wiki/Gray_goo?ref=bounded-regret.ghost.io"&gt;某些类型的纳米技术&lt;/a&gt;也是如此。核武器是危险的，因为它们具有与自然灾害类似的影响，而且因为它们会增加战争造成的最坏损害。&lt;/p&gt;&lt;p&gt;最后，不幸的是，人工智能（我自己的研究领域）与许多灾难驱动因素具有共同的属性。它是一种新颖的自我复制器（它可以自我复制），可以快速适应新数据。人工智能系统可以被&lt;a href="https://arxiv.org/abs/1705.08926?ref=bounded-regret.ghost.io"&gt;训练来协调&lt;/a&gt;并&lt;a href="https://bounded-regret.ghost.io/intrinsic-drives-and-extrinsic-misuse-two-intertwined-risks-of-ai/"&gt;可能寻求权力&lt;/a&gt;，反映协调的人类群体的威胁。最后，如果人工智能导致经济动荡和随后的政治动荡，它可能会加剧灾难的其他驱动因素。&lt;/p&gt;&lt;h1&gt;人口减少的历史原因&lt;/h1&gt;&lt;p&gt;为了开始我们的分析，我研究了人口减少的最大历史原因，以特定事件导致的全球人口死亡比例来衡量。为此，我结合了维基百科上&lt;a href="https://en.m.wikipedia.org/wiki/List_of_anthropogenic_disasters_by_death_toll?ref=bounded-regret.ghost.io#Wars_and_armed_conflicts"&gt;主要战争&lt;/a&gt;、 &lt;a href="https://en.m.wikipedia.org/wiki/List_of_anthropogenic_disasters_by_death_toll?ref=bounded-regret.ghost.io#Abuse_of_workers,_forced_laborers_and_slaves"&gt;奴隶制和其他强迫劳动&lt;/a&gt;、&lt;a href="https://en.m.wikipedia.org/wiki/List_of_famines?ref=bounded-regret.ghost.io"&gt;饥荒&lt;/a&gt;、 &lt;a href="https://en.m.wikipedia.org/wiki/List_of_epidemics_and_pandemics?ref=bounded-regret.ghost.io"&gt;流行病&lt;/a&gt;和&lt;a href="https://en.m.wikipedia.org/wiki/List_of_natural_disasters_by_death_toll?ref=bounded-regret.ghost.io"&gt;自然灾害&lt;/a&gt;列表中的数据。我考虑了其他数据来源，例如技术灾难，但所有这些数据的死亡人数都比上述五个数据要少得多。主要的例外是种族灭绝，因为这些通常与战争同时发生，并且已经包含在死亡人数中，因此我将其排除在外以避免重复计算。&lt;/p&gt;&lt;p&gt;我编写了一个 Python 脚本（在&lt;a href="https://www.lesswrong.com/feed.xml#scraping-script"&gt;附录&lt;/a&gt;中共享）来抓取这些源并将它们聚合到单个 Pandas 数据框中，然后进行过滤以创建两个数据集：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;灾难&lt;/strong&gt;：所有造成至少 0.1% 人口死亡的事件，计算方法是将总死亡人数除以事件开始时的世界人口。 &lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn2"&gt;[2]&lt;/a&gt;&lt;/sup&gt; &lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn3"&gt;[3]&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;严格的灾难&lt;/strong&gt;：我进一步限制“快速”（持续不到十年）且至少有 1% 的人口死亡的事件。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这组灾难包括85个事件，其中80个发生在公元0年以来，其中33个是战争，28个是饥荒，15个是流行病，6个是强迫劳动，3个是自然灾害。严格的灾难包括17个事件：5次战争、8次饥荒和4次流行病。我在下面列出了严格灾难的完整列表，以及所有灾难的散点图（有关原始数据，请参阅&lt;a href="https://www.lesswrong.com/feed.xml#scraping-script"&gt;附录&lt;/a&gt;）。 &lt;/p&gt;&lt;p&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/zsdej27vshx817jxxgzq" /&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/aoh79fzuiwbvftkounrs" /&gt;&lt;/p&gt;&lt;p&gt;除了这些历史事件之外，两个重要的史前事件是&lt;a href="https://en.wikipedia.org/wiki/Toba_catastrophe_theory?ref=bounded-regret.ghost.io"&gt;多巴灾难&lt;/a&gt;（人口减少 97%，可能是由于超级火山）和&lt;a href="https://en.wikipedia.org/wiki/4.2-kiloyear_event?ref=bounded-regret.ghost.io"&gt;4.2kya 事件&lt;/a&gt;（可能导致全球饥荒，但死亡人数尚不清楚）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;报告偏差和基准率。&lt;/strong&gt;很可能存在报告偏差，因为我们看到灾难的发生率在 1500 年代“增加”，并在 1900 年代再次增加，这种情况发生在包括饥荒在内的所有类别中（随着技术的进步，随着时间的推移，饥荒应该会减少）。如果从 1500 年开始，有 51 次灾难（0.11/年）和 11 次严格灾难（0.02/年）。&lt;/p&gt;&lt;p&gt;接下来让我们模拟（快速）灾难&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn4"&gt;[4]&lt;/a&gt;&lt;/sup&gt;的基本发生率如何随其严重程度变化。纵观所有导致至少 1% 人口下降的灾难，我们看到近似的&lt;a href="https://en.wikipedia.org/wiki/Zipf%27s_law?ref=bounded-regret.ghost.io"&gt;Zipfian&lt;/a&gt;分布：死亡率为 r 的灾难的概率与 1/r 成正比。 &lt;/p&gt;&lt;p&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/wgfcegdndv1dtfwggmzl" /&gt;&lt;/p&gt;&lt;p&gt;据此，死亡率为10%的灾难发生率为0.002次/年（每5个世纪一次），死亡率为1%的灾难发生率为0.02次/年（每个世纪两次）。虽然这些数字可能看起来很低，但它们意味着&lt;strong&gt;未来 25 年内大约有 5% 的可能性会发生死亡率为 10% 的灾难&lt;/strong&gt;（因为 0.002 * 25 = 0.05）。&lt;/p&gt;&lt;p&gt;死亡率低于 1% 时，发生灾难的可能性比齐普夫定律预测的要小（参见&lt;a href="https://www.lesswrong.com/feed.xml#log-log-plot-of-catastrophes"&gt;附录&lt;/a&gt;）。例如，0.1% 死亡率的经验频率是 0.08/年（略低于每十年一次）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;随着时间的推移的趋势。&lt;/strong&gt;如果我们统计 1500 年以来每个十年的灾难，我们会得到以下图表： &lt;/p&gt;&lt;p&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/wb5os0qkd9psxc2zrno9" /&gt;&lt;/p&gt;&lt;p&gt; 1850 年至 1950 年间发生了更多的灾难，尽管我怀疑这是报道偏见造成的。在此期间之前，随着时间的推移，灾难发生率似乎大致恒定：无论是&lt;a href="https://en.wikipedia.org/wiki/Ljung%E2%80%93Box_test?ref=bounded-regret.ghost.io"&gt;Ljung-Box 检验&lt;/a&gt;还是&lt;a href="https://en.wikipedia.org/wiki/Wald%E2%80%93Wolfowitz_runs_test?ref=bounded-regret.ghost.io"&gt;Wald-Wolfowitz 检验都&lt;/a&gt;无法拒绝灾难在 1500 年至 1900 年的几十年间均匀分布的零值（p=0.36 和 0.26） ， 分别）。&lt;/p&gt;&lt;p&gt;随着时间的推移，最显着的变化是我们目前所处的平静时期，大约从 1950 年到 1960 年开始。事实上，自 20 世纪上半叶以来，灾难显着减少：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 20世纪上半叶发生了9次饥荒，下半叶只发生了1次（中国大饥荒，1959-1961）&lt;/li&gt;&lt;li&gt;上半年发生了5次重大战争，下半年只发生了1次（朝鲜战争，1950-1953）&lt;/li&gt;&lt;li&gt;疫情较为稳定，上半年2起，下半年1起（加上2019年的新冠疫情）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;由于粮食生产和储存的改善，饥荒似乎有所减少，这有望成为持久的改善。由于&lt;a href="https://en.wikipedia.org/wiki/Pax_Americana?ref=bounded-regret.ghost.io"&gt;美国治下的和平&lt;/a&gt;，战争可能会减少，但不幸的是，随着全球紧张局势的加剧，这种情况现在可能正在缓解。因此，迄今为止，流行病和（可能）战争是现代灾难的主要根源。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;定性分析：多重因果关系。&lt;/strong&gt;许多灾难都有多种原因。例如，在黑死病的主流理论中，气候变化在两个方面起到了推动作用。首先，亚洲的气候变化导致啮齿动物从山区迁移到人口较多的地区，从而传播了疾病。其次，欧洲的小冰期导致饥荒，导致人口体弱，因此更容易感染疾病。 &lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn5"&gt;[5]&lt;/a&gt;&lt;/sup&gt;有趣的是，黑死病可能还加剧了小冰河时代，因为在人口减少的情况下重新造林，导致碳捕获和随后的降温。&lt;/p&gt;&lt;p&gt;举几个多重原因的其他例子：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在欧洲对美洲的殖民统治中，大多数死亡是由于疾病而不是战争。&lt;/li&gt;&lt;li&gt;明清的转变是由多种因素造成的，其中包括疾病和饥荒；饥荒本身可能是由小冰河时期引起的。&lt;/li&gt;&lt;li&gt;太平天国起义是由于饥荒造成的政治动荡而爆发的，随后的许多死亡是由干旱、饥荒和疾病造成的，而不是军事死亡。&lt;/li&gt;&lt;li&gt;一般来说，许多饥荒是由气候事件和/或糟糕的政府政策引起的。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;总的来说，这表明，为了减少灾难的数量或强度，我们不仅应该解决直接原因，还应该解决更系统性的上游原因。&lt;/p&gt;&lt;h1&gt;物种灭绝&lt;/h1&gt;&lt;p&gt;作为第二个参考类别，我考虑了非人类物种的灭绝。 &lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn6"&gt;[6]&lt;/a&gt;&lt;/sup&gt;由于以下几个原因，这更难以分析：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;大多数灭绝发生在数百万年前，因此我们只有间接证据，并且存在显着的采样偏差，因为某些物种更容易保存为化石。&lt;/li&gt;&lt;li&gt;如果一个物种逐渐适应新物种，它可能会灭绝，我们可能不想将其视为“灾难”。&lt;/li&gt;&lt;li&gt;一些所谓的大规模灭绝事件实际上可能是一段时间内发生的许多较小的事件。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了减少这些困难，我将重点关注两个相对较新的灭绝事件：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;第四纪晚期灭绝（ &lt;a href="https://www.annualreviews.org/doi/abs/10.1146/annurev.ecolsys.34.011802.132415?journalCode=ecolsys&amp;amp;ref=bounded-regret.ghost.io"&gt;Koch 和 Barnosky，2006&lt;/a&gt; ），发生在 10,000-50,000 年前，导致大多数大型哺乳动物灭绝。&lt;/li&gt;&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Holocene_extinction?ref=bounded-regret.ghost.io"&gt;全新世灭绝&lt;/a&gt;发生在过去一万年中（并且在过去一个世纪中不断增加），主要是由人类狩猎和栖息地破坏驱动的。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;虽然大多数历史上的大规模灭绝事件是由气候变化或自然灾害引起的，但最近的两次灭绝被认为全部或部分是由人类引起的。我将回顾下面关于这两次灭绝事件的证据和主要理论。&lt;/p&gt;&lt;h2&gt;历史基准利率&lt;/h2&gt;&lt;p&gt;在讨论第四纪和全新世灭绝之前，让我们计算一下上下文的基本速率。根据化石记录，平均&lt;a href="https://en.wikipedia.org/wiki/Background_extinction_rate?ref=bounded-regret.ghost.io"&gt;每百万年大约有一个物种灭绝一次&lt;/a&gt;。 &lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn7"&gt;[7]&lt;/a&gt;&lt;/sup&gt;然而，这些灭绝并不是随着时间的推移而恒定的，而是以“脉冲”的形式出现，如下所示（图片来自&lt;a href="https://en.wikipedia.org/wiki/Extinction_event?ref=bounded-regret.ghost.io"&gt;维基百科&lt;/a&gt;）： &lt;/p&gt;&lt;p&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/dfuifcmc1rwf6nughndc" /&gt;&lt;/p&gt;&lt;p&gt;在这些脉冲期间，每百万年的灭绝次数大约是背景速率的 2-10 倍。 &lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn8"&gt;[8]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;h2&gt;晚第四纪灭绝&lt;/h2&gt;&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Quaternary_extinction_event?ref=bounded-regret.ghost.io"&gt;晚第四纪灭绝&lt;/a&gt;跨越了大约 50,000 至 10,000 年前。在此期间，大约 34% 的哺乳动物灭绝了，其中包括美洲和澳大利亚的大多数哺乳动物以及全世界几乎所有大型哺乳动物。这比预期的背景灭绝率（40,000 年约为 4%）高出一个数量级。&lt;/p&gt;&lt;p&gt;下表（改编自维基百科）按地理区域和规模记录了灭绝事件： &lt;/p&gt;&lt;p&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/hyklusibuiqlssx8a9j4" /&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/xfvtfxj13q8vij8qqsmx" /&gt;&lt;/p&gt;&lt;p&gt;正如表格所示，非洲（人类起源地，因此哺乳动物可以共同进化防御能力）的灭绝最严重，而大型哺乳动物的灭绝最严重。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;原因。&lt;/strong&gt;从历史上看，研究人员一直争论这些灭绝是由气候变化还是人类接触造成的。为了理解这场争论，我阅读了几篇论文并选择遵循&lt;a href="https://www.annualreviews.org/doi/abs/10.1146/annurev.ecolsys.34.011802.132415?journalCode=ecolsys&amp;amp;ref=bounded-regret.ghost.io"&gt;Koch &amp;amp; Barnosky (2006)&lt;/a&gt; ，该论文系统地回顾了许多相互竞争的理论。科赫和巴诺斯基得出的结论是，灭绝的模式和强度是由人类驱动的，但气候变化是一个重要的额外因素：&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt; “总体而言，最近的研究表明，人类通过直接（狩猎）和间接（竞争、栖息地改变和破碎）综合影响，加速了全球许多地区的灭绝，但第四纪晚期的环境变化影响了时间、地理位置，也许还有灭绝的程度。换句话说，如果没有&lt;i&gt;智人&lt;/i&gt;的各种影响，全球生态系统不太可能在第四纪晚期经历大型、繁殖缓慢的动物的大规模灭绝。但是，如果全球许多地方没有同时出现明显的快速气候变化，一些物种可能会存活更长时间。”&lt;/p&gt;&lt;p&gt;因此，人类可能通过多种途径导致物种灭绝：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;直接狩猎&lt;/li&gt;&lt;li&gt;间接狩猎（通过我们带来的狗、老鼠和其他动物）&lt;/li&gt;&lt;li&gt;栖息地破坏（例如人为火灾）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;重要的是，不同的物种可能因不同的原因而灭绝。科赫和巴诺斯基认为，欧亚大陆的大多数灭绝是由于气候变化造成的，澳大利亚和大多数岛屿上的灭绝几乎完全是由人类造成的，而北美主要是人类造成的，气候是加剧因素。&lt;/p&gt;&lt;p&gt;这是一个说明要点的故事。它与 Koch 和 Barnosky 的观点一致，但为了简单性而忽略了不确定性。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;当人类到达岛屿时，他们带来了猪、狗和老鼠，这些动物都捕食当地物种。由于岛屿物种在进化上对这些掠食者来说是幼稚的，因此许多岛屿物种灭绝了。&lt;/li&gt;&lt;li&gt;火灾和土地清理造成的栖息地破坏也导致了岛屿灭绝。&lt;/li&gt;&lt;li&gt;在较大的陆地上，哺乳动物在进化上对肉食性捕食者并不幼稚，因此不会那么容易灭绝。然而，人类是非常高效的狩猎者，足以使许多物种的出生率低于死亡率，最终导致数千年的灭绝。&lt;/li&gt;&lt;li&gt;重要的是，人类的饮食多样化，因此，即使他们猎杀了一些哺乳动物直至灭绝，他们也从其他动植物中收集了足够的食物来维持大量的人口规模，从而避免了传统的&lt;a href="https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations?ref=bounded-regret.ghost.io"&gt;捕食者-猎物循环&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;在非洲和欧亚大陆，哺乳动物与人类或其祖先共同进化了数十万年或更长时间。因此，他们有足够的进化时间来发展对高效人类猎人的防御，这解释了与美国和澳大利亚相比灭绝率较低的原因。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;总体而言，人类狩猎可能是非岛屿物种灭绝的主要驱动因素，气候变化等其他因素也有贡献。重要的是，仅仅人类是一种新的掠食者还不够，因为新的掠食者并不总是导致灭绝。同样重要的是，我们是一种特别高效的掠食者，可以占据许多地理区域并具有多样化的饮食。&lt;/p&gt;&lt;h2&gt;全新世灭绝&lt;/h2&gt;&lt;p&gt;全新世灭绝大约在一万年前开始，最近有可能加速，大多数研究人员认为人类发挥着重要作用。&lt;/p&gt;&lt;p&gt;矛盾的是，尽管全新世灭绝发生得更晚，但其范围比晚第四纪灭绝更具争议，原因有两个。首先，大多数其他灭绝计数依赖于化石记录，但全新世灭绝是基于人类当前和历史的观察；这使得直接比较变得困难，因为这两种方法具有不同（且很大）的采样偏差。其次，全新世灭绝的程度被政治化，因为它是当今有关自然保护的争论的核心，因此很难找到中立的来源。&lt;/p&gt;&lt;p&gt;在浏览了几篇论文后，我决定跟随&lt;a href="https://www.nature.com/articles/nature09678?ref=bounded-regret.ghost.io"&gt;Barnosky 等人的脚步。 (2011)&lt;/a&gt; &lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn9"&gt;[9]&lt;/a&gt;&lt;/sup&gt; ，仔细讨论了抽样偏差的几个来源并尝试纠正它们。巴诺斯基等人。得出的结论是，在过去 500 年里，总物种的百分之几已经灭绝，这比预期的背景灭绝率高出一个数量级（请注意，有些论文给出了更高的估计&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn10"&gt;[10]&lt;/a&gt;&lt;/sup&gt; ）。巴诺斯基等人。还得出结论，如果大多数濒危物种在下个世纪灭绝，并且这种速度继续下去，我们将在几个世纪内失去所有物种的大多数，相当于历史上仅发生过 5 次（通常速度较慢）的大规模灭绝事件。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;原因。&lt;/strong&gt;巴诺斯基等人。列出了导致这些灭绝的几个压力因素：“快速变化的大气条件和变暖[...]、栖息地破碎化、污染、过度捕捞和过度狩猎、入侵物种和病原体[...]以及不断扩大的人类生物量”。 &lt;a href="https://www.annualreviews.org/doi/abs/10.1146/annurev.ecolsys.34.011802.132415?journalCode=ecolsys&amp;amp;ref=bounded-regret.ghost.io"&gt;Koch 和 Barnosky（2006）&lt;/a&gt;将第四纪灭绝造成的生态破坏视为进一步的压力源。 &lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn11"&gt;[11]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;与过去的灭绝不同，我们可以直接观察今天发生的许多全新世灭绝的原因。基于&lt;a href="https://pubmed.ncbi.nlm.nih.gov/20978281/?ref=bounded-regret.ghost.io"&gt;霍夫曼等人。 （2010）&lt;/a&gt; ，栖息地破坏是当前物种灭绝的最大驱动因素，其次是入侵物种（包括疾病）和过度捕猎，最后是气候变化和污染等环境原因。 &lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn12"&gt;[12]&lt;/a&gt;&lt;/sup&gt; &lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn13"&gt;[13]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;h2&gt;摘要：灭绝的典型原因是什么？&lt;/h2&gt;&lt;p&gt;总的来说，我对过去灭绝事件的分析指出了物种灭绝的几种方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;大规模灾难或气候事件，要么直接导致物种无法生存，要么破坏生态系统并导致后来的灭绝。&lt;/li&gt;&lt;li&gt;引入了一种新颖的、具有攻击性的生物体，而原始物种尚未适应这种生物体。这包括：&lt;ul&gt;&lt;li&gt;一种入侵物种，可以直接在其生态位竞争中击败某个物种或破坏周围的生态系统。&lt;/li&gt;&lt;li&gt;一种新的病原体，特别是如果它有&lt;a href="https://en.wikipedia.org/wiki/Natural_reservoir?ref=bounded-regret.ghost.io"&gt;储存物种的&lt;/a&gt;话。 &lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn14"&gt;[14]&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;&lt;li&gt;一种新的、高效的捕食者。这对岛屿物种影响最大，因为大陆物种在进化过程中暴露于足够多样化的捕食者之下，从而制定了强有力的应对策略。然而，具有多样化饮食的高效捕食者甚至可以压倒这些进化出的防御能力，即使对于非岛屿物种也是如此。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;栖息地的变化（通常来自气候变化或其他物种）。&lt;/li&gt;&lt;li&gt;其他物种灭绝的后续影响。这与上述内容部分重叠：例如，巨型食草动物的灭绝导致森林重新生长，从而显着改变了其他物种的栖息地。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;因此，一般来说，大多数物种灭绝是由以下原因引起的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;原始物种没有机会适应的第二个物种。第二个物种也必须不依赖于原始物种来繁殖。&lt;/li&gt;&lt;li&gt;灾难性的自然灾害或气候事件。&lt;/li&gt;&lt;li&gt;由上述两个来源之一造成的栖息地破坏或生态系统破坏。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;为什么灭绝通常很少见。&lt;/strong&gt;由于灭绝的基本发生率通常较低，因此灭绝的原因一定很罕见。为了更好地了解什么&lt;em&gt;会&lt;/em&gt;导致灭绝，让我们了解为什么对物种的大多数威胁&lt;em&gt;不会&lt;/em&gt;导致灭绝。&lt;/p&gt;&lt;p&gt;首先，大多数掠食者不会导致灭绝。这是因为猎物的防御能力随着捕食者的进攻而进化，而捕食者越好，猎物的进化压力就越大（因此防御能力的进化速度越快）。除此之外，如果猎物变得太稀有，那么捕食者种群&lt;a href="https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations?ref=bounded-regret.ghost.io"&gt;通常会崩溃&lt;/a&gt;，从而使猎物种群重新增长。因此，捕食者通常只有在以下情况下才会导致灭绝：（1）它们进入一个有非进化适应猎物的新环境；（2）它们以多种物种为食，这样它们就可以在不导致自身种群崩溃的情况下驱使一个物种灭绝。&lt;/p&gt;&lt;p&gt;同样，新的病原体默认情况下不会导致其宿主灭绝，因为如果它们杀死太多宿主物种，它们就没有目标可以传播。相反，“如果病原体……具有长期的感染阶段，或者是可以在常见储存宿主和更脆弱的目标物种之间传播的多宿主病原体，则它们更有可能导致宿主灭绝”（ &lt;a href="https://www.nature.com/scitable/knowledge/library/disease-ecology-15947677/?ref=bounded-regret.ghost.io"&gt;Kilpatrick 和 Altizer，2010&lt;/a&gt; ） 。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;人类。&lt;/strong&gt;最后，让我们分析一下为什么人类是如此高效的狩猎者，以至于我们能够使如此多的物种灭绝。首先，我们的适应能力很强，因此不仅能够生存，而且能够在各种环境中依靠多种食物来源生存。这让我们能够在全球范围内繁殖并导致一些物种灭绝，同时仍然有替代的食物来源。其次，我们可以有效地协调（ &lt;a href="https://www.scientificamerican.com/article/how-homo-sapiens-became-the-ultimate-invasive-species/?ref=bounded-regret.ghost.io"&gt;Marean，2015&lt;/a&gt; ），通过更好的战术压倒更大的猎物。最后，我们使用工具和技术来提高我们的狩猎能力并塑造我们的环境，放大了上面讨论的两个灭绝的关键驱动因素。&lt;/p&gt;&lt;h1&gt;现代灾难和人工智能的要点&lt;/h1&gt;&lt;p&gt;将人类灾难和非人类灭绝的所有驱动因素放在一起，我们看到了以下几个主题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;超大规模自然事件&lt;/li&gt;&lt;li&gt;高度适应、自我复制的生物体，尤其是那些受害者无法共同适应的生物体（流行病、新型病原体和捕食者、入侵物种）。&lt;/li&gt;&lt;li&gt;协调的人类群体（战争、狩猎、栖息地破坏）&lt;/li&gt;&lt;li&gt;政治镇压或破坏（强迫劳动、导致饥荒的糟糕政策）&lt;/li&gt;&lt;li&gt;其他灾难的后续影响。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;有趣的是，技术似乎并不是大多数人类灾难的直接罪魁祸首，尽管在大规模核战争中它可能是罪魁祸首。对于非人类灭绝来说，它可能是一个因素，因为技术提高了狩猎能力并减轻了栖息地破坏的程度。&lt;/p&gt;&lt;p&gt;纵观现代威胁，纳米技术和生物技术都可能创造出新型的自我复制器，而人类设计的加入可能会导致它们以相对于我们的进化防御而言不符合分布的方式进行“适应”。&lt;/p&gt;&lt;p&gt;核武器会增加战争的最坏结果，大规模监视会增加政治镇压的最坏结果。&lt;/p&gt;&lt;p&gt;气候变化是一个大规模的自然事件。除了直接影响外，如果它导致许多非人类物种灭绝，或引发政治动荡，后续影响可能对人类来说是灾难性的。持续灭绝导致的生物多样性丧失也可能造成不良的后续影响，尽管这种情况发生的速度足够缓慢，可能不会构成直接威胁。&lt;/p&gt;&lt;p&gt;最后，我们将人工智能放在这个等式中的什么位置？不幸的是，它看起来具有许多其他灾难驱动因素的特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;人工智能是自我复制的，因为它可以自我复制，并且可以训练自己快速适应新数据。因此，它是一种适应性的自我复制因子，而人类本身并不适应它。&lt;/li&gt;&lt;li&gt;人工智能很可能经过训练，能够比人类更好地协调，因为人类在进化上只适应在&lt;a href="https://en.wikipedia.org/wiki/Dunbar%27s_number?ref=bounded-regret.ghost.io"&gt;约 150&lt;/a&gt;人的群体中进行协调，而如果我们解决相关的&lt;a href="https://arxiv.org/abs/1705.08926?ref=bounded-regret.ghost.io"&gt;多智能体 RL 挑战，&lt;/a&gt;人工智能就可以被训练成在任意大的群体中进行协调。&lt;/li&gt;&lt;li&gt;人工智能带来的经济取代可能会导致政治动荡。&lt;/li&gt;&lt;li&gt;人工智能也是上述许多其他驱动因素的贡献者（尽管这可以说是重复计算）：它使大规模监视变得更容易，并可能加速其他危险技术（例如工程病原体）的创建。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;人工智能也具有改善的特性。首先，其他新技术并没有造成灾难，这应该会降低我们对人工智能的优先级。其次，人工智能辅助的研究可以帮助解决饥荒和气候变化，如果人工智能可以促进繁荣，那么它可以减少政治动荡。这些都是重要的考虑因素，但许多技术都具有这些特性，但几乎没有一种技术是可以在群体中协调的适应性自我复制器。&lt;/p&gt;&lt;p&gt;总的来说，我预计人工智能会增加灾难的发生率。根据&lt;a href="https://docs.google.com/document/d/1DOmluInO2KkgmumAf1wKLKHU7HbMeveIugR_oiFvHPc/edit?ref=bounded-regret.ghost.io#bookmark=id.xu338fnad04c"&gt;上面的计算&lt;/a&gt;，未来 25 年发生特大灾难（死亡率 10%）的基本概率是 5%，我个人预计人工智能会在此基础上再增加 10%，我将在下一篇中证明这一点。邮政。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;开放式问题。&lt;/strong&gt;这篇文章没有解决几个问题。首先，我的分析对于灾难发生率是否随时间变化或变化程度如何没有结论。来自灭绝事件的数据表明，它可能会有一个数量级的变化，但最好有关于人类事件的数据。&lt;/p&gt;&lt;p&gt;其次，这篇文章很少谈到技术和智能的重要性，尽管它们直观上很重要。技术灾难是否会随着时间的推移而增加，即使目前它们还太小而无法记录在上述数据中？高智慧物种是否经常导致低智慧物种灭绝？ &lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn15"&gt;[15]&lt;/a&gt;&lt;/sup&gt;其中任何一个的基本利率都将为人工智能的预测提供信息。&lt;/p&gt;&lt;p&gt;最后，有人可能会争辩说，经过的时间并不是正确的 x 轴，而是经过的人口增长、经济增长或技术进步。以世界 GDP 为例。自 1900 年以来，世界 GDP 翻番的次数与 1900 年至公元 0CE 之间的翻番次数一样多，因此，如果 GDP 翻番是衡量的正确“时钟”，那么我们可能会预计现在每个十年都会比过去发生更多的灾难。从到目前为止的数据来看，这对我来说似乎并不正确，但我希望看到更详细的分析。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;致谢。&lt;/strong&gt;特别感谢 Dhruv Madeka 的讨论和最初的数据为这篇文章提供了灵感。还要感谢 Sham Kakade、Dean Foster、Tamay Berisoglu、Eli Lifland、Nuño Sempere、Daniel Kokotajlo 和 Ege Erdil 对本文的有益讨论和评论。感谢 Justis Mills 和 Louise Verkin 的文案编辑和有用的反馈。&lt;/p&gt;&lt;hr /&gt;&lt;section class="footnotes"&gt;&lt;ol&gt;&lt;li class="footnote-item" id="fn1"&gt;&lt;p&gt;当然，数字本身可能会产生误导，因为许多历史数字都是基于猜测！这篇文章中的很多工作都是进行广泛的阅读来决定相信哪些数字。 &lt;a href="https://www.lesswrong.com/feed.xml#fnref1"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn2"&gt;&lt;p&gt;人口规模是从&lt;a href="https://ourworldindata.org/grapher/population?time=-1000..latest&amp;amp;country=%7EOWID_WRL&amp;amp;ref=bounded-regret.ghost.io"&gt;我们的世界数据中&lt;/a&gt;收集的，请参阅&lt;a href="https://www.lesswrong.com/feed.xml#population-by-country-across-history"&gt;附录&lt;/a&gt;。 &lt;a href="https://www.lesswrong.com/feed.xml#fnref2"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn3"&gt;&lt;p&gt;太平天国叛乱被双重计算，一次被视为战争，一次被视为饥荒。 &lt;a href="https://www.lesswrong.com/feed.xml#fnref3"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn4"&gt;&lt;p&gt;如上所述，“快”意味着不到十年。 &lt;a href="https://www.lesswrong.com/feed.xml#fnref4"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn5"&gt;&lt;p&gt;另一种理论认为，蒙古人的入侵（另一场灾难）传播了黑死病，因为蒙古人将患病的尸体扔进城市作为生物战的一种形式。这不是目前的主流理论，但将是多重因果关系的另一个例子，并表明不同的重大灾难可以相互联系。 &lt;a href="https://www.lesswrong.com/feed.xml#fnref5"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn6"&gt;&lt;p&gt;从技术上讲，历史化石记录通常只能解决属而非物种层面的灭绝问题，但为了简单起见，我通常会忽略这种区别。 &lt;a href="https://www.lesswrong.com/feed.xml#fnref6"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn7"&gt;&lt;p&gt;请注意，这因分类单元而异，并且分类单元内的估计值是近似值，文献中的不同估计值相差 4 倍或有时更大。 &lt;a href="https://www.lesswrong.com/feed.xml#fnref7"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn8"&gt;&lt;p&gt; 2-10 倍的数字是查看 100 万年的 bin 时的数字。对于小行星撞击等突发灾难性事件，一年时间间隔内的灭绝率会大幅上升。 &lt;a href="https://www.lesswrong.com/feed.xml#fnref8"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn9"&gt;&lt;p&gt;这就是上面的巴诺斯基，尽管我在寻找论文时并不知道这一点——在这两种情况下，他碰巧写了我认为最中立和最有说服力的论文。令我高兴的是，我得知他也在加州大学伯克利分校。熊们走吧！ &lt;a href="https://www.lesswrong.com/feed.xml#fnref9"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn10"&gt;&lt;p&gt;参见&lt;a href="https://www.science.org/doi/10.1126/sciadv.1400253?ref=bounded-regret.ghost.io"&gt;Ceballos 等人。 (2015)&lt;/a&gt; ，估计值比背景率高出接近两个数量级。 &lt;a href="https://www.lesswrong.com/feed.xml#fnref10"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn11"&gt;&lt;p&gt; “例子包括失去种子传播主要媒介的植物，或者充满了对不再存在的食草动物的防御的植物，为所有现有捕食者“过度设计”的食草动物，&lt;br /&gt;还有像秃鹰这样的食腐动物，它们在大陆环境中没有自然产生的尸体可供食用。” &lt;a href="https://www.lesswrong.com/feed.xml#fnref11"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn12"&gt;&lt;p&gt;我遵循&lt;a href="https://pubmed.ncbi.nlm.nih.gov/20978281/?ref=bounded-regret.ghost.io"&gt;Hoffmann 等人的图 S7。&lt;/a&gt; （转载于&lt;a href="https://www.lesswrong.com/feed.xml#species-endangerment-by-cause"&gt;附录&lt;/a&gt;），统计了按濒危原因分组的濒危物种。我将这些行分为“栖息地破坏”、“入侵物种”（包括两栖动物的&lt;a href="https://en.wikipedia.org/wiki/Chytridiomycosis?ref=bounded-regret.ghost.io"&gt;壶菌&lt;/a&gt;病）、“过度狩猎/过度捕捞”和“环境”（气候变化/污染/自然灾害）。有些类别不明确或不适合这 4 个类别。总体而言，我计算出约 360 个栖息地破坏，约 250 个来自入侵物种（以两栖动物为主），约 130 个来自过度狩猎/过度捕捞，约 40 个来自环境。 &lt;a href="https://www.lesswrong.com/feed.xml#fnref12"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn13"&gt;&lt;p&gt;另请参阅&lt;a href="https://www.annualreviews.org/doi/pdf/10.1146/annurev.energy.28.050302.105532?ref=bounded-regret.ghost.io"&gt;Dirzo 和 Raven (2003)&lt;/a&gt; ，他们同样声称栖息地破坏是主要驱动因素。 &lt;a href="https://www.lesswrong.com/feed.xml#fnref13"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn14"&gt;&lt;p&gt;储存物种是病原体不致命的第二种物种，允许其更自由地繁殖，并且病原体可以从其中传播到目标物种。 &lt;a href="https://www.lesswrong.com/feed.xml#fnref14"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn15"&gt;&lt;p&gt;我发现最接近的是&lt;a href="https://www.nature.com/articles/s41598-022-07327-9?ref=bounded-regret.ghost.io"&gt;Dembitzer 等人。 （2022）&lt;/a&gt; ，他们声称更聪明的哺乳动物在第四纪晚期灭绝期间灭绝的可能性较小。然而，理想情况下，我们想要研究相反的问题：更聪明的哺乳动物是否更有可能导致&lt;em&gt;其他&lt;/em&gt;物种灭绝？ &lt;a href="https://www.lesswrong.com/feed.xml#fnref15"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;&lt;h1&gt;附录&lt;/h1&gt;&lt;h2&gt;灾难的双对数图&lt;/h2&gt;&lt;p&gt;正如第 1 节所述，当死亡人数低于 1% 时，灾难的分布不再遵循齐普夫定律，如下所示： &lt;br /&gt;&lt;img alt="events_power_law_01.png" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/pogy0xusqv3jf1vpdej2" /&gt;&lt;br /&gt;一种可能性是实际趋势是对数正态分布而不是幂律分布。另一个原因是不太严重的事件没有得到充分报告。&lt;/p&gt;&lt;h2&gt;物种濒危原因&lt;/h2&gt;&lt;p&gt;以下是&lt;a href="https://www.science.org/doi/10.1126/science.1194442?ref=bounded-regret.ghost.io"&gt;Hoffmann 等人的图 S7 的复制品。 （2010）&lt;/a&gt; 。 &lt;br /&gt;&lt;img alt="霍夫曼_figs7.png" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/SgYz4YPKridWXJSE6/o0x5tingr8fej6jn4f7z" /&gt;&lt;/p&gt;&lt;h2&gt;历史上各个国家的人口&lt;/h2&gt;&lt;div&gt;&lt;a href="https://bounded-regret.ghost.io/content/files/2023/12/population.csv"&gt;&lt;div&gt;&lt;div&gt; 人口&lt;/div&gt;&lt;div&gt;历史世界人口的原始数据（直接参见下面的交互式 HTML）&lt;/div&gt;&lt;div&gt;&lt;div&gt;人口.csv&lt;/div&gt;&lt;div&gt; 1MB&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;下载圈&lt;/div&gt;&lt;/div&gt;&lt;h2&gt;抓取脚本&lt;/h2&gt;&lt;div&gt;&lt;a href="https://bounded-regret.ghost.io/content/files/2023/12/scrape_events.py"&gt;&lt;div&gt;&lt;div&gt;抓取事件&lt;/div&gt;&lt;div&gt;用于抓取维基百科重大灾难列表的 Python 脚本&lt;/div&gt;&lt;div&gt;&lt;div&gt;scrap_events.py&lt;/div&gt;&lt;div&gt; 13KB&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;下载圈&lt;/div&gt;&lt;/div&gt;&lt;h2&gt;所有重大灾难的完整列表&lt;/h2&gt;&lt;div&gt;&lt;a href="https://bounded-regret.ghost.io/content/files/2023/12/events_all.csv"&gt;&lt;div&gt;&lt;div&gt; 全部事件&lt;/div&gt;&lt;div&gt;从维基百科中删除的所有重大灾难的列表&lt;/div&gt;&lt;div&gt;&lt;div&gt;events_all.csv&lt;/div&gt;&lt;div&gt; 6KB&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;下载圈&lt;/div&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.lesswrong.com/posts/SgYz4YPKridWXJSE6/analyzing-the-historical-rate-of-catastrophes#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Tue, 05 Dec 2023 06:30:03 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/SgYz4YPKridWXJSE6/analyzing-the-historical-rate-of-catastrophes</guid></item><item><title>一些开源词典和词典学习基础设施</title><link>https://www.lesswrong.com/posts/AaoWLcmpY3LKvtdyq/some-open-source-dictionaries-and-dictionary-learning</link><description>发布于 2023 年 12 月 5 日上午 6:05（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;随着越来越多的人开始从事包含字典学习的可解释性项目，公开提供高质量的字典将很有价值。 &lt;span class="footnote-reference" id="fnrefxki2bn9t6a"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnxki2bn9t6a"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;为了让事情顺利进行，我和我的合作者（Aaron Mueller）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;开源许多在 Pythia-70m MLP 上训练的稀疏自动编码器字典&lt;/li&gt;&lt;li&gt;发布我们用于训练这些词典的&lt;a href="https://github.com/saprmarks/dictionary_learning"&gt;存储库&lt;/a&gt;&lt;span class="footnote-reference" id="fnrefp7b5kczep0n"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnp7b5kczep0n"&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们首先讨论字典，然后讨论存储库。&lt;/p&gt;&lt;h1&gt;字典&lt;/h1&gt;&lt;p&gt;词典可以从&lt;a href="https://baulab.us/u/smarks/autoencoders/"&gt;这里&lt;/a&gt;下载。有关如何下载和使用它们的信息，请参阅&lt;a href="https://github.com/saprmarks/dictionary_learning"&gt;此处的&lt;/a&gt;“下载我们的开源词典”和“使用经过训练的词典”部分。如果您在发表的论文中使用这些词典，我们要求您在致谢中提及我们。&lt;/p&gt;&lt;p&gt;我们正在为 EleutherAI 的 6 层 pythia-70m-deduped 模型发布两套字典。两组字典都使用来自&lt;a href="https://pile.eleuther.ai/"&gt;The Pile&lt;/a&gt;的约 8 亿个令牌，在 512 维 MLP&lt;i&gt;输出&lt;/i&gt;激活（而不是像 Anthropic 使用的 MLP 隐藏层）上进行训练。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;第一组称为&lt;code&gt;0_8192&lt;/code&gt; ，由大小为&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;8192&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;16&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;×&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;512&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的字典组成。这些训练的 L1 惩罚为&lt;code&gt;1e-3&lt;/code&gt; 。&lt;/li&gt;&lt;li&gt;第二组称为&lt;code&gt;1_32768&lt;/code&gt; ，由大小为&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;32768&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;64&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;×&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;512&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的字典组成。这些训练的 l1 惩罚为&lt;code&gt;3e-3&lt;/code&gt; 。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;以下是一些统计数据。 （有关这些统计数据含义的更多信息，请参阅我们的存储库的&lt;a href="https://github.com/saprmarks/dictionary_learning"&gt;自述文件&lt;/a&gt;。）&lt;/p&gt;&lt;p&gt;对于&lt;code&gt;0_8192&lt;/code&gt;集中的字典：&lt;/p&gt;&lt;figure class="table"&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;层&lt;/th&gt;&lt;th&gt;均方误差损失&lt;/th&gt;&lt;th&gt;L1损失&lt;/th&gt;&lt;th&gt;L0&lt;/th&gt;&lt;th&gt;存活百分比&lt;/th&gt;&lt;th&gt;损失恢复百分比&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt; 0.056&lt;/td&gt;&lt;td&gt; 6.132&lt;/td&gt;&lt;td&gt; 9.951&lt;/td&gt;&lt;td&gt; 0.998&lt;/td&gt;&lt;td&gt; 0.984&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 1&lt;/td&gt;&lt;td&gt; 0.089&lt;/td&gt;&lt;td&gt; 6.677&lt;/td&gt;&lt;td&gt; 44.739&lt;/td&gt;&lt;td&gt; 0.887&lt;/td&gt;&lt;td&gt; 0.924&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 2&lt;/td&gt;&lt;td&gt; 0.108&lt;/td&gt;&lt;td&gt; 11.44&lt;/td&gt;&lt;td&gt; 62.156&lt;/td&gt;&lt;td&gt; 0.587&lt;/td&gt;&lt;td&gt; 0.867&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 3&lt;/td&gt;&lt;td&gt; 0.135&lt;/td&gt;&lt;td&gt; 23.773&lt;/td&gt;&lt;td&gt; 175.303&lt;/td&gt;&lt;td&gt; 0.588&lt;/td&gt;&lt;td&gt; 0.902&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 4&lt;/td&gt;&lt;td&gt; 0.148&lt;/td&gt;&lt;td&gt; 27.084&lt;/td&gt;&lt;td&gt; 174.07&lt;/td&gt;&lt;td&gt; 0.806&lt;/td&gt;&lt;td&gt; 0.927&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 5&lt;/td&gt;&lt;td&gt; 0.179&lt;/td&gt;&lt;td&gt; 47.126&lt;/td&gt;&lt;td&gt; 235.05&lt;/td&gt;&lt;td&gt; 0.672&lt;/td&gt;&lt;td&gt; 0.972&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;对于&lt;code&gt;1_32768&lt;/code&gt;集中的字典：&lt;/p&gt;&lt;figure class="table"&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;层&lt;/th&gt;&lt;th&gt;均方误差损失&lt;/th&gt;&lt;th&gt;L1损失&lt;/th&gt;&lt;th&gt;L0&lt;/th&gt;&lt;th&gt;存活百分比&lt;/th&gt;&lt;th&gt;损失恢复百分比&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt; 0.09&lt;/td&gt;&lt;td&gt; 4.32&lt;/td&gt;&lt;td&gt; 2.873&lt;/td&gt;&lt;td&gt; 0.174&lt;/td&gt;&lt;td&gt; 0.946&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 1&lt;/td&gt;&lt;td&gt; 0.13&lt;/td&gt;&lt;td&gt; 2.798&lt;/td&gt;&lt;td&gt; 11.256&lt;/td&gt;&lt;td&gt; 0.159&lt;/td&gt;&lt;td&gt; 0.768&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 2&lt;/td&gt;&lt;td&gt; 0.152&lt;/td&gt;&lt;td&gt; 6.151&lt;/td&gt;&lt;td&gt; 16.381&lt;/td&gt;&lt;td&gt; 0.118&lt;/td&gt;&lt;td&gt; 0.724&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 3&lt;/td&gt;&lt;td&gt; 0.211&lt;/td&gt;&lt;td&gt; 11.571&lt;/td&gt;&lt;td&gt; 39.863&lt;/td&gt;&lt;td&gt; 0.226&lt;/td&gt;&lt;td&gt; 0.765&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 4&lt;/td&gt;&lt;td&gt; 0.222&lt;/td&gt;&lt;td&gt; 13.665&lt;/td&gt;&lt;td&gt; 29.235&lt;/td&gt;&lt;td&gt; 0.19&lt;/td&gt;&lt;td&gt; 0.816&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; 5&lt;/td&gt;&lt;td&gt; 0.265&lt;/td&gt;&lt;td&gt; 26.4&lt;/td&gt;&lt;td&gt; 43.846&lt;/td&gt;&lt;td&gt; 0.13&lt;/td&gt;&lt;td&gt; 0.931&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;这是一些特征频率的直方图。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/bwz8jq2puk7bt2v5i30r" /&gt;&lt;/figure&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/AaoWLcmpY3LKvtdyq/xbofxvy4qa4st0bujv2y" /&gt;&lt;/figure&gt;&lt;p&gt;总的来说，我认为这些词典还不错，但并不令人惊奇。&lt;/p&gt;&lt;p&gt;我们训练这些字典是因为我们想要进行字典学习的下游应用，但缺乏字典。这些词典足以让我们开始我们的主线项目，但我预计不久之后我们将回来训练一些更好的词典（我们也将开源）。我认为对其他人来说也是如此：这些词典应该足以开始需要词典的项目；当以后有更好的词典可用时，您可以更换它们以获得最佳结果。&lt;/p&gt;&lt;p&gt;关于这些词典的一些杂项注释（您可以在&lt;a href="https://github.com/saprmarks/dictionary_learning"&gt;repo&lt;/a&gt;中找到更多信息）。&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;code&gt;1_32768&lt;/code&gt;的 L1 惩罚似乎太大了；只有10-20%的神经元还活着，恢复的损失就更严重了。也就是说，我们会注意到，在检查了两组词典的特征后， &lt;code&gt;1_32768&lt;/code&gt;集中的词典似乎比&lt;code&gt;0_8192&lt;/code&gt;集中的词典具有更多可解释的特征（尽管很难说）。&lt;ul&gt;&lt;li&gt;特别是，我们怀疑对于&lt;code&gt;0_8192&lt;/code&gt; ，后面层中的许多高频特征是无法解释的，但对重建激活有很大帮助，&lt;strong&gt;从而产生看似漂亮的统计数据&lt;/strong&gt;。 （请参阅下面有关神经元重采样和双峰性的要点。）&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;随着我们逐层推进，字典在大多数指标上往往会变得更糟（恢复损失百分比除外）。这可能与当人们穿过 pythia 模型各层时激活本身的规模不断扩大有关（感谢 Arthur Conmy 提出这一假设）。&lt;/li&gt;&lt;li&gt;我们注意到，我们的字典特征的频率明显高于&lt;a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html"&gt;Anthropic&lt;/a&gt;和&lt;a href="https://www.lesswrong.com/posts/fKuugaxt2XLTkASkk/open-source-replication-and-commentary-on-anthropic-s"&gt;Neel Nanda&lt;/a&gt;中的特征。我们不知道这种差异是因为我们正在使用多层模型还是因为超参数的差异。我们通常怀疑如果我们学习频率较低的特征会更好。&lt;ul&gt;&lt;li&gt;然而，我们会注意到，在第 0 层之后，我们的许多功能似乎并不具有“总是在特定令牌上触发”的形式，而 Anthropic 的许多功能都是如此。因此，更有趣的功能也可能出现频率更高。看看&lt;a href="https://www.lesswrong.com/posts/tEPHGZAb63dfq2v8n/?commentId=zXEsbbJHsg98FY6uj"&gt;这里&lt;/a&gt;有一些味道。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;我们不确定，但&lt;code&gt;0_8192&lt;/code&gt;的直方图中的双峰性可能是由于死亡神经元被重新采样所致。我们每 30000 个步骤重新采样一次，包括 100000 个总步骤中的第 90000 个步骤。重采样的特征往往频率非常高，峰值可能需要超过 10000 步才能向左移动。&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;字典学习库&lt;/h1&gt;&lt;p&gt;同样，这可以&lt;a href="https://github.com/saprmarks/dictionary_learning"&gt;在这里&lt;/a&gt;找到。我们遵循&lt;a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html#appendix-autoencoder"&gt;Anthropic 论文&lt;/a&gt;中详细介绍的方法（包括使用不受限的编码器/解码器权重、限制解码器向量具有单位范数，以及根据其古怪的方案对死亡神经元进行重新采样），但以下情况除外：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们没有足够的空间来存储整个数据集的激活，因此，按照&lt;a href="https://www.lesswrong.com/posts/fKuugaxt2XLTkASkk/open-source-replication-and-commentary-on-anthropic-s"&gt;Neel Nanda 的复制&lt;/a&gt;，我们维护一个来自几千个上下文的令牌缓冲区，并从该缓冲区中随机采样，直到它是半空的（此时我们刷新它带有来自新上下文的标记）。&lt;/li&gt;&lt;li&gt;我们使用简短的线性学习率预热来解决 Adam 会在前几个训练步骤中杀死太多神经元的问题，然后才有机会校准 Adam 参数。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt; （一个简单的插件：这个存储库是使用&lt;a href="http://nnsight.net/"&gt;nnsight&lt;/a&gt;构建的，这是一个新的可解释性工具库（如&lt;a href="https://github.com/neelnanda-io/TransformerLens"&gt;Transformer_lens&lt;/a&gt;和&lt;a href="https://github.com/davidbau/baukit"&gt;baukit&lt;/a&gt; ），由 Jaden Fiotto-Kaufman 和&lt;a href="https://baulab.info/"&gt;Bau 实验室&lt;/a&gt;的其他人开发。 &lt;code&gt;nnsight&lt;/code&gt;仍在开发中，所以我只建议尝试深入研究如果你对偶尔的错误、内存泄漏等没问题的话，现在就进入它（你可以在&lt;a href="https://discord.gg/JqMpyYtS"&gt;这个 Discord 服务器&lt;/a&gt;的反馈通道中报告）。但总的来说，我对这个项目非常兴奋——除了提供一个非常干净的用户之外根据经验，一个主要设计目标是&lt;code&gt;nnsight&lt;/code&gt;代码具有高度&lt;i&gt;可移植性&lt;/i&gt;：理想情况下，您应该能够使用 Pythia-70m 制作实验原型，无缝切换到跨多个 GPU 的 LLaMA-2-70B 上运行，然后将代码发送到人择将在克劳德身上运行。）&lt;/p&gt;&lt;p&gt;除了主线功能之外，我们的存储库还支持一些实验性功能，我们简要研究了这些功能作为训练词典的替代方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; &lt;strong&gt;MLP 担架。&lt;/strong&gt;基于人们可能能够通过“&lt;a href="https://transformer-circuits.pub/2022/toy_model/index.html"&gt;足够大的模型中的神经元&lt;/a&gt;”识别特征的观点，我们尝试训练“自动编码器”，以给定 MLP&lt;i&gt;输入&lt;/i&gt;激活&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;作为输入， &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;输出&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;MLP&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;（&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; MLP 输出） ）。例如，给定一个 MLP，它将 512 维输入&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;映射到 1024 维隐藏状态&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，然后映射到 512 维输出&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，我们训练一个隐藏维度为&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;16384&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;16&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;×&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1024&lt;/span&gt;&lt;/span&gt;的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;字典&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，使得&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;接近&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; （并且像往常一样，因此字典的隐藏状态是稀疏的）。&lt;ul&gt;&lt;li&gt;最终的词典看起来不错，但我们决定不再进一步追求这个想法。&lt;/li&gt;&lt;li&gt; （向 Max Li 提出此建议。）&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;用熵代替 L1 损失&lt;/strong&gt;。基于这篇&lt;a href="https://transformer-circuits.pub/2023/may-update/index.html#simple-factorization"&gt;文章&lt;/a&gt;中的想法，我们尝试使用熵来规范字典的隐藏状态而不是 L1 损失。这似乎导致这些功能要么是死功能（从未触发），要么是在几乎每个输入上触发的非常高频的功能，这不是所需的行为。但似乎有一种方法可以让这项工作变得更好。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果您想追求上述要点中的想法之一，请在获得初步结果后与我（Sam）联系 - 我可能有兴趣讨论结果或合作。&lt;/p&gt;&lt;ol class="footnotes"&gt;&lt;li class="footnote-item" id="fnxki2bn9t6a"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefxki2bn9t6a"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;这既是为了可重复性，也是因为每个字典都需要一些努力来训练。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnp7b5kczep0n"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefp7b5kczep0n"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;当然，来自&lt;a href="https://arxiv.org/abs/2309.08600"&gt;Cunningham 等人的存储库。纸张&lt;/a&gt;也可以&lt;a href="https://github.com/HoagyC/sparse_coding"&gt;在这里&lt;/a&gt;购买。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/AaoWLcmpY3LKvtdyq/some-open-source-dictionaries-and-dictionary-learning#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Tue, 05 Dec 2023 06:05:21 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/AaoWLcmpY3LKvtdyq/some-open-source-dictionaries-and-dictionary-learning</guid></item><item><title>The LessWrong 2022 回顾</title><link>https://www.lesswrong.com/posts/B6CxEApaatATzown6/the-lesswrong-2022-review</link><description>发布于 2023 年 12 月 5 日凌晨 4:00（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;雪花飘落，颂歌开始响起，我们都知道是时候开始我们最喜欢的冬季假期传统了。审稿时间少了！ &lt;/p&gt;&lt;figure class="image image_resized" style="width: 69.55%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/swcjknwqnq58jqjizlbu" /&gt;&lt;/figure&gt;&lt;p&gt;每年我们都会聚在一起审查至少一年前的帖子。这意味着在接下来的两个月里，我们将审核 2022 年的所有帖子。&lt;/p&gt;&lt;p&gt;虽然我们的日常生活充满了时尚，追逐着业力和社会认可的甜蜜滋味，但LessWrong的评论是时候退一步问自己“这真的能帮助我更好地思考吗？”，“这真的是事实吗？变得有价值？”以及“哪些事情经受住了进一步和广泛的审查？”。&lt;/p&gt;&lt;p&gt;到目前为止，我们已经这样做了 4 次（ &lt;a href="https://www.lesswrong.com/posts/3yqf6zJSwBF34Zbys/2018-review-voting-results"&gt;2018 年&lt;/a&gt;、 &lt;a href="https://www.lesswrong.com/posts/kdGSTBj3NA2Go3XaE/2019-review-voting-results"&gt;2019 年&lt;/a&gt;、 &lt;a href="https://www.lesswrong.com/posts/TSaJ9Zcvc3KWh3bjX/voting-results-for-the-2020-review"&gt;2020 年&lt;/a&gt;、 &lt;a href="https://www.lesswrong.com/posts/zajNa9fdr8JYJpxrG/voting-results-for-the-2021-review"&gt;2021 年&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;年度审核如何运作的完整技术细节位于本文的&lt;a href="https://www.lesswrong.com/posts/B6CxEApaatATzown6/the-lesswrong-2022-review#How_does_the_review_work_"&gt;最后部分&lt;/a&gt;，但与过去几年基本相同。分为三个阶段：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;初步投票阶段&lt;/strong&gt;&lt;i&gt;（2 周，12 月 4 日至 17 日）&lt;/i&gt; ：我们在进行初步投票的审核中确定特别值得考虑的帖子。获得 2 票初步投票的帖子进入讨论阶段。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;讨论阶段&lt;/strong&gt;&lt;i&gt;（4 周，12 月 17 日 — 1 月 14 日）&lt;/i&gt; ：&lt;i&gt; &lt;/i&gt;我们审查和辩论帖子。收到至少一篇书面评论的帖子将进入最终投票阶段。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;最终投票&lt;/strong&gt;&lt;i&gt;（2 周，1 月 14 日至 1 月 28 日）&lt;/i&gt; ：我们使用二次投票进行完整投票。其结果决定年度评审结果。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;有关年度审核理念的更多信息，请参阅之前的公告帖子：&lt;a href="https://www.lesswrong.com/posts/qXwmMkEBLL59NkvYR/the-lesswrong-2018-review"&gt;此处&lt;/a&gt;、 &lt;a href="https://www.lesswrong.com/posts/QFBEjjAvT6KbaA3dY/the-lesswrong-2019-review#Improving_our_incentives_and_rewards"&gt;此处&lt;/a&gt;、&lt;a href="https://www.lesswrong.com/posts/M9kDqF2fn3WH44nrv/the-2020-review"&gt;此处&lt;/a&gt;和&lt;a href="https://www.lesswrong.com/posts/qCc7tm29Guhz6mtf7/the-lesswrong-2021-review-intellectual-circle-expansion"&gt;此处&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;入门&lt;/h2&gt;&lt;p&gt;在任何符合审核资格的帖子的顶部，您都会看到： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1672905457/mirroredImages/qCc7tm29Guhz6mtf7/d0fpa6iead1yz8j7y10n.png" /&gt;&lt;/figure&gt;&lt;p&gt;这些将是您对 2022 年审核的初步投票。帖子需要获得至少 2 票初步投票（正面或负面）才能进入下一阶段的审核。&lt;/p&gt;&lt;p&gt;要开始仔细阅读帖子，我建议转到&lt;a href="https://www.lesswrong.com/allPosts?timeframe=yearly&amp;amp;after=2022-01-01&amp;amp;before=2023-01-01&amp;amp;limit=100&amp;amp;sortedBy=top&amp;amp;filter=unnominated&amp;amp;includeShortform=false"&gt;&lt;u&gt;“2022 年所有帖子”页面&lt;/u&gt;&lt;/a&gt;或&lt;a href="https://www.lesswrong.com/votesByYear/2022"&gt;&lt;u&gt;“查看您过去的点赞”&lt;/u&gt;&lt;/a&gt;页面。&lt;i&gt;注意：只有2022年1月之前注册账户的用户才有资格投票。&lt;/i&gt;&lt;/p&gt;&lt;h2&gt;今年没有书了，抱歉各位&lt;/h2&gt;&lt;p&gt;2018年、2019年和2020年，我们印制了审查结果的书籍。我们已经售出了数千件，我为它们感到非常自豪，很多人告诉我，这些是他们最喜欢的东西之一： &lt;/p&gt;&lt;figure class="table"&gt;&lt;table style="border-color: white; border-style: solid;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;figure class="image image_resized" style="width: 100%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/hkxvgpqalnv6oevaxned" /&gt;&lt;figcaption&gt; 2018：反映领土的地图（ &lt;a href="https://www.amazon.com/Map-that-Reflects-Territory-LessWrong/dp/1736128507/ref=sr_1_1?crid=5YSFIY94WGVQ&amp;amp;keywords=lesswrong+books&amp;amp;qid=1701728381&amp;amp;sprefix=lesswrong+book%2Caps%2C145&amp;amp;sr=8-1"&gt;亚马逊&lt;/a&gt;） &lt;/figcaption&gt;&lt;/figure&gt;&lt;/td&gt;&lt;td&gt;&lt;figure class="image image_resized" style="width: 100%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/kcpulhgcmm5hsxlnaxga" /&gt;&lt;figcaption&gt; 2019：认知引擎（ &lt;a href="https://www.amazon.com/Engines-Cognition-Essays-LessWrong-Community/dp/1736128515/ref=sr_1_2?crid=5YSFIY94WGVQ&amp;amp;keywords=lesswrong+books&amp;amp;qid=1701728381&amp;amp;sprefix=lesswrong+book%2Caps%2C145&amp;amp;sr=8-2"&gt;亚马逊&lt;/a&gt;） &lt;/figcaption&gt;&lt;/figure&gt;&lt;/td&gt;&lt;td&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/B6CxEApaatATzown6/noak9x8qlrktfpottnxx" /&gt;&lt;figcaption&gt; 2020：现实的雕刻（ &lt;a href="https://www.amazon.com/Carving-Reality-Essays-LessWrong-Community/dp/B0C95MJJBK/ref=sr_1_5?crid=5YSFIY94WGVQ&amp;amp;keywords=lesswrong+books&amp;amp;qid=1701728398&amp;amp;sprefix=lesswrong+book%2Caps%2C145&amp;amp;sr=8-5"&gt;亚马逊&lt;/a&gt;）&lt;/figcaption&gt;&lt;/figure&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;遗憾的是，今年不会有书（也不会有 2021 年的评论）。随着我们许多其他项目的需求不断增加（以及资金的减少，因为如果考虑到每年 4-5 个员工月的制作成本，我们在以下方面净损失了资金）这些）。&lt;/p&gt;&lt;p&gt;我正在考虑其他方法来创建一个易于参考的工件，以捕获今年和去年的审查结果。我认为我想做的最低限度是创建一本好的电子书，也许还可以使用我们的机器旁白（或进行人类旁白）制作一个有声版本。欢迎提出其他建议。&lt;/p&gt;&lt;p&gt;我们将在接下来的几天内对前几年的所有书籍进行圣诞特卖，希望在圣诞节之前我们还将推出一本包含去年评论结果的优秀电子书（甚至可能是有声读物版本）。&lt;/p&gt;&lt;h1&gt;审核如何进行？&lt;/h1&gt;&lt;h2&gt;第一阶段：初步投票&lt;/h2&gt;&lt;p&gt;要提名职位，请对其进行初步投票。符合资格的选民将看到此用户界面： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1672905457/mirroredImages/qCc7tm29Guhz6mtf7/d0fpa6iead1yz8j7y10n.png" /&gt;&lt;/figure&gt;&lt;p&gt;如果您认为某个帖子是重要的智力贡献，您可以投票表明其大致的重要性。对于一些粗略的指导：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 1 票意味着“这很好”。&lt;/li&gt;&lt;li&gt; 4 票意味着“这非常重要”。&lt;/li&gt;&lt;li&gt; 9 票意味着它是“智力进步的一个重要部分”。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;您可以在帖子页面的顶部或帖子出现在列表中的任何位置（例如&lt;a href="https://www.lesswrong.com/allPosts?timeframe=yearly&amp;amp;after=2022-01-01&amp;amp;before=2023-01-01&amp;amp;limit=100&amp;amp;sortedBy=top&amp;amp;filter=unnominated&amp;amp;includeShortform=false"&gt;&lt;u&gt;“所有帖子”页面&lt;/u&gt;&lt;/a&gt;或新的&lt;a href="https://www.lesswrong.com/votesByYear/2022"&gt;&lt;u&gt;“查看您过去的投票&lt;/u&gt;&lt;/a&gt;”页面）进行投票。&lt;/p&gt;&lt;p&gt;获得至少一票赞成票的帖子将进入&lt;a href="https://lesswrong.com/reviewVoting/2022"&gt;投票仪表板&lt;/a&gt;，其他用户可以在其中投票。我们鼓励您根据去年的记忆至少进行一次粗略的投票。稍后改变主意是可以的（鼓励！）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;写一篇简短的评论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果您认为某篇文章很重要，我们还鼓励您至少写一篇简短的评论，说明该文章的突出之处及其重要性。 （如果您想先记下您的快速印象，然后再进行更详细的审核，欢迎您对一篇文章进行多篇评论）&lt;/p&gt;&lt;p&gt;至少有一条评论的帖子会被排序到&lt;a href="https://www.lesswrong.com/reviewVoting"&gt;要投票的帖子列表&lt;/a&gt;的顶部，因此，如果您希望某个帖子获得更多关注，对其进行评论会很有帮助。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为什么要进行初步投票？为什么要分两个投票阶段？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;每年，LessWrong 上都会写出更多的帖子。 2018 年第一次审查考虑了 1,500 个职位。 2021 年，这一数字为 4,250。处理这么多帖子是一项艰巨的工作。&lt;/p&gt;&lt;p&gt;初步投票旨在帮助处理帖子数量的增加。我们不是简单地提名职位，而是直接从投票开始。这些初步投票随后将被公布，只有至少两人投票的帖子才会进入下一轮。&lt;/p&gt;&lt;p&gt;在审核阶段，这可以让各个网站成员注意到某些内容的放置是否特别不准确。如果您认为某个帖子的排名不准确，您可以写一篇积极的评论，认为它应该更高，其他人可以在最终投票时考虑这一点。获得大量中等选票的帖子可能会在审核阶段被取消优先级，从而使我们能够专注于最有可能对最终结果产生影响的对话。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;初步投票是如何计算的？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;您可以投不限数量的选票，但超过一定阈值后，您的选票总分越大，您每张选票的影响力就越小。在后端，我们使用&lt;a href="https://www.lesswrong.com/posts/qQ7oJwnH9kkmKm2dC/feedback-request-quadratic-voting-for-the-2018-review"&gt;&lt;u&gt;修改后的二次投票系统&lt;/u&gt;&lt;/a&gt;，该系统根据投票的强度在您的投票中分配固定数量的分数。&lt;/p&gt;&lt;p&gt;&lt;i&gt;细节：1 票得 1 分。 4 票得 10 分。 9 票需要 45 分。如果您花费的积分超过 500 点，您的投票就会开始按比例变弱。&lt;/i&gt;&lt;/p&gt;&lt;h2&gt;第二阶段：评论&lt;/h2&gt;&lt;p&gt;第二阶段为期一个月，完全专注于撰写评论。评论是评估帖子的特殊评论。评论中需要回答的好问题包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;这篇文章给对话添加了什么？&lt;/li&gt;&lt;li&gt;这篇文章对您、您的想法和行动有何影响？&lt;/li&gt;&lt;li&gt;它的主张是否准确？它是否在关节处雕刻了现实？你怎么知道？&lt;/li&gt;&lt;li&gt;您可以测试这篇文章的从属声明吗？&lt;/li&gt;&lt;li&gt;您希望在这篇文章的基础上看到哪些后续工作？&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;第三阶段：最终投票&lt;/h2&gt;&lt;p&gt;至少收到一项审核的帖子将进入最终投票阶段。&lt;/p&gt;&lt;p&gt;用户界面将要求选民在最终确定对每个帖子的投票之前至少简要浏览一下评论，因此可以考虑有关每个帖子的争论。&lt;/p&gt;&lt;p&gt;和往年一样，我们将公布1000+karma的用户以及所有用户的投票结果。 LessWrong 审核团队将把投票结果作为将哪些帖子纳入 2022 年最佳帖子序列的有力指标。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;首先，您可以&lt;/strong&gt;&lt;a href="https://www.lesswrong.com/votesByYear/2022"&gt;&lt;strong&gt;&lt;u&gt;查看您过去的点赞&lt;/u&gt;&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;并开始对某些帖子进行投票。&lt;/strong&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.lesswrong.com/posts/B6CxEApaatATzown6/the-lesswrong-2022-review#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Tue, 05 Dec 2023 04:00:00 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/B6CxEApaatATzown6/the-lesswrong-2022-review</guid></item><item><title>乐队和低风险舞蹈</title><link>https://www.lesswrong.com/posts/atwkvWcSppkKN9dRJ/bands-and-low-stakes-dances</link><description>发布于 2023 年 12 月 5 日凌晨 3:50（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;span&gt;当我开始在波士顿地区参加反对派舞会时，有几种你可以考虑“低风险”的地区舞会。小型舞会，费用不高，老牌乐队的热情也较低。因此，他们相对愿意预订那些刚刚起步、友好、鼓励、能够容忍缺乏经验的错误的乐队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;我认为这就是为什么这么多实力雄厚的乐队和舞蹈音乐家走出这个领域的一个重要原因：不需要你足够优秀，能够在“大型”舞蹈中保持自己的风格，就可以开始获得作为乐队跳舞的经验。 。例如，回顾一下我的日历，在我们玩我们的第一个“大型”游戏（&lt;a href="https://challcontra.weebly.com/"&gt;协和星期五&lt;/a&gt;）之前， &lt;a href="https://www.freeraisins.com/"&gt;Free Raisins&lt;/a&gt;玩了十八个不同的晚上。&lt;/p&gt;&lt;p&gt;不幸的是，这比以前少了很多。一些在大流行前关闭了（我非常想念麻省理工学院的反对派舞蹈！），其他人还没有回来（还没有？）或者已经转向室内乐队。有&lt;a href="https://www.bidadance.org/"&gt;BIDA&lt;/a&gt;&lt;a href="https://www.jefftk.com/p/why-does-the-bida-open-band-work-well"&gt;开放乐队&lt;/a&gt;和（风险更低的）家庭舞蹈乐队，但虽然我认为这种经验也很有价值，但有一种不同的学习方式，来自于在小组中演奏、演奏你已经练习过的曲目，以及对音乐完全负责。&lt;/p&gt;&lt;p&gt;我在这里没有一个很好的解决方案：很难故意开始一些低风险的活动，而且人们通常更喜欢举办那种很多人都想参加并且有很棒音乐的活动。但我确实认为 2010 年代初期的环境非常特别，为新乐队提供了很多学习成为舞蹈乐队的机会，如果我们能够带回类似的东西，或者至少具有类似效果的东西，我会很高兴。&lt;/p&gt;&lt;p&gt; （这种同样的动力对于“技术魂斗罗”来说更加强烈：唯一的表演机会是重大的特别活动，甚至更高调！但我对这种舞蹈形式的成功投入也较少，所以这不太困扰我。 ）&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.lesswrong.com/posts/atwkvWcSppkKN9dRJ/bands-and-low-stakes-dances#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Tue, 05 Dec 2023 03:50:22 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/atwkvWcSppkKN9dRJ/bands-and-low-stakes-dances</guid></item><item><title>通过可进化的机构加速科学发展</title><link>https://www.lesswrong.com/posts/9uEAwHzoDS8shpdoX/accelerating-science-through-evolvable-institutions</link><description>发布于 2023 年 12 月 4 日晚上 11:21（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;i&gt;这是向圣达菲研究所“加速科学”工作组提交的演讲的书面版本。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;我们来这里是为了讨论“加速科学发展”。我喜欢从历史的角度来开始讨论这样的话题：科学在过去什么时候（如果有的话）加速了？现在还在加速吗？我们可以从中学到什么？&lt;/p&gt;&lt;p&gt;我认为，在整个人类历史中，科学以及更广泛的人类知识&lt;i&gt;一直&lt;/i&gt;在加速发展。我还不能证明这一点（而且我自己对此只有大约 90% 的把握），但让我诉诸你的直觉：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Behavioral_modernity"&gt;从行为上看，现代人类&lt;/a&gt;已有 50,000 多年的历史&lt;/li&gt;&lt;li&gt;文字只有大约 5000 年的历史，因此在人类时间线的 90% 以上，我们只能积累能够适应口头传统的知识&lt;/li&gt;&lt;li&gt;在古代和中世纪世界，我们只有少数几门科学：天文学、几何学、一些数论、一些光学、一些解剖学&lt;/li&gt;&lt;li&gt;在科学革命之后的几个世纪（大约 1500 年代至 1700 年代），我们得到了日心说、运动定律、万有引力理论、化学的起源、细胞的发现、更好的光学理论&lt;/li&gt;&lt;li&gt;在 1800 年代，事情真正开始发展，我们有了电磁学、原子理论、进化论、细菌理论&lt;/li&gt;&lt;li&gt;1900 年代，核物理、量子物理、相对论、分子生物学和遗传学继续蓬勃发展&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我把自 1950 年左右以来科学是否已经放缓的问题放在一边，我对此没有强烈的看法。即使确实如此，这也只是整个历史加速的总体模式中最近的一个小插曲。 （或者，你知道，历史上前所未有的逆转和衰退的开始。其中之一。）&lt;/p&gt;&lt;p&gt;我对这种加速模式深信不疑的部分原因是，加速的不仅仅是科学：几乎所有衡量人类进步的指标都显示出相同的趋势，包括&lt;a href="https://ourworldindata.org/grapher/world-gdp-over-the-last-two-millennia?yScale=log"&gt;世界 GDP&lt;/a&gt;和&lt;a href="https://ourworldindata.org/grapher/population?yScale=log&amp;amp;country=~OWID_WRL"&gt;世界人口&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;是什么推动了科学的加速发展？许多因素，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;资金。&lt;/strong&gt;曾经，科学家必须&lt;a href="https://rootsofprogress.org/funding-models-for-science-and-innovation"&gt;寻求赞助，或者独立致富&lt;/a&gt;。现在有可用的赠款，并且资金总额在过去几十年中大幅增加： &lt;/li&gt;&lt;/ul&gt;&lt;figure class="image"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9uEAwHzoDS8shpdoX/dhxfk91oznfay66wdxnn" /&gt;&lt;figcaption&gt;&lt;a href="https://www.aaas.org/programs/r-d-budget-and-policy/historical-trends-federal-rd"&gt;&lt;i&gt;美国科学促进会&lt;/i&gt;&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;人们。&lt;/strong&gt;更多的科学家（在其他条件相同的情况下）意味着科学发展得更快，科学家的数量急剧增加，这既是因为总体人口的增长，也是因为更多的劳动力进入研究领域。在&lt;a href="https://archive.org/details/sciencesincebaby0000pric/page/107/mode/1up?view=theater"&gt;&lt;i&gt;《自巴比伦以来的科学》一&lt;/i&gt;&lt;/a&gt;书中，德里克·J·德·索拉·普赖斯 (Derek J. de Solla Price) 表示，“历史上大约 80% 到 90% 的科学家现在还活着”，这&lt;a href="https://futureoflife.org/guest-post/90-of-all-the-scientists-that-ever-lived-are-alive-today/"&gt;可能仍然是正确的&lt;/a&gt;： &lt;/li&gt;&lt;/ul&gt;&lt;figure class="image"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9uEAwHzoDS8shpdoX/wh3ldfdjulipzfcrroyg" /&gt;&lt;figcaption&gt; &lt;a href="https://futureoflife.org/guest-post/90-of-all-the-scientists-that-ever-lived-are-alive-today/"&gt;&lt;i&gt;埃里克·加斯特弗兰德&lt;/i&gt;&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;仪器。&lt;/strong&gt;更好的工具意味着我们可以做更多更好的科学研究。伽利略有一个简单的望远镜。现在我们有&lt;a href="https://en.wikipedia.org/wiki/James_Webb_Space_Telescope"&gt;JWST&lt;/a&gt;和&lt;a href="https://en.wikipedia.org/wiki/LIGO"&gt;LIGO&lt;/a&gt; 。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;计算。&lt;/strong&gt;更强的计算能力意味着更多更好的数据处理方式。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;沟通。&lt;/strong&gt;思想传播得越快越好，科学传播就越高效、越有效。科学期刊是在印刷机发明之后才发明的。互联网支持预印本服务器，例如 arXiv。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;方法。&lt;/strong&gt;更好的方法造就更好的科学，从培根经验主义到&lt;a href="https://en.wikipedia.org/wiki/Koch%27s_postulates"&gt;科赫假设&lt;/a&gt;再到&lt;a href="https://en.wikipedia.org/wiki/Randomized_controlled_trial"&gt;随机&lt;/a&gt;对照试验（实际上是所有统计数据）。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;机构。&lt;/strong&gt;实验室、大学、期刊、资助机构等共同构成了一个支持现代科学的生态系统。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;社会地位。&lt;/strong&gt;科学越受到尊重和声望，就会有越多的人和金钱流入它。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;现在，如果我们想问科学是否会继续加速发展，我们可以思考哪些驱动因素将继续增长。我建议：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;只要世界经济持续增长，科学经费就会继续增长&lt;/li&gt;&lt;li&gt;仪器、计算和通信将随着技术的发展而不断改进&lt;/li&gt;&lt;li&gt;我认为方法没有理由不继续改进，作为科学本身的一部分&lt;/li&gt;&lt;li&gt;科学的社会地位似乎相当强大：它是一个受人尊敬和享有盛誉的机构，获得了一些社会最高荣誉&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;从长远来看，如果&lt;a href="https://ourworldindata.org/grapher/comparison-of-world-population-projections"&gt;世界人口像预计的那样趋于稳定&lt;/a&gt;，我们可能会耗尽继续扩大研究人员基础的人员，这是一个潜在的问题，但不是我今天的重点。&lt;/p&gt;&lt;p&gt;最大的危险信号是我们的科学机构。制度影响所有其他因素，尤其是资金和人才的管理。今天，元科学界的许多人对我们的机构感到担忧。常见的批评包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;速度。&lt;/strong&gt;获得资助很容易需要 12-18 个月的时间（如果你幸运的话）&lt;/li&gt;&lt;li&gt;&lt;strong&gt;高架。&lt;/strong&gt;研究人员通常将 30-50% 的时间花在资助上&lt;/li&gt;&lt;li&gt;&lt;strong&gt;耐心。&lt;/strong&gt;研究人员认为他们需要定期展示结果，并且不能走一条可能需要多年才能得出结果的道路&lt;/li&gt;&lt;li&gt;&lt;strong&gt;风险承受能力。&lt;/strong&gt;赠款资金倾向于保守的、渐进的建议，而不是大胆的、“高风险、高回报”的计划（尽管&lt;a href="https://commonfund.nih.gov/highrisk"&gt;做出了相反的努力&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;strong&gt;共识。&lt;/strong&gt;一个领域可能会过快地集中于一个假设并修剪替代的研究分支&lt;/li&gt;&lt;li&gt;&lt;strong&gt;研究员年龄。&lt;/strong&gt;随着时间的推移，赠款的趋势是拨款给年龄更大、更成熟的研究人员&lt;/li&gt;&lt;li&gt;&lt;strong&gt;自由。&lt;/strong&gt;科学家缺乏完全自主地指导研究的自由；赠款资金附加太多条件&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;现在，作为一名前科技创始人，我不禁注意到，在营利性风险投资领域，大多数问题似乎都得到了缓解。筹集风险投资资金相对较快（通常一轮融资会在几个月内完成，而不是一年或更长时间）。作为创始人/首席执行官，我花了大约 10-15% 的时间筹款，而不是 30-50%。风险投资公司大胆下注，积极寻求逆向立场，并支持年轻的新贵。他们大多给予创始人自主权，也许会在董事会中占据一席之地以进行治理，并且只有在表现非常糟糕时才会解雇首席执行官。 （上面列出的初创公司创始人可能还会抱怨的唯一问题是耐心：如果你的钱用完了，你最好能取得进展，否则你在下一轮融资时就会遇到困难。）&lt;/p&gt;&lt;p&gt;我不认为风险投资界在这些方面做得更好，因为风险投资家比科学资助者更聪明、更有智慧或更优秀——但事实并非如此。相反，风险投资家：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;争夺优惠（并且真的不想错过好优惠）&lt;/li&gt;&lt;li&gt;从长远来看，成功或失败取决于其投资组合的表现&lt;/li&gt;&lt;li&gt;在大约 5-10 年内看到这些结果&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;简而言之，&lt;strong&gt;风险投资面临着进化压力。&lt;/strong&gt;他们不能陷入明显的不良均衡，因为如果这样做，他们就会在竞争中落败并失去市场力量。&lt;/p&gt;&lt;p&gt;证明这一点的是风险投资在过去几十年里&lt;i&gt;的&lt;/i&gt;发展——主要是朝着为创始人提供更好待遇的方向发展。例如，早期阶段存在较高估值的长期趋势，这最终意味着较低的稀释度以及权力从风投向创始人的转移：创始人在过去的几年里放弃公司一半或更多的股份是很常见的。第一轮融资；最后我检查了一下，大约是 20% 或更少。风险投资并不总是资助大学刚毕业的年轻技术人员。曾经有一段时间，他们倾向于青睐更有经验的首席执行官，或许还拥有 MBA 学位。他们并不总是支持创始人领导的公司；曾经，创始人在最初几年后被解雇并由专业首席执行官取代的情况很常见（当 A16Z 在 2009 年推出时，他们大肆宣扬&lt;a href="https://a16z.com/why-we-prefer-founding-ceos/"&gt;他们不会这样做&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;所以我认为&lt;strong&gt;，如果我们希望看到我们的科学机构&lt;/strong&gt;&lt;i&gt;&lt;strong&gt;得到改进&lt;/strong&gt;&lt;/i&gt;&lt;strong&gt;，我们需要考虑它们如何&lt;/strong&gt;&lt;i&gt;&lt;strong&gt;发展&lt;/strong&gt;&lt;/i&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们的科学机构的发展程度如何？不是特别的。当今大多数科学组织都是大学或政府部门。尽管我很尊重大学和政府，但我认为任何人都必须承认它们是我们行动较为缓慢的机构之一。 （大学尤其具有极强的弹性和抵抗力：例如，牛津大学和剑桥大学的历史可以追溯到中世纪，经历了帝国的兴衰，直到今天仍然完好无损。）&lt;/p&gt;&lt;p&gt;科学资助机构的进化所面临的挑战与风险投资的进化相反：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;他们往往缺乏竞争，&lt;/strong&gt;尤其是 NIH 和 NSF 等集中式联邦机构&lt;/li&gt;&lt;li&gt;&lt;strong&gt;他们缺乏任何真正的反馈循环&lt;/strong&gt;，在这种循环中，资助者的资源是由过去的判断和其投资组合的成功决定的（迈克尔·尼尔森多次&lt;a href="https://twitter.com/michael_nielsen/status/1451626771690897408"&gt;指出&lt;/a&gt;，从“爱因斯坦作为专利职员做了最好的工作”到“卡塔林·卡里科”的资助失败）在获得诺贝尔奖之前被拒绝授予资助和终身教职”似乎甚至没有引发相关机构内部的反思过程）&lt;/li&gt;&lt;li&gt;&lt;strong&gt;他们需要很长的周期&lt;/strong&gt;才能了解其工作的真正影响，而这种影响可能需要 20-30 年才能显现出来&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们如何提高科学经费的可进化性？我们应该思考如何改善这些因素。我没有什么好主意，但我会抛出一些不成熟的想法来开始对话：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我们如何增加科学资助的竞争？&lt;/strong&gt;我们可以增强慈善事业的作用。在美国，我们可以将联邦资金转移到州一级，设立五十个资助者而不是一个。 （国家农业实验站就是一个成功的例子，这些实验站之间的竞争是杂交玉米研究的关键，这是 20 世纪农业科学最伟大的成功之一。）在国际层面，我们可以支持对科学家更加开放的移民。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我们如何创建更好的反馈循环？&lt;/strong&gt;这很困难，因为我们需要某种方法来衡量结果。实现这一目标的一种方法是将资金从预期赠款转向各级各种回顾性奖项。如果这个“经济”足够大和强大，这些成果就可以被金融化，以创建一个动态的、有竞争力的融资生态系统，并具有适当水平的风险承担和耐心，经验丰富的退伍军人与年轻特立独行者之间的适当平衡等.（ &lt;a href="https://forum.effectivealtruism.org/posts/r7vmtHZKuosJZ3Xq5/altruistic-equity-allocation"&gt;影响证书&lt;/a&gt;，例如&lt;a href="https://protocol.ai/blog/hypercert-new-primitive/"&gt;超级证书&lt;/a&gt;，可以成为该解决方案的一部分。）&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我们如何解决反馈周期长的问题？&lt;/strong&gt;我不知道。如果我们不能缩短周期，也许我们需要延长资助者的职业生涯，这样他们至少可以从几个周期中学习——这&lt;a href="https://rootsofprogress.org/how-curing-aging-could-help-progress"&gt;是长寿技术的潜在好处&lt;/a&gt;。或者，也许我们需要一个科学资助者，它可以极快地学习，可以消耗大量有关研究项目及其最终结果的历史信息，永远不会忘记其经历，并且永远不会退休或死亡——当然，我想到的是人工智能。关于人工智能支持、增强或取代科学研究人员本身的讨论很多，但人工智能在科学领域的最大机会可能是在资金和管理方面。&lt;/p&gt;&lt;p&gt;我怀疑资助机构会在这个方向上走得太远：它们必须自愿接受竞争、加强问责并承认错误，而这种情况很少见。 （看看现在那些因卡里科获得诺贝尔奖而获得功劳的机构，他们几乎没有为她提供支持。）如果机构很难进化，那么元进化就更难了。&lt;/p&gt;&lt;p&gt;但也许资助者背后的资助者，即那些向资助者提供预算的资助者，可以开始将资金分配给多个机构，以要求绩效指标，或者干脆转向上述回顾性模式。这可以提供所需的进化压力。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/9uEAwHzoDS8shpdoX/accelerating-science-through-evolvable-institutions#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Mon, 04 Dec 2023 23:21:35 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/9uEAwHzoDS8shpdoX/accelerating-science-through-evolvable-institutions</guid></item><item><title>与国会工作人员谈论人工智能风险</title><link>https://www.lesswrong.com/posts/2sLwt2cSAag74nsdN/speaking-to-congressional-staffers-about-ai-risk</link><description>发布于 2023 年 12 月 4 日晚上 11:08（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt; 2023 年 5 月和 6 月，我（Akash）与国会工作人员就人工智能风险举行了大约 50-70 次会议。我一直想写一篇文章来反思这次经历和我的一些收获，我认为这可能是 LessWrong 对话的一个好话题。我看到他们&lt;a href="https://www.lesswrong.com/posts/kQuSZG8ibfW6fJYmo/announcing-dialogues-1?commentId=L2qFjT8taEhkm4hCB"&gt;提出要与人们进行 LW 对话&lt;/a&gt;，于是我伸出了援手。&lt;/p&gt;&lt;p&gt;在这次对话中，我们讨论了我如何决定与工作人员聊天、我在华盛顿的初步观察、有关国会办公室如何工作的一些背景、我的会议是什么样的、我学到的教训以及关于我的经历的一些杂项。&lt;/p&gt;&lt;h2&gt;语境&lt;/h2&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;嘿！在您的留言中，您提到了一些与您在华盛顿的经历相关的主题。&lt;/p&gt;&lt;p&gt;我认为我们应该从您与国会办公室谈论人工智能风险的经历开始。我很有兴趣了解更多；似乎没有太多公共资源来说明这种外展活动是什么样的。&lt;/p&gt;&lt;p&gt;那是怎么开始的？是什么让你想这么做？ &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;阿卡什&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;2023 年 3 月，我开始在&lt;a href="https://www.safe.ai/"&gt;人工智能安全中心&lt;/a&gt;从事一些人工智能治理项目。我的一个项目涉及帮助 CAIS 响应&lt;a href="https://www.ntia.gov/issues/artificial-intelligence/request-for-comments"&gt;NTIA&lt;/a&gt;发布的关于人工智能问责制的评论请求。&lt;/p&gt;&lt;p&gt;作为这项工作的一部分，&lt;strong&gt;我开始思考一个好的前沿人工智能监管框架应该是什么样子。&lt;/strong&gt;例如：如果我可以为前沿人工智能系统建立许可制度，它会是什么样子？它会被安置在美国政府的什么地方？我希望它评估哪些信息？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我开始想知道实际的政策制定者会对这些想法有何反应&lt;/strong&gt;。我也很好奇更多地了解政策制定者如何考虑人工智能灭绝风险和灾难性风险。&lt;/p&gt;&lt;p&gt;我开始询问人工智能治理领域的其他人。绝大多数人（根本）没有与国会工作人员交谈过。一些人有与员工交谈的经验，但没有与他们谈论人工智能风险。很多人告诉我，他们认为与政策制定者的接触非常重要，但却被忽视了。当然，也存在下行风险，所以你不希望有人做得不好。&lt;/p&gt;&lt;p&gt;在咨询了 10-20 名人工智能治理人员后，我询问 CAIS 我是否可以去华盛顿并开始与国会办公室交谈。目标是（a）提高对人工智能风险的认识，（b）更好地了解国会办公室如何考虑人工智能风险，（c）更好地了解国会办公室的人们有哪些与人工智能相关的优先事项，以及 (d) 获取有关我的 NTIA 评论想法请求的反馈。&lt;/p&gt;&lt;p&gt; CAIS 批准了，我于 2023 年 5 月至 6 月去了华盛顿。需要澄清的是，这不是 CAIS 告诉我要做的事情——这更像是 CAIS 意识到正在发生的“阿卡什事件”。 &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;哇，这真的很有趣。几个随机问题：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;当然，也存在下行风险，所以你不希望有人做得不好。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;一个人怎样才能把一件事做得不差呢？如何学习与政策制定者互动？&lt;br /&gt;&lt;br /&gt;另外，你的背景是什么？在此之前您做过政策方面的工作吗？ &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;阿卡什&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;是的，很好的问题。我不确定最好的学习方法是什么，但我尝试过以下一些方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;与有与政策制定者互动经验的&lt;strong&gt;人交谈&lt;/strong&gt;。询问他们说什么、他们发现什么令人惊讶、他们犯了什么错误、他们注意到什么下行风险等等。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;看书&lt;/strong&gt;。我发现&lt;a href="https://www.amazon.com/Master-Senate-Years-Lyndon-Johnson/dp/0394720954"&gt;参议院议长&lt;/a&gt;和&lt;a href="https://www.amazon.co.uk/Act-Congress-Americas-Essential-Institution/dp/0307744515"&gt;国会法案&lt;/a&gt;特别有帮助。我目前正在阅读&lt;a href="https://www.amazon.com/Devils-Chessboard-Dulles-Americas-Government/dp/0062276174"&gt;《魔鬼的棋盘》，&lt;/a&gt;以更好地了解中央情报局和情报机构，到目前为止，我发现它内容丰富。&lt;/li&gt;&lt;li&gt;与你已经认识的政策制定者&lt;strong&gt;进行角色扮演&lt;/strong&gt;，并要求他们提供直率的反馈。&lt;/li&gt;&lt;li&gt;在风险较低的会议中&lt;strong&gt;进行练习&lt;/strong&gt;，并利用这些经验进行迭代。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在此之前我没有做过太多政策方面的事情。在大学里，我为《哈佛政治评论》撰稿，并参与了政治研究所的工作，但这比“现实世界的政策参与”的内容更具学术性。&lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;h2&gt;抵达华盛顿特区并进行初步观察&lt;/h2&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;这一切都是有道理的。到达华盛顿后你做了什么？ &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;阿卡什&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;我给国会办公室以及一些行政部门的人员发送了冷电子邮件。我还联系了华盛顿的一些 EA。我还继续处理 NTIA 的评论请求（截止日期为 6 月 6 日）。&lt;/p&gt;&lt;p&gt;最初的计划是召开几次会议，评估会议的进展情况，如果我认为进展相当顺利，则再召开更多会议。&lt;/p&gt;&lt;p&gt;总的来说，我最终与国会工作人员举行了大约 50-70 次会议（以及一些与智库人员和行政部门机构人员的会议，但我将在这篇文章中重点讨论与国会工作人员的会议）。 &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;我认为他们进展得相当顺利，那么？ &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;阿卡什&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;据我说，是的！我要注意的一件事是，这些可能有点难以评估——比如，员工应该对人友善，他们不会说“我以为你是个白痴”或“你浪费了我的时间”之类的话。时间”或“我现在对人工智能安全性的印象更差了。”&lt;/p&gt;&lt;p&gt;记住这一点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;我对员工们的开放态度感到惊讶。&lt;/strong&gt;奥弗顿之窗最近发生了很大的变化，但当时，我真的不知道人们是否会说“哈！&lt;i&gt;灭绝风险？&lt;/i&gt;这听起来像科幻小说。”&lt;/li&gt;&lt;li&gt;&lt;strong&gt;主导氛围是“人工智能非常重要，我是一名忙碌的员工，有 100 个优先事项，所以我没有时间了解它。我&lt;/strong&gt;真的很高兴能与能够告诉我有关人工智能的东西的人交谈– 我一直渴望跟上进度。”&lt;/li&gt;&lt;li&gt;&lt;strong&gt;员工们对有机会见到愿意回答有关人工智能基本问题的人表示非常感激&lt;/strong&gt;（例如，什么是大型语言模型，它与其他类型的人工智能有何不同？有多少公司从事前沿人工智能？）&lt;/li&gt;&lt;li&gt;有一些“切实”的信号表明事情进展顺利。例如，一些工作人员将我介绍给他们认识的其他人，一些人将他们办公室正在起草的工作发给我，还有一些人甚至将我介绍给国会议员（总共两个）。&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/section&gt;&lt;h2&gt;国会办公室的层级&lt;/h2&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;这真的很有趣！&lt;br /&gt;&lt;br /&gt;顺便说一句，您能给我描绘一下国会办公室的人员配置等级吗？例如，您通常与谁交谈，他们通常与国会议员有什么关系？ &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;阿卡什&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;好问题！因此，我的理解是，国会办公室通常具有以下角色，从“最有影响力”到“最没有影响力”列出：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;参谋长&lt;/li&gt;&lt;li&gt;立法主任&lt;/li&gt;&lt;li&gt;立法助理&lt;/li&gt;&lt;li&gt;立法通讯员&lt;/li&gt;&lt;li&gt;实习生和研究员&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;还有一些其他角色，但从立法角度来看，这些角色往往最重要。&lt;/p&gt;&lt;p&gt;请注意，每个办公室都有自己的氛围。有人曾经告诉我“每个国会办公室都是自己的初创企业，每个国会议员都可以按照自己的意愿管理自己的办公室。”&lt;/p&gt;&lt;p&gt;因此，在某些办公室，实习生和研究员实际上可能有很大的影响力（例如，如果国会议员或立法主任信任实习生是特定主题的主题专家）。但总的来说，我认为这种层次结构很常见。&lt;/p&gt;&lt;p&gt;我想我主要是与立法助理/立法通讯员级别的人交谈。我还与几位立法官员进行了交谈。&lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;h2&gt;外展到办事处&lt;/h2&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;好吧，这一切都有道理。那么，您是如何从几次会议增加到 60-80 次的呢？ &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;阿卡什&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;我向技术政策工作人员发送了一封群发电子邮件，回复人数给我留下了深刻的印象。这封电子邮件相当短，提到我在 CAIS，用 1-2 个要点介绍了 CAIS 的工作，并用要点说明了我正在处理 NTIA 的评论请求。&lt;/p&gt;&lt;p&gt;我认为国会工作人员现在确实对人工智能内容非常感兴趣。就像，如果我向人们发送电子邮件讨论其他问题，我认为我不可能召开这么多会议。&lt;/p&gt;&lt;p&gt;有人感觉“人工智能现在很热，但没有人真正了解人工智能”。我认为目前还不清楚这种情况会持续多久（尤其是“人们了解不多，办公室还没有下定决心”）部分。&lt;/p&gt;&lt;p&gt;我什至会说“我认为这是一个 AIS 社区作为一个整体可以/应该充分利用的机会”。比如，国会工作人员曾经（而且我认为仍然）对与人们讨论人工智能问题非常感兴趣——很难想象还有比这更好的机会让 AIS 社区的人们能够进来并担任顾问/倡导者。 &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;这就说得通了。&lt;/p&gt;&lt;p&gt;如何才能开始与国会工作人员接触？人们应该做什么才能进入这个领域/哪些组织可能适合为此部署人员？ &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;阿卡什&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;这将是一个相当模糊的答案，但我认为这在很大程度上取决于人、他们的技能和他们的政策目标。&lt;/p&gt;&lt;p&gt;另外——我在上面提到过这一点，但重要的是要重申——人们做得不好肯定会带来风险。另一方面，存在过于“不作为偏见”或类似情况的风险，并留下很多价值。&lt;/p&gt;&lt;p&gt;这确实很难且令人困惑。我之前提到，我咨询了 10-20 名 AI 治理人员。他们中的大多数人都说“这似乎很重要但被忽视了，但我不知道，这似乎很令人困惑。”他们中的一些人就像“是的，我完全认为你应该这样做，特别是如果你采用 XYZ 策略。”一位相当著名的人工智能治理人士明确告诉我，他们不希望我这样做。我发现很难平衡这种相互矛盾的反馈。&lt;/p&gt;&lt;p&gt;我还认为我的很多建议取决于某人到底想说什么——例如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;他们的推销方式是什么？如果会议开始，工作人员说“那么，你想谈什么？”，最初的反应是什么？&lt;/li&gt;&lt;li&gt;他们是那种善于提出问题、对别人的世界观感到好奇的人吗？&lt;/li&gt;&lt;li&gt;他们听起来会危言耸听吗？&lt;/li&gt;&lt;li&gt;他们了解很多关于人工智能的事实吗？当他们不知道某件事时，他们是否能够认识到这一点并进行适当的对冲？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;考虑到所有这些，如果阅读本文的人有兴趣与国会工作人员互动（或让他们组织中的某人这样做），并且他们重​​视我的意见，&lt;strong&gt;我建议他们通过 LW 与我联系。&lt;/strong&gt;我能够在更多背景下提供更好的建议。&lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;h2&gt;一次典型的会议&lt;/h2&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;是的，这一切都有道理。您能向我介绍一下您可能举行过的典型会议吗？例如，您将如何首次与员工联系，您将在哪里与他们见面，实际对话是什么样的，您将如何跟进或以其他方式弄清楚这是否有帮助？ &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;阿卡什&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;&lt;strong&gt;会议物流&lt;/strong&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;将通过电子邮件联系&lt;/li&gt;&lt;li&gt;通常会在国会办公室（华盛顿特区基本上有 4 座主要建筑都设有所有国会办公室）或通过 Zoom 与他们会面&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;会议进展如何&lt;/strong&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;谈话通常会从我询问他们是否对人工智能有任何疑问或希望我分享我正在研究的东西开始。通常，他们希望我先开始。&lt;/li&gt;&lt;li&gt;我首先介绍我自己和 CAIS。一旦&lt;a href="https://safe-ai.webflow.io/statement-on-ai-risk"&gt;CAIS 声明&lt;/a&gt;出来，我就会引用 CAIS 声明。我会告诉他们，我正在关注先进人工智能带来的全球安全风险。我还会告诉他们我正在制定 NTIA 响应，并且会告诉他们我正在考虑的一些高级想法。&lt;/li&gt;&lt;li&gt;然后，我会停下来看看他们是否有任何问题。&lt;/li&gt;&lt;li&gt;通常，他们要么询问更多有关灭绝风险的问题，要么询问有关人工智能的各种问题（例如，您对如何处理深度造假有什么想法吗？），或者提出一些有关监管的高级问题（例如，我们如何监管而不扼杀创新？我们如何监管而不输给中国？）&lt;/li&gt;&lt;li&gt;在一些最好的会议中，我会听到办公室正在研究的一些与人工智能相关的东西。大多数办公室没有能力/兴趣在人工智能领域发挥带头作用。大约 10% 的办公室表示“是的，我的国会议员对此非常感兴趣，我们正在考虑引入立法或成为其他人立法的核心部分。”&lt;/li&gt;&lt;li&gt;很多人问我是否有立法草案。显然，如果你有监管想法，人们希望看到你有一个像法案一样写成的（简短的）版本。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;跟进&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;NTIA 的评论请求回复完成后，我向遇到的每个人发送了一份后续信息。当我有一次特别好的会议时（例如，一位员工对人工智能风险表示强烈兴趣，或者告诉我他们想向我发送他们正在研究的东西），我会发送个性化的后续信息。我认为最明显的帮助迹象来自于人们继续向我发送问题/想法、将我介绍给同事或希望与我合作提出建议的情况。 （需要明确的是，这种情况发生在少数情况下，但我认为这是大部分影响的来源）。&lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;h2&gt;员工对人工智能风险的态度&lt;/h2&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;blockquote&gt;&lt;p&gt;很多人问我是否有立法草案。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;他们正在寻求针对哪些类型的问题进行立法？您建议的任何立法？ &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;阿卡什&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;工作人员经常想知道我是否有立法草案来描述我在 NTIA 回复中所写的许可制度（我没有立法草案，但后来在帮助 Thomas 关闭&lt;a href="https://www.aipolicy.us/"&gt;人工智能政策中心&lt;/a&gt;时参与了立法起草工作）地面。） &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;啊好吧。更一般地说，人们对人工智能风险有哪些先验？您认为您通常会导致他们处理该主题的方式发生重大变化吗？ &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;阿卡什&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;&lt;strong&gt;似乎大多数人对人工智能风险没有强烈的先见之明。&lt;/strong&gt;我本以为人们的先验会更加怀疑（比如“什么？世界末日？&lt;i&gt;真的吗&lt;/i&gt;？”）。但我认为很多人都会说“是的，我完全可以看到人工智能如何导致全球安全风险”，甚至“是的，我实际上很担心类似天网的人工智能，我很高兴其他人正在努力”关于这一点。”&lt;/p&gt;&lt;p&gt;通常，人们似乎&lt;strong&gt;真正担心人工智能带来的灭绝风险&lt;/strong&gt;，但也&lt;strong&gt;没有任何计划来解决这个问题&lt;/strong&gt;。有人提醒我，“X 是一种存在风险”实际上是一件非常 EA 的事情 --&amp;gt;“因此我应该认真考虑在 X 上工作。”很多人就像“我很高兴其他人正在考虑这个问题[但我不会，我也不指望我的国会议员会]。”&lt;/p&gt;&lt;p&gt;就我的效果而言，我认为我主要只是让他们更多地考虑这一点，并将其列入他们内部的“人工智能政策优先事项”列表中。我认为人们忘记了员工的优先事项清单上有大约 100 件事，所以仅仅让他们接触并重新接触这些想法就会有所帮助。&lt;/p&gt;&lt;p&gt;我还遇到了一些员工，他们似乎非常关心人工智能风险，并且似乎是人工智能政策领域的坚定盟友。我仍然与几个人保持着联系，当托马斯创办人工智能政策中心时，我向他介绍了其中的一些人。如果我希望通过一项法案，我想我可以更好地了解我会尝试与哪些特定人员取得联系。&lt;strong&gt;在我看来，整个华盛顿之行的大部分影响可能在于弄清楚盟军工作人员是谁并与他们建立初步关系。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;最后一件事是，我通常不强调失去控制//超级智能//递归自我完善。我没有隐藏它，但我将其包含在更长的威胁模型列表中，并且它很少是我试图传达的主要内容。如果我再做一次，我可能会更多地强调这些威胁模型。 &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;blockquote&gt;&lt;p&gt;在我看来，整个华盛顿之行的大部分影响可能在于弄清楚盟军工作人员是谁并与他们建立初步关系。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;啊好吧！有哪些特征可以很好地预测员工是否会同情这项事业？例如特定地区、政治倾向、其他政策。 &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;阿卡什&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;blockquote&gt;&lt;p&gt;有哪些特征可以很好地预测员工是否会同情我们的事业？&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br /&gt;并不真地。样本量非常小。就像，总共可能有大约 4 名工作人员，我会把他们安排在“非常关心灭绝风险，并且他们可以在推动立法方面提供很大帮助”的位置。 1 名共和党人和 3 名民主党人。 &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;啊，明白了。你们所进行的讨论（在 CAIS 声明发布之前）是否对该声明产生了任何影响（措辞、外展等）？ &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;阿卡什&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;讨论并未影响该声明；该声明是在我前往华盛顿之前写的。 （有趣的事实：我是参与起草 CAIS 声明的人之一。认为为一个好句子做出贡献比我所做的许多其他事情的影响力要大 100 倍，这有点奇怪，但是嘿，有时它会起作用那样）。 &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;blockquote&gt;&lt;p&gt;（有趣的事实：我是参与起草 CAIS 声明的人之一。认为为一个好句子做出贡献比我所做的许多其他事情的影响力要大 100 倍，这有点奇怪，但是嘿，有时它会起作用那样）。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;该死。我们生活在一个奇怪的世界。顺便说一句，做得很好。 &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;阿卡什&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;谢谢！看到这个声明有多么重要确实很奇怪。&lt;/p&gt;&lt;p&gt;我认为这也是相当令人谦卑的——当我第一次听到这个声明时（当时我们称其为公开信），我记得当时我很沮丧，就像“嗯，一封公开信会做什么？我们已经有 FLI 暂停信。”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;这是一个有用的提醒，有时您可能无法提前预测某些事情的影响&lt;/strong&gt;。事后看来，很明显（至少对我来说）CAIS 声明是有用的，并且变革理论非常可靠。但当时，这并不像是一个落后的总体规划。感觉这只是 20 个项目清单中的一个项目，而且它有一种模糊的变革理论，这只是另一个似乎值得冒险的赌注。&lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;h2&gt;得到教训&lt;/h2&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;如果您再次进行此过程，您会采取哪些不同的做法？让您感到惊讶/您觉得自己从中学到的主要事情是什么？ &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;阿卡什&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;&lt;strong&gt;我想我会写一份文档来解释我的推理&lt;/strong&gt;，记录我咨询过的人，记录我所意识到的上行和下行风险，并将其发送给一些 EA。我认为一些谣言称这是以相当单边主义的方式完成的。这很棘手，让我很难过。我不认为我这样做的方式实际上是单边主义的，但我认为通过书面推理来避免误解会更好。 Thomas 在 CAIP 中做了很多这样的事情，并为&lt;strong&gt;“如何在不确定的情况下采取行动，同时以推理透明和高度协调的方式采取行动”等问题提供了一个很好的模型。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我还认为我会提出&lt;strong&gt;立法草案&lt;/strong&gt;（假设我所在的组织对此感到满意）。如果你有立法草案，人们似乎会更认真地对待你。&lt;/p&gt;&lt;p&gt;我还会写一份&lt;strong&gt;更短的 NTIA 回复&lt;/strong&gt;– 我们最终写了一篇大约 20 多页的论文。我会针对较短的材料进行更多优化。&lt;/p&gt;&lt;p&gt;啊，说到这里，我会带&lt;strong&gt;一份打印出来的单页纸&lt;/strong&gt;来解释什么是 CAIS 并总结 NTIA 答复中的监管理念。我在中途就完成了这件事，而且我本来可以早点完成这件事。&lt;/p&gt;&lt;p&gt;另外，我会带着&lt;strong&gt;名片&lt;/strong&gt;来。人们似乎很喜欢名片！ &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;是的，这一切都有道理，尽管我绝对不会提前猜到。&lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;h2&gt;最后拍摄&lt;/h2&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;我想我已经没有什么问题要问了：你还有什么要说的吗？随意闲逛。 &lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;阿卡什&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;以下是一些杂项：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;我在华盛顿的经历让我觉得&lt;strong&gt;奥弗顿之窗非常宽&lt;/strong&gt;。国会没有对人工智能政策的缓存，而且似乎很多人真的想学习。目前尚不清楚这种情况会持续多久（例如，人工智能风险最终可能会两极分化），但我们似乎正处于一个异常高度开放和好奇心的时期。&lt;/li&gt;&lt;li&gt;然而，&lt;strong&gt;让国会采取任何行动也非常困难&lt;/strong&gt;。就像，由于相当无聊的原因，没有多少法案获得通过。在这个过程中，有很多步骤可能会导致账单失效。当事情需要两党合作时更是如此（目前他们确实这样做，因为我们有民主党参议院和共和党众议院）。这主要让我想到&lt;strong&gt;“哇，现状通常不会发生任何事情，而且需要做很多工作才能获得任何有意义的立法。”&lt;/strong&gt;考虑到这一点，我确实认为我们在人工智能安全方面处于一个非常独特的境地（&lt;i&gt;实际上&lt;/i&gt;没有那么多事情会带来灭绝风险和各种其他灾难​​性风险；也没有那么多事情会成为现实）参议院多数党领袖的优先事项，激发与世界领导人的国际峰会，或成为整个行政命令的焦点）。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;许多人高估了华盛顿特区的“内部游戏”数量&lt;/strong&gt;，尤其是在国会参与方面。有一些秘密的事情正在发生，但在大多数情况下，我认为没有人有掌控权。&lt;/li&gt;&lt;li&gt;我希望看到&lt;strong&gt;围绕具体政策愿景进行更多协调&lt;/strong&gt;。有一段时间，您加入 Cool Kids Club 仅仅是为了关心 xrisk。我认为奥弗顿之窗已经发生了很大的变化，我们已经到了“关心xrisk”已经不够的地步了。重要的是人们支持并愿意倡导哪些具体政策。&lt;/li&gt;&lt;li&gt;考虑到这一点，我还认为拥有更广泛的人工智能风险社区是有好处的。&lt;strong&gt;协调实施不当可能会导致一事无成，因为你永远无法达成共识&lt;/strong&gt;（目前这有利于领先的实验室和不受监管的扩展）。&lt;strong&gt;协调太少可能会导致缺乏联盟建设和不必要的冲突。&lt;/strong&gt;我认为我已经从“协调是好的”转变为“如果做得好，协调是好的，但实际上需要技巧、机智和努力才能做好协调”。&lt;/li&gt;&lt;li&gt;我通常认为&lt;strong&gt;更多的人应该公开写下他们的观点。&lt;/strong&gt;当我不知道人们相信什么时，很难协调。我认为社会应该不太愿意赞扬那些没有提出任何特定立场的人。 &lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;我对 DC AI 安全社区了解了很多（我所说的“AI 安全社区”主要指那些出于避免 xrisk 或社会规模灾难的愿望而从事 AI 安全工作的人们。有些人被认为是 EA/长期主义者） ，但很多人没有）&lt;ol&gt;&lt;li&gt; TLDR：这很复杂。我认为前10%的思想家都非常有才华，并且追求合理的变革理论。另一方面，也有很多人声称对人工智能政策感兴趣，但对各种人工智能安全威胁模型没有基本的了解。人们还（真实且合理地）担心，社交无能和政治无能的新来者可能会以威胁或削弱现有努力的方式进入该领域。&lt;/li&gt;&lt;li&gt;总的来说，我觉得主流文化对新的政策努力过于不屑一顾。我希望随着人工智能政策对话的不断向前发展并吸引新的人群，这种情况会发生变化。我会对社区的反应更像是“啊，新人感兴趣！让我们给您一些提示/指示，并指出我们所拥有的具体经验并讨论下行风险的具体模型”感到兴奋。现状常常让人感觉不那么具体，而且（在我看来）对新的努力过于保护主义。我发现这种文化让我更难清晰地思考或进行倡导，尤其是我所说的“高度直接性倡导”（EG 主要试图向人们传达你的内部世界状态，而不是主要尝试）传达一系列能够很好地吸引观众的信念）。我认为关于各种倡导工作应该如何“直接”进行认真的辩论（而且我认为如果华盛顿特区的一些人完全直接的话，他们实际上会失去一些影响力/“严肃性点”），但我仍然感到惊讶影响的大小——文化似乎阻碍我和我的同事直接表达的程度。我相信这种文化大大减缓了新政策的努力，并继续以我认为对世界不利的方式威胁/削弱/阻碍新的政策努力。与许多事情一样，我认为高层关注是正确的，但这些高层关注的具体应用/实施方式存在问题&lt;/li&gt;&lt;li&gt;评估不同人员/计划的跟踪记录也很困难。部分原因是某些信息是秘密的，部分原因是“我们与重要利益相关者有良好的关系”之类的事情是有用的工具性步骤，但不一定转化为影响，部分原因是许多变革理论都是基于点击量的，需要时间才能产生直接影响（例如，如果某人与 X 建立了良好的关系，也许在某个时候 X 将变得与人工智能监管极其相关，但也许只有 1-10% 的可能性是真的。）话虽如此，我认为，如果人们最终更明确地表达自己的信念，更明确地表达他们希望实现的具体政策目标，更明确地表达他们明显的胜利（和损失），那么协调会更容易。如果没有这一点，我们就会冒着赋予那些“玩游戏”、发展影响力但最终没有利用他们的影响力来实现有意义的变革的人太多权力和太多资源的风险。 （另请参阅多米尼克·卡明斯&lt;a href="https://www.dwarkeshpatel.com/p/dominic-cummings#details"&gt;播客&lt;/a&gt;）。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;与此相关的是， &lt;a href="https://forum.effectivealtruism.org/posts/tdaoybbjvEAXukiaW/what-are-your-main-reservations-about-identifying-as-an?commentId=gNC53rsuMNTBjLCWY"&gt;奥利弗·哈布里卡（Oliver Habryka）的评论&lt;/a&gt;引起了我的共鸣。我发现，当我与“主流 EA”保持一定距离时，我的思维往往会更清晰。有很多抗体和微妙的文化压力可以阻止我思考某些想法，并可能削弱我在世界上采取直接行动的能力。 （当然，我不认为解决方案是“永远不要与 EA 互动”——但我确实认为人们可能低估了社区对良好思考和实现困难事物的负面影响。我确实低估了。）&lt;/li&gt;&lt;li&gt;对于有兴趣捐赠的人，我目前推荐&lt;strong&gt; &lt;/strong&gt;这&lt;strong&gt; &lt;/strong&gt;&lt;a href="https://www.aipolicy.us/"&gt;&lt;strong&gt;人工智能政策中心&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt; &lt;/strong&gt;（尤其是托马斯·拉森继续高度参与其战略方向）。我与托马斯有一些战略/战术上的分歧，但我认为他是一个非常聪明和有才华的人，我认为他是人工智能政策领域最值得支持的新人之一（COI：托马斯是我的朋友之一，我在人工智能政策中心的早期阶段参与了帮助）。&lt;/li&gt;&lt;li&gt;如果您想与我交谈，&lt;strong&gt;请随时联系 LessWrong&lt;/strong&gt; 。我喜欢与从事人工智能政策工作的人交谈。我也愿意接受我可以做的或我知道的其他人可以做的有影响力的事情。 &lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/section&gt;&lt;section class="dialogue-message ContentStyles-debateResponseBody"&gt;&lt;section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"&gt;&lt;b&gt;有&lt;/b&gt;&lt;/section&gt;&lt;div&gt;&lt;p&gt;哇，好吧。感谢您进行这次对话！&lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;div&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/2sLwt2cSAag74nsdN/speaking-to-congressional-staffers-about-ai-risk#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Mon, 04 Dec 2023 23:08:52 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/2sLwt2cSAag74nsdN/speaking-to-congressional-staffers-about-ai-risk</guid></item><item><title>开放主题 – 2023/2024 年冬季</title><link>https://www.lesswrong.com/posts/tRa92qDonDLi6RA8u/open-thread-winter-2023-2024</link><description>发布于 2023 年 12 月 4 日晚上 10:59（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;如果它值得说，但不值得单独发表，这里有一个地方可以放置它。&lt;/p&gt;&lt;p&gt;如果您是 LessWrong 的新手，这里是您自我介绍的地方。欢迎您就您如何找到我们以及您希望从网站和社区获得什么发表个人故事、轶事或只是一般性评论。如果您不想写完整的顶级帖子，这也是讨论功能请求和您对该网站的其他想法的地方。&lt;/p&gt;&lt;p&gt;如果您是社区新手，您可以开始阅读&lt;a href="https://lesswrong.com/highlights"&gt;Sequences 的亮点&lt;/a&gt;，这是有关 LessWrong 核心思想的帖子集合。&lt;/p&gt;&lt;p&gt;如果您想更多地探索社区，我建议您&lt;a href="https://www.lesswrong.com/library"&gt;阅读图书馆&lt;/a&gt;，&lt;a href="https://www.lesswrong.com/?view=curated"&gt;查看最近策划的帖子&lt;/a&gt;，&lt;a href="https://www.lesswrong.com/community"&gt;看看您所在的地区是否有任何聚会&lt;/a&gt;，并查看&lt;a href="https://www.lesswrong.com/faq"&gt;LessWrong 常见问题&lt;/a&gt;&lt;a href="https://www.lesswrong.com/faq#Getting_Started"&gt;解答&lt;/a&gt;的入门部分。如果您想了解网站上的内容，您还可以查看&lt;a href="https://www.lesswrong.com/tags/all"&gt;“概念”部分&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;开放线程标签在&lt;a href="https://www.lesswrong.com/tag/open-threads?sortedBy=new"&gt;这里&lt;/a&gt;。 Open Thread 序列在&lt;a href="https://www.lesswrong.com/s/yai5mppkuCHPQmzpN"&gt;这里&lt;/a&gt;。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/tRa92qDonDLi6RA8u/open-thread-winter-2023-2024#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Mon, 04 Dec 2023 22:59:51 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/tRa92qDonDLi6RA8u/open-thread-winter-2023-2024</guid></item><item><title>采访 Vanessa Kosoy 谈人工智能理论研究的价值</title><link>https://www.lesswrong.com/posts/QPxrH5ex6MpYoLwer/interview-with-vanessa-kosoy-on-the-value-of-theoretical</link><description>发布于 2023 年 12 月 4 日晚上 10:58（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;以下是我与 Vanessa Kosoy 进行的&lt;a href="https://youtu.be/1MCRQF0_5zY?feature=shared"&gt;&lt;i&gt;视频采访&lt;/i&gt;&lt;/a&gt;&lt;i&gt;的文字记录（经过语法编辑）&lt;/i&gt; ，从我的&lt;a href="https://www.zenmarmotdigital.com/blog/interview-with-vanessa-kosoy"&gt;&lt;i&gt;博客&lt;/i&gt;&lt;/a&gt;&lt;i&gt;交叉发布&lt;/i&gt;&lt;i&gt;。它旨在（相对）对初学者友好地解释&lt;/i&gt;&lt;a href="https://www.lesswrong.com/posts/ZwshvqiqCvXPsZEct/the-learning-theoretic-agenda-status-2023#Direction_6__Metacognitive_Agents"&gt;&lt;i&gt;学习理论议程&lt;/i&gt;&lt;/a&gt;的目标&lt;i&gt;，以及为什么需要更多的理论工作来确保人工智能大规模安全可靠。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;简介（作者：Will Petillo）：&lt;/strong&gt;讨论人工智能的未来往往会变得哲学化。有“目标”或“理解”意味着什么？追求权力是想要东西的默认结果……还是我们独特的进化历史造成的人类怪癖？是什么激发了善良？以这种方式提出问题可以使问题易于理解，让每个人都参与对话。但这种缺乏精确性也使得此类问题变得棘手，因为分歧会变成直觉冲突。&lt;/p&gt;&lt;p&gt;今天“一致性守护者”的嘉宾是瓦妮莎·科索伊 (Vanessa Kosoy)，她是一位由机器智能研究所 (MIRI) 和长期未来基金 (LTFF) 支持的独立研究员，致力于构建安全人工智能的数学理论。这种对理解第一原理的关注使她的工作与领先人工智能实验室的“快速行动并打破常规”实验方法形成鲜明对比。在这次采访和其他地方，瓦妮莎捍卫了更加基于理论的方法的价值，并解释了探索机器学习作为基础科学的意义。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;您是如何进入人工智能安全领域的？&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;我一直是一个自学者，所以我倾向于自学东西。当我小的时候，我想我会成为一名理论物理学家。我实际上拥有数学学士学位，但在完成学士学位后，我没有进入学术界，而是决定在软件行业从事职业生涯。&lt;/p&gt;&lt;p&gt;我在软件行业有很长的职业生涯，特别是算法工程，主要是计算机视觉，各种角色，算法工程师，团队领导，研发经理。我也有自己的创业公司。大约 10 年前，我是一名顾问。我接触到了人工智能带来的生存风险这一整个话题，并开始思考，嗯，这实际上似乎很重要。所以我开始转向这一点，最初只是我在空闲时间做研究。随后得到了 MIRI 的支持。最近我还得到了长期未来基金的支持，这使我能够全职工作。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;那么这个过程是怎样的呢？你只是以一种自我导向的方式工作，然后你获得了美里和其他来源的支持？这是怎么来的？&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;我开始阅读 MIRI 和 Less Wrong 的人们写的一些东西。我开始研究自己的想法，并在 Less Wrong 上发表文章。之后，我被邀请参加一些研讨会、一些活动，最终 MIRI 说，好吧，看来你在这里做了一些不错的工作，所以也许我们也会付钱给你。我很棒，因为这也使我能够做更多的事情，而花更少的时间做其他事情。&lt;br /&gt;&lt;br /&gt;威尔·佩蒂略&lt;strong&gt;（Will Petillo）：&lt;/strong&gt;这里为观众介绍一下背景知识。 Less Wrong 是一个受欢迎的博客。它最初是关于理性的，但也是关于人工智能相关的事情。 MIRI 是机器智能研究所。我喜欢将他们描述为在它变得很酷之前就致力于协调的人。请告诉我更多关于 MIRI 作为一个机构的信息。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt; MIRI 或多或少是第一个谈论人工智能存在风险的人。 Eliezer Yudkowsky 在 2000 年开始谈论这个问题，最初 Miri 只是 Yudkowsky，然后多年来他们设法获得一些资金来吸引其他研究人员加入。他们正在思考这个问题：我们如何使人工智能安全，以及我们如何解决这个问题？我们能想出什么样的数学理论来解决这个问题？这甚至早于深度学习革命开始之前，也早于近年来大型语言模型的整体炒作。他们的大部分时间都致力于提出一些基础数学理论，以帮助我们进行人工智能调整。&lt;br /&gt;&lt;br /&gt;最近，他们转向外展并试图影响政策，因为他们相信时间确实很短，不幸的是我们没有时间发展这一理论。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;你参与了这一转变吗？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;不，我的观点不同。你可以说我比较保守。我认为时间表并不像风险界许多人认为的那么短。我认为，如果通过政策渠道规范人工智能发展并推迟人工智能发展以阻止真正危险的人工智能出现的努力能够成功，那么这只是为我们赢得了时间。那么问题是：为我们争取时间做什么？我认为理论基础绝对仍然是我们应该利用我们所拥有的时间或我们将通过某种政策计划成功购买的时间做的事情中最重要的事情，无论怎样。&lt;br /&gt;&lt;br /&gt;我认为实际上在任何世界中，创建这个基础理论都是关键。这就是我正在做的事情。这绝对是我的个人技能和优势所在，研究数学而不是政策。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;你提到了时间表。直觉上，我知道不可能以任何精确度真正预测这些事情，但就你的动机而言，你认为需要解决这些问题的时间表是什么？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;有些人认为 AGI 将在 10 年甚至更短的时间内到来。我认为这有点极端。但当事情需要解决的时候，越快越好不是吗？如果我们在五年内找到解决方案，那么我们的处境会比我们在 10 年内找到解决方案更好，这仍然比我们在 20 年内找到解决方案更好，依此类推。&lt;br /&gt;&lt;br /&gt;实际上，我个人的观点是，我们还需要几十年的时间才能真正实现那种带来生存风险的人工智能。所以这给了我们更多的时间，但不是无限的时间。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;是什么让你觉得这是你想做的事情？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;一开始更像是一种好奇心，因为它实际上是从我完全随机发现开始的，你可以说一些关于 AGI 的论文，甚至不是关于人工智能对齐或风险或类似的东西，而只是 Jürgen Schmidhuber 和 Marcus Hutter 的一些论文关于 AGI 的一些想法。我一直是一个数学迷，所以有那些思考 AGI 的数学框架看起来真的很酷。我开始阅读相关内容，最终也发现了Less Wrong，其中也有人在讨论这类事情。&lt;br /&gt;&lt;br /&gt;一方面，我读了越来越多的 Eliezer Yudkowsky 写的关于这个主题的文章，以及 LessWrong 上的人们写的关于这个主题的文章，但我也开始思考数学模型。最终，我突然意识到，当你思考实际的数学时，就完全有道理了，没有任何数学原因可以解释为什么人工智能必须关心人类或关心任何与我们人类关心的事情一致的东西。&lt;br /&gt;&lt;br /&gt;另一方面，它似乎也明显比我们更有能力。我认为直观上很清楚，但对我来说，我喜欢通过数学来理解一切。因此，当我看到你实际上可以将其放入数学模型中时，我真的意识到这是真实的事情，这是我们真正应该关心的事情。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;没有理由认为人工智能一定是好的，这听起来很像尼克·博斯特罗姆写的正交性论文。智力和事物的美好程度并不一定要同时出现；任何一套价值观都可以与任何水平的智力相匹配。这本质上就是你的见解吗？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;是的，这正是术语。事后看来，这似乎是一件显而易见的事情。但对我来说，有必要看到你实际上可以用数学对象来思考它；值可以形式化为效用函数。然后，代理可以被形式化为某种优化器、某种贝叶斯最优策略或该效用函数的任何形式。实际上，你可以在每个术语背后赋予严格的含义，并发现它们实际上都是有意义的——这不仅仅是某种哲学上的挥手把戏。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;在您看来，导致人工智能对齐问题变得困难的根本原因是什么？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;我认为这个问题很难。我认为，首先，困难在于我们的目标非常狭窄，因为人类价值观非常复杂和具体。我们关心很多非常细节的事情：爱、友谊、美（以我们自己的主观理解）、性，所有这些东西都是人类的东西，因为一些复杂的进化事故而存在，就像它发生在某些人身上的方式一样。非常特别的星球。这是特定宇宙历史上非常特殊的时刻。这组价值观只是你可以想象的巨大的可能价值观或思想空间中非常非常狭窄的一部分。&lt;br /&gt;&lt;br /&gt;因此，按照我们的标准，大多数人的思想绝对不会对我们有好处。更糟糕的是，内特·苏亚雷斯（Nate Soares）在他最近的一篇文章中很好地阐述了这种现象，他在其中写道，围绕代理能力存在一个吸引力盆，但对于代理对齐却没有吸引力盆。这意味着，如果您施加足够的优化压力，即使使用强力技术，您最终也将生成功能强大的代理。进化就是一个例子，对吗？进化是一种非常原始的蛮力算法，最终创造了人类大脑，这是一种更加复杂的算法。如果您投入足够的强力优化来寻找在开放世界环境中成功的事物，最终您将遇到智能代理。这甚至是在你在方程中加入递归自我改进之前的，这使得它作为你汇聚的这种吸引力盆地变得更加强大。然而，在与人类价值观保持一致方面，情况并非如此。很有可能的是，我们可以通过盲目或半盲目的试错，早在我们了解足够的知识以实际使这些代理对齐之前就创建出高能力的代理。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;这听起来像是违背了博斯特罗姆流行的工具融合的另一个理念，即几乎任何足够努力优化的系统都需要诸如生存之类的东西。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;有一种工具收敛目标的概念，这是大多数智能代理都会追求的某些目标，因为它们帮助他们实现最终目标，无论他们的最终目标是什么。这些都是诸如生存、获得更多资源、变得更加聪明等等之类的事情。但人类的价值观并非如此。我想，如果我们设法构建一个能够生存并获得大量资源的人工智能，这对人工智能来说是件好事，但它对我们与我们的价值观保持一致没有任何帮助。这是一种非常不同的事情。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillio：&lt;/strong&gt;现代人工智能是根据人类生成的数据进行训练并存在于人类社会中这一事实没有帮助吗？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;我认为这有帮助，但也留下了很多问题。一个问题是：好吧，你可以从人类生成的数据中学习，但你如何从中进行概括呢？因为确实不清楚需要什么条件才能获得良好的概括，尤其是当您正在学习的概念非常复杂时。&lt;br /&gt;&lt;br /&gt;您正在学习的概念的复杂性越高，学习它所需的数据点就越多。我们正在利用近年来炒作的所谓大型语言模型来尝试模仿人类。我的意思是，这很好。它可能会以一定的概率带来一些好处——但概率不是很高。但它的问题是，为了使用它，您需要在训练分布之外进行泛化。这里我们实际上需要看看目标是什么。&lt;br /&gt;&lt;br /&gt;问题是，从技术上讲，创造出超级智能的人工智能是可能的，但这将是危险的。为了解决这个问题，仅仅创建某种不危险的人工智能是不够的，因为否则他们可能只是编写一个不做任何事情的算法。这并不危险，任务完成了。我们需要能够创建足够强大的人工智能，作为防御系统来抵御那些潜在危险的人工智能。因此，这些系统必须具有超人的能力，能够构建复杂的世界模型，并在此基础上制定复杂的长期计划。这远远超出了大型语言模型或任何基于人类模仿的训练分布。目前还非常不清楚我们是否真的可以依赖我们必须泛化到训练分布之外的算法，而不会完全失去它们的所有对齐属性。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;总而言之，法学硕士从根本上来说是模仿性的，这本身似乎并不是特别危险，但它也限制了他们能做的事情。因此，我们不能真的指望开发会就此停止。最终可能会添加像强化学习这样的东西——也许不一定是算法，但可以像围棋中的 Alpha Zero 一样具有创造性，并找到一个以前没有人见过的真正创造性的棋步。因此，我们需要为更强大的事物做好准备，因为它们将是有用的，而导致建立法学硕士的经济学将导致建立更大的事物。这就是你的意思吗？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;是的，这听起来很当场。要么是强化学习，要么……好吧，我不想过多地推测让人工智能变得更强大需要什么，因为这不是很好的信息。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;很公平。继续讨论您实际从事的事情，我看到的与此相关的一个想法是术语“代理基础”。还有“学习理论议程”。那些东西是什么？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;智能体基础是一个抽象的概念，它表明我们需要创建一个基础数学理论来解释智能体是什么。从数学角度来说，算法作为代理意味着什么？可以使用哪些类型的代理？他们可以拥有或不具备哪些能力？等等。学习理论议程比这更具体，因为它就像一个试图实现这一目标的非常具体的计划。具体来说，是通过建立在统计和计算学习理论、算法信息论、控制理论等基础上的工具。这是我创建的程序，旨在应对提出这些代理基础的挑战。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;好的，代理基础就像“思维如何工作？”的问题，其中包含人工智能，而学习理论议程就像“我们如何设计算法，将其推向一个好的方向？”是对的吗？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;我不会那样说。我只想说，特工基金会只是试图了解思维如何运作，人们一直在尝试以各种方式做到这一点。 MIRI 历史上有各种证明理论模型试图解决这个问题，然后是加拉布兰特的逻辑归纳法，在这个非常广泛的保护伞下有各种想法，而学习理论议程是一种非常具体的方法。&lt;br /&gt;&lt;br /&gt;正是这种方法以 AIXI 和经典强化学习理论为起点，然后寻找其中缺少的成分，以便拥有代理的基础理论，并开始利用下贝叶斯主义和下贝叶斯物理主义和元认知代理等等。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;您在这里谈论的代理和思维类型，是否与前沿的大型语言模型相关，或者是否更广泛地涉及人工智能或任何类型的思维实体？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;当我说经纪人时，我的意思是非常广泛的。比现有的人工智能甚至只是人工智能要广泛得多。当然包括人类、潜在的外星人或其他什么。因此，对我来说，代理是一个具有特定目标的系统，它正在学习它所嵌入的世界的复杂模型，并使用这些模型来构建长期计划以实现其目标。这就是我所说的“代理”的非正式描述。该程序的整个目标是从这个到一个完全正式的数学定义，并研究这个定义的所有含义。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;因此，即使不超出法学硕士，它的范围甚至比机器学习还要广泛。采取这种做法的原因是什么？鉴于机器学习的主导地位，为什么不关注那些似乎使用最广泛的东西呢？&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;首先，让我们保持术语的顺序。我会区分人工智能、机器学习和深度学习。人工智能是人们自 20 世纪 50 年代以来就开始思考的东西，关于如何构建思维系统，但并没有真正理解它的含义，而只是某种直观的概念，认为存在思考这样的东西，我们应该能够在机器中复制它。&lt;br /&gt;&lt;br /&gt;机器学习是出现的一种更具体的方法……好吧，我不想具体指出什么时候，但可能是在八十年代。机器学习具体是这样的想法：思维的核心要素是学习，学习意味着你正在与一些未知的环境交互，你需要创建这个环境的模型。因此，您需要获取您看到的数据并使用它来创建模型。这类似于科学家如何进行实验、收集数据，然后根据这些数据建立理论。&lt;/p&gt;&lt;p&gt;这个总体想法称为机器学习，或者更准确地说，只是学习。 “机器”部分来自尝试想出在机器内部实际实现这一点的方法。这是一个有很多数学理论的领域。机器学习背后的数学理论就是所谓的统计和计算学习理论，这实际上是学习理论议程的基础。这就是为什么它被称为“学习理论”。&lt;/p&gt;&lt;p&gt;有一种假设认为，这种学习概念抓住了我们所说的思维的大部分重要部分。我认为这一假设得到了最新技术发展的充分支持。这是我完全赞同的，也是我整个研究计划的基础。所以这里并不矛盾，因为学习仍然是一件很普遍的事情。人类也进行学习。外星人也必须学习。&lt;/p&gt;&lt;p&gt;深度学习是一组更具体的算法，用于如何在机器中实际高效地完成学习，这就是 2010 年左右深度学习革命的开始，尽管这些算法在此之前已经以某种形式存在了几十年。但需要一段时间才能获得正确的细节，并拥有合适的硬件来运行它们。深度学习的不幸特征是我们无法从数学上理解它。很多人都在试图理解它，但我们并没有一个很好的理论来解释它为什么有效。这就是为什么它不是我的研究计划的重点，因为我试图提出一些数学理解。我绝对希望人们最终能够解开深度学习如何运作的这种谜团，然后就有可能将其整合到我正在构建的理论中。&lt;br /&gt;&lt;br /&gt;但即使我们有了这个理论，那么以尽可能广泛的普遍性来思考似乎仍然非常重要，因为，首先，我们不知道今天存在的算法将是带来 AGI 的算法。而且因为最广泛的普遍性只是思考问题的正确抽象级别，以了解系统“对齐”意味着什么的概念。这里需要解决一些哲学问题，并且它们特定于一些非常特殊的算法。此外，事实上，我实际上希望这个理论包括人类，因为我可能想用这个理论来形式化价值学习等事物。如何设计一个能够向人类学习价值观的人工智能系统？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;查看机器学习和深度学习的维基百科级别，或者只是浏览互联网描述，很容易互换使用它们。我想我已经看到了这样的描述，深度学习就是添加多层神经元的想法。因为有多层，所以它很“深”&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;让我尝试澄清其中的区别。机器学习谈论获取数据并从中构建模型。您正在构建的模型类型可能非常不同。在深度学习之前，我们有支持向量机等算法，多项式回归也是一种非常简单的机器学习类型——将模型拟合到数据。统计中使用的各种方法可以被视为一种机器学习。有一些模型或假设空间，您尝试以最佳方式使用数据来推断正确的假设是什么，或者如果您正在使用贝叶斯方法，则获得假设的一些概率分布。&lt;br /&gt;&lt;br /&gt;但是，不同类型的假设类会在算法的能力方面以及我们所知道的如何学习这些假设类方面导致非常不同的结果。我们知道什么可以用数学方法证明在什么条件下我们可以真正学习它们？比如支持向量机，数学理论基本解决了。有一些建立在其之上的内核方法，并且也有非常扎实的数学理论。深度学习是一种特殊类型的学习算法，它使用人工神经网络架构。&lt;/p&gt;&lt;p&gt;这不仅仅是多层，还有很多细节很重要。例如，激活函数是 ReLU，这一事实对于您在训练中使用哪种正则化方法非常重要。例如，辍学基本上是深度学习革命的开始。如果您正在使用序列，那么我们有变压器，这是一种非常具体的网络架构。因此，多年来人们实际上提出了很多非常具体的细节，主要是通过反复试验的过程，看看什么是有效的。我们没有一个好的理论来解释为什么这些特定的东西运作良好。我们甚至不了解这些东西实际上正在学习的模型空间，因为你可以从理论上证明，如果你采用一个神经网络，然后让它学习另一个神经网络，那么在某些情况下这是不可行的。&lt;br /&gt;&lt;br /&gt;但对于现实世界的问题，神经网络在很多时候都能成功学习。这表面上是因为现实世界具有一些使其可学习的特定属性，或者神经网络正在学习一些特定的潜在假设类，并且它捕获了许多现实世界的现象，但我们甚至没有数学描述这个基本假设类别是什么。我们对一些非常简单的情况有一些结果，比如两层或三层神经网络，或一些其他简化的假设，但我们还没有接近得到完整的答案。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;深度学习假设了世界的某些情况，就其可以获取的信息而言，它恰好工作得相当好，但目前还不清楚它的假设是什么。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;凡妮莎·科索伊：&lt;/strong&gt;是的，完全正确。所以我们有不同的不可行定理，它说对于任意数据，即使该数据是完全可实现的，即使该数据使得神经网络可以完美地表达一个完全正确的模型，该问题也是不可行的。一般来说，梯度下降不会收敛到正确的模型，而且其他算法也不会收敛，因为问题很棘手。世界具有一些属性，并且由于深度学习在如此多种不同的情况下取得了成功，所以感觉这些属性应该有一些简单的数学描述。&lt;br /&gt;&lt;br /&gt;它不像某些特定于文本、音频或图像的属性。这些属性非常通用，适用于各种不同的模式和问题。这些是我可以推测的属性，例如，与组合性有关，现实世界通常如何被很好地描述为由部分组成，以及事物如何根据不同的空间尺度或不同的时间尺度进行解耦。动态正在发生。但我们没有真正解释它的理论。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;您提到 ReLU 是有效的例子之一。据我了解，ReLU 基本上就像获取输出，以一种可以表示为一侧平坦且对角线超过零的图形的方式对其进行更改。而以前，模型通常使用 Sigmoid 作为激活函数，它更像是一条平滑的曲线，可以防止数字变得太大。出于某种原因，ReLU 效果更好。我从你的解释中得到的感觉是，这种变化会影响神经网络能够以更符合现实的方向理解什么样的事物。但所有这些变化都是以“把东西扔到墙上，看看什么粘住”的方式开发的，只是简单地测量结果，而没有真正理解&lt;i&gt;为什么&lt;/i&gt;ReLU 比 sigmoid 更好。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;凡妮莎·科索伊：&lt;/strong&gt;或多或少是对的。当我们说神经网络可以“理解”什么时，我们必须小心我们的意思。这是一个非常复杂的概念，因为它不仅仅是神经网络可以用一组权重来表达的内容，而是神经网络实际上可以通过梯度下降过程学习的内容。它不仅与神经网络可以描述的函数空间有关，而且与我们查看特定数据集时在这个权重空间中创建的整个损失景观有关。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;当你描述梯度下降和损失景观时，我经常听到的比喻是一个从山上滚下来的球——有一个恒定的重力，你希望球下降到海平面。但通常情况下它不会，因为它发现了一些局部最小值，比如一个洞或其他东西，它可以移动的任何方向都是向上的，所以它不会再滚动。所以你必须塑造景观，使球始终到达海平面。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;是的，这是一个很好的解释。梯度下降是我们有很好的数学理论来解释它如何收敛到凸函数的全局最小值，但神经网络的损失是非凸的......但它仍然恰好有效。人们已经对其工作原理有了一些了解，但我们仍然没有完整的答案。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;好吧，如果地貌确实崎岖不平，那么你就不会期望球到达海平面，因此它无论如何都会到达海平面这一事实需要一个我们实际上没有的解释。我可以看到这种框架如何引发了许多有关不可预测性的问题。&lt;br /&gt;&lt;br /&gt;接下来，您曾提到过 AIXI。那是什么？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt; AIXI 是 Marcus Hutter 的想法，它应该是完美代理的数学模型。它的工作原理是：有一个先验，即所罗门诺夫先验。对于那些不知道这是什么的人来说，这基本上是一种用数学形式化奥卡姆剃刀概念的方法。奥卡姆剃刀的思想是，简单的假设应该被认为比更复杂的假设更有可能是先验的。这确实是所有理性推理的基础。哈特采用了所罗门诺夫先验，这是一种非常聪明的方法，可以在数学上形式化奥卡姆剃刀的概念，并且说，好吧，让我们考虑一个生活在所罗门诺夫先验的宇宙样本中的智能体。这个代理有一些特定的奖励函数，它正在最大化。我们假设它只是以贝叶斯最优方式运行。因此，它只是遵循策略，使其根据先验最大化其预期效用。我们称之为“艾希”。这是一个非常酷的想法......只是它有很多问题，首先是它无法计算的“小”问题。即使在理论上，也没有一种算法可以实现它。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;我想我曾经听过这样的解释：将整个宇宙想象成一堆比特——1和0。一开始，所有这些都可以是一或零，然后你得到一点数据，现在你已经锁定了其中一些数字，并将所有可能的空间减少了一半。当你不断学习时，你会变得越来越确定。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;实际上比这更微妙一些。拥有很多可能性这一事实并不意味着它是不可计算的。也许确切的事情是无法计算的，但你仍然可以想象有一些聪明的算法可以近似这个贝叶斯推理过程。例如，如果你看看经典的强化学习理论，就会发现有一些算法可以在具有 n 个状态的任意马尔可夫决策过程中进行学习。在具有 n 个状态的马尔可夫决策过程中，仍然存在指数级大的可能方式空间，并且我们仍然拥有实际上有效的算法，可以通过利用问题的某些属性，从指数级大的事物中收敛到正确的事物。&lt;br /&gt;&lt;br /&gt; AXI 的问题是，它的先验是这样的，即使先验中的单个假设在计算上也已经是任意昂贵的，因为在它的先验中它考虑了每个可能的程序，所以你可以在通用图灵机上编写的每个可能的程序都是一个可能的假设了解世界如何运作。其中一些程序的计算成本极其昂贵。其中一些程序甚至不会停止，它们只是进入无限循环。你甚至不知道是哪一个，因为这就是停机问题，对吗？这就是为什么 AIXI 不适合做可计算的事情，更不用说计算上易于处理的事情了。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;抛开不可计算性这个小问题不谈，“完美算法”……这是什么意思？如果 AIXI 是通过某种方式神奇地计算出来的，它会安全吗？&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;不，这并不能保证安全。它是“完美”的，因为它是你能想象到的最强大的算法。再次，在一些假设下。我的意思是，这还存在其他问题，例如它假设外部世界比代理本身更简单。这有很多问题，但如果你能把所有这些问题放在一边，那么你可以说这是最好的代理。从这个意义上来说，它是完美的。这是非常非常不安全的。为了保证它的安全，我们需要以某种方式将正确的实用函数插入其中。这仍然是一个非常重要的问题。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;假设你正在寻找可计算的东西，你会寻找什么样的算法？&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;可计算性只是问题之一。我想象会有一种我称之为节俭普遍先验的东西，这是我们可以在数学上定义的某种先验，它同时足够丰富以捕获各种各样的现象。另一方面，我们将有一些聪明的算法，实际上可以允许对这个先验使用进行有效的学习，例如，这个先验假设的一些组合属性或类似的东西。&lt;/p&gt;&lt;p&gt;但即使事先知道这一点，您还需要处理许多其他概念问题。就像我所说的特权问题，奥卡姆剃刀和 AXI 的形式化赋予了观察者特权，你需要了解如何处理这个问题。还有一个可实现性的问题，你实际上不能有一个假设来精确描述宇宙，而只能有某种近似或部分描述，你需要了解如何处理它。还有一个事实是，您希望效用函数不仅仅是您观察的函数，而且还包括一些您无法直接观察到的参数。您还希望能够证明该算法的一些频率论保证。要知道该算法实际上需要了解多少数据才能学习特定事实并拥有良好的理论。研究 AIXI 等模型时会出现一系列不同的问题。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;研究 AIXI 之类的模型，这就是您正在做的工作吗？&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;我想，是的，如果你想用一句话来表达的话，你可以这样做。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;您有兴趣解决哪些有趣的问题？我见过纽科姆的问题以及与此相关的问题。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;凡妮莎·科索伊：&lt;/strong&gt;纽科姆的问题是埃利泽·尤德科斯基（Eliezer Yudkowsky）写的很多东西，作为经典理性解释中非常令人困惑的一个例子。您有两个框需要从中进行选择。一盒有一千块钱。另一个盒子要么什么也没有，要么有一百万美元。您可以选择第一个盒子，也可以拿走两个盒子里的钱。通常情况下，拿走两个盒子里的钱总是比只拿一个盒子要好。&lt;br /&gt;&lt;br /&gt;除了在这个现场实验中，有一个叫做欧米茄的实体可以预测你会做什么，因此如果它知道你只会拿走那个盒子而不会尝试拿走那一千美元，那么它只会将 1,000,000 美元放入另一个盒子中盒子也是如此。因此，只有当您是那种可以预测（对于欧米茄）只拿走一个盒子的特工时，只有在这种情况下，您才能带着 1,000,000 美元离开这个房间。而在另一种情况下，您只有 1,000 美元。因此，可以说，拿一个盒子比拿两个盒子更好，这与许多经典的理性解释所说的相反。这是一个有趣的思想实验的一个例子。&lt;/p&gt;&lt;p&gt;对我来说，这种思想体验是不可实现性问题的一个特例，在这种情况下，您需要处理非常复杂的环境，以至于您无法对可以实际模拟的环境进行完整的描述。因为在这个例子中，环境中包含了这个代理Omega，它模拟了你，这意味着你不能模拟它，因为否则就会产生这种循环悖论。实际上，我还表明，我处理不可实现性的理论（我称之为下贝叶斯主义）实际上会在此类类似纽科姆的问题场景中带来最佳行为。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;研究类似纽科姆问题的原因并不是因为我们期望在某个时候面对欧米茄为我们提供盒子，而是因为这只是一种说明性的思考方式，思考如何在你不知道的情况下处理事情这是怎么回事。也因为可能很容易说，“是的，好吧，我只拿一盒，因为这样我会得到更多”，但是当你真正深入了解一个连贯的、非手作的理由来解释为什么时，然后可能会产生一些有趣的见解。通过探索这些事情，你有什么发现吗？&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;我想说，下贝叶斯主义本身就是一个有趣的发现，它是对代理的一些理论描述，可以推理复杂的世界，而这些世界对于代理来说太复杂了，无法模拟。现在我通过陈述不可实现性问题来描述动机，但我实际上思考这个问题的方式是通过思考所谓的逻辑不确定性。人们开始思考它的原因是所谓的无更新决策理论，它来自对纽科姆时间悖论的思考。因此，这一切都来自于这种推理，尽管事后你可以通过一些更普遍的抽象思维来激发它。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;这些决策理论类型的问题与打造更安全的人工智能之间有什么联系？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;这个想法是创建一个代理的通用数学理论。它帮助我们让人工智能更安全的方式有几个原因，最明显的是，通过这个理论，我们希望能够提出严格的模型来解释系统作为一个协调代理意味着什么。 。有了这个严格的定义，我们将能够提出一些算法，我们可以证明这些算法实际上是安全的代理。或者至少我们可以有一些猜想，表明这种猜想的给定模型，我们认为这些算法是安全代理。就像在密码学中一样，你有一些具有非常有力的证据支持的猜想。&lt;/p&gt;&lt;p&gt;我们至少可以有一些半正式的论证，因为现在当人们争​​论某个特定设计是否安全时，一切都归结为那些挥手的哲学论证，而这些论证没有任何真正坚实的基础。然而，这为我们提供了更精确、更清晰地思考此类问题的工具。假设它还赋予我们更多的权力来利用实证研究，因为也许我们将能够将我们拥有的实证研究，将其插入数学理论中，并得到一些关于我们期望这些结果如何实际外推到各种制度的答案，其中我们还没有这样做。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;您正在进行的这一系列研究最终是否可用于评估大型语言模型或基于深度学习的系统等事物，以便能够更确定地判断它们的安全或不安全程度？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;我认为产生影响的途径有多种。因此，我们最终会提出深度学习理论，从而产生影响。或者，如果不是一个完全经过验证的理论，那么至少有一些关于深度学习如何工作的强有力的猜想，可以与我正在构建的代理理论相结合。然后我们可以使用这种复合理论来证明事物，或者至少对深度学习中构建的系统的属性进行强有力的论证。&lt;/p&gt;&lt;p&gt;当我们使用这一理论提出构建人工智能的全新类型的算法时，可能会产生不同的影响路径，这些算法不是深度学习，但我们对此有很好的理论理解。&lt;/p&gt;&lt;p&gt;还有第三种可能性，我们不会有一个好的理论，但我们至少可以通过类比进行推理，类似于有多少深度学习算法是通过类比我们有数学理论的某些算法来设计的。例如，深度 Q 学习类似于简单 Q 学习，我们有数学理论。因此，我们可以想象一个世界，其中我们有某种理想主义的玩具模型算法，我们有一些严格的论证为什么它们是对齐的，然后我们有一些更多的启发式算法，我们无法直接证明这些算法，但可以说它们是相似的到那些玩具模型。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;所以我听到了三种影响途径。人们可能会构建一种不同形式的人工智能，它可以从头开始验证，并且可以做与基于深度学习的人工智能相同的事情，但以一种更严格的方式。第二个是评估或至少更好地理解深度学习或任何最先进的技术。第三种，介于两者之间，是拥有一种更简单的人工智能形式，可以类比最先进的事物，这样你就可以使用前者来理解后者。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;是的，听起来不错。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;我想重点关注利用基础研究来理解深度学习等其他事物，了解这种基于理论的方法。引入完全相反的观点，有人可能会说：不，你应该只看正在使用的东西并收集有关它的数据，然后通过查找数据中的模式来建立你的理论。当理论被证明是错误的——由于更多的数据——然后更新你的理论。为什么要提前研究理论？&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;最大的原因是，如果没有基础理论，就无法从实证研究中可靠地推断。因为例如，您可能会进行一些测量并发现一些趋势......但随后会出现一些您在趋势中看不到的相变，但会发生这种情况并且行为会改变为完全不同的状态。而且因为没有理论解释，所以你不会注意到，或者人们会转而使用完全不同的算法，这些算法的行为方式完全不同。&lt;/p&gt;&lt;p&gt;你可能有现有人工智能的经验模型，但这些经验模型非常短视。他们总是向前迈出一步。然后你就看不到前方三步之外的悬崖了。根据发生的新事物更新这些理论、经验模型——可能还不够快。最终你跌下了悬崖，然后再说“哦，实际上，趋势线是错误的！”就为时已晚了。&lt;/p&gt;&lt;p&gt;幸运的是，我们所处的领域即使没有经验数据，也有工具可以进行研究。当然，我们应该使用我们拥有的经验数据，但我们不会受到经验数据的瓶颈，因为我们研究的是算法，而算法是数学对象，因此可以用数学方法来研究它们。这与研究某些物理现象非常不同，如果没有数据，就无法在没有数据的情况下生成数据。在这里，这确实应该归结为数学。更准确地说，它应该归结为数学加上我们想要在数学理论中假设的现实世界现象所具有的任何属性。&lt;br /&gt;&lt;br /&gt;是的，这是我们需要经验输入的东西。但另一方面，我们已经对物理学有了很好的理解。因此，考虑到我们所拥有的物理学和其他科学领域的知识，即使我们根本没有经验数据，我们也很有可能拥有足够的信息来纯粹通过数学探究来回答所有问题。这并不是说我们不应该使用经验数据来加强这项研究，但我们并不限于此。&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;所以这不是理论与实验之间的选择，我们应该同时使用两者。您专注于理论方面，可以说这方面的工作还不够，因为理论才是瓶颈所在，而不是获取更多数据。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;是的，我认为我们绝对应该两者都做。理想情况下，需要协同作用，实验产生新现象供理论家解释，理论启发实验。理论家应该告诉实验家哪些问题和什么样的实验最有趣，我们应该有这种协同作用。但我认为，在当前的形势下——尤其是在人工智能领域——理论方面目前被抛在了后面。我认为这就是我们应该投入边际努力的地方。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;你认为现在存在协同效应吗？比如，OpenAI 是否要求 MIRI 对他们的实验提供反馈，或者是否存在任何形式的联系，或者人们只是彼此隔离？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;我认为它现在几乎不存在了。好吧，不，公平地说，它在某些领域存在，而在其他领域则更少。例如，有人致力于奇异学习理论。我认为它们与实验工作的联系更加紧密，这很好。 MIRI 正在做的研究和我正在做的研究与实验工作的联系要少得多。我有一些计划，作为我的长期大计划的一部分，创建一个实验小组，与我密切合作解决这些问题，但我还没有抽出时间去做。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;如果你可以改变任何人的想法，或者设定政治和商业议程，你希望看到什么有更多的界面？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;首先，我们只需要更多的理论家。为了拥有一个接口，我们需要与之交互的东西，所以我们只需要更多的理论家。我认为这实际上是现在的瓶颈所在。一旦理论上的进展足够快，就会出现很多问题。我的意思是，已经有一些问题我希望看到实验，但是这个事情发生得越多，我们就会有更多这样的问题。我认为现在主要的瓶颈在于让更多的人研究这个理论。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;如果有更多的理论工作，从外部角度来看会发生什么变化？我想怀疑论者可能会说：“OpenAI 和其他公司正在以一种很大程度上是实验性的方式取得这些真正令人敬畏的突破，而且效果很好！如果它没有坏，就不要修复它！”在你看来，哪里出了问题？&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;凡妮莎·科索伊：&lt;/strong&gt;我认为目前的道路正在将我们引向一场灾难。我认为像 OpenAI 这样的公司和其他领先的实验室对于自己解决问题的能力过于自信。我认为他们还没有对问题的困难部分提出任何令人信服的解决方案，而且由于缺乏理论理解，他们甚至没有工具来做到这一点。我们甚至没有足够精确的模型来提供我们真正有信心的解决方案。我们需要非常精确地论证使我们相信解决方案是好的。我们甚至没有达到这种精度的工具。&lt;br /&gt;&lt;br /&gt;这些公司所做的基本上只是在反复试验中开发东西。如果我们发现任何问题，那么我们就会进行调整，直到问题消失。这是一种创可贴的方法，也就是说它一直有效，直到不起作用为止。它只是表面上解决问题，但最终会出现这样的情况：要么问题不能及时发现，结果将是灾难性的，要么问题得到了及时发现，但那时没人知道该做什么。执行此操作以修复它。无论如何，最终有人会做出灾难性的事情。&lt;br /&gt;&lt;br /&gt;唯一让我不像美里其他人那么悲观的是我认为我们还有更多的时间。我不认为他们离 AGI 很近，而且我认为在这段时间里很多事情都可以改变。再说一次，并不是说它们会改变——我们可能会一直燃烧，但最终仍然会陷入一场灾难。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;现有问题只有表面解决方案的例子是什么？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;我的意思是，我们关心的真正问题并不是真正存在的问题，对吗？我们主要担心的是，未来的人工智能系统——将比现有的人工智能系统强大得多——将带来人类的灭绝或类似程度的灾难。&lt;br /&gt;&lt;br /&gt;这不是一个现有的问题，原因很简单，我们今天拥有的人工智能系统无法学习如此复杂的世界模型，无法让您执行这些类型的操作。但即使是现在，这些公司仍在努力应对大型语言模型发生的所有问题，例如臭名昭​​著的越狱，他们试图以各种方式使其表现良好。例如，不告诉用户攻击性的、危险的信息，用户很容易找到越狱来解决这个问题，或者只是给出错误的答案。&lt;br /&gt;&lt;br /&gt;但同样，对我来说，这不是真正的问题，这只是一个类比。我的意思是，他们现在正在努力解决这些非常简单、容易得多的问题，但这并不是说他们不会解决这些问题。尝试和错误最终会让你到达目的地。反复试验不能解决存在风险，因为一旦所有人都死了，试验就结束了。没有更多的审判了。所以我们现在遇到的问题，他们仍在努力解决，因为他们没有解决这些问题的基本工具，但最终他们会反复试验并以某种方式修补它们，或者至少很好地解决它们足够经济了。但一旦失败成为全球性灾难，反复试验就不再是解决问题的可接受方法。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;显然我们看不到世界末日的大量测试数据。但我想会有一些较小的先兆问题，但暗示着即将发生的事情。您是否认为幻觉或无法控制人工智能所说的内容是此类前兆所面临的挑战？或者它们完全不相关并且不会出现任何先兆问题？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;这是一个很难回答的问题，因为现有人工智能系统仍然缺少一些非常重要的部分，从而产生存在风险。我们可以举出系统有点错误概括的例子，有很多著名的例子：一些程序通过永远暂停游戏来“赢得”俄罗斯方块，或者通过无限循环地赛船来赢得一些赛船游戏，各种奇怪的意外行为，因为算法最大化的指标实际上并不是用户想要的。你可以称这些为前兆，但我觉得它并没有完全反映问题的严重性，因为这些仍然是玩具设置。不存在在开放的物理世界中运行的开放世界系统。他们试图解决的目标比人类价值观简单得多；并不存在真正存在复杂道德考虑的运营领域。&lt;br /&gt;&lt;br /&gt;也许大型语言模型开始解决这个问题，因为它们进入的领域会出现一些（至少在道德上）不完全微不足道的问题。另一方面，大型语言模型并没有真正做一些超人的事情。嗯，他们可能是超人，因为与人类相比，他们拥有非常广泛的知识，但在其他意义上却不是。所以这很难。有些事情有点相似，但相似程度不高。&lt;br /&gt;&lt;br /&gt;但话又说回来，我们担心这种风险的动机并不是来自于法学硕士。在深度学习出现之前，Eliezer Yudkowsky 就开始谈论这些事情了。这不是动力的来源。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;我想我问这个问题的原因是，在这个问题引起争论和两极分化的地方，常见的反对意见之一是：“这背后没有证据！这只是讲故事！”&lt;i&gt;是否&lt;/i&gt;有证据表明存在危险，或者它真的只是来自数学计算？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;问题是，你所说的证据是什么？这是一个非常复杂的问题。明显的证据包括：人工智能完全失控、打破常规、侵入计算机、将自身复制到其他计算机、彻底操纵人类操作员等等。但这种事情就像金丝雀一样，你只希望在非常非常接近的时候看到它，但已经太晚了。不可能说我们只会依靠这类证据来解决争论。&lt;/p&gt;&lt;p&gt;对于其他类型的证据，有人说进化是机器学习算法如何产生与原始算法完全不一致的东西的证据。其他人向您展示强化学习算法并不符合设计者的意图。但对于每一个这样的论点，你都可以有一个反论点，它说：“是的，但这个例子并不真正相似。我们不能真正从那里预测存在风险，因为存在一些不相似之处。”&lt;br /&gt;&lt;br /&gt;是的，总会有一些不相似的地方，因为除非你在现实世界中拥有非常接近存在风险的人工智能，否则你不会拥有任何与呈现存在风险的事物完全相似的东西。因此，我们别无选择，只能根据基本原理、数学或一些更复杂、更多维的分析来推理。我们别无选择。宇宙并不欠我们一个非常简单的、经验性的方法来测试这些担忧是否真实。我希望的一件事是，该理论将为人工智能的危险性提供更有力的论据，或者该理论会告诉我们不，一切都很好，我们都可以放松。缺乏理论是我们在一个方向或另一个方向上没有万无一失、完全可靠的论据的部分原因。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;寻找证据的挑战在于，任何你能指出的现在存在的东西都可以用多种方式解释。拥有扎实的理论可以为一种解释提供一定的可信度，而不是另一种解释。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;凡妮莎·科索伊：&lt;/strong&gt;是的，绝对如此。如果你有一个理论，认为某种特定类型的误概括在大多数可能的机器学习系统中都是普遍存在的，并且我们也看到这种类型的误概括发生在真实的机器学习系统中，那么就很难驳斥它并说：“哦，是的，我们遇到了这个问题，但我们会做这个做那个，这样就很容易解决它。”&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;有一件事仍然困扰着我，那就是目前无法获得证据的问题。我立即想到的类比是气候变化。你可以说“哦，世界上大片地区不适合居住的想法只是这个精心设计的故事，因为这一切以前从未发生过！”但是你可以看看已经存在的一堆事情：小规模灾难、二氧化碳与温度的关系图等等，指着这些说：“嘿，真正糟糕的事情还没有发生，但是已经发生了。”有很多证据表明它会的！”是什么让人工智能与众不同？&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;凡妮莎·科索伊：&lt;/strong&gt;我认为气候变化是一个很好的类比。最大的区别在于，在气候变化方面，我们有一个非常好的理论。就像气候变化一样，我们有物理学，对吧？我们有行星科学，它有非常非常坚实的基础。我们有计算机模拟。这仍然不是微不足道的，有一些混沌现象很难模拟或预测，所以并不是所有的事情都是完全微不足道的，但我们仍然有一些非常非常强大的理论基础来理解这些事物是如何工作的以及机制是什么。这个理论告诉我们，在这样那样数量的二氧化碳的影响下，我们到底会变暖多少度，仍然存在很大的不确定性区间，但我们仍然有一个相当可靠的预测。&lt;br /&gt;&lt;br /&gt;而对于人工智能，我们没有这个。类似的情况，如果你想想象人工智能风格的气候变化，那么这就像是没有一个理论来解释为什么二氧化碳会导致变暖。温度和二氧化碳之间存在一些经验相关性，然后人们就可以无休止地争论。相关性不是因果关系，也许变暖是由完全不同的事情引起的，也许如果我们做一些不相关的事情就会阻止变暖，但这实际上不是真的。我们会在黑暗中。对于人工智能，我们目前仍处于黑暗之中。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;您目前在 MIRI 的工作进展如何？&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;目前我正在考虑多个问题。希望我很快就会发表一篇关于不精确线性强盗的论文，该论文与我之前提到的下贝叶斯主义相关，这是一种推理复杂世界的代理理论。这是在一些非常简单的特殊情况下分析这个理论，在这种情况下，我成功地得到了算法学习特定事物需要多少数据的精确界限。之后，我开始研究强化学习中学习状态表示的理论，这是目前该理论中缺失的另一大块，它是关于你的算法应该如何了解世界的哪些特征实际上是重要的关注点在。&lt;br /&gt;&lt;br /&gt;与此同时，我还有一位合作者 Gergely Szucs，他正在致力于利用我的基础贝叶斯物理主义理论来创建量子力学的新解释。他在那里得到了一些非常有趣的结果。这是一个测试用例，展示了这种关于代理的思考框架如何帮助您解决各种哲学困惑。在这种情况下，混乱与量子力学的解释有关。斯科特·加拉布兰特（Scott Garrabrant）有一个关于新型不精确概率的项目，这是一种表示具有良好组合特性的信念的新方法。卡内基梅隆大学的 Kaspar Osterheld 和 Abram Demski 最近发表了一篇论文，介绍了一些新型的频率论保证算法，这些算法基于类似于预测市场的东西做出决策。是的，很多有趣的事情正在发生。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;是否还有其他我没有问过的问题，可以帮助看到此内容的人了解您在这里的情况？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;确切地说，这不是一个问题，但我还有一个更具体的方法来解决如何实际解决对齐问题，如何实际设计一个对齐的代理，我称之为物理主义超级模仿。这是价值学习主题的变体，但它借鉴了基础贝叶斯物理主义的框架，该框架来自学习理论议程和算法信息论中的一些想法，提出了一种半正式的方法来解决如何一种能够以稳健的方式学习人类价值观的人工智能。&lt;br /&gt;&lt;br /&gt;它解决了其他价值学习方法所存在的许多问题，例如：如何确定代理的边界在哪里？什么是人？你如何在太空中找到这个人？在推断人类的价值观时，您如何考虑不仅是行为，而且还考虑人类的内部思维过程？如何防止人工智能以某种方式改变或操纵人类来改变他们的价值观等不正当激励措施？如何避免内部对齐问题？它解决了其他方法所存在的一系列问题。&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Will Petillo：&lt;/strong&gt;这听起来让人想起逆强化学习？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;逆强化学习的理念是我们应该观察人类的行为，推断这些人类想要做什么，然后我们就可以做这件事。 “我们”作为人工智能。所以我实际上有一些演讲，其中我将物理超级模仿解释为类固醇的逆强化学习。它采用了这个基本想法，但以解决更简单的方法所存在的许多深层问题的方式来实现它。简单化方法存在的一个问题是，它们将人类建模为完美的代理，在对环境有完美的了解的情况下遵循完美的政策，这是非常不现实的。&lt;br /&gt;&lt;br /&gt;相反，我将人类建模为学习代理。他们边走边学。他们甚至可能做得并不完美。还有一个就是边界问题。人类到底是什么？你把人类的界限放在哪里？是否只有人类使用的某些特定输入和输出，并且您认为通过此端口的所有内容都是人类？但是，你如何处理进入这个端口的内容与人类实际想要做的事情之间的各种差异，或者像人工智能劫持这个通道这样的各种可能性？&lt;br /&gt;&lt;br /&gt;在我的方法中，人类的形式化方式是人类是宇宙正在运行的特定计算。我实际上可以使用基础贝叶斯物理主义将其形式化。它具有特定的属性，这使得它具有代理性，因此代理会检测宇宙正在运行哪些计算，其中检测哪些计算是代理，并且在这些代理中，它通过研究因果关系来选择哪个代理是其用户，这样它位于代理的边界上。第一件事是因为我们正在谈论这个人正在运行的计算，这是人类的推理并被视为一种计算。我们也会自动将内部视为内部思维过程，而不仅仅是表达为外部行为的事物。所以我们在那里可能有更多的信息。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;人们参与其中的最佳方式是什么？他们想提前了解什么？&lt;br /&gt;&lt;br /&gt; &lt;strong&gt;Vanessa Kosoy：&lt;/strong&gt;他们可以立即开始做的一件事是阅读人们迄今为止在代理基金会和学习理论议程中所做的事情。我最近有一篇文章《 &lt;a href="https://www.lesswrong.com/posts/ZwshvqiqCvXPsZEct/the-learning-theoretic-agenda-status-2023"&gt;&lt;u&gt;学习理论议程：2023 年现状》&lt;/u&gt;&lt;/a&gt; ，其中总结了很多内容。我还有一个&lt;a href="https://www.alignmentforum.org/posts/fsGEyCYhqs7AWwdCe/learning-theoretic-agenda-reading-list"&gt;&lt;u&gt;阅读列表帖子&lt;/u&gt;&lt;/a&gt;，为想要进入该领域的人推荐一些背景阅读材料。更具体地说，就职业步骤而言，现在申请已经太晚了，但我正在&lt;a href="https://www.matsprogram.org/"&gt;&lt;u&gt;MATS&lt;/u&gt;&lt;/a&gt;中运行一个轨道&lt;i&gt;，&lt;/i&gt;这是一个针对想要进入人工智能安全领域的研究人员的培训计划。我有一个专注于学习理论议程的曲目。希望明年还会有另一条这样的赛道。我还梦想有一个实习计划，这将把人们带到以色列与我一起从事这方面的工作。目前，由于战争，这件事被推迟了，但希望事情最终会稳定下来，我会恢复这个项目。这些是目前参与的主要方式。&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;威尔·佩蒂略：&lt;/strong&gt;谢谢您的描述。我祝愿您能够最好地发展这一理论并获得更多的兴趣，以便证据和理论之间的不匹配开始得到纠正，研究人员知道他们在做什么，而不是在黑暗中跌跌撞撞！&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;凡妮莎·科索伊：&lt;/strong&gt;谢谢你邀请我。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/QPxrH5ex6MpYoLwer/interview-with-vanessa-kosoy-on-the-value-of-theoretical#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Mon, 04 Dec 2023 22:58:42 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/QPxrH5ex6MpYoLwer/interview-with-vanessa-kosoy-on-the-value-of-theoretical</guid></item></channel></rss>