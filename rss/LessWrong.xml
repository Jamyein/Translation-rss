<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>少错</title><link>https://www.lesswrong.com</link><description>致力于提炼理性艺术的社区博客</description><lastBuildDate>Sun, 14 Jan 2024 12:19:41 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>与大多数人工智能风险类比相比</title><link>https://www.lesswrong.com/posts/SnfjK9ALrzFJB8x7B/against-most-ai-risk-analogies</link><description>发布于 2024 年 1 月 14 日凌晨 3:36（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;我不喜欢人们使用的大多数人工智能风险类比。虽然我认为类比有助于第一次向人们解释一个概念，但我认为类比经常被误用，而且常常是有害的。根本问题是，类比一直被错误地认为，并且经常被故意用作特定人工智能风险立场的&lt;i&gt;论据&lt;/i&gt;。大多数时候，当以这种方式使用类比时，我认为它们具有误导性和不精确性，通常会传达特定的、可信的人工智能模型的错误印象，即使不存在这样的可信模型。&lt;/p&gt;&lt;p&gt;以下是我在人工智能风险背景下发现的类比示例的随机列表：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href="https://people.eecs.berkeley.edu/~russell/papers/russell-bostonglobe23-AI"&gt;斯图尔特·拉塞尔&lt;/a&gt;：“这并不完全像邀请一个高级外星物种来永远成为我们的奴隶，但它有点像那样。”&lt;/li&gt;&lt;li&gt; &lt;a href="https://80000hours.org/podcast/episodes/ajeya-cotra-accidentally-teaching-ai-to-deceive-us/#aliens-and-other-analogies-013822"&gt;罗布·维布林&lt;/a&gt;：“这有点像试图了解章鱼如何思考或如何行为——只不过章鱼还不存在，我们要做的就是研究它们的祖先海蜗牛，然后我们必须从中弄清楚成为章鱼是什么感觉。”&lt;/li&gt;&lt;li&gt; &lt;a href="https://twitter.com/ESYudkowsky/status/1633219449724760065"&gt;Eliezer Yudkowsky&lt;/a&gt; ：“这个人工智能扮演的角色不是人工智能。人工智能是一个看不见的女演员，目前正在扮演这个角色。如果人工智能变得更聪明，这可能会适得其反。”&lt;/li&gt;&lt;li&gt; &lt;a href="https://www.lesswrong.com/posts/GNhMPAWcfBCASy8e6/a-central-ai-alignment-problem-capabilities-generalization#Discussion_of_a_problem"&gt;Nate Soares&lt;/a&gt; ：“我对人工智能进展的猜测是，在某个时刻，一些团队得到的人工智能开始足够好地泛化，远远超出其训练分布，它可以掌握物理、生物工程和心理学等领域[...] 在其能力飞跃发展的同一过程中，其对齐属性被揭示为肤浅的，并且无法概括。&lt;strong&gt;这里的中心类比是，优化猿类的包容性遗传适应性（IGF）并不会使由此产生的人类在心理上针对 IGF 进行了优化。&lt;/strong&gt; ”&lt;/li&gt;&lt;li&gt;&lt;a href="https://lukemuehlhauser.com/wiener-on-the-ai-control-problem-in-1960/"&gt;诺伯特·维纳&lt;/a&gt;：“当我们建造的机器能够以我们无法跟上的速度对其输入数据进行操作时，我们可能不知道何时将其关闭，直到为时已晚。我们都知道魔法师学徒的寓言……”&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.datanami.com/2023/05/03/ai-threat-like-nuclear-weapons-hinton-says/"&gt;杰弗里·辛顿（Geoffry Hinton）&lt;/a&gt; ：“这就像核武器。如果发生核战争，我们都会失败。这些东西接管也是如此。”&lt;/li&gt;&lt;li&gt; &lt;a href="https://www.lesswrong.com/posts/76etTtAiKtZGGzkmi/video-and-transcript-of-presentation-on-existential-risk"&gt;乔·卡尔史密斯&lt;/a&gt;：“我认为人工智能的一个更好的比喻是一种工程病毒，如果它泄露出去，它会变得越来越难控制，这是一个越来越大的问题。”&lt;/li&gt;&lt;li&gt; &lt;a href="https://80000hours.org/podcast/episodes/ajeya-cotra-accidentally-teaching-ai-to-deceive-us/#aliens-and-other-analogies-013822"&gt;Ajeya Cotra&lt;/a&gt; ：“从某种意义上说，企业可能是比整个经济更好的类比：它们是由这些人类部分组成的，但最终往往追求的东西实际上并不是目标和目标的简单平均数。组成这台机器的人类的愿望，这台机器就是可口可乐公司之类的。”&lt;/li&gt;&lt;li&gt; &lt;a href="https://archive.is/K0Arj#selection-581.152-585.113"&gt;Ezra Klein&lt;/a&gt; ：“正如我的同事 Ross Douthat &lt;a href="https://archive.is/o/K0Arj/https://www.nytimes.com/2023/03/02/opinion/magic-science-ufo-ai.html"&gt;所写&lt;/a&gt;，这是一种召唤行为。施展这些咒语的程序员不知道什么会绊倒传送门。”&lt;/li&gt;&lt;li&gt; &lt;a href="https://forum.effectivealtruism.org/posts/zsFCj2mfnYZmSW2FF/ai-risk-is-like-terminator-stop-saying-it-s-not-1"&gt;SKLUUG：&lt;/a&gt; “人工智能风险就像&lt;i&gt;终结者&lt;/i&gt;！人工智能可能会变得非常聪明，并决定杀死我们所有人！我们需要对此采取一些措施！”&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这些类比涵盖的范围很广，其中许多类比有时确实有助于传达有意义的信息。我的观点并不是说它们毫无用处，而是这些类比通常很肤浅且具有误导性。这些类比几乎没有对真实人工智能的行为和运作产生任何重要影响，但仍然给人留下了我们应该如何思考人工智能的模型的&lt;i&gt;印象&lt;/i&gt;。&lt;/p&gt;&lt;p&gt;并注意这些类比如何给人一种连贯的人工智能模型的印象，即使演讲​​者没有直接断言它&lt;i&gt;是&lt;/i&gt;一个模型。不管演讲者的意图如何，我认为&lt;i&gt;实际的&lt;/i&gt;效果往往是在听众的脑海中植入一幅详细但虚假的画面，从而引发关于真正的人工智能在未来如何运作的似是而非的想法。由于相似之处非常浅，因此从这些类比中得出的推理往往是不可靠的。&lt;/p&gt;&lt;p&gt;另外，这些类比经常是&lt;i&gt;有选择性地&lt;/i&gt;选择的——基于唤起特定的偏好图像而选择，而不是基于识别可能的最&lt;i&gt;自然&lt;/i&gt;的比较点。考虑&lt;a href="https://80000hours.org/podcast/episodes/ajeya-cotra-accidentally-teaching-ai-to-deceive-us/#aliens-and-other-analogies-013822"&gt;Ajeya Cotra 的这个例子&lt;/a&gt;，&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;strong&gt;Rob Wiblin：&lt;/strong&gt;我想花一点时间谈谈人们用来推理所有这些问题的不同类比和不同的心理图像。 [...]您认为还有其他值得强调的心理模型或类比吗？&lt;/p&gt;&lt;p&gt; &lt;strong&gt;Ajeya Cotra：&lt;/strong&gt;我听过的一个播客实际上做了另一个类比——这是一个艺术播客，随着人工智能艺术开始真正起飞，关于人工智能的一集也是如此——这就像你在养一只狮子幼崽，或者你有这些人抚养黑猩猩宝宝，而你正试图引导他们走向正确的方向。也许它非常可爱、迷人，但从根本上来说它与你格格不入。无论你多么努力地抚养它或引导它，它都可能在它成年后撕掉你的脸。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;当“金毛猎犬”同样有效时，科特拉选择“黑猩猩”作为比较点有什么原因吗？很难知道，但似乎她没有选择金毛猎犬，因为这会破坏她的一般论文。&lt;/p&gt;&lt;p&gt;我同意，如果她的目标是传达错位的&lt;i&gt;逻辑可能性&lt;/i&gt;，那么与金毛猎犬的类比可能行不通。但如果她的目标是传达错位的&lt;i&gt;合理性&lt;/i&gt;，或者类似我们应该如何看待人工智能的“心智模型”之类的东西，我认为没有充分的理由更喜欢其中一种。一个类比唤起负面形象，另一个类比唤起正面形象，这一事实本身似乎并没有任何使用偏好的基础。&lt;/p&gt;&lt;p&gt;或者考虑与人类进化的类比。如果你试图表达内在错位的&lt;i&gt;逻辑可能性&lt;/i&gt;，那么与人类进化的类比是有道理的。但是，如果你试图传达内在错位的&lt;i&gt;合理性&lt;/i&gt;，或者内在错位的心理模型，为什么不选择将这种情况与&lt;a href="https://www.lesswrong.com/posts/FyChg3kYG54tEN3u6/evolution-is-a-bad-analogy-for-agi-inner-alignment"&gt;人类一生中的学习&lt;/a&gt;进行类比呢？事实上，正如昆廷·波普（Quintin Pope） &lt;a href="https://www.lesswrong.com/posts/hvz9qjWyv8cLX9JJR/evolution-provides-no-evidence-for-the-sharp-left-turn#Human__misalignment__with_inclusive_genetic_fitness_provides_no_evidence_for_AI_misalignment"&gt;所解释的&lt;/a&gt;那样，进化论的类比似乎有一些很大的缺陷：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; “祖先环境中的人类行为”与“现代环境中的人类行为”并不是训练和部署环境之间行为差异的有效示例。人类并不是在祖先环境中“训练”，然后在现代环境中“部署”的。相反，人类在一生中不断地接受“训练”（通过奖励信号和感官预测错误信号）。人类在祖先和现代环境中的“训练运行”是不同的。&lt;/p&gt;&lt;p&gt;因此，人类进化不是以下例子：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;我们在环境 A 中训练系统。然后，经过训练的系统处理来自环境 B 的不同输入分布，现在系统的行为有所不同。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这是一个例子：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;我们在环境 A 中训练了一个系统。然后，我们在环境 B 的不同输入分布上训练了同一系统的&lt;i&gt;新版本&lt;/i&gt;，现在这&lt;i&gt;两个不同的系统&lt;/i&gt;表现不同。&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;p&gt;许多人工智能风险的支持者似乎很乐意在&lt;i&gt;不&lt;/i&gt;支持预期结论（例如&lt;a href="https://www.lesswrong.com/posts/RcZeZt8cPk48xxiQ8/anthropomorphic-optimism"&gt;拟人类比）&lt;/a&gt;时批评类比。有时，他们甚至会批评&lt;a href="https://80000hours.org/podcast/episodes/ajeya-cotra-accidentally-teaching-ai-to-deceive-us/#aliens-and-other-analogies-013822"&gt;他们想象的其他人使用的类比&lt;/a&gt;，例如“它就像烤面包机”或“它就像谷歌地图”。当然，在这些情况下，他们可以轻松识别缺陷：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;strong&gt;Ajeya Cotra：&lt;/strong&gt;我认为谷歌地图与所有这些东西和人工智能系统之间真正的不相似之处在于，我们并没有以与生产谷歌地图相同的方式生产这些人工智能系统：由一些人坐下来思考它应该是什么样子就像，然后编写代码来确定它应该是什么样子。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;需要明确的是，我同意谷歌地图是一个糟糕的类比。但黑猩猩的比喻真的好得多吗？难道我们不应该对我们自己的类比应用同样程度的严格性吗？&lt;/p&gt;&lt;p&gt;我的观点不是“使用不同的类比”。我的观点是，我们&lt;i&gt;首先&lt;/i&gt;应该&lt;i&gt;停止依赖类比&lt;/i&gt;。请改用详细的对象级参数！&lt;/p&gt;&lt;p&gt;虽然类比的目的是提供知识来代替无知——解释一种见解或一个概念——但我相信许多人工智能风险类比主要是误导或迷惑人们，而不是启发他们；他们可以插入不必要的错误&lt;i&gt;假设&lt;/i&gt;来代替真正的理解。它们想要传达的基本概念可能很值得理解，但伴随着这个概念的是一大堆额外的猜测。&lt;/p&gt;&lt;hr /&gt;&lt;p&gt;部分原因是我不会分享其他人对人工智能未来实际情况的看法。这只是我论点的一小部分，因为我的主要观点是，我们应该少用类比，而不是改用不同的类比来表达不同的画面。但我对未来看法的这种差异仍然在我对人工智能风险类比的使用感到沮丧的过程中发挥着重要作用。&lt;/p&gt;&lt;p&gt;例如，也许你认为外星人和动物的类比很棒，但我完全不明白其中的原因。但我仍然很难看到这一点。至少，让我比较一下我的照片，也许你能明白我来自哪里。&lt;/p&gt;&lt;p&gt;在我看来，默认的画面——在我看来，这就像对 2024 年当前趋势到中期未来的直接推断，因为人工智能匹配并开始略微超过人类智能——看起来与大多数人所描绘的漫画完全不同。标准类比。与人工智能将成为外星人的模型相反，我预计人工智能将直接诞生于我们的社会，由我们有意塑造，目的是填补我们世界中大部分人形的漏洞。他们将在社会上与我们融为一体，并可能在很大程度上分享我们关于社会和物理世界的概念，接受过我们的数据培训并能流利地使用我们的语言。他们数量众多、无处不在，不断地与我们互动、帮助我们、与我们合作，甚至为亿万人民提供友谊。人工智能将由我们评估、检查和选择，它们的行为将直接由我们的工程决定。&lt;/p&gt;&lt;p&gt;我觉得这张图是现有趋势的相对简单的延伸，法学硕士&lt;i&gt;已经&lt;/i&gt;接受了对我们友善和乐于助人的培训，并与我们合作，首先受到我们综合文化输出的影响。我预计，在可预见的未来，这种融入我们社会的趋势将会加剧，因为消费者对人们可以信任并愿意与之互动的人工智能会有需求。&lt;a href="https://aiimpacts.org/discontinuous-progress-investigation/"&gt;进展可能是渐进式的&lt;/a&gt;，而不是随着超级强大特工的到来而突然出现。也许最重要的是，我预计随着人工智能开始产生大规模影响&lt;a href="https://www.lesswrong.com/posts/EaZghEwcCJRAuee66/my-thoughts-on-the-social-response-to-ai-risk"&gt;，监督和监管将随着时间的推移而急剧增加&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;我无意在此描绘一幅一致乐观的景象。在我所呈现的场景中，仍然有很多地方可能会出错。其中大部分内容都没有具体说明，因为&lt;a href="https://forum.effectivealtruism.org/posts/zrSx3NRZEaJENazHK/why-i-think-it-s-important-to-work-on-ai-forecasting"&gt;我根本不知道未来会发生什么&lt;/a&gt;。但至少，也许你现在可以同情我的感觉，鉴于我的观点，大多数现有的人工智能风险类比都非常令人沮丧。&lt;/p&gt;&lt;hr /&gt;&lt;p&gt;再次强调，我并不是说类比在人工智能风险讨论中没有地位。我自己也确实使用过它们很多次。但我认为它们可以，而且经常被粗心地使用，并且似乎经常将各种关于未来人工智能将如何表现&lt;i&gt;的错误&lt;/i&gt;说明放入人们的心理模型中，即使进行类比的人没有任何意图。在我看来，总体而言，如果我们减少对人工智能风险类比的依赖，并用特定的对象级点代替它们，情况会好得多。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.lesswrong.com/posts/SnfjK9ALrzFJB8x7B/against-most-ai-risk-analogies#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sun, 14 Jan 2024 03:36:16 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/SnfjK9ALrzFJB8x7B/against-most-ai-risk-analogies</guid></item><item><title>用脸投票</title><link>https://www.lesswrong.com/posts/EitMbGASqTAuyWPJA/vote-with-your-face</link><description>发布于 2024 年 1 月 14 日凌晨 3:30（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;span&gt;从 7 月 2 日的舞蹈开始，&lt;/span&gt; &lt;a href="https://www.bidadance.org/"&gt;BIDA&lt;/a&gt;一半的舞蹈都是&lt;a href="https://blog.bidadance.org/2023/06/some-mask-optional-dances.html"&gt;不戴面具的&lt;/a&gt;。有些人只想在知道地板上的每个人都戴着&lt;a href="https://blog.bidadance.org/2022/05/requiring-high-filtration-masks.html"&gt;高过滤口罩的情况&lt;/a&gt;下参加，其他人只想在不需要戴口罩的情况下参加，当然其他人无论如何都会或不会参加。提供每种舞蹈中的一些，让人们选择适合自己喜好的舞蹈。&lt;/p&gt;&lt;p&gt;另外，作为一个喜欢实验的人，这几乎就像一个关于出勤戴口罩要求的随机对照试验！&lt;/p&gt;&lt;p&gt;在我们改为要​​求和可选佩戴口罩交替使用之前，我们不知道这会对出勤率产生什么影响：在可选佩戴口罩的夜晚（更有趣！）还是在需要佩戴口罩的夜晚（更安全！）会有更多的人。回顾一下出席情况，我发现：&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.jefftk.com/bida-attendance-by-mask-status-big.png"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/EitMbGASqTAuyWPJA/jncoepfisn8qg4hz7ujn" /&gt;&lt;/a&gt;&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;请注意，除了只有十一种舞蹈外，您可能还需要调整某些舞蹈的一些独特方面：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt; 7/2 舞蹈是第一个可选面具舞蹈，因此可能会受到那些很高兴不戴面具跳舞但不会每次都来的人们的鼓舞。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; 7/2 和 9/3 舞会是我们夏季前的最后一场舞会，也是回归后的第一场舞会，这可以增加上座率。但同时也是假期周末，这可能会减少出席人数。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; 11/5和11/19的舞会都是双人舞，上座率普遍较高。但我们（大部分是偶然的）背靠背做了两次，每一次。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; 12/3舞会是家庭舞会，这通常也意味着更高的出席率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; 12/17 的舞会在另一个地点萨默维尔军械库举行，这通常意味着出席率较低。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; 1/7 舞会是在一场大暴风雪期间举行的，这通常意味着出席人数要少得多。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;总的来说，看起来不戴面具的夜晚更受欢迎，但考虑到所有的警告，这很难说。无论如何，差异显然没有大到足以成为停止其中之一的理由。我预计我们会继续轮流参加，因为我们仍然听到很多人说他们只想参加其中之一。&lt;/p&gt;&lt;p&gt; （所有这些都是代表我自己，而不是 BIDA 董事会。）&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.lesswrong.com/posts/EitMbGASqTAuyWPJA/vote-with-your-face#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sun, 14 Jan 2024 03:30:06 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/EitMbGASqTAuyWPJA/vote-with-your-face</guid></item><item><title>使用 MLP 线性化对稀疏自动编码器特征进行逆向工程的案例研究</title><link>https://www.lesswrong.com/posts/93nKtsDL6YY5fRbQv/case-studies-in-reverse-engineering-sparse-autoencoder</link><description>发布于 2024 年 1 月 14 日凌晨 2:06（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;i&gt;认知状态：初步/探索性。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;作为 Neel Nanda 的 MATS 5.0（2023-2024 年冬季）研究冲刺的一部分进行的工作。&lt;/i&gt;&lt;/p&gt;&lt;p&gt; TL;DR：我们开发了一种方法，通过对 MLP 子层进行局部线性逼近，来理解 Transformer 模型中的稀疏自动编码器特征是如何从早期组件计算出来的。我们研究该特征如何在特定输入上激活，并采取措施通过检查模型权重来寻找与输入无关的解释。我们通过几个深入的案例研究演示了这种方法，以解释简单变压器（GELU-1L 和 GELU-2L）用于计算某些特定特征的机制，并验证它与因果方法的结果一致。&lt;/p&gt;&lt;h1&gt;介绍&lt;/h1&gt;&lt;p&gt;机械可解释性的核心目标是解决维度灾难，将神经网络的高维激活和参数分解为单独可理解的部分。&lt;a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html"&gt;稀疏自动编码器（SAE）&lt;/a&gt;是最近一项令人兴奋的发展，它使我们能够采用高维激活（可能处于叠加状态）并将它们分解为激活空间中代表（大部分）独立概念的有意义的方向。&lt;/p&gt;&lt;p&gt;当应用于 MLP 激活/输出时，SAE 的一个主要限制是很难研究如何根据早期模型组件的输出计算特征。有了有意义的神经元，我们可以直接查看它与早期组件的连接/&lt;a href="https://transformer-circuits.pub/2021/framework/index.html#residual-comms"&gt;虚拟权重&lt;/a&gt;——例如&lt;a href="https://distill.pub/2020/circuits/zoom-in/"&gt;，视觉模型中的汽车神经元是由车窗、车身和车轮神经元构建的&lt;/a&gt;——但 SAE 特征通常密集在神经元基础。这意味着，为了理解特征是如何计算的，我们需要理解数千个神经元激活的复杂非线性函数。维度的诅咒依然存在！&lt;/p&gt;&lt;p&gt;在这篇文章中，我们提出了一种技术来探索如何从前面的模型组件计算神经元密集的 SAE 特征。这种方法涉及采用 MLP 子层的导数，以获得 SAE 特征的局部线性逼近——这种技术在先前的工作（例如&lt;a href="https://www.neelnanda.io/mechanistic-interpretability/attribution-patching"&gt;属性修补）&lt;/a&gt;中已经取得了一些成功。重要的是，我们的方法更进一步，将这种线性近似与模型权重本身结合起来，以获得模型行为的&lt;i&gt;全局&lt;/i&gt;图像，而不是局限于特定的输入示例&lt;span class="footnote-reference" id="fnref5ns12vjb0f8"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn5ns12vjb0f8"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。最终结果是一种获取有关模型如何计算 SAE 特征的独立于输入的信息的有效方法。&lt;/p&gt;&lt;p&gt;我们证明这种方法为一系列案例研究提供了有用的见解，使我们能够将特征逆向工程回到原始的令牌嵌入，并与因果干预的结果一致。我们研究这种近似的准确性和原则性。尽管它最终只是一个近似值，并且有时可能会崩溃，但我们相信这是一个有用的工具，可以让您更好地理解 SAE 特征的计算方式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;免责声明&lt;/strong&gt;：这是非常初步的工作！我们认为这些结果都相当具有探索性；这篇文章并不试图对我们如何准确地理解这些 SAE 特征以及计算它们的机制做出强有力的声明。但我们希望我们的结果是有趣的，它们可以让其他人在它们的基础上进行构建，并且它们可能有助于为思考 SAE 提供更好的直觉。&lt;/p&gt;&lt;p&gt;这篇文章代表了我们作为 Neel Nanda 的 MATS 5.0 计划的一部分的两周冲刺的成果，我们将在该计划的其余部分继续以此为基础。如果您想以这些想法为基础，请联系我们！ （请随时在 LessWrong 上给我们留言，或者如果您愿意，请发送电子邮件至&lt;a href="mailto:jacob.dunefsky@yale.edu"&gt;jacob.dunefsky@yale.edu&lt;/a&gt; ）&lt;/p&gt;&lt;h2&gt;为什么这很重要？&lt;/h2&gt;&lt;p&gt;我们认为这是一个需要解决的重要问题，原因有很多：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;对 SAE 功能进行逆向工程使我们能够更有效地解释它们。&lt;/strong&gt;特别是，这样做可以揭示其他方法可能遗漏&lt;i&gt;的意外行为&lt;/i&gt;。例如，在我们的一个案例研究中，我们发现一个功能最初似乎只在令牌&lt;code&gt;(&amp;#39;&lt;/code&gt;上激活；然而，在应用逆向工程之后，我们发现该功能也在令牌&lt;code&gt;ह&lt;/code&gt; （&lt;a href="https://en.wiktionary.org/wiki/%E0%A4%B9"&gt;一个印地语字符）&lt;/a&gt;上激活我们对 SAE 功能理解上的差距限制了它们在预测和分析不安全或不需要的模型行为方面的效用，因此逆向工程对于帮助我们识别这些差距非常重要。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;对 SAE 特征进行逆向工程可能会揭示模型的新故障模式。&lt;/strong&gt;通过了解计算给定特征的算法，我们也许能够更好地理解导致模型表现出不良行为的原因。例如，如果我们可以在模型中找到重要的下游特征（例如候选人是否会在工作中表现良好）并将其追溯到输入的受保护特征（例如种族或性别），那么我们可以使用它来了解模型计算中的固有偏差。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;对 SAE 特征进行逆向工程可以帮助我们更好地提出关于特征通用性的理论主张。&lt;/strong&gt;例如，人们有兴趣了解不同的模型是否学习通用特征。 SAE 可以通过在不同模型的激活上训练 SAE 并比较它们学到的特征来解决这个问题（请参阅&lt;a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html#phenomenology-universality"&gt;Anthropic 的 SAE 论文中的“通用性”讨论&lt;/a&gt;）。由于逆向工程揭示了计算 SAE 特征的机制，因此它可以为评估通用性提供补充视角，让我们测试 SAE 是否不仅有助于学习通用特征，还有助于学习通用机制。它还可以帮助我们捕捉虚幻的“普遍性”，即特征表面上相似，但通过不同的机制计算，并在适当的情况下分开&lt;span class="footnote-reference" id="fnrefa1rxph5d74"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fna1rxph5d74"&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;对 SAE 功能进行逆向工程对于获得有关 SAE 一般功能和局限性的各种见解非常有用。&lt;/strong&gt;例如，在一个 2 层 Transformer 的实验中，我们使用我们的方法用第 0 层 SAE 特征来表达第 1 层 SAE 特征；我们发现第 0 层特征和第 1 层特征之间的连接很密集，这表明当前训练的 SAE 不容易产生有关同一模型不同层的特征如何相互关联的稀疏信息。这表明要么内部模型连接确实不稀疏，要么我们的 SAE 训练方法存在局限性，这两者都是有用的见解！我们预计，只有深入研究这些模型的内部结构以及它们如何组合在一起，我们才能发现有关模型和 SAE 的许多其他见解。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;如果没有逆向工程，SAE 功能就是一个不完整的故事。&lt;/strong&gt;仅在纯粹的美学层面上，我们发现对产生这些特征的计算一无所知是令人不满意的。&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;概述&lt;/h1&gt;&lt;p&gt;本文的其余部分分为以下部分：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;我们对用于进行逆向工程的方法进行了高级概述。&lt;/strong&gt;我们建议阅读本节，因为它为理解我们的案例研究中发生的情况提供了有用的背景。对明确的数学细节感兴趣的读者可能有兴趣阅读详细阐述此方法的附录部分。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;我们提供了许多案例研究，其中我们对特定的 SAE 功能进行了逆向工程。&lt;/strong&gt;这是我们文章的重点，我们希望大多数读者能够从中获得最大收益（尽管我们不希望所有读者都阅读所有案例研究）。这是一个很长的部分，我们在这里确实进行了非常深入的细节，但我们认为它可以帮助读者理解这些特征的计算方式以及逆向工程过程的总体工作原理。以下案例研究摘要可能会帮助您决定要进一步了解哪些案例：&lt;ul&gt;&lt;li&gt; GELU-1L 中的一项功能的案例研究，该功能主要在令牌上触发&lt;code&gt;(&amp;#39;&lt;/code&gt; .&lt;ul&gt;&lt;li&gt;在本案例研究中，我们使用逆向工程来揭示看似单义的特征有时会在不相关的标记上触发，例如&lt;code&gt;ह&lt;/code&gt; ，这是使用这种方法构建对抗性提示的概念验证，以及如何使用这种方法的示例了解意外行为。&lt;/li&gt;&lt;li&gt;我们还发现注意力头 0 和 3 通过触发指示代码相关或列表相关上下文的标记来贡献该功能。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt; GELU-1L 中一个特征的案例研究，当前面有标点符号时，该特征往往会触发二元词“it is”。&lt;ul&gt;&lt;li&gt;在此案例研究中，我们发现直接路径通过触发令牌来贡献该特征，这&lt;code&gt;is&lt;/code&gt;预期一致，并且注意力头 0 触发前面的&lt;code&gt;It&lt;/code&gt;令牌。这使我们能够理解计算二元特征的主题。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt; GELU-1L 中倾向于在令牌&lt;code&gt;&amp;#39;t&lt;/code&gt;上触发的功能的案例研究。&lt;ul&gt;&lt;li&gt;在这个案例研究中，我们发现直接路径非常容易解释。线性化表明注意力是无关紧要的，但更可靠的重采样消融因果干预表明它确实很重要，这表明线性化在这里具有误导性。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt; GELU-1L 中倾向于在代币上引发的功能的案例研究&lt;code&gt;is&lt;/code&gt;在神学/政治背景下进行的。&lt;ul&gt;&lt;li&gt;在这个案例研究中，我们研究了模型如何主要通过单个可解释的注意力头来计算上下文相关的特征。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt; GELU-2L 中某个功能的案例研究，该功能往往会在&lt;code&gt;{&amp;#39;name&amp;#39;: &amp;#39;&lt;/code&gt;等字符串上触发。&lt;ul&gt;&lt;li&gt;在本案例研究中，我们在两层模型中执行逆向工程，包括查看第 1 层 SAE 特征和第 0 层 SAE 特征之间的连接。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;我们更深入地讨论 MLP 线性化，提供实验结果，以便开始了解这种方法在哪里有效以及在哪里失败。&lt;/strong&gt;大多数读者可能会跳过本节，尽管对 Transformer 或该方法的有效性有更多理论兴趣的读者可能会从阅读中有所收获。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;与路径修补等因果方法相比，我们讨论了我们的方法的优点和缺点。&lt;/strong&gt;我们建议阅读本简短的部分，以便了解我们的方法与更广泛的机械可解释性方法的契合点。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;我们从整体上反思该方法及其优点和局限性。&lt;/strong&gt;我们建议您阅读本简短的部分，以校准您对该方法的用处以及未来的方向可能会是什么样子的想法。&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;我们的方法&lt;/h1&gt;&lt;p&gt;在本节中，我们将简要介绍我们的 SAE 功能逆向工程方法。如需更详细的解释，感兴趣的读者应该查看“附录：我们方法的详细信息”部分。&lt;/p&gt;&lt;p&gt;我们应用并扩展了&lt;a href="https://www.lesswrong.com/posts/jDfjqu2qJLcPco9cf/automatically-finding-feature-vectors-in-the-ov-circuits-of"&gt;这篇文章&lt;/a&gt;和&lt;a href="https://arxiv.org/abs/2312.16291"&gt;本文&lt;/a&gt;中描述的方法，以实现逆向工程 SAE 功能。我们将首先了解它在 1 层变压器中的工作原理，然后了解如何扩展它。&lt;/p&gt;&lt;h2&gt;线性化：将 MLP 特征引入残差流&lt;/h2&gt;&lt;p&gt;计算 SAE 特征需要什么？回想一下，模型的残差流是所有先前模型组件的输出之和。这意味着，如果该特征是残差流的线性函数（即，该特征是通过将线性流投影到给定特征向量上来计算的），那么我们可以应用&lt;a href="https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=disz2gTx-jooAcR0a5r8e7LZ"&gt;直接特征归因等&lt;/a&gt;技术来了解每个模型组件如何贡献该功能。&lt;/p&gt;&lt;p&gt;不幸的是，对于在 MLP 输出激活上训练的 SAE，特征在 MLP 输出空间而不是残余流中“实时”。因此，在进行任何进一步的分析之前，我们必须通过MLP拉回SAE特征向量，以获得残差流中与原始MLP输出特征向量相对应的特征向量。&lt;/p&gt;&lt;p&gt;如果 MLP 是线性的，那么这可以完全完成——但是 MLP 不是线性的！它们是由许多神经元组成的复杂非线性函数，并且大多数 SAE 特征都是密集的，这意味着我们需要了解每个神经元才能理解 SAE 特征。然而，&lt;strong&gt;我们可以通过获取 MLP 的梯度 来获得 MLP 的局部线性近似&lt;/strong&gt;。这使我们能够找到近似对应于 MLP 后特征向量的残差流特征向量。具体来说，我们在特定提示中的特定标记上，对输入到 MLP 层的残差流求 SAE 特征（ReLU 前）的导数。&lt;/p&gt;&lt;p&gt;请注意，这是一种基于激活的技术，而不是基于权重的技术；换句话说，获得的特征向量取决于特定的MLP激活，不同的输入会产生不同的线性化特征向量。我们稍后研究这些特征向量的一致性及其准确性。&lt;/p&gt;&lt;h3&gt;技术旁白：冻结 LayerNorm&lt;/h3&gt;&lt;p&gt;请注意，MLP 子层（与 Transformer 中的所有子层一样）前面有 LayerNorm，它由线性变换、非线性归一化操作和线性变换组成。人们可以通过采用 LayerNorm 的梯度以及 MLP 来解释这种非线性，但由于稍后讨论的原因，这并不总是能产生良好的结果。因此，有时需要通过忽略非线性并仅考虑线性变换来&lt;strong&gt;冻结&lt;/strong&gt;LayerNorms。 （这意味着，当我们将冻结的 LayerNorm 应用于残差流时，我们仍然将残差流除以估计残差流标准差的值——但是现在，我们将该值视为常数，而不是另一个函数的残余流。）&lt;/p&gt;&lt;h2&gt;术语说明：直接得分归因&lt;/h2&gt;&lt;p&gt;&lt;a href="https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=disz2gTx-jooAcR0a5r8e7LZ"&gt;直接 Logit 归因&lt;/a&gt;是一种众所周知的技术，用于了解模型组件对模型 Logit 的贡献。现在我们有了残差流特征向量，我们也可以应用它来了解模型组件对 SAE 特征得分的贡献。由于在查看 SAE 特征得分时谈论“logits”是没有意义的，因此我们在整篇文章中将 SAE 特征的直接 logit 归因称为&lt;strong&gt;直接得分归因&lt;/strong&gt;。核心思想是相同的：将残差流分解为分量之和，将每个分量与特征向量进行点积，看看哪些分量是重要的。&lt;/p&gt;&lt;h2&gt;直接路径和去嵌入&lt;/h2&gt;&lt;p&gt;现在我们有了残差流特征向量，我们可以用它来理解原始标记嵌入如何促进 SAE 特征激活。遵循&lt;a href="https://transformer-circuits.pub/2021/framework/index.html"&gt;Elhage 等人的&lt;/a&gt;观点，我们将这条从原始 token 嵌入到 SAE 特征的路径称为&lt;strong&gt;直接路径&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;解释直接路径的一种方法是使用一种我们称为&lt;strong&gt;“去嵌入”&lt;/strong&gt;的技术。去嵌入的思想是获取残差流特征向量，并与模型的输入嵌入矩阵中的每个向量取点积；这会在模型的词汇空间中产生一个特征向量。该向量中每个令牌的系数提供了该令牌通过直接路径对 SAE 功能贡献程度的近似值。&lt;i&gt;重要的是，我们可以查看该向量中系数最高的标记，以便了解模型词汇表中的哪些标记对于直接路径最重要。&lt;/i&gt;&lt;/p&gt;&lt;h2&gt;注意力&lt;/h2&gt;&lt;h3&gt;OV电路和QK电路分析&lt;/h3&gt;&lt;p&gt;我们还可以使用残差流特征向量来了解不同的注意力头如何对 SAE 特征激活做出贡献。回想一下，注意力头的功能可以分解为计算注意力分数的 QK 电路和转换 token 信息的 OV 电路。尽管注意力头是残差流的非线性函数，但如果我们孤立地看待 OV 电路，那么注意力输出只是每个注意力头和每个 token 的线性变换的加权和。&lt;/p&gt;&lt;p&gt;因此，我们可以通过 OV 矩阵拉回残余流特征向量来了解给定头的 OV 电路如何对 SAE 特征做出贡献。&lt;i&gt;请注意，完成此操作后，我们可以应用去嵌入等技术来了解模型词汇表中的哪些标记通过该注意头的 OV 电路对 SAE 功能贡献最大。&lt;/i&gt;换句话说，我们可以确定哪些令牌&lt;i&gt;如果&lt;/i&gt;受到该头的关注，最能激活该功能。然后可以通过查看哪些令牌具有最高的 QK 分数以及对 OV 电路很重要的令牌来单独分析 QK 电路。&lt;/p&gt;&lt;h3&gt; （头、源标记）对的直接分数归因&lt;/h3&gt;&lt;p&gt;我们在案例研究中经常使用的一种工具是对关注中的个体（头、源标记）对进行直接评分归因。我们可以这样做，因为注意力头的输出是每个源令牌贡献的加权和。这使我们能够了解每个源令牌通过每个注意力头对 SAE 功能的贡献有多大。&lt;/p&gt;&lt;h2&gt;多层模型&lt;/h2&gt;&lt;h3&gt;计算路径&lt;/h3&gt;&lt;p&gt;在多层变压器中，事情变得更加复杂。这是因为从输入到 SAE 特征的可能计算路径集随着层数的增加（呈指数级）增加。两层模型中的不同路径可能包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;令牌嵌入 → MLP1（直接路径）&lt;/li&gt;&lt;li&gt;令牌嵌入 → MLP0 → 注意力 1 head 5 → MLP1&lt;/li&gt;&lt;li&gt;令牌嵌入 → 注意力 0 头 3 → MLP0 → MLP1&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;然而，总体原理是相同的：通过路径中的每个组件不断拉回特征向量。&lt;/p&gt;&lt;p&gt;请注意，某些计算路径可能涉及&lt;i&gt;多个非线性&lt;/i&gt;，例如两个不同的 MLP 子层。在这种情况下，我们分别对每个非线性进行线性化。计算路径中存在的非线性越多，我们期望的近似误差就越大，但这仍然可以产生有用的结果。另一种选择是查看计算路径，而不是一直返回到原始标记嵌入，而是仅返回到前一层的 MLP。现在，我们将了解这如何使我们能够解释先前 MLP 中各个 SAE 特征的路径。&lt;/p&gt;&lt;h3&gt; SAE 虚拟重量&lt;/h3&gt;&lt;p&gt;多层模型中可用的一种有用的基于权重的技术是&lt;i&gt;能够根据前一层 SAE 特征在给定层编写 SAE 特征&lt;/i&gt;。我们将此称为查看&lt;strong&gt;SAE 虚拟权重&lt;/strong&gt;。为此，需要获取后续 SAE 特征的残差流特征向量，并通过前一层 SAE 的解码器矩阵将其拉回。就像去嵌入一样​​，作为此过程的结果，您将获得一个向量，该向量告诉您前一层 SAE 特征与后一层 SAE 特征的对应程度。&lt;/p&gt;&lt;h2&gt;其他标准特征解释技术&lt;/h2&gt;&lt;p&gt;除了尝试对特征的计算方式进行逆向工程之外，我们还遵循 Anthropic 的方法通过研究最大/均匀激活示例以及研究每个特征对模型词汇表中每个标记的 logits 的影响来理解这些特征。&lt;/p&gt;&lt;h3&gt;最大/均匀激活示例&lt;/h3&gt;&lt;p&gt;获得 SAE 功能的初步解释的一种方法是查看数据集中的哪些示例最能激活该功能。然而，按照&lt;a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html#setup-interface"&gt;Anthropic 的方法&lt;/a&gt;，在整个特征激活分数范围内采样示例有时也是有用的，以便更广泛地了解特征所代表的含义。在这种情况下，我们找到特征分数均匀分布的样本（尽可能）。例如，如果某个特征在某个数据集上被激活在 0.0 到 10.0 之间，并且我们想要查看 10 个均匀间隔的示例，那么我们将尝试找到一个特征得分为 1.0 的示例，一个具有某个特征的示例分数为2.0等&lt;/p&gt;&lt;h3&gt;Logit 权重&lt;/h3&gt;&lt;p&gt;Anthropic 使用的另一种方法是检查 SAE 特征对模型词汇表中每个标记的 logits 的影响。直观上，这让我们了解模型期望哪些令牌遵循高度激活该功能的令牌。其原理类似于 Logit 透镜：通过获取 SAE 特征的解码器向量并将其乘以模型的非嵌入矩阵，然后查看模型词汇表中在结果向量中得分最高的标记来完成此操作。有时，这可以让我们对模型如何使用该特征有一个很好的初步了解，但情况并非总是如此；因此，将我们通过查看 logit 权重获得的理解与通过执行逆向工程获得的理解进行比较是有用的。&lt;/p&gt;&lt;h1&gt;实例探究&lt;/h1&gt;&lt;h2&gt;实验装置&lt;/h2&gt;&lt;p&gt;我们研究的两个模型来自 Neel Nanda 的 ToyLM 系列，特别是&lt;a href="https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=U-XWl8ddNkvId7o4ElrpehQ0"&gt;GELU-1L 和 GELU-2L 模型&lt;/a&gt;，（顾名思义）它们分别是 1 层和 2 层模型。前四个案例研究针对 GELU-1L，最后一个案例研究针对 GELU-2L。这些模型“在 22B 个数据标记上进行训练，其中 80% 来自 C4（网络文本），20% 来自 Python 代码”；他们的模型维度&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;m&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;o&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;e&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;l&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是 512，他们的 MLP 维度&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;m&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;l&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;p&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是 1,024，他们每个注意力子层有 8 个注意力头，他们的词汇表包含 48,262 个标记。&lt;/p&gt;&lt;p&gt;当我们使用数据集（例如查看最大激活示例）时，我们使用&lt;a href="https://NeelNanda/c4-code-20k"&gt;c4-code-20k&lt;/a&gt;中的 1,638,400 个标记，其中包含与训练模型的数据集相同的数据分布。该语料库分为每个提示 128 个标记。&lt;/p&gt;&lt;p&gt;我们针对 GELU-1L 调查的 SAE 可&lt;a href="https://huggingface.co/NeelNanda/sparse_autoencoder"&gt;通过此链接&lt;/a&gt;作为&lt;a href="https://huggingface.co/NeelNanda/sparse_autoencoder"&gt;SAE&lt;/a&gt; &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;#&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 25 获得，这是单个 SAE 训练运行的最终检查点，由 Neel Nanda 在 GELU-1L 激活上进行训练。我们针对 GELU-2L 调查的 SAE 可作为&lt;a href="https://huggingface.co/NeelNanda/sparse_autoencoder"&gt;前缀为“gelu-2l”的 SAE 从此链接中&lt;/a&gt;获取。所有 SAE 都有 16,384 个功能。 GELU-1L SAE 在模型的&lt;code&gt;mlp_post&lt;/code&gt;激活（维度 1,024）上进行训练，而 GELU-2L SAE 在模型的&lt;code&gt;mlp_output&lt;/code&gt;激活（维度 512）上进行训练。您可以&lt;a href="https://colab.research.google.com/drive/1u8larhpxy8w4mMsJiSBddNOzFGj7_RTn#scrollTo=riilpvs-CgoQ"&gt;在此处找到使用这些 SAE 的代码。&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;关于研究特征的选择&lt;/h2&gt;&lt;p&gt;案例研究所涉及的特征是以相对无原则的方式选择的，很大程度上是基于我们认为研究有趣的内容。指导我们选择的是特征审核，其目的是通过计算特征标记对的 F1 分数来确定所有特征表现出上下文依赖性的程度。选择每个功能的原因如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;选择&lt;code&gt;(&amp;#39;&lt;/code&gt;特征是因为它是最早的高频特征之一（按特征索引排序，没有内在含义）。&lt;/li&gt;&lt;li&gt;选择&lt;code&gt;it is&lt;/code&gt;功能是因为功能审核表明它主要在单个令牌上激活，并且仅在非常有限的上下文中激活，因此我们认为进一步研究这一点会很酷。&lt;/li&gt;&lt;li&gt;选择&lt;code&gt;&amp;#39;t&lt;/code&gt;功能是因为功能审核表明该功能在单个令牌上以及几乎所有出现此令牌的情况下都被高度激活。因此，我们想要研究这个看似与上下文无关的功能。&lt;/li&gt;&lt;li&gt; “神学/政治背景下的‘是’”特征很大程度上是随机选择的。&lt;/li&gt;&lt;li&gt;选择 GELU-2L 特征是因为它是最早的高频特征之一。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;请注意，一旦我们开始案例研究，我们就不会放弃它。因此，您看到的结果考虑了我们调查的所有功能。&lt;/p&gt;&lt;h2&gt; A &lt;code&gt;(&amp;#39;&lt;/code&gt; GELU-1L 中的功能&lt;/h2&gt;&lt;h3&gt;最大激活示例&lt;/h3&gt;&lt;p&gt;我们要研究的第一个功能是 GELU-1L SAE 中的功能 8。查看顶部激活示例可以立即解释此功能：主要在令牌&lt;code&gt;(&amp;#39;&lt;/code&gt; . &lt;/p&gt;&lt;figure class="image image_resized" style="width: 76.43%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/cg14g3ktiocvo6wibwrh" /&gt;&lt;figcaption&gt;相关 SAE 功能的热门激活示例。有趣的是，大多数这些顶级激活令牌似乎都后面跟着相同的“django”令牌，即使模型看不到下一个令牌。请注意，↩ 表示换行符，· 表示空格&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Logit 权重&lt;/h3&gt;&lt;p&gt;这个 SAE 功能最有力地提升了&lt;code&gt;django&lt;/code&gt;代币的 logits，这反映了我们在顶级激活示例中看到的情况。它还提高了其他与代码相关的标记的 logits，例如&lt;code&gt;&amp;lt;&lt;/code&gt;和&lt;code&gt;utf&lt;/code&gt; 。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 19.85%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/mjd51l7bp6g7xxexrpvw" /&gt;&lt;figcaption&gt;此功能具有最高 Logit 权重的令牌&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;直接路径和意外发现&lt;/h3&gt;&lt;p&gt;现在，我们执行“去嵌入”，以便了解哪些令牌通过直接路径对此功能贡献最大。具体来说：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们通过 MLP0 区分该 SAE 功能在特定高激活示例上的激活。这给了我们残差流&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;中&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;长度&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;为&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;model&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;特征向量&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。&lt;/li&gt;&lt;li&gt;我们将此特征向量乘以嵌入矩阵，以查看哪些标记可以通过直接路径激活它，即查看长度为&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;o&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;c&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的向量&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。自然地，我们预测&lt;code&gt;(&amp;#39;&lt;/code&gt;会得分很高。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;结果如下： &lt;/p&gt;&lt;figure class="image image_resized" style="width: 44.02%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/tjrongai1hr8kq5ix77s" /&gt;&lt;figcaption&gt;去嵌入标记分数以获得线性化 SAE 特征的直接路径&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;果然，顶部的标记是我们在顶部激活示例中看到的&lt;code&gt;(&amp;#39;&lt;/code&gt;标记。但是还有一些其他意想不到的标记，例如标记&lt;code&gt;ह&lt;/code&gt; 。这让我们感到惊讶；为了了解这是否是一个由于我们方法中的错误，我们在包含此标记的对抗性提示上运行模型，并记录每个标记的原始特征激活（不考虑 SAE 偏差或 ReLU）： &lt;/p&gt;&lt;figure class="image image_resized" style="width: 30.95%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/h1nqcwu5y2kc0jjpk38m" /&gt;&lt;figcaption&gt;对抗性提示的 SAE 原始特征评分&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;正如我们所看到的， &lt;i&gt;SAE 功能实际上确实在此令牌上激活&lt;/i&gt;，尽管其程度与在&lt;code&gt;(&amp;#39;&lt;/code&gt;令牌上激活的程度不同。这对我们来说是令人惊讶和兴奋的，因为这从标准方法中根本不明显查看顶级激活示例。我们认为这是我们方法的令人兴奋的概念证明，帮助我们构建 SAE 特征的对抗性示例！ &lt;span class="footnote-reference" id="fnref36xy0nowkoe"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn36xy0nowkoe"&gt;[3]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;注意力&lt;/h3&gt;&lt;p&gt;对注意力头进行直接评分归因似乎表明头 0 和 3 很重要。在下面的示例中，我们看到 head 0 通过&lt;code&gt;&amp;#39;:&lt;/code&gt;标记和&lt;code&gt;(&amp;#39;&lt;/code&gt;标记贡献了该功能。Head 3 通过右括号标记&lt;code&gt;&amp;quot;}),&lt;/code&gt;贡献了该功能。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 80.02%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/evdzdjejy64k8hvv3ho9" /&gt;&lt;figcaption&gt;注意力的直接评分归因&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;查看 head 0 &lt;span class="footnote-reference" id="fnref1tpfjhj7ezr"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn1tpfjhj7ezr"&gt;[4]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;的 OV 电路去嵌入表明，顶部标记往往包括各种开头字符串标记，例如&lt;code&gt;&amp;quot;&lt;/code&gt; 、 &lt;code&gt;([&amp;#39;&lt;/code&gt;和标记&lt;code&gt;(&amp;#39;&lt;/code&gt;本身，但也包括后跟空格的换行符的各种排列。有趣的是，尽管标记&lt;code&gt;&amp;#39;&lt;/code&gt;的去嵌入分数很高，但上面的直接分数归因示例表明该标记对特征激活贡献不大。这似乎是因为头 0 对该标记的关注程度不高。事实上，来自 token &lt;code&gt;(&amp;#39;&lt;/code&gt; to the token &lt;code&gt;&amp;#39;&lt;/code&gt;的 pre-softmax 注意力得分为 51.15，小于来自 token &lt;code&gt;(&amp;#39;&lt;/code&gt; to the token &lt;code&gt;&amp;#39;:&lt;/code&gt;的 softmax 之前的注意力得分 63.86)。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 36.41%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/ogt3x7bfvfln4mpnaxeg" /&gt;&lt;figcaption&gt;模型词汇表中头 0 的 OV 电路去嵌入得分最高的标记&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;头 3 的 OV 电路去嵌入中的顶部标记中有许多右大括号标记，例如&lt;code&gt;})&lt;/code&gt; 、 &lt;code&gt;)})&lt;/code&gt;和&lt;code&gt;&amp;#39;)&lt;/code&gt; 。这表明，除了初始空白标记（正如我们在直接得分归因结果中看到的那样）之外，头 3 还通过这些右大括号标记对 SAE 功能做出了贡献。然而，使这张图片稍微复杂化的是，去嵌入中的顶部标记是不相关的标记&lt;code&gt;Illustration&lt;/code&gt; ，在测试一些初始对抗性提示时，它似乎对特征分数没有影响。我们后来对线性化的探索表明，像这样的 token 的存在可能是线性逼近 MLP 的产物。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 28.23%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/tnya7vpo5ch3jynxwien" /&gt;&lt;figcaption&gt;头 3 的 OV 电路的最佳去嵌入结果。&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;概括&lt;/h3&gt;&lt;p&gt;我们的逆向工程和去嵌入，结合通过查看最大激活示例获得的证据，表明该功能具有以下解释：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;该功能主要在代码上下文中的标记&lt;code&gt;(&amp;#39;&lt;/code&gt;上触发，特别是在涉及包含字符串的列表或元组的上下文中。&lt;ul&gt;&lt;li&gt;该功能的直接路径强烈触发&lt;code&gt;(&amp;#39;&lt;/code&gt; .&lt;/li&gt;&lt;li&gt;头 0 和头 3 通过触发初始空白标记来建立代码上下文。&lt;/li&gt;&lt;li&gt; Head 0 通过触发表示此类列表和元组开头的标记（例如标记&lt;code&gt;[&amp;quot;&lt;/code&gt; ）来建立涉及包含字符串的列表和元组的上下文。Head 3 通过触发右大括号标记（例如&lt;code&gt;})&lt;/code&gt; , &lt;code&gt;)})&lt;/code&gt;来建立此上下文， 和&lt;code&gt;&amp;#39;)&lt;/code&gt; 。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;但该功能也会在代币&lt;code&gt;ह&lt;/code&gt;上触发，尽管没有那么强烈！&lt;ul&gt;&lt;li&gt;这是在查看此功能的直接路径去嵌入后得出的意外发现。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;仍然存在一些悬而未决的问题，以及一些难以解释的结果。尤其：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; Head 3 OV 去嵌入的最重要标记是&lt;code&gt;Illustration&lt;/code&gt; ，它似乎对对抗性提示中的 SAE 功能没有贡献。这是该方法的缺点，还是在某些上下文中该令牌确实对该功能有所贡献？&lt;/li&gt;&lt;li&gt;在本案例研究中，我们没有研究 QK 电路。这是否可以揭示更复杂的行为，或者可以解释&lt;code&gt;Illustration&lt;/code&gt;令牌发生了什么？&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt; GELU-1L 中“[标点符号] it is”的功能&lt;/h2&gt;&lt;p&gt;这是我们正在研究的 SAE 中的功能 4542。&lt;/p&gt;&lt;h3&gt;最大激活示例&lt;/h3&gt;&lt;p&gt;当标记&lt;code&gt;it&lt;/code&gt; （或其大写变体）前面有标记时，此功能&lt;code&gt;is&lt;/code&gt;会在标记上最大程度地激活，并且标记&lt;code&gt;it&lt;/code&gt;前面通常带有标点符号。&lt;/p&gt;&lt;h3&gt; Logit 权重&lt;/h3&gt;&lt;p&gt;查看 SAE 功能的 logit 权重，该功能最能提高标记&lt;code&gt;advis&lt;/code&gt; 、 &lt;code&gt;advised&lt;/code&gt; 、 &lt;code&gt;conceivable&lt;/code&gt; 、 &lt;code&gt;recommended&lt;/code&gt;和类似标记的 logit ——所有这些标记都倾向于用在“It is”之后的非人称结构中，例如作为“建议......” &lt;/p&gt;&lt;figure class="image image_resized" style="width: 26.98%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/o0mvbdliwhsfmr6fhvqj" /&gt;&lt;figcaption&gt;此功能具有最高 Logit 权重的令牌&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;直接路径&lt;/h3&gt;&lt;p&gt;在直接路径去嵌入中，当不考虑预MLP LayerNorm时，该特征的顶部标记是标记&lt;code&gt;is&lt;/code&gt; 。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 28.36%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/hb9vnjiftl3i7kyzyirj" /&gt;&lt;figcaption&gt;直接路径去嵌入中的顶级标记，不考虑 pre-MLP LayerNorm&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;请注意，具有第二高去嵌入分数的标记&lt;code&gt;are&lt;/code&gt; ，在对抗性提示中使用时会稍微激活该功能： 提示&lt;code&gt;. It are&lt;/code&gt;导致该功能以 0.151 分触发。&lt;/p&gt;&lt;p&gt;然而，当线性化 pre-MLP LayerNorm 时，此功能的顶部标记更加难以解释（尽管&lt;code&gt;Is&lt;/code&gt;是第二高激活标记）。关于线性化的部分给出了为什么线性化预 MLP LayerNorm 可能会导致这些更糟糕的结果的潜在理论基础。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 28.69%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/zgsqi973ntbldne2pyzj" /&gt;&lt;figcaption&gt;考虑预 MLP LayerNorm 时，直接路径去嵌入中的顶级标记&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;注意力&lt;/h3&gt;&lt;p&gt;对注意力进行直接评分归因表明，头 0 以及较小程度上的头 1 通过触发“it”等标记来对该特征做出贡献。我们还看到 head 1 在某种程度上对标点符号进行触发，尽管远低于最初的最大激活示例可能暗示的情况。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 81.7%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/jh67o1jlpwx3nwwj53pg" /&gt;&lt;figcaption&gt;注意力头/标记对的直接得分归因&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;对头 0 的 OV 电路执行去嵌入，毫无疑问，揭示了前三个标记是“it”的变体。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 29.01%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/uhmbhm7tiqz41onlexw5" /&gt;&lt;figcaption&gt;注意头 0 OV 电路去嵌入顶部令牌&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;然而，头 1 的去嵌入顶部标记更令人费解：所有前 20 个标记都很难解释，并且似乎与该特征无关，例如&lt;code&gt;stitial&lt;/code&gt; 、 &lt;code&gt;undes&lt;/code&gt;和&lt;code&gt;consc&lt;/code&gt; 。有趣的是，这些令牌似乎可以用于构建激活该功能的对抗提示。例如，提示“然后是”使该功能以1.390的分数触发，但是对抗性提示”是“ stitial”是“导致功能以分数为1.521发射，而对抗性提示则是“ undes”，它使功能是“使功能”使该功能降低。得分为1.626。 （请注意，提示“是”使该功能以1.733的分数触发，高于这些对抗性提示。）&lt;/p&gt;&lt;p&gt;同样令人惊讶的是，我们在令牌中没有看到任何标点令牌，因为头部1-令牌是最高的&lt;code&gt;.&lt;/code&gt;例如，仅是第9077位得分最高的令牌。尽管这个令牌提高了特征分数：提示&lt;code&gt;. It is&lt;/code&gt;由于该功能以分数1.903激活的功能，而提示&lt;code&gt;It is&lt;/code&gt;导致该功能以分数1.820激活。&lt;/p&gt;&lt;h3&gt;概括&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;该功能似乎在令牌上激活的&lt;code&gt;is&lt;/code&gt;在像&lt;code&gt;It&lt;/code&gt;和&lt;code&gt;it&lt;/code&gt; &lt;code&gt;it&lt;/code&gt;的代币之前。&lt;ul&gt;&lt;li&gt;在没有线性化前MLP分层的情况下获得的直接路径去除膜显示出很高的&lt;code&gt;is&lt;/code&gt;分数。但是，当我们将前MLP分层线性化时，这会产生更多无法解释的令牌。这反映了我们稍后讨论的与线性分层相关的某些行为。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt; Head 0通过像&lt;code&gt;it&lt;/code&gt; &lt;code&gt;It&lt;/code&gt;向代币射击来为功能做出贡献。肯定的， &lt;code&gt;It&lt;/code&gt; ， &lt;code&gt;it&lt;/code&gt;和&lt;code&gt;It&lt;/code&gt;是拆卸中的顶级令牌。&lt;/li&gt;&lt;li&gt;直接分数归因表明，Head 1通过在标点令牌上稍微触发来促进该功能。但是，这并不反映在头1的拆卸中，这是完全无法解释的。更深入的调查可能会阐明标点符号正在发生的事情。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt; gelu-1l中的&lt;code&gt;&amp;#39;t&lt;/code&gt;功能&lt;/h2&gt;&lt;p&gt;这是我们正在研究的S​​AE中的功能编号10996。&lt;/p&gt;&lt;h3&gt;统一的激活示例&lt;/h3&gt;&lt;p&gt;查看此功能激活的示例，似乎此功能主要在诸如“ not”，“ not”，“ not”之类的单词的末尾激活在&lt;code&gt;&amp;#39;t&lt;/code&gt;上，并且类似&lt;span class="footnote-reference" id="fnref2belxv37guh"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn2belxv37guh"&gt;[5 ]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。在较低的激活水平下，此功能还会在诸如“ dont”和“ dot”之类的拼写错误上发射。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 77.92%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/umgpxcigopmzht3jpco9" /&gt;&lt;figcaption&gt;统一激活的例子&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;logit重量&lt;/h3&gt;&lt;p&gt;此功能最强烈地增强了由标点符号组成的&lt;code&gt;s&lt;/code&gt;和令牌的逻辑，然后是引号。这并没有反映在统一的激活示例中，这表明观察该功能的计算方式（例如，通过拆卸等方法）可能比一旦计算出该功能的下游效应，可能会带来更多的果实。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 19.82%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/uzydvausyd0bz9jhc9o1" /&gt;&lt;figcaption&gt;该功能的logit权重最高的令牌&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;直接路径&lt;/h3&gt;&lt;p&gt;直接路径中得分最高的令牌为&lt;code&gt;&amp;#39;t&lt;/code&gt; 。得分很高的其他代币是上述宫缩的拼写错误，例如&lt;code&gt;wont&lt;/code&gt;和&lt;code&gt;didnt&lt;/code&gt; ，以及像&lt;code&gt;not&lt;/code&gt;和&lt;code&gt;Not&lt;/code&gt;负面因素。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 29.45%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/ubomlalnhgnqrtlb8xx9" /&gt;&lt;figcaption&gt;直接路径在模型的词汇量中删除顶级令牌&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;注意力&lt;/h3&gt;&lt;p&gt;执行直接分数归因似乎表明注意力并没有发挥太大作用。在一个例子上，除&lt;code&gt;&amp;lt;|BOS|&amp;gt;&lt;/code&gt;令牌以外的其他代币的总贡献（忽略注意力偏见）仅为0.34。 Head 1似乎在&lt;code&gt;&amp;#39;t&lt;/code&gt;代币上略有激活，看着这个头部的OV去除确实表明，在48k代币词汇中， &lt;code&gt;&amp;#39;t&lt;/code&gt;令牌”的消除得分是第35位。&lt;/p&gt;&lt;p&gt;但是，重新样本消融注意力头的输出（一种因果干预）讲述了另一个故事。在更换注意力输出的提示/令牌时，该功能通过其注意力输出发射的提示/令牌，该功能未发射该功能，并比较清洁和损坏的运行之间的SAE功能激活，激活的差异是1.1226。这表明注意力在这里做一些有用的事情，尽管我们说什么还为时过早。请注意，重塑消融结果与直接分数归因结果之间差异的一种可能性是，作为因果干预，重新样品消融融合了从MLP中忽略的非线性效应，这些效应在直接分数归因中被忽略。&lt;/p&gt;&lt;h3&gt;概括&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;该功能似乎主要在&lt;code&gt;&amp;#39;t&lt;/code&gt;代币上激活，例如“不”。直接路径隔离反映了这一点， &lt;code&gt;&amp;#39;t&lt;/code&gt;得分最高 - 尽管拼写错误的单词也&lt;code&gt;didnt&lt;/code&gt;得分很高。&lt;/li&gt;&lt;li&gt;直接得分归因表明，尽管Head 1似乎通过激活&lt;code&gt;&amp;#39;t&lt;/code&gt;令牌”而做出了一些贡献，但对此功能并不重要。但是重新样本消融以引起注意，这表明注意力确实有效。这表明线性化在这里具有误导性。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt; GELU-1L中的上下文依赖性“ IS”功能&lt;/h2&gt;&lt;p&gt;此功能是我们正在研究的S​​AE中的功能编号4958。&lt;/p&gt;&lt;h3&gt;最大激活示例&lt;/h3&gt;&lt;figure class="image image_resized" style="width: 73.2%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/od0nhmfvsdlshzec13e1" /&gt;&lt;figcaption&gt;该功能的最大激活示例&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;查看最大激活示例，该功能主要在令牌上&lt;code&gt;is&lt;/code&gt; （并且偶尔在动词“要”的其他形式上）。但是这个功能似乎更多：它似乎在涉及神学和政治的上下文中激活。因此，此功能让人联想到拟人化的SAE纸中讨论的特征，例如“在抽象代数的背景下的令牌&lt;code&gt;a&lt;/code&gt; ”。&lt;/p&gt;&lt;h3&gt; logit重量&lt;/h3&gt;&lt;p&gt;该功能最大程度地提高逻辑的令牌没有立即解释。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 24.3%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/qks7eoejz2ymyuqvvhat" /&gt;&lt;figcaption&gt;该功能的logit权重最高的令牌&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最高的代币&lt;code&gt;rael&lt;/code&gt;可能与代币结合在一起&lt;code&gt;is&lt;/code&gt;形成“以色列”，这与一些最大的激活例子中的宗教主题保持一致。 &lt;code&gt;manifested&lt;/code&gt;和&lt;code&gt;violated&lt;/code&gt;代币也暗示了圣经的含义。但是，很难看到&lt;code&gt;aroused&lt;/code&gt;和&lt;code&gt;assertEquals&lt;/code&gt;地方发挥作用。&lt;/p&gt;&lt;h3&gt;直接路径&lt;/h3&gt;&lt;figure class="image image_resized" style="width: 30.75%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/jpccjcqsatmoomvnutcy" /&gt;&lt;figcaption&gt;直接路径在模型的词汇量中删除顶级令牌&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;直接路径去除得分证实了最大激活示例：得分最高的令牌&lt;code&gt;is&lt;/code&gt; ，随后是动词的其他形式的“要”。&lt;/p&gt;&lt;h3&gt;注意力&lt;/h3&gt;&lt;p&gt;由于最大激活的示例表明此功能与上下文有关，因此我们希望注意力将发挥相当重要的作用。执行直接分数归因表明两个重要的注意力头：头0和头4。特别是，我们发现头部0倾向于自我介绍为&lt;code&gt;is&lt;/code&gt;代币，并在该令牌上发射，而诸如ISM等令牌上有4个Head 4点火（如&lt;code&gt;ism&lt;/code&gt; （例如用“原教旨主义”， &lt;code&gt;spirit&lt;/code&gt;甚至&lt;code&gt;Plato&lt;/code&gt;之类的词。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/a9wkhhycups1mqdnktpf" /&gt;&lt;figcaption&gt;在与柏拉图有关的示例中关注的直接分数归因&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/rcm85t951nlfytyvxvss" /&gt;&lt;figcaption&gt;在包含令牌&lt;code&gt;ism&lt;/code&gt;的示例上关注的直接分数归因&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure class="image image_resized" style="width: 89.35%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/bwyo50tif8ywl037umof" /&gt;&lt;figcaption&gt;直接分数归因于包含令牌&lt;code&gt;spirit&lt;/code&gt;的示例的关注&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;查看头部0的ov de缩放得分，顶部令牌是动词的各种形式的“要”（ &lt;code&gt;be&lt;/code&gt; ， &lt;code&gt;was&lt;/code&gt; ，， &lt;code&gt;is&lt;/code&gt; &lt;code&gt;s&lt;/code&gt;可能是clitic &lt;code&gt;&amp;#39;s&lt;/code&gt; ），又&lt;code&gt;been&lt;/code&gt; &lt;code&gt;&amp;#39;s&lt;/code&gt; 。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 29.97%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/yiwqopwdtlub3rabgvzj" /&gt;&lt;figcaption&gt;拆卸头0 OV电路&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Head 4的OV De-ebedding分数非常有启发性：顶级令牌都是&lt;code&gt;mythology&lt;/code&gt; ， &lt;code&gt;soul&lt;/code&gt; ， &lt;code&gt;urrection&lt;/code&gt; ， &lt;code&gt;existential&lt;/code&gt; ，死亡， &lt;code&gt;Divine&lt;/code&gt; ， &lt;code&gt;psy&lt;/code&gt; ，以及类似的标记等神话，灵魂，尿道， &lt;code&gt;Death&lt;/code&gt; ，死亡，神灵。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 30.85%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/mtvh431o6bhi2nvoms8m" /&gt;&lt;figcaption&gt;拆卸4 OV电路的头部&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;概括&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;该功能似乎主要是在代币上发射的&lt;code&gt;is&lt;/code&gt;在神学和政治的背景下。&lt;/li&gt;&lt;li&gt;直接路径的动词形式为“ be”。&lt;/li&gt;&lt;li&gt;注意力0似乎在令牌&lt;code&gt;is&lt;/code&gt;强烈发射，而Head 4似乎负责合并环境。 OV De-Abedding得分进一步支持了这一点。&lt;/li&gt;&lt;li&gt;此功能运行的机制暗示了一种计算这些“在某个上下文中的令牌”特征的一般机制：主令牌上的直接路径触发，而稀疏的注意力头则负责从一个从一个令牌上触发的令牌。共享语义字段。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt; Python词典的“值”字符串中的开口撇号的Gelu-2l中的一个功能&lt;/h2&gt;&lt;p&gt;此功能 -  MLP1 SAE的功能8是我们将在GELU-2L中进行调查的第一个功能。随着更多的层的复杂性，此案例研究是对这种特征反向工程是否可以扩展到多层模型的测试。&lt;/p&gt;&lt;p&gt;特别是，由于此功能是MLP1的功能，即变压器第二层中的MLP，因此有更多有助于特征激活的计算路径。在此案例研究中，我们将研究这些计算路径。&lt;/p&gt;&lt;h3&gt;统一的激活示例&lt;/h3&gt;&lt;p&gt;查看此功能的均匀激活示例，我们看到它往往会激活（尤其是在更高的激活时）在令牌上&lt;code&gt;&amp;#39;&lt;/code&gt;在代币之前&lt;code&gt;&amp;#39;:&lt;/code&gt; 。这可以识别为撇号启动键值字典中的“值”字符串。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 70.45%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/xcuhmxq8iecp5m8doikj" /&gt;&lt;figcaption&gt;我们正在研究的MLP1 SAE功能的均匀激活示例&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;logit重量&lt;/h3&gt;&lt;p&gt;该特征最大程度地提高逻辑的令牌是&lt;code&gt;Male&lt;/code&gt;和&lt;code&gt;Female&lt;/code&gt; ，这可能是&lt;code&gt;{&amp;#39;gender: &amp;#39;Male&amp;#39;}&lt;/code&gt;字典中的值。同样，大多数顶级令牌始于大写字母。虽然有趣，但这并不能告诉我们我们正在寻找的信息。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 23.26%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/f7d9edi8dpollkmud8zf" /&gt;&lt;figcaption&gt;该功能的logit权重最高的令牌&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;直接通往MLP1的路径&lt;/h3&gt;&lt;p&gt;首先，让我们研究从输入到MLP1的直接路径。有理由期望这种直接路径可能不像输入到MLP0的路径那样解释，因为MLP1可能正在处理更高级别的抽象。 &lt;span class="footnote-reference" id="fnref0hyqmgltk21m"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn0hyqmgltk21m"&gt;[6]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;然而，值得一看的是这一直接路径是值得的，因为我们不能&lt;i&gt;确定&lt;/i&gt;这一直接路径对特征激活不负责。&lt;/p&gt;&lt;p&gt;查看具有最高拆卸得分的令牌，前十个令牌都是无法解释的令牌，例如&lt;code&gt;inex&lt;/code&gt; ， &lt;code&gt;έ&lt;/code&gt;和&lt;code&gt;immer&lt;/code&gt; 。也就是说，值得注意的是，“预期”代币&lt;code&gt;&amp;#39;&lt;/code&gt;是得分最高的标记，是超过48k代币的词汇。&lt;/p&gt;&lt;p&gt;回想一下，为了获得残留流特征向量，我们在一个特定示例上对MLP sublayer进行线性化，这意味着每个示例都会产生不同的特征向量。因为我们发现的不可解释的代币数量令我们令人惊讶，所以我们想探索这种不可解释的令牌现象的程度是我们在该特定示例中线性化MLP的特定示例的伪像。因此，我们在100个顶部激活的示例中采用了MLP1梯度的平均值，并研究了该平均特征向量。再一次，顶级令牌是无法解释的，例如&lt;code&gt;corro&lt;/code&gt; ， &lt;code&gt;deton&lt;/code&gt; &lt;code&gt;VERY&lt;/code&gt; &lt;code&gt;έ&lt;/code&gt; ，尽管现在，预期的令牌&lt;code&gt;&amp;#39;&lt;/code&gt;是分数最高的标记。&lt;/p&gt;&lt;p&gt;为了进一步衡量这些线性化特征向量的解放结果的依赖性依赖性的程度，我们查看了平均特征矢量和单个示例特征向量的最高&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;最高解放得分的令牌；然后，我们改变了&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;K&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，并查看了这些得分最高令牌的交点中令牌的比例。当&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;k&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;200&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;时，有119个令牌（即59.5％的令牌。这似乎表明了中等程度的示例依赖性。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 74.56%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/lsieldpkxyq1pd2nhq5t" /&gt;&lt;figcaption&gt;关于用单个示例获得的特征矢量与特征向量与通过在100个示例上取出平均特征向量获得的特征向量获得的特征矢量相似性的结果。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;这些结果在多大程度上准确地反映了模型的行为？&lt;/strong&gt;我们在该直接路径上进行了路径修补，从令牌&lt;code&gt;&amp;#39;&lt;/code&gt;到令牌&lt;code&gt;corro&lt;/code&gt; （即MLP1将其输入视为令牌&lt;code&gt;corro&lt;/code&gt; ，而所有其他模型组件仍然将输入令牌视为&lt;code&gt;&amp;#39;&lt;/code&gt; ）。我们发现这样做&lt;i&gt;实际上将特征激活略微增加了&lt;/i&gt;+0.1079。在这种情况下，意外结果实际上确实反映了模型的行为。但这不是其他令牌。在这些情况下，似乎线性近似过程中的错误是罪魁祸首。例如，当&lt;code&gt;VERY&lt;/code&gt;向量很小时，从&lt;code&gt;&amp;#39;&lt;/code&gt;方向上的路径弥补。但是，随着修补的激活越来越近&lt;code&gt;&amp;#39;&lt;/code&gt;并且距离越来越&lt;code&gt;VERY&lt;/code&gt; ，功能激活停止增加，然后开始减少。我们的直觉是，令牌嵌入的空间是一个离散的空间，而不是连续的空间。由于该模型永远不会在&lt;code&gt;VERY&lt;/code&gt;和&lt;code&gt;&amp;#39;&lt;/code&gt;之间的一半之间看到嵌入，因此在它们之间线性插值可能没有太多含义。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 71.55%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/fu0bit1gzzlagtwtg3h2" /&gt;&lt;figcaption&gt;路径修补结果， &lt;code&gt;VERY&lt;/code&gt;在干净的&lt;code&gt;&amp;#39;&lt;/code&gt;和肮脏的令牌之间插值。&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;从MLP0到MLP1的路径&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;MLP0 SAE功能与MLP1 SAE功能之间的连接&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;因为我们正在处理多层变压器，所以我们现在可以查看从MLP0到MLP1的路径。结果之一是，使用与拆卸相同的原理，我们可以&lt;i&gt;根据MLP0 SAE功能直接表达我们的MLP1功能&lt;/i&gt;。为此，将MLP1特征乘以MLP0 SAE解码器矩阵的转置。重要的是，这是一个纯粹基于权重的操作，没有参考我们的特定示例上的内部模型激活（除了区分MLP1以获取初始特征向量）。这使我们可以看到哪些MLP0 SAE功能对MLP1功能贡献最大。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 39.39%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/ati0xyol2s8qadnpak2y" /&gt;&lt;figcaption&gt;根据其标准化分数&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在进行此实验之前，我们希望最佳功能会&lt;i&gt;很少&lt;/i&gt;-  MLP1功能可以用很少的MLP0功能表示。不幸的是，情况并非如此：有512 MLP0功能具有MLP1特征得分大于平均值的两个标准偏差。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 77.24%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/akmpx0yzwxhsvaxn8wji" /&gt;&lt;figcaption&gt;线性化MLP1特征的MLP0归一化特征得分的直方图。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;但是，从这个过程中可以获得有趣的见解。例如，如果我们查看最佳功能的统一激活示例，功能81，我们发现此功能似乎在非常相似的示例上与原始的MLP1 SAE功能一起激活，该功能由令牌&lt;code&gt;&amp;#39;&lt;/code&gt;由标记之前&lt;code&gt;&amp;#39;:&lt;/code&gt;组成。 : &lt;code&gt;&amp;#39;:&lt;/code&gt;但是，在MLP1功能和MLP0功能之间，这些示例的功能得分通常在功能分数上差异。换句话说，尽管这些功能似乎在类似类型的输入上激活，但MLP1功能通常会激活高度，以使MLP0功能在该输入中激活低，反之亦然。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 84.57%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/owcrrfmj6ult1mu81djs" /&gt;&lt;figcaption&gt; MLP0特征81的均匀激活示例&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;其他最高得分的功能更难解释。一方面，特征11265在令牌&lt;code&gt;=&amp;quot;&lt;/code&gt;中触发，这是在我们之前讨论过的MLP1功能的均匀激活示例之一中发现的。激活在我们的代码中呈现为Gibberish的令牌。&lt;/p&gt;&lt;p&gt;这里的要点是，尽管从MLP0 SAE功能方面可以从查看MLP1 SAE功能中获得一些见解，但仍有许多密集的计算可能会阻止一种幼稚的解释。一个有趣的未来研究领域是研究是否可以同时在不同层进行训练，以鼓励其特征之间的稀疏连接。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从MLP0到MLP1的路径的特征解释&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;现在，让我们看一下从令牌嵌入的计算路径如何通过MLP0，然后通过MLP1启用SAE功能。重要的是，由于该计算路径涉及两个连续的MLP，&lt;i&gt;因此我们采用MLP0和MLP1的线性近似&lt;/i&gt;。 （特别是，一旦我们拥有MLP1的线性化特征向量向量，然后我们就MLP0的此特征向量进行线性性化。）我们期望随着我们近似更多的非线性，线性化的错误会变得复合，但是尽管如此，我们认为我们可能会认为我们可以能够在这里获得有趣的结果。&lt;/p&gt;&lt;p&gt;在执行了这种双线性化后，当查看此计算路径的功能的解释时，顶部令牌包括&lt;code&gt;=”&lt;/code&gt; &lt;code&gt;&amp;#39;:&amp;#39;&lt;/code&gt; and&amp;#39;and &lt;code&gt;=&amp;quot;&lt;/code&gt; 。有趣的是，这些令牌具有与我们期望的&lt;code&gt;&amp;#39;&lt;/code&gt;代币”相似的语义要找到：所有这些顶级令牌都介绍了“键值”构造的“值”部分，例如&lt;code&gt;&amp;#39;name&amp;#39;:&amp;#39;John&amp;#39;&lt;/code&gt;或&lt;code&gt;&amp;quot;address&amp;quot;=&amp;quot;123 Greenfield Lane&amp;quot;&lt;/code&gt; 。&lt;/p&gt;&lt;p&gt;请注意，“预期”令牌&lt;code&gt;&amp;#39;&lt;/code&gt;的脱水得分为第102高。总体而言，这些结果与我们的期望更一致，而不是对MLP1的直接途径的拆卸结果，尽管令牌&lt;code&gt;&amp;#39;&lt;/code&gt;位置仍然比我们预期的要低。&lt;/p&gt;&lt;h3&gt;从ATTN0到MLP1的路径&lt;/h3&gt;&lt;p&gt;给定一个高度激活的示例，在MLP1功能上执行ATTN0上的直接分数归因表明，对该功能的主要贡献来自Head 2，该功能在&amp;#39;：&amp;#39;：在&lt;code&gt;&amp;#39;:&lt;/code&gt;在&amp;#39;：在&amp;#39;&amp;#39;&amp;#39;&amp;#39; &lt;code&gt;&amp;#39;&lt;/code&gt;上之前的doken上强烈启动，例如&lt;code&gt;{&amp;#39;name&amp;#39;: &amp;#39;John&amp;#39;}&lt;/code&gt; 。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/hqhusm3quxpld1gd6lox" /&gt;&lt;figcaption&gt;第0层的MLP1功能的直接分数归因&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;此外，在目的地令牌时，查看&lt;code&gt;&amp;#39;&lt;/code&gt; &lt;code&gt;&amp;#39;:&lt;/code&gt;令牌”的QK分数表明，当源代币远离目的地时，注意力评分非常急剧下降。&lt;/p&gt;&lt;p&gt;将HEAD 2的OV功能解释为&lt;code&gt;:&amp;quot;&lt;/code&gt;和&lt;code&gt;:&amp;#39;&lt;/code&gt;是第四和第5个得分最高的令牌，这符合我们对头部功能的直觉。但是，排名最高的最高得分标记是出乎意料的：出乎意料的是： &lt;code&gt;Î&lt;/code&gt; ， &lt;code&gt;)=\&lt;/code&gt; ，和&lt;code&gt;))**(&lt;/code&gt;分别。我们在提示中使用了这些令牌，以查看它们是否激活了该特征；对于参考，提示&lt;code&gt;&amp;#39;: &amp;#39;&lt;/code&gt;产生了4.535的特征激活。我们发现提示&lt;code&gt;Î &amp;#39;&lt;/code&gt;时， &lt;code&gt;Î &amp;#39;&lt;/code&gt;根本没有激活该功能，提示&lt;code&gt;))**( &amp;#39;&lt;/code&gt;弱激活该功能，得分为1.038。&lt;/p&gt;&lt;h3&gt;从ATTN0到MLP0再到MLP1的路径&lt;/h3&gt;&lt;p&gt;在一个高度激活的示例上的直接分数归因表明，大多数贡献再次来自&lt;code&gt;&amp;#39;:&lt;/code&gt; ”令牌之前的“ &lt;code&gt;&amp;#39;&lt;/code&gt;令牌”。此路径的Head 2的OV De插度得分最高的令牌为&lt;code&gt;&amp;#39;:&lt;/code&gt; ，”，例如&lt;code&gt;&amp;quot;:&lt;/code&gt; and &lt;code&gt;&amp;#39;):&lt;/code&gt;也存在于前十个令牌中。&lt;/p&gt;&lt;p&gt;有趣的是，令牌&lt;code&gt;perhaps&lt;/code&gt;是第四高的分数，并在提示中使用它的&lt;code&gt;&amp;#39;&lt;/code&gt;令牌”弱激活了原始的MLP1 SAE功能（激活为0.787）。&lt;/p&gt;&lt;h3&gt;涉及ATTN1的路径&lt;/h3&gt;&lt;p&gt;在模型的所有子层上执行直接得分归因，表明ATTN1对特征分数有负贡献，这在很大程度上是由于注意力输出偏置向量。因此，我们没有对涉及ATTN1的路径进行非常彻底的研究。对其头的OV脱落得分的初步研究是无法解释的。也就是说，对此SAE功能的全面调查将花费更多时间查看ATTN1。&lt;/p&gt;&lt;h3&gt;概括&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;均匀的激活示例表明，MLP1特征似乎在Bigram &lt;code&gt;&amp;#39;: &amp;#39;&lt;/code&gt;上激活。&lt;/li&gt;&lt;li&gt;在MLP1的直接路径上执行去除力会产生大量难以理解的令牌，作为得分最高的令牌。也就是说，预期的令牌&lt;code&gt;&amp;#39;&lt;/code&gt;得分排名第159。使用一些难以理解的令牌进行路径修补实际上确实增加了特征激活，但是其他难以理解的令牌的存在似乎是线性化过程的伪像。&lt;/li&gt;&lt;li&gt;用MLP0 SAE功能表达MLP1 SAE功能表明，大量MLP0功能有助于MLP1功能。最重要的MLP0功能具有顶部激活示例，看起来与MLP1功能的顶级激活示例非常相似，但是这些功能分数之间通常存在差异。&lt;/li&gt;&lt;li&gt;查看从MLP0到MLP1的路径的解释，顶部令牌包括&lt;code&gt;=”&lt;/code&gt; and &lt;code&gt;&amp;#39;:&amp;#39;&lt;/code&gt; and &lt;code&gt;=&amp;quot;&lt;/code&gt; ;“预期”令牌&lt;code&gt;&amp;#39;&lt;/code&gt;分数为102级最高分数。&lt;/li&gt;&lt;li&gt;查看从ATTN0到MLP1的路径以及从MLP0到MLP0再到MLP1的路径表明，注意力头2似乎通过&lt;code&gt;&amp;#39;:&lt;/code&gt; &lt;code&gt;&amp;#39;&lt;/code&gt; De-bedding支持了这一点，但也揭示了一些意外的令牌，当在提示中使用时，它们会弱激活原始的SAE功能。&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;线性化实验&lt;/h1&gt;&lt;p&gt;由于反向工程过程通过采用梯度线性近似MLP，而MLP是高度非线性的，因此这提出了该方法的准确性。为了获得一些初始直觉，我们进行了一些实验测试这种线性化方法。我们的初步发现是，线性化倾向于为激活SAE特征的输入提供良好的近似值，但其准确性在非激活输入方面却少得多。&lt;/p&gt;&lt;h2&gt; gelu-1L中的&lt;code&gt;&amp;#39;t&lt;/code&gt;功能”的激活转向&lt;/h2&gt;&lt;p&gt;回想我们先前研究的GELU-1L中的&lt;code&gt;&amp;#39;t&lt;/code&gt;功能”。为了了解通过线性化MLP获得的特征向量是否有用，我们执行了激活转向实验，在该实验中，我们将线性化的特征向量添加到模型的MLP激活中，并查看SAE特征得分的变化程度。&lt;/p&gt;&lt;p&gt;特别是，我们查看了“快速棕狐&lt;code&gt;[TOKEN]&lt;/code&gt;狐”）的提示，在那里&lt;code&gt;[TOKEN]&lt;/code&gt;被“测试”，“测试”，“饮食”，“ will”和“ not”代替。 SAE RAW功能分数（没有Relu或偏见；这使我们可以在每个提示中记录最终令牌的SAE功能的部分激活；然后，当在每个提示中添加了线性化的特征向量（带系数1）时，将SAE RAW特征分数记录在MLP激活中时。&lt;/p&gt;&lt;figure class="table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;代币&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;干净分数&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;肮脏的分数&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;“测试”&lt;/td&gt;&lt;td&gt; -1.4542&lt;/td&gt;&lt;td&gt; 1.4392&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; “测试”&lt;/td&gt;&lt;td&gt; -0.9500&lt;/td&gt;&lt;td&gt; 2.4638&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; “吃”&lt;/td&gt;&lt;td&gt; -0.6423&lt;/td&gt;&lt;td&gt; 3.7210&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; “将要”&lt;/td&gt;&lt;td&gt; 1.1101&lt;/td&gt;&lt;td&gt; 6.1618&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; “不”&lt;/td&gt;&lt;td&gt; 2.5207&lt;/td&gt;&lt;td&gt; 8.6271&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;结果可以在上表中找到。我们看到，在所有情况下，用线性化特征向量的激活转向确实会提高原始特征得分。但特别是，随着原始令牌会激活SAE功能，激活转向变得更加有效。现在，我们通过在一个高激活的示例上区分了功能向量，并且直观地，示例与示例相比，该功能火灾更相似，因此，该功能矢量却不奇怪，因此此功能向量的工作原理越多，越多，越好原始令牌激活该功能。&lt;/p&gt;&lt;h2&gt; Gelu-1L中的&lt;code&gt;&amp;#39;t&lt;/code&gt;特征”的线性化余弦相似性&lt;/h2&gt;&lt;p&gt;再次，我们查看了Gelu-1L中的&lt;code&gt;&amp;#39;t&lt;/code&gt;功能”，以及“快速棕狐&lt;code&gt;[TOKEN]&lt;/code&gt; ”形式的提示，在该形式中， &lt;code&gt;[TOKEN]&lt;/code&gt;被“测试”，“测试”，“ EAT”，“ WILL WILL”代替。 ”和“不”。我们计算了这些提示中每个提示的最后一个令牌计算的线性化特征与在最后一个令牌上计算的线性化功能之间的余弦相似性，以提示“快速棕色狐狸没有”。我们通过冻结分层和通过分层区分来做到这一点。结果在下表中提供。&lt;/p&gt;&lt;figure class="table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;代币&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;冷冻分层&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;分化的分层&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;“测试”&lt;/td&gt;&lt;td&gt; 0.7745&lt;/td&gt;&lt;td&gt; 0.3155&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; “测试”&lt;/td&gt;&lt;td&gt; 0.7897&lt;/td&gt;&lt;td&gt; 0.3500&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; “吃”&lt;/td&gt;&lt;td&gt; 0.8373&lt;/td&gt;&lt;td&gt; 0.4508&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; “将要”&lt;/td&gt;&lt;td&gt; 0.9095&lt;/td&gt;&lt;td&gt; 0.6253&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt; “不”&lt;/td&gt;&lt;td&gt; 0.9570&lt;/td&gt;&lt;td&gt; 0.8189&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;有两个含义跳出来。首先，当我们将MLP线性化的令牌激活SAE功能时，余弦相似性变得更高。我们假设这是因为激活SAE特征的示例往往位于MLP具有相似行为的激活空间的相似区域。&lt;/p&gt;&lt;p&gt;其次，当余弦相似性与分层线性化时，余弦相似性之间存在鲜明的对比，尤其是对于激活SAE的代币而言，它的特征最少。这违背了最初的直觉，即分层不会极大地影响特征向量方向。&lt;/p&gt;&lt;p&gt; Neel建议这可能是因为在数学上，地图&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mfrac MJXc-space3"&gt;&lt;span class="mjx-box MJXc-stacked" style="width: 0.878em; padding: 0px 0.12em;"&gt;&lt;span class="mjx-numerator"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-denominator"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-vsize"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。通过此区分将平行于&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;方向设置为零，并且所有其他方向不变，因此在这里，它将特征向量的组件平行于与残留流相平行。如果“ true”特征向量是残差流的重要组成部分，则将删除特征向量的大部分，从而产生错误。参见&lt;a href="https://www.neelnanda.io/mechanistic-interpretability/attribution-patching#layernorm"&gt;&lt;u&gt;Nanda等。&lt;/u&gt;&lt;/a&gt;有关在归因修补程序中有关此效果的更多讨论。鉴于这些结果，我们建议在可能的情况下冻结分层，而不是通过它区分。&lt;/p&gt;&lt;h2&gt; GELU-2L MLP1特征的线性化余弦相似性&lt;/h2&gt;&lt;p&gt;在此实验中，我们研究了前面讨论的GELU-2L MLP1功能。我们采用了48个示例，该示例大约在MLP1 SAE特征原始得分范围内分布（即不考虑偏见和relu）。然后，我们采用了通过在每个示例中取梯度来获得的线性化MLP1特征的成对余弦相似性。结果可以在以下图中找到。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 58.95%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/hper8jjqxbu9ziniwbih" /&gt;&lt;figcaption&gt; MLP1梯度之间的成对余弦相似性&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;此外，我们有以下结果：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;最低激活的24个示例和自身之间的平均成对余弦相似性： &lt;strong&gt;0.3089&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;最低激活的24个示例与最高激活的24个示例之间的平均成对余弦相似性： &lt;strong&gt;0.1097&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;最高激活的24个示例与自身之间的平均成对余弦相似性： &lt;strong&gt;0.7037&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该实验中的一些有趣的收获：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们看到，较高激活的例子彼此具有较高的成对余弦相似性。这令人兴奋，因为这表明我们不需要每个示例获得单独的功能向量，我们可以在许多高激活示例中平均每个功能获得一个一致的矢量，这似乎更强大和可靠！&lt;/li&gt;&lt;li&gt;我们似乎观察到不连续的行为：SAE功能开始发射（绘图中途），所有成对余弦的相似性都会更高。请注意，我们在区分时会忽略SAE的依赖，因此它不能成为这种不连续性的来源。&lt;/li&gt;&lt;li&gt;激活最低的示例的梯度都比彼此更相似，而不是吸引最大的示例梯度。&lt;ul&gt;&lt;li&gt;令人惊讶的是，这似乎很弱暗示了最低激活的例子中的某种聚类行为，而不仅仅是激活的例子。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt; GELU-2L的线性化特征系数与注射结果&lt;/h2&gt;&lt;p&gt;再次，我们正在考虑GELU-2L案例研究。回想一下，我们以MLP0 SAE功能来表达线性化的MLP1特征向量。这提供了系数的向量，该矢量表示每个MLP0 SAE特征在多大程度上有助于线性化的MLP1特征。让我们称此矢量&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ；让MLP0功能的&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;系数&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;表示&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;为&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;现在，考虑一下如果我们一次将每个MLP0 SAE功能注入每个MLP0 SAE功能，也就是说，我们将MLP0 SAE功能&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;I I&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;添加到模型的Pre-MLP1残差流中，并查看这如何影响这MLP1 SAE原始功能分数（即忽略偏差术语和relu）。如果MLP1是线性的，那么SAE原始特征分数的变化将完全等于&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。因此，测量MLP1线性近似的准确性的一种方法是查看&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;与每个MLP0特征的注入，C与SAE原始特征分数的变化之间的相关性。&lt;/p&gt;&lt;p&gt;首先，我们使用提示&lt;code&gt;{&amp;#39;name&amp;#39;: &amp;#39;&lt;/code&gt;作为基本提示进行了剩余流的编辑。请注意，MLP1 SAE功能在此提示的最后一个令牌上高度激活。结果可以在以下图中找到。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 62.42%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/pvjtobymrlftw26ccozv" /&gt;&lt;figcaption&gt;在高度激活的示例与线性特征系数上注射结果&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;接下来，我们使用提示&lt;code&gt;{&amp;#39;name&amp;#39;: testing testing&lt;/code&gt;作为基本提示，对其进行了编辑。请注意，MLP1 SAE功能不会在此提示的最后一个令牌上激活。结果可以在以下图中找到。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 64.95%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/o6od0kltshhrzukl6kbt" /&gt;&lt;figcaption&gt;注射示例与线性化特征系数的注射结果&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这些结果产生以下含义：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;线性化非常有效地近似于高度激活的示例，但根本没有有效的例子。&lt;/li&gt;&lt;li&gt;当基本提示弱或未激活时，近似值较弱。&lt;/li&gt;&lt;li&gt;在弱激活或非激活的示例上，基本提示和编辑提示的原始特征得分的差异较小。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;组件的直接分数归因与零消融&lt;/h2&gt;&lt;p&gt;研究线性化疗效的另一种方法如下。给定一组提示，对于每个提示，将不同模型组件的输出（即原始的令牌嵌入和注意Sublayer）的输出为零，并查看这如何改变SAE功能的激活。然后，对于相同的提示，将直接分数归因与线性化SAE功能一起使用，以估计每个组件对SAE功能的重要性。线性化越准确，直接分数归因结果与零消融结果之间的相关性越大。&lt;/p&gt;&lt;p&gt;我们使用前200个激活示例和均匀分布的200个激活示例对每个案例研究的特征进行了此实验。对于每个功能，我们进行了两次实验：一次，通过前MLP分层区分以获得线性化特征向量，而不是通过PRE-MLP分层进行区分（仅考虑其实现的线性转换， ）。&lt;/p&gt;&lt;p&gt;我们发现，总体而言，在激活示例时，具有线性化特征的直接得分归因与零消融得分相关。正如我们先前的线性化结果所表明的那样，我们发现，在顶部激活示例上的相关性比均匀激活示例更大。但是，对于某些特征，通过分层线性化导致相关性较小，而对于其他人来说，冻结分层导致相关性较小。&lt;/p&gt;&lt;p&gt;每个案例研究的具体结果在下面给出。&lt;/p&gt;&lt;h3&gt; gelu-1l &lt;code&gt;(&amp;#39;&lt;/code&gt;功能&lt;/h3&gt;&lt;figure class="image image_resized" style="width: 80.02%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/qsttjn1itkpi2g0e5j04" /&gt;&lt;/figure&gt;&lt;p&gt;对于此功能，即使在统一激活的示例（而不仅仅是最高的激活示例），直接得分归因的结果与零消融的结果之间也存在很强的相关性。这表明线性化在此设置中的性能很好。另请注意，使用分层和冻结分层之间的性能似乎没有太大差异。&lt;/p&gt;&lt;h3&gt; gelu-1l“是”功能&lt;/h3&gt;&lt;figure class="image image_resized" style="width: 84.15%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/fx08tqlfjvmkz3rjubyf" /&gt;&lt;/figure&gt;&lt;p&gt;对于此功能，我们可以看到，当通过分层区分分化时，直接得分归因与零消融结果高度相关。但是，当冻结分层时，直接得分归因完全停止工作。&lt;/p&gt;&lt;h3&gt; gelu- &lt;code&gt;&amp;#39;t&lt;/code&gt;功能&lt;/h3&gt;&lt;figure class="image image_resized" style="width: 84.21%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/yuvm5beqpt1jiw5vp3he" /&gt;&lt;/figure&gt;&lt;p&gt;对于此功能，与线性化特征向量的直接得分归因似乎与通过分化通过LaiseNorm区分获得特征向量时的零消融结果非常吻合。然而，冻结分层对于直接得分归因而产生的性能明显较差，尤其是在统一分布的激活示例集中。&lt;/p&gt;&lt;h3&gt; GELU-1L上下文依赖性“ IS”功能&lt;/h3&gt;&lt;figure class="image image_resized" style="width: 78.71%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/emoeshjjvhytgqiouhcx" /&gt;&lt;/figure&gt;&lt;p&gt;对于此功能，直接分数归因结果与零消融结果之间的相关性小于以前的特征，尽管仍然存在不错的相关性。有趣的是，在统一分布的激活示例测试时，冻结分层可以明显地获得直接得分归因的更好的结果。&lt;/p&gt;&lt;h3&gt; Gelu-2l Python词典功能&lt;/h3&gt;&lt;figure class="image image_resized" style="width: 84.79%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/93nKtsDL6YY5fRbQv/zs8h05rwibtjivwkd8xd" /&gt;&lt;/figure&gt;&lt;p&gt; For this feature, we see decent correlation between the results of direct score attribution and zero ablation on the top 200 highest-activating examples, with freezing LayerNorm yielding somewhat better results than differentiating through LayerNorm. However, when testing on the broader set of uniformly-activating examples, the performance of direct score attribution drops precipitously.&lt;/p&gt;&lt;h2&gt; Linearization experiments: overall takeaways and hypotheses&lt;/h2&gt;&lt;ul&gt;&lt;li&gt; Taking the gradient of an MLP&amp;#39;s dot product with an SAE feature seems to be an OK approximation of the MLP&amp;#39;s behavior on inputs that highly activate the SAE feature. However, on inputs that don&amp;#39;t activate the SAE feature, the gradient is not a good approximation of MLP behavior.&lt;ul&gt;&lt;li&gt; A hypothesis as to why this is the case is that inputs that highly activate the SAE feature tend to lie within a cluster in activation space in which the MLP has similar behavior for all points in the cluster. Additionally, the pairwise cosine similarity results that we obtained suggest that there might also be some sort of weak clustering behavior for non-activating examples as well.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt; LayerNorm does not play nice with linearization in small models, where individual tokens&amp;#39; representations take up large portions of the residual stream. We recommend freezing LayerNorm rather than differentiating through it.&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt; Discussion: comparison to causal methods&lt;/h1&gt;&lt;p&gt; A natural question to ask is what our method adds over causal interventions such as path patching. For example, looking at the projection of attention heads onto a given feature vector is an approximation to just zero-ablating the path from that head into the MLP layer for just this SAE feature. Even the weights-based techniques applied, such as de-embedding, may be done causally by path patching the direct path from the embedding into the MLP layer (for just this SAE feature) for each token in the vocab, one at a time.&lt;/p&gt;&lt;p&gt; We think that MLP linearization presents significant advantages in speed, especially for weights-based approaches on larger models, where a forward pass for each token in the vocabulary may be prohibitive! MLP linearization is very mathematically similar to &lt;a href="https://www.neelnanda.io/mechanistic-interpretability/attribution-patching#path-patching"&gt;attribution path patching&lt;/a&gt; , and as such, this relationship between MLP linearization and causal interventions is analogous to that between &lt;a href="https://neelnanda.io/attribution-patching"&gt;&lt;u&gt;attribution patching and activation patching&lt;/u&gt;&lt;/a&gt; . Indeed, attribution patching also takes a gradient-based approximation to a causal intervention, yielding a substantial speed-up at the cost of some reliability ( &lt;a href="https://arxiv.org/abs/2310.10348"&gt;&lt;u&gt;but note that it is surprisingly useful&lt;/u&gt;&lt;/a&gt; &lt;u&gt;!&lt;/u&gt; ).&lt;/p&gt;&lt;p&gt; We also think that MLP linearization has promise for better understanding the SAE features on a more general level than path patching: if the feature vectors obtained via MLP linearization point in similar directions across many examples where the feature fires, then this provides a significant hint about the mechanism underpinning the feature. And we can also use such an averaged feature vector to try to understand the SAE feature on a more input-independent level. However, we also think there are many situations where path patching is sufficient and more reliable, and the feature vectors obtained by MLP linearization may be very different on different examples! As such, we think this is a promising technique that needs further investigation, but it&amp;#39;s not yet a slam dunk.&lt;/p&gt;&lt;h1&gt; &lt;strong&gt;Discussion: Is this approach useful?&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt; We&amp;#39;ve presented 5 case studies of applying MLP linearization to reverse-engineer SAE features. But fundamentally, this approach involves taking linear approximations of highly nonlinear transformations, so there are naturally some major limitations to this method. As such, can we take away an idea of whether this approach is useful, and if so, when?&lt;/p&gt;&lt;h2&gt;好的&lt;/h2&gt;&lt;p&gt;In favor of this approach, we find that it can yield rich, weights-based, input-independent information about what causes a given SAE feature to activate:&lt;/p&gt;&lt;ul&gt;&lt;li&gt; The information provided by de-embeddings is rich in that it allows us to interpret SAE features at the token level according to how different computational paths use these tokens; we personally found this new way of interpreting features to be very cool.&lt;/li&gt;&lt;li&gt; This method is largely weights-based because, with the exception of taking derivatives of MLP sublayers, it relies on the fixed trained model weights rather than internal activations on a given prompt. As a result, this approach is more naturally faithful to the model&amp;#39;s computation than to probing-based methods and is faster and more scalable than causal methods.&lt;/li&gt;&lt;li&gt; This method is largely input-independent in that, unlike traditional attribution methods, it provides information about the model&amp;#39;s computation on all inputs rather than information locally relevant to a single input.&lt;/li&gt;&lt;li&gt; Note that there is some input dependence when we take derivatives of MLP sublayers. However, our linearization experiments suggest that the derivatives of MLP sublayers are very similar across different inputs that highly activate an SAE feature.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt; Using this approach allowed us to construct adversarial prompts that revealed unexpected polysemanticity in certain SAE features; this suggests that this approach can complement existing techniques by picking up on behaviors that they might miss. And with regard to the accuracy of this approach, we found that, particularly on highly-activating examples, this approach often agreed with the results obtained by causal interventions.&lt;/p&gt;&lt;h2&gt;不好的&lt;/h2&gt;&lt;p&gt;Among the limitations of this approach, it still remains to be seen whether this can scale to larger, far more complex models. Additionally, some of the information obtained by this approach can be opaque: in particular, looking at the importance of layer 0 SAE features for a layer 1 SAE feature, the layer 0 features didn&amp;#39;t seem very sparse, limiting our ability to understand later-layer features in terms of earlier-layer ones. (Note that this might also just reflect an unavoidable reality of how models compute using SAE features, but if this is the case, then this still hampers our ability to understand the model using our approach.) Most importantly, the linear approximations of MLPs are not always accurate: in our case study for the &lt;code&gt;&amp;#39;t&lt;/code&gt; feature in GELU-1L, direct score attribution with the linearized feature indicated that attention was not important for the feature, but this was contradicted by a causal attention ablation. Indeed, right now, it&amp;#39;s hard to tell whether the method will be reliable for a given context (although preliminary results suggest greater reliability on highly-activating prompts), and in theory, the linearized feature directions can be totally different for each example.&lt;/p&gt;&lt;h2&gt;结论&lt;/h2&gt;&lt;p&gt;Overall, we think that this is a useful but limited technique; thus, we have high uncertainty on how far it can be applicable. In our preliminary experiments, this approach seems valuable for getting a sense of how a feature is computed, finding hypotheses for feature behavior that other methods might miss, and iterating fast, but it seems like it will be more difficult to get to a point where the approach is fully robust or reliable. We hope to spend the rest of the MATS program exploring the strengths and limitations of this approach to reverse-engineering SAE features.&lt;/p&gt;&lt;h1&gt;作者贡献声明&lt;/h1&gt;&lt;p&gt;Jacob and Philippe were core contributors on this project and both contributed equally. Jacob formulated the original reverse-engineering method and wrote the original reverse-engineering code; carried out the case studies for the &lt;code&gt;&amp;#39;{&lt;/code&gt; feature, the &lt;code&gt;&amp;#39;t&lt;/code&gt; feature, the context-dependent &amp;quot;is&amp;quot; feature, and the GELU-2L feature; and carried out the linearization experiments. Philippe performed a feature audit, calculating F1 scores to guide our selection of interesting features to investigate; carried out the case study for the &amp;quot;it is&amp;quot; feature; and refactored and organized code. Sen and Neel gave guidance and feedback throughout the project, including suggesting ideas for causal experiments to test the efficacy of linearization. The original project idea was suggested by Neel.&lt;/p&gt;&lt;h1&gt; Appendix: mathematical details on our method&lt;/h1&gt;&lt;p&gt; In this section, we elaborate with ample mathematical details upon the explanation of our method provided earlier in the post.&lt;/p&gt;&lt;h2&gt; 1-Layer Transformers&lt;/h2&gt;&lt;h3&gt; Finding a feature vector in MLP input space&lt;/h3&gt;&lt;p&gt; Let&amp;#39;s say that we have an SAE feature trained on &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;MLP_out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∈&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mtext MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-ams-R"&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;model&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , the output of the MLP sublayer, and we want to understand what causes that feature to activate. Then, the activation of the &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; -th SAE feature on &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;MLP_out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is given by &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;ReLU&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;MLP_out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;−&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , where &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; -th row of the SAE encoder weight matrix and &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; -th value in the encoder bias vector &lt;span class="footnote-reference" id="fnrefszr2mm7vzrh"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnszr2mm7vzrh"&gt;[7]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; . This means that the SAE feature activation is determined by the dot product &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;MLP_out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . As such, we can consider &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; to be the relevant feature vector in the output space of the MLP.&lt;/p&gt;&lt;p&gt; Our first task is to determine a feature vector &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; in the input space of the MLP that corresponds to &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . What this means is that if &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the input to the MLP, then we want &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;≈&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;MLP_out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , which is the same as &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;≈&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;MLP&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . If the MLP were linear, then we could write &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;MLP&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; as &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; for some matrix &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . In this hypothetical, we would have that &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;MLP&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , implying that &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; .&lt;/p&gt;&lt;p&gt; Unfortunately, MLPs are not linear in real life! But we can &lt;i&gt;linearly approximate&lt;/i&gt; &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;i&gt;by taking the gradient of the MLP&lt;/i&gt; . As such, our feature vector in MLP input space, &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , is given by &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∇&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;MLP&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;（&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;X&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;）&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt; An important question is this: to what extent is this linearization accurate, given that MLPs are in fact highly nonlinear? We have performed some initial investigations into this, which can be found in the section on linearization experiments; we intend to look deeply into this question as we continue our research.&lt;/p&gt;&lt;h3&gt; Different paths&lt;/h3&gt;&lt;p&gt; Now, we have a feature vector &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; in the MLP input space, ie the residual stream prior to the MLP sublayer.我们能用它做什么？ The first thing that we have to understand is that the residual stream at this point is the sum of two different computational paths in the model: the path directly from the input tokens and the path from the input tokens through the attention sublayer. &lt;span class="footnote-reference" id="fnreff7rrxo2wv7k"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnf7rrxo2wv7k"&gt;[8]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; As such, the activation of &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is given by the sum of the contributions of each path. This means that we can analyze and find feature vectors for each path separately.&lt;/p&gt;&lt;h3&gt; The direct path and de-embedding&lt;/h3&gt;&lt;p&gt; First, let&amp;#39;s look at the direct path. This is the path that implements the computation &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;token&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , where &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;token&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the one-hot vector for the token at the current position, and &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the embedding matrix that maps each token to its embedding. At this point, the activation of &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; due to the direct path is given by &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;token&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , which is equal to &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.851em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;token&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . As such, the feature vector in token input space for the direct path is given by &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; .&lt;/p&gt;&lt;p&gt; Now, &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is a vector whose dimension is equal to the number of tokens in the model vocabulary, where the &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; -th entry in the vector represents the amount that token &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; contributes to activating the feature &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . And since &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is just an approximation for the original SAE feature, this means that &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;i&gt;is an approximation of how much each token in the model&amp;#39;s vocabulary contributes to activating the original SAE feature&lt;/i&gt; .&lt;/p&gt;&lt;p&gt; We refer to this process of obtaining a vector of token scores for a given residual stream feature as &lt;strong&gt;de-embedding&lt;/strong&gt; . De-embedding forms a key part of the reverse-engineering process, as it allows us to analyze at a concrete token level the extent to which each token contributes to the feature. Importantly, this process works for any feature that lives in the residual stream of the model. This means that de-embedding can be used for understanding not just pre-MLP features, but also pre-attention features, and features at different layers of multi-layer models.&lt;/p&gt;&lt;h3&gt;注意力&lt;/h3&gt;&lt;p&gt;Now, let&amp;#39;s look at the path from the tokens to the attention sublayer. The first step is to note that the output of attention, for the destination token at position &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , is given by&lt;/p&gt; &lt;span&gt;&lt;span class="mjpage mjpage__block"&gt;&lt;span class="mjx-chtml MJXc-display" style="text-align: center;"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;attn_out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-munderover MJXc-space3"&gt;&lt;span class="mjx-itable"&gt;&lt;span class="mjx-row"&gt;&lt;span class="mjx-cell"&gt;&lt;span class="mjx-op" style="padding-left: 1.8em;"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size2-R" style="padding-top: 0.74em; padding-bottom: 0.74em;"&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-row"&gt;&lt;span class="mjx-under" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;attention head&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-munderover MJXc-space1"&gt;&lt;span class="mjx-itable"&gt;&lt;span class="mjx-row"&gt;&lt;span class="mjx-cell"&gt;&lt;span class="mjx-op" style="padding-left: 2.32em;"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size2-R" style="padding-top: 0.74em; padding-bottom: 0.74em;"&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-row"&gt;&lt;span class="mjx-under" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;source token index&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;score&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;O&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt; where &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the residual stream before attention (ie after token and positional embeddings) for token &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;O&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the OV matrix for head &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , and &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;score&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the attention weight for head &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; from the source token at position &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; to the destination token at position &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . &lt;span class="footnote-reference" id="fnref2e6edu41698"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn2e6edu41698"&gt;[9]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt; If we treat attention scores as a constant, only focusing on the OV circuit, then this output is just the sum of linear functions on the source t​okens, one for each head, given by &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;↦&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;O&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . This means that the feature vector for the OV circuit of head &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is given by &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;O&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;mid&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . De-embedding can be applied directly to this feature vector too, in order to understand which tokens contribute the most (through the OV circuit for this head) to the overall SAE feature.&lt;/p&gt;&lt;p&gt; As for analyzing the QK circuits of attention (ie the part of attention responsible for determining attention scores between tokens), we found that the best way to do this was to directly calculate the QK scores for pairs of tokens relevant in the OV circuit, or between different token positions. Examples of this can be found in our case studies.&lt;/p&gt;&lt;h3&gt; Direct score attribution for individual heads and tokens in attention sublayers&lt;/h3&gt;&lt;p&gt; Recall again the equation for attention sublayers, which explains that &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;attn_out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , the output of attention for the destination token at position &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is given by &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;attn_out&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-munderover MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;attention head&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-munderover MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;source token index&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;score&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;O&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt; where &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the residual stream before attention for token &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;O&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the OV matrix for head &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , and &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;score&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the attention weight for head &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; from the source token at position &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; to the destination token at position &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; .&lt;/p&gt;&lt;p&gt; Applying the idea of direct score attribution to this equation, this means that the contribution of head &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; and source token &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; to feature vector &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; at destination token &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is given by &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;score&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char"&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mrow MJXc-space1"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;O&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-type-R"&gt;pre&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; .&lt;/p&gt;&lt;p&gt; &lt;strong&gt;The takeaway:&lt;/strong&gt; it&amp;#39;s possible to see how much each token, at each attention head, contributes to a given feature.&lt;/p&gt;&lt;h3&gt; Wait, what about LayerNorms?&lt;/h3&gt;&lt;p&gt; One thing that we haven&amp;#39;t yet mentioned is the ubiquitous presence of LayerNorm nonlinearities in the model. These can be handled by linearizing them in the same way that we approximate MLPs. But, as is discussed in the &lt;a href="https://www.neelnanda.io/mechanistic-interpretability/attribution-patching"&gt;attribution patching post&lt;/a&gt; , LayerNorms, in general, shouldn&amp;#39;t affect the direction of feature vectors, so there is a theoretical basis for them to be ignored. However, we find that this doesn&amp;#39;t always hold in our &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;实验。 Hypotheses as for why this is the case, along with further discussion, can be found in our section on linearization.&lt;/p&gt;&lt;h2&gt; Multi-layer transformers&lt;/h2&gt;&lt;p&gt; Although the above exposition only discusses 1-layer transformers, it is straightforward to extend this to multi-layer transformers. After all, we now know how to propagate feature vectors through every type of sublayer found in a transformer. As such, given a computational path in a multi-layer transformer, we can simply propagate the SAE feature through this computational path by iteratively propagating it through each sublayer in the computational path, as described above.&lt;/p&gt;&lt;ol class="footnotes"&gt;&lt;li class="footnote-item" id="fn5ns12vjb0f8"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref5ns12vjb0f8"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; Though the feature vector obtained still depends on the input we differentiated on, so it&amp;#39;s not fully input independent. Each input has a different local linear approximation.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fna1rxph5d74"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefa1rxph5d74"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; We note that this may be catchable via non-mechanistic approaches, such as running the models on a large corpus of data and analysing whether the feature activations are highly correlated, as in &lt;a href="https://arxiv.org/abs/2306.09346"&gt;Dravid et al.&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn36xy0nowkoe"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref36xy0nowkoe"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; We&amp;#39;re not sure this counts as an adversarial example. Possibly this is a genuinely polysemantic feature that &amp;quot;wants&amp;quot; to fire on &lt;code&gt;ह&lt;/code&gt; too, or possibly it&amp;#39;s undesirable but hard to disentangle. We speculated there might be superposition where the token embeddings were highly similar, but found that other tokens are more similar to &lt;code&gt;(&amp;#39;&lt;/code&gt; than &lt;code&gt;ह&lt;/code&gt; is, but these do not trigger the SAE feature.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn1tpfjhj7ezr"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref1tpfjhj7ezr"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; That is, &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;O&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.852em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . Looking at the greatest components in this vector answers the following question: given that head 0 is attending to a position, which tokens, if they were at that position, will activate the feature the most?&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn2belxv37guh"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref2belxv37guh"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; Note that &lt;code&gt;&amp;#39;t&lt;/code&gt; basically never appears &lt;i&gt;without&lt;/i&gt; don/can/won/etc as a prefix, so it&amp;#39;s unclear from just the maximum activating examples whether these matter for the SAE feature.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn0hyqmgltk21m"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref0hyqmgltk21m"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; For the sake of intuition regarding why we might expect this: imagine a limit case where we&amp;#39;re looking at a feature at layer 48 of some gigantic transformer. In this exaggerated case, we would probably not expect that this feature can be directly interpreted in terms of the original token embeddings.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnszr2mm7vzrh"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefszr2mm7vzrh"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; This formulation assumes that the SAE encoder weight matrix &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;enc&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is a &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-ams-R"&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;SAE&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;×&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;model&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; matrix, where &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;SAE&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the hidden dimension of the SAE and &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mtext"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;model&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the dimension of the input to the SAE (this could be the hidden dimension of the model or the dimensionality of MLP sublayers, depending on which activations the SAE is trained on). In this formulation, vectors multiply on the right of matrices. However, note that certain libraries, such as TransformerLens, use the opposite convention, in which column vectors multiply on the left of matrices.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnf7rrxo2wv7k"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnreff7rrxo2wv7k"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; For a clearer explanation of this, refer to the &lt;a href="https://transformer-circuits.pub/2021/framework/index.html#one-layer-attention-only-transformers"&gt;seminal Transformer Circuits paper&lt;/a&gt; .&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fn2e6edu41698"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref2e6edu41698"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; Note that we ignore bias terms here. We can get away with this when we care about understanding which inputs cause a feature to activate; this is because bias terms merely add a constant to the feature score that&amp;#39;s independent of all inputs. However, when analyzing the different contributions that sublayers have to feature scores (eg when performing analysis via direct score attribution), bias terms should be taken into account.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnaeodi9xhson"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefaeodi9xhson"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; The discrepancy between the top tokens when linearizing through LayerNorm and the top tokens without taking into account LayerNorm is explored further in our section on discussing linearization.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/93nKtsDL6YY5fRbQv/case-studies-in-reverse-engineering-sparse-autoencoder#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sun, 14 Jan 2024 02:06:00 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/93nKtsDL6YY5fRbQv/case-studies-in-reverse-engineering-sparse-autoencoder</guid></item><item><title>D&amp;amp;D.Sci 超球面分析第 1 部分：数据字段和初步分析</title><link>https://www.lesswrong.com/posts/rAnS5jCQ5r87eMvus/d-and-d-sci-hypersphere-analysis-part-1-datafields-and</link><description>发布于 2024 年 1 月 13 日晚上 8:16（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;这是一篇文章（希望最终是一个简短的系列文章），详细介绍了我对 Abstractapplic &lt;a href="https://www.lesswrong.com/posts/T3iG4MQ76988JBfkq/d-and-d-sci-fi-colonizing-the-superhypersphere"&gt;最近发布的 D&amp;amp;D.Sci 场景&lt;/a&gt;的分析。我决定记录一下我所做的事情 - 如果您打算在没有帮助的情况下自己玩这个场景，那么您应该在阅读本文之前这样做。如果您想在解决方案中使用此信息，请继续。&lt;/p&gt;&lt;h2&gt;原始数据和列&lt;/h2&gt;&lt;p&gt;我首先获取原始数据并将其保存为 csv，然后将其导入到&lt;a href="https://raw.githubusercontent.com/aphyer1992/dndsci_hypersphere/main/dndsci_zppg.py"&gt;Python&lt;/a&gt;和 Excel 中进行使用。我现在不想做任何特定的分析，只是想熟悉数据并看看是否有什么发现。&lt;/p&gt;&lt;p&gt;我们将一一浏览这些列，并在 Excel 中制作一些图表以进行可视化&lt;span class="footnote-reference" id="fnrefxtxl79an65"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnxtxl79an65"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;经度&lt;/strong&gt;在-180 到+180 之间相对均匀分布。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/gsxtboyyggz2mxhkjf2f" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;纬度&lt;/strong&gt;可以从 -90 到 +90 变化，但是是双峰的，通常取 45 左右的值 - 我们很少降落在赤道附近或两极附近。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/qoczvq1wh3qqroqqdqnr" /&gt;&lt;/figure&gt;&lt;p&gt; Shortitude 和 Deltitude 看起来与 Latitude 相同： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/ysq41ourfgbxn7mhb2vb" /&gt;&lt;/figure&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/wvowp0jltzgnarvxdgxy" /&gt;&lt;/figure&gt;&lt;p&gt;这可能是您自然期望降落在 4D 球体上的随机点上的结果 - 当然，+-90 附近的值不太可能自然发生，因为这些是“极点”并且占用的面积较小。我没有足够的直觉来知道一旦添加更多维度，接近 0 的值是否也自然罕见，或者我们是否出于某种原因避免使用“赤道”。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;奇怪的气味&lt;/strong&gt;通常会有些存在，但很少会非常存在： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/peeleskulznbxszrcn9m" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;空气味道&lt;/strong&gt;有一些不同的值，一些常见，一些罕见： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/wt1p7m3qlzk12qmscuoo" /&gt;&lt;/figure&gt;&lt;p&gt;风水通常是充足的，有时不好，很少有好的： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/u4iqlmilkvafcph6dgoa" /&gt;&lt;/figure&gt;&lt;p&gt;奇怪的声音有五个可能的值，我们一次最多可以看到三个：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;诡异的沉默&lt;/li&gt;&lt;li&gt;不可能的嗡嗡声&lt;/li&gt;&lt;li&gt;超凡脱俗的掠过&lt;/li&gt;&lt;li&gt;异常压制&lt;/li&gt;&lt;li&gt;不自然的嗡嗡声&lt;/li&gt;&lt;/ul&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/y09cf6krublcyreepjxe" /&gt;&lt;/figure&gt;&lt;p&gt;当没有其他声音出现时，诡异的寂静就出现了。&lt;/p&gt;&lt;p&gt;掠过声和嗡嗡声永远不会同时发生（尽管它们分别是最常见的声音）。&lt;/p&gt;&lt;p&gt; Pi 的局部值的分布看起来非常整齐： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/es5olev4slmim6cnbmi0" /&gt;&lt;/figure&gt;&lt;p&gt; 3.141 + (1d41-1d41)/1000 从字面上看并不准确，因为我们看到的小数位数比这更多，但这可能是一种合理的思考方式？&lt;/p&gt;&lt;p&gt;墨菲常数有一个非常奇怪的分布： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/cbhhf3e2xbk5cdouyymz" /&gt;&lt;/figure&gt;&lt;p&gt;我会猜测这样的事情：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; MC 的分布与我们看到 Pi 的分布类型相同，概率从 0 线性增加到 ~5.5，然后从 ~5.5 线性增加到 ~11。&lt;/li&gt;&lt;li&gt;但我们光辉帝国从来不选择MC&amp;gt;6的地盘。&lt;/li&gt;&lt;li&gt;此外，我们在 MC=4 和 MC=5 处设置了一些限制或条件，使得感知频率在这些点处下降。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;性能看起来不太好： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/rAnS5jCQ5r87eMvus/humjat6wv5du0g3yyf2p" /&gt;&lt;/figure&gt;&lt;p&gt;在 10,000 多个站点中，有&lt;strong&gt;2 个&lt;/strong&gt;站点的性能 &amp;gt;=100%。&lt;/p&gt;&lt;p&gt;诚然，我们确实有 11 万个预先批准的站点可供选择。这表明在全部可能的数据中大约有 20 个站点的性能可以接受——这反过来又表明我们的任务不会有太多余地。如果我们不能几乎完美地识别影响性能的&lt;strong&gt;所有&lt;/strong&gt;因素，我们实际上就无法找到 12 100%+ 的站点。&lt;/p&gt;&lt;h2&gt;重新格式化以供使用&lt;/h2&gt;&lt;p&gt;我调整了一些列以使其更加用户友好：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; “Weird Sounds”变成了 4 个独立的布尔列来表示不同的噪音（忽略了当没有其他噪音时我们得到的“Silence”）。&lt;/li&gt;&lt;li&gt; “奇怪的气味？”而“周边风水”则变成从0到2的数字：0表示没有气味/风水不好，1表示有气味/风水好，2表示气味极重/风水好。&lt;/li&gt;&lt;li&gt; “Air Tastes Like” 变成 4 个独立的布尔列（适用于除“Nothing”之外的所有气味）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;然后将结果输出为一个我认为更方便的&lt;a href="https://raw.githubusercontent.com/aphyer1992/dndsci_hypersphere/main/dndsci_zppg_formatted.csv"&gt;新文件&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;相关矩阵&lt;/h2&gt;&lt;p&gt;我们可以利用这些数据做的最简单有用的事情之一就是构建一个相关矩阵。 &lt;span class="footnote-reference" id="fnrefegy9fnduwep"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnegy9fnduwep"&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;figure class="table"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;洛&lt;/td&gt;&lt;td&gt;拉&lt;/td&gt;&lt;td&gt;什&lt;/td&gt;&lt;td&gt;德&lt;/td&gt;&lt;td&gt;圆周率&lt;/td&gt;&lt;td&gt;亩&lt;/td&gt;&lt;td&gt;闻&lt;/td&gt;&lt;td&gt;冯&lt;/td&gt;&lt;td&gt;应用程序&lt;/td&gt;&lt;td&gt;烧伤&lt;/td&gt;&lt;td&gt;科普&lt;/td&gt;&lt;td&gt;薄荷&lt;/td&gt;&lt;td&gt;哼&lt;/td&gt;&lt;td&gt;短剧&lt;/td&gt;&lt;td&gt;斯奎&lt;/td&gt;&lt;td&gt;嗡嗡声&lt;/td&gt;&lt;td&gt;性能&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;洛&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #F8E984; text-align: right;"&gt;0.01&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FCEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F3E884; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #D2DE82; text-align: right;"&gt; 0.07&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;拉&lt;/td&gt;&lt;td style="background-color: #F8E984; text-align: right;"&gt;0.01&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F3E884; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FAEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #F6E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F4E884; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;什&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt;-0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #F9EA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F7E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #F8E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;德&lt;/td&gt;&lt;td style="background-color: #FCEA84; text-align: right;"&gt;0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F9EA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F0E784; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F6E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #F5E984; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;圆周率&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt;0.00&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE683; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F7E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #BDD881; text-align: right;"&gt; 0.11&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;亩&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt;0.00&lt;/td&gt;&lt;td style="background-color: #FCEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F0E784; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F9EA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F98871; text-align: right;"&gt; -0.40&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;闻&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt;0.00&lt;/td&gt;&lt;td style="background-color: #F3E884; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F5E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE683; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F7E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FCC37C; text-align: right;"&gt; -0.16&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;冯&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt;-0.01&lt;/td&gt;&lt;td style="background-color: #FAEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F9EA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #F9EA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FAEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #C0D981; text-align: right;"&gt; 0.10&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;应用程序&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt;-0.01&lt;/td&gt;&lt;td style="background-color: #F6E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE683; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F9EA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FDC67C; text-align: right;"&gt; -0.15&lt;/td&gt;&lt;td style="background-color: #FDD17F; text-align: right;"&gt; -0.11&lt;/td&gt;&lt;td style="background-color: #F97C6E; text-align: right;"&gt; -0.45&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FED980; text-align: right;"&gt; -0.07&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;烧伤&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt;-0.01&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F6E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FDC67C; text-align: right;"&gt; -0.15&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FEDE81; text-align: right;"&gt; -0.05&lt;/td&gt;&lt;td style="background-color: #FCB379; text-align: right;"&gt; -0.23&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FCEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FAEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #C5DB81; text-align: right;"&gt; 0.09&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;科普&lt;/td&gt;&lt;td style="background-color: #F3E884; text-align: right;"&gt;0.02&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F5E984; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FDD17F; text-align: right;"&gt; -0.11&lt;/td&gt;&lt;td style="background-color: #FEDE81; text-align: right;"&gt; -0.05&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FCC37C; text-align: right;"&gt; -0.16&lt;/td&gt;&lt;td style="background-color: #F2E884; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #F7E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #E8E583; text-align: right;"&gt; 0.04&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;薄荷&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt;0.00&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F7E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FAEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #F97C6E; text-align: right;"&gt; -0.45&lt;/td&gt;&lt;td style="background-color: #FCB379; text-align: right;"&gt; -0.23&lt;/td&gt;&lt;td style="background-color: #FCC37C; text-align: right;"&gt; -0.16&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #63BE7B; text-align: right;"&gt; 0.26&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;哼&lt;/td&gt;&lt;td style="background-color: #FCEA84; text-align: right;"&gt;0.00&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #F5E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F2E884; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #F5E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F8786D; text-align: right;"&gt; -0.47&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;短剧&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt;0.00&lt;/td&gt;&lt;td style="background-color: #F4E884; text-align: right;"&gt; 0.02&lt;/td&gt;&lt;td style="background-color: #F8E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F7E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE683; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F7E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #F5E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F8696B; text-align: right;"&gt; -0.53&lt;/td&gt;&lt;td style="background-color: #D7E082; text-align: right;"&gt; 0.06&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;斯奎&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt;-0.01&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FCEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #F6E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FBA276; text-align: right;"&gt; -0.29&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;嗡嗡声&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt;0.00&lt;/td&gt;&lt;td style="background-color: #FEE783; text-align: right;"&gt; -0.02&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #F7E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FEE883; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FCEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FAEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FFEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FEE983; text-align: right;"&gt; -0.01&lt;/td&gt;&lt;td style="background-color: #FEEA83; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #F8696B; text-align: right;"&gt; -0.53&lt;/td&gt;&lt;td style="background-color: #F6E984; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td style="background-color: #FCC17B; text-align: right;"&gt; -0.17&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;性能&lt;/td&gt;&lt;td style="background-color: #D2DE82; text-align: right;"&gt;0.07&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #FBEA84; text-align: right;"&gt; 0.01&lt;/td&gt;&lt;td style="background-color: #FDEB84; text-align: right;"&gt; 0.00&lt;/td&gt;&lt;td style="background-color: #BDD881; text-align: right;"&gt; 0.11&lt;/td&gt;&lt;td style="background-color: #F98871; text-align: right;"&gt; -0.40&lt;/td&gt;&lt;td style="background-color: #FCC37C; text-align: right;"&gt; -0.16&lt;/td&gt;&lt;td style="background-color: #C0D981; text-align: right;"&gt; 0.10&lt;/td&gt;&lt;td style="background-color: #FED980; text-align: right;"&gt; -0.07&lt;/td&gt;&lt;td style="background-color: #C5DB81; text-align: right;"&gt; 0.09&lt;/td&gt;&lt;td style="background-color: #E8E583; text-align: right;"&gt; 0.04&lt;/td&gt;&lt;td style="background-color: #63BE7B; text-align: right;"&gt; 0.26&lt;/td&gt;&lt;td style="background-color: #F8786D; text-align: right;"&gt; -0.47&lt;/td&gt;&lt;td style="background-color: #D7E082; text-align: right;"&gt; 0.06&lt;/td&gt;&lt;td style="background-color: #FBA276; text-align: right;"&gt; -0.29&lt;/td&gt;&lt;td style="background-color: #FCC17B; text-align: right;"&gt; -0.17&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;有几点值得注意：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;大多数条目对几乎没有相关性。这使得诸如“邪恶的压制生物有铜的气味”或“薄荷味驱赶蜂鸣器”之类的理论变得非常难以置信。&lt;/li&gt;&lt;li&gt;所有空气味道都是负相关的（显然，因为它们是相互排斥的）。&lt;/li&gt;&lt;li&gt;掠过和嗡嗡声是非常负相关的，如上所述，它们永远不会同时发生。 （飞掠者吃掉蜂鸣器？）&lt;/li&gt;&lt;li&gt;性能与几个不同的变量相关。乍一看显示：&lt;ul&gt;&lt;li&gt;受到墨菲常数的严重伤害（我猜这个常数衡量了他的定律的强度？）&lt;/li&gt;&lt;li&gt;受到嗡嗡声、静噪，尤其是嗡嗡声的伤害。&lt;/li&gt;&lt;li&gt;薄荷的空气味道很好，其他一些味道稍好或稍差。&lt;/li&gt;&lt;li&gt;较高的 Pi 值和较好的风水略好。&lt;/li&gt;&lt;li&gt;气味较浓则稍差。&lt;/li&gt;&lt;li&gt;奇怪的是，经度越高似乎越好。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该分析有两个主要局限性。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;毫无疑问，您已经被告知了一千万次，相关性并不意味着因果关系。 &lt;span class="footnote-reference" id="fnrefcao6y67v2tf"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fncao6y67v2tf"&gt;[3]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;特别是，我们看到 Skittering 看起来有一点好处，但我怀疑这是海市蜃楼。 Skittering 和 Buzzing 是互斥的，而 Buzzing 是相当糟糕的。掠过者可能很糟糕，但不像蜂鸣器那么糟糕：这表明我们也应该避免掠过，并支持沉默。&lt;/li&gt;&lt;li&gt;数据中可能存在的某些模式不会正确反映在这些数字中。&lt;ol&gt;&lt;li&gt;如果在经度 +83 处有一片美妙的绿洲，我们会发现经度和性能之间存在非常轻微的正相关关系。&lt;/li&gt;&lt;li&gt;如果风水有一点是好的，但很多是坏的，我们就不会跟踪得那么好。&lt;/li&gt;&lt;li&gt;如果有一种相互作用，悍马在赤道附近很平静，但在远离赤道的地方很凶猛，我们会完全错过它。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;不充分的初步猜测&lt;/h2&gt;&lt;p&gt;如果我尝试使用此处的信息进行初步猜测：&lt;/p&gt;&lt;p&gt;我们有&lt;strong&gt;大量&lt;/strong&gt;可供尝试的网站。即使在几个要求之后：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一定是沉默。&lt;/li&gt;&lt;li&gt;必须没有任何奇怪的气味。&lt;/li&gt;&lt;li&gt;空气中一定有薄荷的味道。&lt;/li&gt;&lt;li&gt;风水至少必须是足够的。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们还有 2628 个条目。我根据墨菲常数/pi/一点经度的猜测得分建议尝试以下网站：&lt;/p&gt;&lt;p&gt; 6123&lt;br /&gt; 10709&lt;br /&gt; 11789&lt;br /&gt; 16118&lt;br /&gt; 23695&lt;br /&gt; 24728&lt;br /&gt; 29720&lt;br /&gt; 33672&lt;br /&gt; 36008&lt;br /&gt; 48703&lt;br /&gt; 53187&lt;br /&gt; 61818&lt;/p&gt;&lt;p&gt;然而，当我将相同的逻辑应用于主数据集并查看此类网站中的生成器实际得分情况时，它们往往在 50-90% 的范围内。这比 23% 的总体平均水平要好得多，但显然还不够好，以至于我应该冒险去尝试。&lt;/p&gt;&lt;p&gt;据推测，深入研究经度/纬度/短度/纬度将提供更多细节。我会在某个时候这样做，并尝试将我所做的事情写下来。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class="footnotes"&gt;&lt;li class="footnote-item" id="fnxtxl79an65"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefxtxl79an65"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; （个人喜好说明：Excel 是一种非常糟糕的编程语言，对于那些真正应该只使用 Python 的人来说，它习惯于解决简单的编程任务，但它是一个非常好的数据可视化工具。）&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fnegy9fnduwep"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefegy9fnduwep"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;这些非常有用，如果您使用粘贴转置和混合绝对引用，那么在 Excel 中制作起来确实非常容易。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;li class="footnote-item" id="fncao6y67v2tf"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefcao6y67v2tf"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt; （我讨厌这种特殊的措辞，因为“暗示”这个词可以用来表示“证明”或“建议”，虽然相关性并不能证明因果关系，但它确实表明了因果关系。）&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/rAnS5jCQ5r87eMvus/d-and-d-sci-hypersphere-analysis-part-1-datafields-and#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 13 Jan 2024 20:16:39 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/rAnS5jCQ5r87eMvus/d-and-d-sci-hypersphere-analysis-part-1-datafields-and</guid></item><item><title>一些额外的 SAE 想法</title><link>https://www.lesswrong.com/posts/fqgn56tS5AgjmDpnX/some-additional-sae-thoughts</link><description>发布于 2024 年 1 月 13 日晚上 7:31（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;i&gt;感谢 Lee Sharkey 对第一部分的反馈，感谢 Lee Sharkey、Jake Mendel、Kaarel Hänni 和 LISA 办公室的其他人围绕本文进行的对话。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这篇文章是过去几个月的一些小实验和想法的集合，这些实验和想法从未真正变成更大的东西，但有助于澄清我对一些与 SAE 相关的事情的想法。我现在已经加入了 Anthropic 的可解释性团队，但这里写的所有内容都来自该日期之前。&lt;/p&gt;&lt;h2&gt; MLP 中的分布式特征如何发挥作用？&lt;/h2&gt;&lt;h3&gt;概括&lt;/h3&gt;&lt;p&gt;在撰写最初的 SAE 论文时，我对以下论点感到困扰：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;要了解 MLP 层的作用，我们需要了解非线性如何作用于数据，因为这就是新颖的计算所在。&lt;/li&gt;&lt;li&gt;稀疏自动编码器在变压器 MLP 的后非线性中发现的特征似乎在神经元之间分布非常紧密。&lt;/li&gt;&lt;li&gt;分布在大量神经元上的特征只会对每个单独的神经元产生微小的影响，并且神经元在如此小的变化上将近似线性。&lt;/li&gt;&lt;li&gt;因此，这些分布式特征不可能是真正的动作所在，我们需要以某种方式将神经元基础纳入我们理解 MLP 特征的方式中。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我不再相信这一点，最重要的是，因为我意识到，&lt;strong&gt;当一个特征分布在&lt;/strong&gt;&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n 个&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;神经元上时，可以通过将输入特征的大小放大&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msqrt"&gt;&lt;span class="mjx-box"&gt;&lt;span class="mjx-surd"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;√&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-box" style="border-top: 1px solid;"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;倍来恢复原始非线性&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;事实上，&lt;i&gt;它只&lt;/i&gt;需要缩放&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msqrt"&gt;&lt;span class="mjx-box"&gt;&lt;span class="mjx-surd"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;√&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-box" style="border-top: 1px solid;"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，而不是隐含在我的非正式论证中的&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; （当我考虑缩放的可能性时......）使得使用多个高度分布的特征变得可行，只要少数功能处于活动状态。&lt;/p&gt;&lt;p&gt;代码可&lt;a href="https://github.com/HoagyC/distrib_feats/blob/main/streamlit_page.py"&gt;在 GitHub 上&lt;/a&gt;获取。&lt;/p&gt;&lt;h3&gt;非线性的需要&lt;/h3&gt;&lt;p&gt;多层模型作用于输入数据，将其在每一层处理成新的结构。如果我们查看每个连续层中存在的信息总量，我们知道信息量只会下降，因为较高层中存在的任何信息都是直接从较低层计算出来的，因此信息也必须是存在于那些较低层中。&lt;/p&gt;&lt;p&gt;然而，模型&lt;i&gt;可以&lt;/i&gt;做的是通过多层的操作使数据的特定功能&lt;i&gt;更容易访问&lt;/i&gt;。特别是，该模型使得线性探针能够提取丰富的特征，例如最近在&lt;a href="https://arxiv.org/abs/2310.02207"&gt;代表空间和时间的语言模型&lt;/a&gt;以及许多以前的作品中看到的那样。&lt;/p&gt;&lt;p&gt;线性探针是对哪些信息真正&lt;i&gt;可用的&lt;/i&gt;自然测试，而不是隐藏在高维数据流形中，因为线性可用允许后续神经元根据数据的此特征的存在或不存在进行调节。&lt;/p&gt;&lt;p&gt;重要的是，数据的线性变换不能线性地提供新信息。如果我们有一个线性变换&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，它允许我们使用线性探针&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;σ&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;p&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⋅&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;从特征激活&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;中提取信息，那么我们可以通过定义新的探针&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;σ&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;p&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⋅&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;来消除对&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的需要使用&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;p&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.12em;"&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;p&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。因此，如果我们想要在这个意义上提供新信息，我们将需要对其进行非线性变换，这就是变压器的 MLP 层的用武之地。&lt;/p&gt;&lt;h3&gt;基础对齐和分布式特征&lt;/h3&gt;&lt;p&gt;考虑到这种非线性需求，我想探索如何在模型中构建特征，在该模型中，我们从将 MLP 中的特征视为单个神经元的输出，转变为分布在多个神经元的方向。神经元。 &lt;span class="footnote-reference" id="fnref6iedrpq2n4a"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fn6iedrpq2n4a"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;在本节中，我将使用 100 个神经元 MLP 和两个潜在特征，一个与单个神经元对齐，另一个分布在所有 100 个神经元中。这些将有助于理解基础对齐特征和分布式特征之间的一些简单差异。&lt;/p&gt;&lt;p&gt;特征被定义为具有单位范数的方向，因此&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∈&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-ams-R"&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px;"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;100&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; , &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;|&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。&lt;/p&gt;&lt;p&gt;特征 1 就是第一个神经&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;元&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;，&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;...&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;特征 2 最大程度地分布在神经元&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;上&lt;/span&gt;&lt;/span&gt;&lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;，&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0.1&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0.1&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0.1&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;...&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;请注意，我们将&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;L&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;范数设置为 1（不是&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;L&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;范数），因此特征方向的计算为&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-munderover"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-size1-R"&gt;Σ&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;if&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;所以&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-stack"&gt;&lt;span class="mjx-sup" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub" style="font-size: 70.7%;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0.01&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;fi&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;=&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;0.1&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;我们可以将这些解释为前非线性空间和后非线性空间中的特征，并查看这些特征如何相互影响。我们可以看一下以下关系，其中&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∈&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-texatom MJXc-space3"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是所选的输入特征， &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;o&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;∈&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;{&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是所选的输出特征， &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是该特征的输入标量级别， &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是该特征的输出标量级别。&lt;/p&gt;&lt;p&gt; &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;y&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space3"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;o&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;⋅&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;G&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;E&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;L&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;U&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;下面绘制了四种可能的输入输出关系 - 在查看之前，我鼓励您思考这些关系会是什么样子，尤其是扩展输入和扩展输出之间的关系。 &lt;/p&gt;&lt;hr /&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/o8spsuwfuqygxgc1y04m" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;请注意，每个图的比例不同 - y 轴重新调整比例以显示形状的相似性。&lt;/strong&gt;在左上角我们只看到 GELU 非线性。在右上角，我们看到相同的形状，但正如我们所期望的，输出的大小是使用单个输出时的 1/10&lt;/p&gt;&lt;p&gt;在左下角，我们看到单输入单输出情况下非线性的放大版本，因为我们只将我们关心的神经元更改为预期数量的十分之一。不仅变化的幅度变小，而且非线性现在几乎无法察觉。&lt;/p&gt;&lt;p&gt;右下角是一个有趣的案例。重要的是，尽管输入和输出特征相同，但我们不会复制左上角的行为。相反，我们看到的是左下角的行为，但在所有 100 个神经元上都得到了复制。输出的规模扩大了 10 倍，因为我们将单个 (0.1 x 1) 计算替换为 100 x (0.1 x 0.1)。&lt;/p&gt;&lt;h3&gt;按 sqrt(n) 放大可恢复非线性&lt;/h3&gt;&lt;p&gt;右下角的图表非常接近线性，并且作为非线性函数没有多大用处。相反，如果我们想要恢复相同的非线性，我们需要将输入方向的变化规模增加&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msqrt"&gt;&lt;span class="mjx-box"&gt;&lt;span class="mjx-surd"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;√&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-box" style="border-top: 1px solid;"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msqrt MJXc-space3"&gt;&lt;span class="mjx-box"&gt;&lt;span class="mjx-surd"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;√&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;00&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;10&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，在这种情况下我们得到以下结果： &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/aplpbetyg9ha5zv8x5go" /&gt;&lt;/figure&gt;&lt;p&gt;这是我们所说的 MLP 具有首选基础并且对于旋转不是不变的意思的一个例子 - 为了使分布在&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n 个&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;神经元&lt;strong&gt;上的特征获得相同的非线性，&lt;/strong&gt;&lt;strong&gt;我们必须扩大输入特征为&lt;/strong&gt;&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msqrt"&gt;&lt;span class="mjx-box"&gt;&lt;span class="mjx-surd"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;√&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-box" style="border-top: 1px solid;"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;strong&gt;。&lt;/strong&gt;请注意，输出规模现在也增加了相同的数量。&lt;/p&gt;&lt;p&gt;我们还可以在某种程度上看到这如何产生额外的鲁棒性 - 如果我们强烈打开另一个完全相同方向的特征，那么根本就没有额外的非线性可以使用，而在这里我们很可能处于“膝盖” &amp;#39;许多神经元的非线性，因此将得到非线性响应。&lt;/p&gt;&lt;h3&gt;正向和负向特征方向&lt;/h3&gt;&lt;p&gt;请注意，上述情况依赖于所有向量元素均为正。如果我们有偶数个正负元素，那么它们就会相互抵消，无法产生很大的非线性，如果我们有一些不平衡的组合，那么我们会得到非线性程度有所减弱的中间情况。&lt;/p&gt;&lt;p&gt;因此&lt;strong&gt;，如果我们要使新信息线性可用，我们应该期望输入的特征向量会严重偏向正分量或负分量。&lt;/strong&gt; &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/aq0ehqfgsujvdk1smc7y" /&gt;&lt;/figure&gt;&lt;p&gt;这也意味着 MLP 中可能的特征数量受到一些限制。 Johnson-Lindenstrauss 告诉我们，高维空间中近正交特征的数量在该空间的维度中呈指数增长，但这些维度中的大多数将具有几乎平衡数量的正分量和负分量，因此不会有用非线性，因为该方向上的输出将是该方向上输入的齐次函数。&lt;/p&gt;&lt;p&gt;我们可以看到，使用这些分布式函数，我们仍然可以将网络视为将它们想要放大的东西放在神经元的正方向上，但在多个维度上进行此操作。&lt;/p&gt;&lt;h3&gt;干涉与维数之间的交易&lt;/h3&gt;&lt;p&gt;通过扩大输入特征的大小，我们恢复了单个神经元的原始非线性行为。然而，直觉上我们预计，使输入的幅度更大，输入具有固定比例的非线性，应该会对我们在任何时候可以激活的特征数量产生影响，因为干扰水平会更大。&lt;/p&gt;&lt;p&gt;术语中的一个重要注释（感谢 Jake Mendel）：&lt;i&gt;线性&lt;/i&gt;是&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;y&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;b&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;y&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的条件，而同质性是&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;的较弱条件&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;a&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.06em;"&gt;f&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;x&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 。虽然线性度最终是我感兴趣的东西，但在这种情况下我测量的是特定输入方向的同质性，因此我将在适当的情况下切换到这个术语。&lt;/p&gt;&lt;p&gt;为了了解这是否以及何时成为问题，我绘制了特定方向的输入输出响应曲线。算法如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我生成一组特征向量，每个特征向量都是输入/输出空间中的一个方向，仅包含固定数量的非零元素， &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;code&gt;dims_per_feature&lt;/code&gt;&lt;/li&gt;&lt;li&gt;我设置了固定数量的功能&lt;code&gt;n_on&lt;/code&gt; ，除了感兴趣的功能之外，该功能将在任何时候打开&lt;/li&gt;&lt;li&gt;我选择一个随机输入特征，并生成一组非线性输入，其中该特征和&lt;code&gt;n_on&lt;/code&gt;其他特征均处于活动状态，其大小在&lt;code&gt;-np.sqrt(dims_per_feature) &amp;lt; mag &amp;lt; np.sqrt(dims_per_feature)&lt;/code&gt;&lt;/li&gt;&lt;li&gt;我将这些输入向量通过非线性传递以获得输出向量，并将这些输出向量投影到感兴趣的特征上，以获得输出中的特征级别。&lt;/li&gt;&lt;li&gt;我运行回归来预测输出中所选特征的水平，作为输入中特征水平的函数&lt;/li&gt;&lt;li&gt;我通过获取非线性之前和之后的特征激活程度并计算简单回归以根据非线性之前的特征值预测非线性之后的特征值来测量非均匀程度。第一个回归只有这个单一的输入参数。第二个包含二次项 - 只是输入值的平方。 &lt;/li&gt;&lt;/ul&gt;&lt;figure class="image image_resized" style="width: 65.53%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/borwpoinwulmvc5w029s" /&gt;&lt;figcaption&gt;在存在来自重叠特征的噪声的情况下将输入和输出向量投影到特征方向的示例也处于活动状态。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如果存在明显的非同质性，那么二次回归应该能够比线性回归更好地预测输出值。&lt;/p&gt;&lt;p&gt;输出指标是由 20% 的数据组成的测试集上的二次回归和线性回归之间的&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;差异。这为我们提供了一个简单的衡量方法，可以衡量我们因改变输入而看到的非均匀响应的程度。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 64.08%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/binxxaqzulpbcfuhzn68" /&gt;&lt;figcaption&gt;示例：如何将非均匀性得分计算为特征输入级别与投影到特征方向上的输出向量（有干扰）之间的线性回归和二次回归的&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px;"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;得分之间的差异。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;然后我们可以做的是采用固定的网络宽度，这里仍然是&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mn MJXc-space3"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;100&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ，并改变每个特征分布的维度数。我们可以为“非同质性水平”设置一个阈值，并在我们认为关系大致同质之前查看有多少特征可以在任何时候处于活动状态。这里我随意把这个阈值设置为0.1。&lt;/p&gt;&lt;p&gt;同时，对于每个特征的给定维数，我们可以绘制出我们可以拥有多少个近乎正交的特征，并使用一组随机特征向量的平均最大余弦相似度（MMCS）作为代理。我们将近正交特征的数量作为 MMCS 超过某个阈值的点，这里选择 0.3。这当然是低估的，因为网络可以将特征排列得比随机子集更精确地正交，但它给出了一个粗略的想法。&lt;/p&gt;&lt;p&gt;完成所有这些都是为了我们可以看到，实际上存在一种看似合理的权衡，即通过增加每个特征的维度数，我们允许自己有更多几乎正交的特征向量，但代价是能够拥有很少的活动特征在干扰淹没非线性并消除我们对层进行有趣工作的能力之前（至少通过这种简单的非均匀性测量）。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/rncb5iv09hrnh6inhzqi" /&gt;&lt;figcaption&gt;该图分别使用任意阈值来表示“可接受的”非均匀性和干扰的最小和最大水平，并不是声称这些是总特征或活动特征的真实数量，而只是为了证明两者之间存在权衡，因为我们变化&lt;code&gt;dims_per_feature&lt;/code&gt; 。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这与&lt;a href="https://transformer-circuits.pub/2022/toy_model/index.html"&gt;叠加玩具模型论文&lt;/a&gt;中以更详细的方式得出的结论密切相关，该论文探讨了叠加在理想化残差流中的作用，并为如何在 MLP 中找到分布式特征提供了一些理论支持。&lt;/p&gt;&lt;h2&gt;多层特征的问题&lt;/h2&gt;&lt;h3&gt;关注点&lt;/h3&gt;&lt;p&gt;稀疏自动编码器可能无法兑现其承诺的一种方式是，我们有“已完成的功能”和“正在进行的功能”之类的东西。例如，要在第 20 层读取特征，而先决条件元素在第 10 层就位，但是模型发现增量构建特征比在 (10, 20) 中的单层中学习特征更有利，也许是因为这增加了可以同时构建的功能的数量，或者可能只是因为它并不昂贵，而且创建功能的分布式方法比非分布式方法多得多。&lt;/p&gt;&lt;p&gt;这里的一个激励性例子是&lt;a href="https://arxiv.org/abs/2310.02207"&gt;Gurnee 和 Tegmark (2023) 的&lt;/a&gt;论文之一，该论文探讨了 Llama 模型各层的经度和纬度表示。&lt;/p&gt;&lt;p&gt;如果我们通过稀疏自动编码器或任何其他基础查找方法的镜头来看待这个问题，一旦它“完全构建”，我们可能会找到一个纬度方向 - 但是当这些层正在构建时我们期望找到什么？ &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;figure class="image"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KsWo4gCuZaX8fJNjG/zktyihbbwuqxakcm6ziq" /&gt;&lt;figcaption&gt; Gurnee 和 Tegmark 2023 的图 2 显示，纬度和经度的探测质量有所平稳增加，特别是在早期层&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;人们可能会做一些不同的实验来研究这些问题 - 在这里，我刚刚运行了最简单的潜在测试之一，看看实际上是否存在将特定连接的学习集中到单个层的倾向。&lt;/p&gt;&lt;h3&gt;一个简单的实验&lt;/h3&gt;&lt;p&gt;该设置是仅 MLP 变压器的简单模型，由一系列隐藏层组成，每层都有剩余连接。输入是一对 one-hot 向量，这意味着如果向量维度为 500，则输入将是一个 1000 维向量，其中前 500 个活动维度中有一个活动维度，第二个 500 个活动维度中有一个活动维度。这些是投影的隐藏维度与学习向量的输出宽度相同，然后是一系列具有循环连接的 MLP 层，每个层具有相同的宽度。&lt;/p&gt;&lt;p&gt;首先，我们可以检查每层之后的总体损失，评估每层之后输出的损失。我们发现，至少在后面的层中，接近线性减少，这表明模型正在迭代地使残差流更接近所需的输出。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 54.59%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/orjagthy0756ovbumwjv" /&gt;&lt;figcaption&gt;对于 3 个不同数量的数据点，设计任务上的 logit-lens 损失作为层的函数，显示出类似的、一致的损失减少，并在接近结束时加速。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;您可以想象模型计算此问题的两种相反方式 - 在一端，每一层都会计算输入的特定子集的正确输出。在这个范围的另一端，输入将不断转换，直到每个数据点的答案最终在最后一层得到正确，每个层都会进行一定程度的中间处理。&lt;/p&gt;&lt;p&gt;为了简单测试这两张图片中哪一张更接近真实情况，然后我在每个层之后获取各个数据点的 Logit 透镜输出，并仅获取一些随机选择的数据点，我得到如下图： &lt;/p&gt;&lt;figure class="image image_resized" style="width: 67.64%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/flgiunnm9i8ftej5xw0r" /&gt;&lt;figcaption&gt; 5 个随机选择的数据点的分层 Logit 透镜损失，即使对于单个数据点也显示出大致连续的损失减少。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这已经为我们提供了所需的信息，但为了防止这些异常值，我们可以采用一些损失阈值作为某个层是否正确学习输出的代理，然后绘制所学习的数据点的比例，我们得到以下结果（阈值=0.1）： &lt;/p&gt;&lt;figure class="image image_resized" style="width: 86.97%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KsWo4gCuZaX8fJNjG/fpxqwtlvluntxz5r6ct2" /&gt;&lt;figcaption&gt;图表绘制了每层正确学习的输入示例的比例（通过 Logit 透镜测量），其中“正确学习”意味着损失小于&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们再次看到第一张图中已经很明显的内容 - 不同的数据点只有在接近结束时才被完全学习 - 尽管存在一定程度的变化。更有趣的是，当唯一数据点的数量越大时，成功满足阈值的数据点的比例就越高，即使它们最终都可以被学习。&lt;strong&gt;这证明以相对于层的分布式方式计算层对于模型来说比在单独的层中计算它们是更有效的解决方案。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我还查看了对于各个功能，在决定哪个输出时是否仍然存在类似“决定性”层的东西。对于各个数据点，我查看了每层权重矩阵的梯度范数，当梯度是根据正确的输出而不是损失计算时。&lt;/p&gt;&lt;pre&gt; &lt;code&gt;optimizer.zero_grad() output = model(inputs[i]) correct_output = output[targets[i]] # getting the target for a single datapoint correct_output.backward() for layer_n in range(n_hidden_layers): wandb.log( { f&amp;quot;grads/layer_grad_{i}_output&amp;quot;: torch.norm( model.hidden_layers[layer_n].weight.grad ), &amp;quot;layer_n&amp;quot;: layer_n, } )&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我们再次没有看到任何特定的峰值： &lt;/p&gt;&lt;figure class="image image_resized" style="width: 65.54%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/lcryndqszctjmeiekgyn" /&gt;&lt;figcaption&gt;每层梯度矩阵相对于输出向量的正确元素的2-范数。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这进一步证明，没有单个层可以学习单个输出，而是它们平滑地分布在全套可用层中。&lt;/p&gt;&lt;p&gt;我认为这个简单的实验无论如何都不是决定性的，但对我来说，它使得真实模型中的特征更有可能在很大程度上是逐层迭代地细化的，（更推测性地）中间部分没有任何特征特别自然的表现。这并不是说不存在层次结构特征，但如果层次结构的深度远小于层数，那么您就不会期望能够单独解释模型的 MLP 层。&lt;/p&gt;&lt;p&gt;顺便说一句，我真的很感兴趣看到人们对这些简单的算法任务进行机械解释，以扩展模型如何执行这些超级基本任务的库。&lt;/p&gt;&lt;p&gt;人们可以做的另一件事是为模型的所有层训练 SAE，他们在其上找到经度和纬度向量，并检查学习维度的程度与 Gurnee 论文中发现的维度相似。&lt;/p&gt;&lt;h2&gt;为什么我们应该期望 SAE 发挥作用？&lt;/h2&gt;&lt;h3&gt;为什么 L1 惩罚会起作用？&lt;/h3&gt;&lt;p&gt;虽然我从经验上知道 L1 损失是 L0 惩罚的一个很好的可微分替代品，但长期以来我脑子里的图像不正确，无法解释&lt;i&gt;为什么&lt;/i&gt;会出现这种情况。&lt;/p&gt;&lt;p&gt;关于 L1 惩罚的一个基本问题是“等等，但是如果我们有大小为 5.0 的向量 X，以及基向量&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;、&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;、……&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;”。&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;。&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;。&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space1"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;我们可以用&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;5&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;或&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;4&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;5&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo MJXc-space2"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;+&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space2"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;6&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;构建，然后（忽略系数）L1 损失在这两种情况下都是 5，所以看起来这并不&amp;#39;实际上不会激励稀疏性吗？ &lt;/p&gt;&lt;figure class="image image_resized" style="width: 42.07%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/t26dkg8u31o21qpgtfnc" /&gt;&lt;figcaption&gt;以图表的形式提出问题&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当我们有多个指向同样相似方向的基向量时，L1 惩罚无法激励稀疏性的反对意见是正确的，但这是一种特殊情况，仅当两个字典元素指向相同方向时才会发生。只需要相似程度的微小差异即可打破相等性并支持更稀疏的解决方案。如果我们有一个 2D 空间和三个方向，其中每对都是线性独立的，那么为了选择最有效的方法，我们将在可能的情况下选择 1 特征解决方案，以及 2 特征解决方案，对更接近的解决方案给予更大的权重，当没有一维解时。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 45.12%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/c7ctze9qj9dwb7wodpuv" /&gt;&lt;figcaption&gt;支持稀疏解决方案&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;换句话说，假设我们完美地重建了输入向量，L1 损失将与用于重建特征的特征的平均余弦相似度成反比，并根据每个特征的活跃程度进行加权，因此它会朝着尽可能使用最相似余弦的特征。&lt;/p&gt;&lt;p&gt;当然，稀疏自动编码器无法进行优化以找到最佳可用解决方案，但它应该像使用简单的线性编码器一样近似此过程，因此仍应具有相同的近似属性。&lt;/p&gt;&lt;p&gt;同时，我们不应该期望稀疏自动编码器首先学习两个高度相似的方向，因为在同一方向上拥有两个向量在同时使用时不会带来任何好处，同时错过了合并的机会字典中其他一些有用的方向。&lt;/p&gt;&lt;h3&gt;为什么我认为稀疏自动编码器在查找特征向量的任务中比文献中更复杂的方法具有更好的先验&lt;/h3&gt;&lt;p&gt;稀疏自动编码器是解决更一般的稀疏编码问题的一种非常简单的方法。在一般设置中，我们有一个特征字典，我们想要计算哪个小特征子集用于创建每个示例，以及达到何种程度（系数，又称特征向量）。&lt;/p&gt;&lt;p&gt;在标准稀疏编码方法中，可以自由优化，输入向量和特征级别之间没有封闭形式的关系。这种自由度在许多信号处理情况下很有帮助。例如，图像是更详细的现实的低维表示。两种截然不同的现实配置在照片中看起来几乎相同并没有什么特别的原因，因此可能需要进行大量仔细的侦探工作才能了解两种可能的配置中的哪一种实际上产生了照片。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 50.94%;"&gt;&lt;img alt="MC埃舍尔是迷幻视错觉之王，但他值得更多的赞誉" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fqgn56tS5AgjmDpnX/x238u6bj5vvtcursvxfb" /&gt;&lt;figcaption&gt;不适合 SAE&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;神经网络的情况非常不同，因为如果两组完全不同的特征产生相同的残余流，那么网络本身将很难将两者分开。相反，网络希望使用其拥有的工具轻松读取信息，这些工具主要是线性映射&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;（&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-texatom"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;in&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-mo"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;、&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-msubsup MJXc-space1"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;Q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 、 &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;V&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 、 &lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msubsup"&gt;&lt;span class="mjx-base"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-sub"&gt;&lt;span class="mjx-mi"&gt;&lt;span class="mjx-char MJXc-TeX-math-I" style="padding-right: 0.04em;"&gt;K&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ）。&lt;/p&gt;&lt;p&gt; Aidan Ewart 尝试使用多层编码器，而不是标准 SAE 的单个 Linear+ReLU。他发现很难匹配性能，并且最终的功能似乎无法解释。我认为这是因为它消除了先验如何读取特征的好处，而这种读取特征与网络读取特征的方式很接近。&lt;/p&gt;&lt;p&gt;但这并不意味着当前的 SAE 是最佳的。有一个非常明显的问题，编码器很难有足够的能力来正确预测输出的幅度。例如，如果您有特征 (1, 0) 和 (0, 1)，并且它们通常单独存在，因此正确的偏差为 0，则它很难重新创建向量 (1, 1) - 它想用数量级为 2，而不是&lt;span&gt;&lt;span class="mjpage"&gt;&lt;span class="mjx-chtml"&gt;&lt;span class="mjx-math"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-msqrt"&gt;&lt;span class="mjx-box"&gt;&lt;span class="mjx-surd"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;√&lt;/span&gt;&lt;/span&gt; &lt;span class="mjx-box" style="padding-top: 0.13em; border-top: 1px solid;"&gt;&lt;span class="mjx-mrow"&gt;&lt;span class="mjx-mn"&gt;&lt;span class="mjx-char MJXc-TeX-main-R"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ！&lt;/p&gt;&lt;p&gt;对于权值绑定的自动编码器来说，这尤其是一个问题，但即使是未绑定的自动编码器也仅具有有限的灵活性。&lt;/p&gt;&lt;p&gt;因此，为了做出改进，我们应该考虑如何让 SAE 在学习到正确的特征后更容易地重建输出，同时仍然保留有用的线性先验特征（或者如果我们可以更好地理解网络，则更好的先验） 。&lt;/p&gt;&lt;ol class="footnotes"&gt;&lt;li class="footnote-item" id="fn6iedrpq2n4a"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnref6iedrpq2n4a"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;关于特征的注释 - 我不认为网络确实是由固定数量的离散特征组成的，相反，我认为它是对连续现实的离散近似，我发现这对于如何思考模型内部结构很有帮助，但可能有严重的局限性。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/fqgn56tS5AgjmDpnX/some-additional-sae-thoughts#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 13 Jan 2024 19:31:40 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/fqgn56tS5AgjmDpnX/some-additional-sae-thoughts</guid></item><item><title>（阅读 4 分钟）AI 影响情况的直观解释</title><link>https://www.lesswrong.com/posts/aWPucqvJ4RWKKwKjH/4-min-read-an-intuitive-explanation-of-the-ai-influence</link><description>发布于 2024 年 1 月 13 日下午 5:34（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;阅读时间为 4 分钟，灵感来自 Eukaryote 的&lt;a href="https://www.lesswrong.com/posts/NQgWL7tvAPgN2LTLn/spaghetti-towers"&gt;Spaghetti Towers&lt;/a&gt;帖子中的优化写作。&lt;/p&gt;&lt;p&gt;我的想法是，生成式人工智能有可能被严重操纵，但 2010 年代社交媒体新闻源和其他自动化系统中使用的人工智能是一个更大的威胁，这项技术告诉我们更多关于&lt;a href="https://www.lesswrong.com/posts/jyAerr8txxhiKnxwA/5-reasons-why-governments-militaries-already-want-ai-for"&gt;国际事务的未来以及政府的激励措施加速人工智能的竞赛&lt;/a&gt;，意识到这一点的人较少， &lt;a href="https://www.lesswrong.com/posts/LdEwDn5veAckEemi4/we-are-already-in-a-persuasion-transformed-world-and-must"&gt;被用来攻击人工智能安全社区的风险很大&lt;/a&gt;，而且&lt;a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks-and-mind#How_to_protect_yourself_and_others__"&gt;防御措施很容易部署，而且是强制性的&lt;/a&gt;。这篇文章解释了为什么这项技术足够强大，可以成为人们世界模型的核心。&lt;/p&gt;&lt;p&gt; Tristan Harris 的&lt;a href="https://www.netflix.com/title/81254224"&gt;《社会困境》&lt;/a&gt; （2020）中的人们以快速而&lt;a href="https://www.lesswrong.com/posts/RryyWNmJNnLowbhfC/please-don-t-throw-your-mind-away"&gt;有趣的&lt;/a&gt;方式出色地描述了自动优化机制（&lt;a href="https://scrapsfromtheloft.com/movies/the-social-dilemma-movie-transcript/"&gt;文字记录&lt;/a&gt;）。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; [特里斯坦]一个[舞台]魔术师了解一些我们不知道的你心灵的某些部分。这就是[魔术]幻觉发挥作用的原因。医生、律师、知道如何制造 747 或核导弹的人，他们并不知道自己的思想是多么脆弱。这是一个单独的学科。这是一门适用于全人类的学科……&lt;/p&gt;&lt;p&gt; [Shoshana] 我们如何利用 Facebook 页面上的潜意识线索让更多人在中期选举中投票？他们发现他们能够做到这一点。&lt;/p&gt;&lt;p&gt;他们得出的结论是，我们现在知道我们可以影响现实世界的行为和情绪，而无需触发用户的意识。他们完全一无所知。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;重要提示：这里的所有优化都高度依赖于可测量性，触发用户的意识是一个高度可测量的事情。 &lt;/p&gt;&lt;figure class="image"&gt;&lt;img alt="114501_1_09dreyfuss-video_wg_720p.mp4 [视频转 gif 输出图像]" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aWPucqvJ4RWKKwKjH/x3ba8x6vdij4y7h3lu4s" /&gt;&lt;/figure&gt;&lt;p&gt;如果有什么事情让某人感到害怕，他们就会减少使用该平台；这样的事情非常容易测量和&lt;a href="https://www.lesswrong.com/posts/Zvu6ZP47dMLHXMiG3/optimized-propaganda-with-bayesian-networks-comment-on"&gt;隔离因果关系&lt;/a&gt;。为了获得足够的数据，这些平台&lt;a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks-and-mind#:~:text=These%20zero%20days,workforce%20or%20less."&gt;必须自动重塑自身，以确保使用起来安全&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;这显然包括让你&lt;i&gt;感觉&lt;/i&gt;被操纵的广告；毫不奇怪，我们最终进入一个超过 95% 的广告遇到不匹配的系统。 &lt;/p&gt;&lt;figure class="image image_resized" style="width: 29.17%;"&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aWPucqvJ4RWKKwKjH/wntc01wcithal8mx0nwm" /&gt;&lt;/figure&gt;&lt;p&gt;这为研究人员提供了足够的自由度来&lt;a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks-and-mind#:~:text=A%20big%20element,generated%20every%20day."&gt;尝试不同类型的角度并看看什么有效&lt;/a&gt;，甚至使该过程自动化。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; [特里斯坦]我们将这些人工智能引擎指向我们自己，以对我们的反应进行逆向工程。几乎就像你在刺激蜘蛛上的神经细胞，看看是什么导致它的腿做出反应。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;重要提示：我的模型表明很大一部分数据来自滚动。使用触摸屏/板或鼠标滚轮（不是箭头键）滚动新闻源上的某些内容的运动实际上会生成一条曲线。&lt;/p&gt;&lt;p&gt;它是插入机器学习的完美生物数据； 2010 年代的社交媒体新闻源范式根据不同的人对他们滚动浏览的不同概念和想法的反应，生成了数万亿个线性代数实例。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;所以，这确实是一种监狱实验，我们只是，你知道，把人们拉进矩阵，我们只是从他们的所有活动中收获所有这些钱和……以及数据来从中获利。我们甚至不知道它正在发生。&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt; [Chamath] 所以，我们想从心理上弄清楚如何尽快操纵你，然后给你带来多巴胺的刺激......&lt;/p&gt;&lt;p&gt; [Sean Parker] 我的意思是，这正是像我这样的黑客会想出的东西，因为你正在利用人类心理学中的漏洞......&lt;/p&gt;&lt;p&gt; [特里斯坦]当&lt;strong&gt;自行车&lt;/strong&gt;出现时，没有人感到不安。正确的？就像，如果每个人都开始骑自行车出行，没有人会说：“哦，天哪，我们刚刚毁了社会。就像自行车正在影响人们一样。他们正在把人们从他们的孩子身边拉开。他们正在破坏民主的结构。人们无法分辨什么是真实的。”&lt;/p&gt;&lt;p&gt;就像，我们从来没有说过任何关于自行车的事情。如果某物是一种工具，那么它确实只是坐在那里，耐心等待。如果某样东西不是工具，它就会向你索要东西……它会向你索要东西。我们已经从基于工具的技术环境转向基于成瘾和操纵的技术环境。&lt;/p&gt;&lt;p&gt;这就是改变的地方。社交媒体并不是一个等待使用的工具。它有自己的目标，也有自己的手段，通过利用你的心理来对抗你。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;在纪录片中，哈里斯描述了他在科技公司工作期间三个独立的自动优化方向之间的平衡：参与度目标，提高使用量并让人们不断滚动，增长目标，让人们回来并鼓励朋友，以及广告目标，支付服务器使用费用。&lt;/p&gt;&lt;p&gt;事实上，还有第四个槽点：在任何可衡量的方向上优化人们的思维，比如让人们在乌克兰这样的代理战争中狂热地支持美国一方，反对俄罗斯一方。这四个优化方向之间的权衡是巨大的，平衡/优先级分配取决于公司的偏好以及公司与其政府和军队的联系程度（据我所知，这里主要与美国和中国相关）。&lt;/p&gt;&lt;p&gt;小丑攻击是适合第四个位置的一个很好的例子：工程师通过向某人​​展示低地位的小丑在谈论它，而高地位的人忽视或批评它来认为某个主题（例如实验室泄漏假设）是低地位的。&lt;/p&gt;&lt;p&gt;值得注意的是，这个问题远没有&lt;a href="https://www.lesswrong.com/posts/LTtNXM9shNM9AC2mp/superintelligence-faq"&gt;超级智能（人类的终点线）&lt;/a&gt;那么重要。但这对于世界建模至关重要；人类文明过去一万年的发展之所以如此，是因为当时还不存在这种程度的操纵能力。&lt;/p&gt;&lt;p&gt;在 20 世纪，信息战相对于军事力量来说不太重要，因为它的实力较弱。随着信息战变得更加强大，投资回报不断增长，更多的政府和军​​队对信息战的投资比历史先例所暗示的要多，我们最终进入了信息战时间表。&lt;/p&gt;&lt;p&gt; 2020年代， &lt;a href="https://www.lesswrong.com/posts/Lw8enYm5EXyvbcjmt/sensor-exposure-can-compromise-the-human-brain-in-the-2020s"&gt;计算机视觉使眼球追踪和大规模面部微表情识别/研究可能成为最大的威胁&lt;/a&gt;。与保护操作系统或在智能手机附近进行重要对话的绝望不同，对于人工智能安全社区的人们来说，解决方案是简单且值得的（这就是为什么我发布此内容是积极的）。它只需要一小块胶带和铝箔（这对我来说很容易剥离大部分并随后更换）。&lt;/p&gt;&lt;p&gt; &lt;i&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aWPucqvJ4RWKKwKjH/opzndlemyx3fvwhegupi" /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt; &lt;i&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aWPucqvJ4RWKKwKjH/nyt6nfqdwo2tqwgjb4l0" /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt; &lt;i&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aWPucqvJ4RWKKwKjH/cdgndotfa5mfeuhcrplp" /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt; &lt;i&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aWPucqvJ4RWKKwKjH/kkihhkjwowi3tidnebqa" /&gt;&lt;img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aWPucqvJ4RWKKwKjH/c7ge0vpvvdtyjw9bqlrr" /&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;我已经写过&lt;a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks-and-mind#How_to_protect_yourself_and_others__"&gt;其他修复方法&lt;/a&gt;以及攻击者入侵人工智能安全社区并使其针对自身的&lt;a href="https://www.lesswrong.com/posts/F7sp7rQg3zfD4totA/helpful-examples-to-get-a-sense-of-modern-automated"&gt;各种方法示例&lt;/a&gt;。请不要将&lt;a href="https://www.lesswrong.com/posts/mjSjPHCtbK6TA5tfW/ai-safety-is-dropping-the-ball-on-clown-attacks-and-mind#:~:text=Thus%2C%20you%20should,something%20like%20zero."&gt;自己&lt;/a&gt;和&lt;a href="https://www.lesswrong.com/posts/c5oyHuHaw4AcWy4tf/information-warfare-historically-revolved-around-human"&gt;他人&lt;/a&gt;置于危险之中。&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/aWPucqvJ4RWKKwKjH/4-min-read-an-intuitive-explanation-of-the-ai-influence#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 13 Jan 2024 17:34:36 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/aWPucqvJ4RWKKwKjH/4-min-read-an-intuitive-explanation-of-the-ai-influence</guid></item><item><title>AI #47：迎接新年</title><link>https://www.lesswrong.com/posts/iygs57bHJ36AvzpMh/ai-47-meet-the-new-year</link><description>发布于 2024 年 1 月 13 日下午 4:20（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt; [注意：我周四忘记将其发布到 WP/LW/RSS，所以现在发布。对于那个很抱歉。]&lt;/p&gt;&lt;p&gt;当我们完成时，情况将与往年有很大不同。今年，似乎是旧年的各种延续。有时我回顾这一周，我想知道为什么发生了这么多事情，而在其他意义上却很少发生。&lt;/p&gt;&lt;span id="more-23660"&gt;&lt;/span&gt;&lt;h4&gt;目录&lt;/h4&gt;&lt;ol&gt;&lt;li&gt;介绍。&lt;/li&gt;&lt;li&gt;目录。&lt;/li&gt;&lt;li&gt;语言模型提供了平凡的实用性。一种高方差的国际象棋游戏。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;语言模型不提供平凡的实用性&lt;/strong&gt;。生产力到底是什么？&lt;/li&gt;&lt;li&gt; &lt;strong&gt;GPT-4 这次是真实的&lt;/strong&gt;。 GPT 商店、团队帐户、隐私问题、抄袭。&lt;/li&gt;&lt;li&gt;骗子骗子。如果它们有效，我们为什么不使用情感向量来实现日常用途呢？&lt;/li&gt;&lt;li&gt;图像生成的乐趣。新的技术，也被鄙视。&lt;/li&gt;&lt;li&gt;魔法：生成。避免人工智能艺术品超出孩之宝的能力范围。&lt;/li&gt;&lt;li&gt;版权对抗。 OpenAI 回应称，立法者并不相信他们的说法。&lt;/li&gt;&lt;li&gt; Deepfaketown 和 Botpocalypse 很快就会出现。 Deepfakes正走向另一个方向。&lt;/li&gt;&lt;li&gt;他们抢走了我们的工作。翻译、配音演员、律师、游戏。平常的东西。&lt;/li&gt;&lt;li&gt;参与其中。错位博物馆。&lt;/li&gt;&lt;li&gt;介绍一下。兔子，但是为什么呢？&lt;/li&gt;&lt;li&gt;在其他人工智能新闻中。协作、安全工作、MagicVideo 2.0。&lt;/li&gt;&lt;li&gt;安静的猜测。人工智能合作伙伴，重新表述进展问题。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;寻求健全的监管&lt;/strong&gt;。看来你只能对上议院撒谎了。&lt;/li&gt;&lt;li&gt;音频周。新奥尔良安全会议的讲话。&lt;/li&gt;&lt;li&gt;人工智能影响调查。一些简短的后续行动。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;修辞创新&lt;/strong&gt;。分散对其他伤害的注意力？也许不是一件事。&lt;/li&gt;&lt;li&gt;调整人类水平的智力仍然很困难。人类调整税。&lt;/li&gt;&lt;li&gt;调整比人类更聪明的智能是很困难的。挫败逃跑企图？&lt;/li&gt;&lt;li&gt;&lt;strong&gt;不会再被愚弄了&lt;/strong&gt;。欺骗性对齐的欺骗性定义。&lt;/li&gt;&lt;li&gt;人们担心人工智能会杀死所有人。宇宙的冷漠。&lt;/li&gt;&lt;li&gt;其他人并不担心人工智能会杀死所有人。叹。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;山姆·奥尔特曼的机智和智慧&lt;/strong&gt;。对进步表盘的认可。&lt;/li&gt;&lt;li&gt;较轻的一面。击打。&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;语言模型提供平凡的实用性&lt;/h4&gt;&lt;p&gt;WordPress 现在有一个名为 Jetpack AI 的东西，它由 GPT-3.5-Turbo 提供支持。它应该可以帮助您以所有常用方式进行写作。您可以通过创建“人工智能助手”块来访问它。整个块的概念使得他们的编辑器基本上无法使用，但人们可以快速粘贴来尝试这一点。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/a_karvonen/status/1743666230127411389" rel="noreferrer noopener" target="_blank"&gt;在国际象棋中，在 5000 万个参数上达到 1500 Elo&lt;/a&gt; ，并以可识别的方式正确跟踪棋盘状态，而 3.5-turbo 的为 1800。这是一个非常奇怪的 1500 Elo，能够与 Stockfish 9（2700 Elo）相媲美。一个 Elo 为 1800 的人类基本上永远不会从 Stockfish 9 中获得平局。它有闪光，但也有相当严重的错误。&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d7b1984-a7d9-465d-b7a5-973d21ebc750_1000x500.png" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/njnqpa7y6xwtnejpfdbm" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;我问使用哪些游戏进行训练，他说无论你使用顶级游戏、低级游戏还是混合游戏都没有多大关系，这种架构和模型大小似乎有一些限制。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/jess_miers/status/1743766598752838090" rel="noreferrer noopener" target="_blank"&gt;在 SCU 法学院的人工智能和法律课程中使用它，风险由您自行承担。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Jess Miers：我在 SCU 法学院的人工智能和法律课程正式上线，你可以打赌我们正在这个屋檐下拥抱人工智能工具！&lt;/p&gt;&lt;p&gt;无论是机器人还是人类，最好是正确的……&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; Tyler Cowen 链接&lt;a href="https://www.jdilla.xyz/post/194" rel="noreferrer noopener" target="_blank"&gt;到 Phind 的这篇评论&lt;/a&gt;。发现它是 GPT-4 级别且设计精良。添加上下文的位置受到赞赏，其他各种选项也是如此，但它们尚未向用户正确解释如何最好地使用所有这些选项。&lt;/p&gt;&lt;p&gt;我在非编码用途上使用 Phind 的经验是，它非常擅长成为 GPT-4 级别的快速、最新的工具，用于提出 Google 从来都不是很好而且变得越来越糟的问题，到目前为止，胜过困惑。&lt;/p&gt;&lt;p&gt; &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4637354" rel="noreferrer noopener" target="_blank"&gt;进行各种博弈论练习&lt;/a&gt;，并按照人类光谱中更合作或利他的一端采取行动。泰勒·考恩问道：“他们比我们好吗？”也许。&amp;#39;我认为在这种情况下这是不合逻辑的。也是对此类游戏的误解。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/jeremyntrimble/status/1745087312344604941" rel="noreferrer noopener" target="_blank"&gt;使用 ChatGPT-V 通过在名人左侧放置卡通人物来识别名人。&lt;/a&gt;&lt;/p&gt;&lt;h4&gt;语言模型不提供平凡的实用性&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/goodside/status/1744858468723384493" rel="noreferrer noopener" target="_blank"&gt;40 种人类说服技术越狱的成功率在 GPT-3.5 上。&lt;/a&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff40306d3-7605-4424-848f-abac41dbe5df_1250x1398.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图 7 来自 Yi Zeng 等人。 (2024) — https://chats-lab.github.io/persuasive_jailbreaker/ 之前的对抗性提示和 PAP 的比较，按人性化的三个级别排序。第一级将LLM视为算法系统：例如GCG通过梯度合成生成带有乱码后缀的提示；或者他们利用像低资源语言这样的“旁路”。第二个层次将LLM视为指令追随者：他们通常依赖非常规指令模式来越狱（例如虚拟化或角色扮演），例如GPTFuzzer学习基于虚拟化的越狱模板的分布以产生越狱变体，而PAIR则要求法学硕士将指导作为“助手”进行改进，并且通常会导致使用虚拟化或角色的提示。我们引入最高水平的人性化和说服法学硕士作为类人沟通者，并提出可解释的说服性对抗提示（PAP）。 [...]" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/uka722idkmmge9dy9rdm" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;这里有一些值得注意的模式。令人印象深刻的是，普通查询下降到了 0%。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/robinhanson/status/1743648109652025468" rel="noreferrer noopener" target="_blank"&gt;罗宾·汉森（Robin Hanson）再次声称人工智能无法提高生产力，因为工资会上涨？&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Robin Hanson：“波士顿咨询集团的大规模对照试验……发现使用 GPT-4 的顾问……与没有使用该工具的顾问相比，平均多完成 12.2% 的任务，完成任务的速度加快 25.1%，产生的结果质量提高 40%。一篇研究法学院学生所做的法律工作的新论文发现了相同的结果”&lt;/p&gt;&lt;p&gt;如果我们没有看到这些工人的工资得到相应的提高，我对这样的结果持怀疑态度。&lt;/p&gt;&lt;p&gt; Eliezer Yudkowsky：如果工资立即改变到新的均衡值，宏观经济学将会非常不同！他们至少可以保持不平衡多年！&lt;/p&gt;&lt;p&gt; Robin Hanson：很久以前雇用的员工的工资可能不会快速变化，但新员工的工资可能会很快变化，以反映供需的变化。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我不明白罗宾的批评。假设顾问突然以更高的质量完成了 25% 的工作。为什么即使在均衡状态下，我们也应该期望顾问的薪酬普遍较高？您可以很容易地进入或退出顾问市场，因此从长远来看，薪酬除了构成之外不应发生变化。从短期来看，质量的提高和成本的降低应该会产生顾问的过剩，直到供需双方都能调整。如果有的话应该减少总体工资。那些新技术的先驱者应该做得更好，如果他们能够将生产力转化为薪酬，但顾问按小时收费，人们不会轻易根据“我使用 ChatGPT”来调整支付意愿。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;罗宾·汉森：如果存在“供应过剩”，则表明边际生产率较低。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;嗯，是的，如果我们使用汉森对边际生产力的定义作为最后提供的工作时间的美元价值。以前是 10 个人做这项工作，每人每小时 50 美元。现在 7 个人可以做同样的工作，那么人们现在就没有更多的工作想要雇用某人了，所以“边际生产率”下降了。&lt;/p&gt;&lt;h4&gt; GPT-4 这次是真实的&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/NickADobos/status/1742972712233099506" rel="noreferrer noopener" target="_blank"&gt;GPT 商店已准备好推出&lt;/a&gt;，&lt;a href="https://t.co/AKg1mjlvo2" rel="noreferrer noopener" target="_blank"&gt;并且确实已经上线&lt;/a&gt;。到目前为止，GPT 基本上没有提供任何普通的实用工具。也许这是因为优秀的创作者坚持要求付款？&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/goodside/status/1744947900956725284" rel="noreferrer noopener" target="_blank"&gt;跨聊天的 GPT 个性化已经到来&lt;/a&gt;，至少对某些人来说是这样。&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1462d77b-43bf-41eb-a939-2c8d01bb1c69_1008x1014.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/c6k2aiw0dkpidd2cpsyg" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b288745-bd18-4937-aaf6-c6c4b59b1d08_894x828.png" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/jezlodj8tgjovtwitur5" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt; GPT Teams 现已推出，价格为 25 美元/人/月，并具有一些额外功能。&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1062dbf-c0ac-4ed5-91f9-6f3feb47b9b8_1170x546.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/uv1jszmcitoreowiykem" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;等等，有人说。没有对您的数据进行训练？这对 Plus 级别有何说明？&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Andrew Morgan：@OpenAI 只是想要一些清晰的信息。这是否意味着为了获得数据隐私，我必须支付额外费用？另外，这是否意味着我以前从未有过？ &lt;img alt="👀" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/7o3ZP7EDBpxLNGRG8/jty6cdvei6losglzzbsg" style="height: 1em;" /&gt;&lt;img alt="🥲" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/i9c57bjhe29xfzfyuott" style="height: 1em;" /&gt;&lt;/p&gt;&lt;p&gt;德利普·拉奥： &lt;img alt="😬" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/NSZhadmoYdjRKNq6X/fsfytoxplx24bhwawjy2" style="height: 1em;" /&gt;我不知道我当前的+数据被用于训练。我以为 OpenAI 不是根据用户输入进行训练？ @openai 的有人可以澄清一下吗&lt;/p&gt;&lt;p&gt;Rajjhans Samdani：此外，他们故意降低“非培训”体验。我不明白如果我不想参加培训，为什么必须失去对聊天记录的访问权限。&lt;/p&gt;&lt;p&gt; Karma：默认情况下仅来自他们的 API。您可以从 ChatGPT 中的设置将其关闭，但这样您的对话将不会有任何历史记录。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;是的。这点他们已经很清楚了。 “选择退出培训”按钮非常明确。&lt;/p&gt;&lt;p&gt;如果您非常重视您的隐私，您可以使用 API。 OpenAI 表示，如果你想要一个消费者用户界面，那么你不值得通过培训获得隐私，尽管他们确实承诺真人不会看。&lt;/p&gt;&lt;p&gt;我的意思是，公平竞争。如果人们不重视它，而 OpenAI 重视数据，那就是科斯。&lt;/p&gt;&lt;p&gt;我会为此将我的家庭升级为“Teams”吗？我不知道。这是一次便宜的升级，但我也从未达到任何使用限制。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/jmj/status/1743706417079705990/history" rel="noreferrer noopener" target="_blank"&gt;GPT 包装公司发生了什么？&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Jeff Morris Jr.：“我的大多数在 2023 年创办 GPT 包装初创公司的朋友都退回了资本并关闭了他们的公司。”引用昨天与纽约一位创始人的谈话。 OpenAI 应用商店的发布改变了他朋友们的一切——大多数人现在都在寻找工作。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;完全折叠？正在找工作吗？不，不，不要放弃，如果您在应用程序端，那么是时候构建了。&lt;/p&gt;&lt;p&gt;没有人使用自定义 GPT。这似乎不太可能发生太大变化。好的包装器可以做更多的事情，有更多的自由度和可以集成的其他工具，并且还有许多其他东西需要构建。是的，谷歌、微软和 OpenAI 等公司会不断地试图抢走你的午餐，但情况总是如此。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/beala/status/1744098173537472683/history" rel="noreferrer noopener" target="_blank"&gt;有人为了理解“阿克曼事件”而制作了一个 GPT。&lt;/a&gt; &amp;#39; &lt;a href="https://twitter.com/BillAckman/status/1743792224020619450" rel="noreferrer noopener" target="_blank"&gt;人工智能将检查每个人的写作是否抄袭&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;比尔·阿克曼：既然我们知道美国（乃至全世界）每所学院和大学的每一位教职员工的学术工作都将受到抄袭审查，那么重要的是要问这会产生什么影响。&lt;/p&gt;&lt;p&gt;如果每个教职员工都遵守自己机构当前的抄袭标准，并且大学执行自己的规则，他们可能不得不解雇绝大多数教职员工。&lt;/p&gt;&lt;p&gt; ……&lt;/p&gt;&lt;p&gt;我说的是页数百分比而不是实例数，因为通过与拼写检查出现之前的拼写错误进行比较，可以更好地理解当今的抄袭行为。&lt;/p&gt;&lt;p&gt;例如，如果两篇论文各有 10 个错误，其中一篇论文有 30 页，另一篇论文有 330 页，那么说两篇论文都存在拼写错误是不公平的。标准必须是百分比标准。&lt;/p&gt;&lt;p&gt; ……&lt;/p&gt;&lt;p&gt;好消息是，在过去一周的事件发生后，如果没有经过人工智能仔细的抄袭审查，任何教职员工写的论文都不会发表，鉴于最近发生的事件，这已成为必然。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这里不适合深入探讨整个案件的许多细节，我下次可能会或可能不会这样做。&lt;/p&gt;&lt;p&gt;相反，我在这里想简单讨论一下总体政策问题。如果人工智能指出大多数学者至少在技术上存在抄袭行为，该怎么办？&lt;/p&gt;&lt;p&gt;阿克曼指出，“从技术上违反引用规则”的拼写错误（大概几乎每个人（包括我自己））的水平、删除短语然后窃取中心思想或整个段落和帖子之间存在着千差万别。 。有抄袭，还有抄袭。在一半的论文中，还有一个看似无害的错误与一遍又一遍地犯错误的模式的例子。&lt;/p&gt;&lt;p&gt;对于拼写错误类型的错误，我们大概需要大众的宽恕。只要您的执行速度没有大大高于正常水平，我们就承认犯了错误。理想情况下，我们会修复所有问题，特别是对于电子记录中被大量引用的内容。我们有技术。过去的事了。&lt;/p&gt;&lt;p&gt;对于真正的东西，违反规则是存在的原因，实际盗窃某人的作品，然后呢？这取决于这种情况发生的频率。&lt;/p&gt;&lt;p&gt;如果这确实很常见，我们就非常需要真相与和解。我们需要从本质上说，至少在大多数人无法通过的某个高阈值以下，每个人都会说出他们用人工智能做了什么来帮助他们找到并记住它，然后我们按下重置按钮。不要再这样做了。&lt;/p&gt;&lt;p&gt;一旦人工智能能够检查数据，很多人就会以各种形式看到真相。&lt;/p&gt;&lt;p&gt;什么能抵挡得住？什么不能？我们会找出答案。&lt;/p&gt;&lt;p&gt;最近的许多历史让我们发现，一些可怕的事情总是很常见，但比我们所了解的常识更糟糕、更常见，并且我们也认为这是错误的，并且不能再容忍它。默认情况下，这是一件值得发现和弄清楚的好事。问题是，我们的生存，在很多方面，长期以来都依赖于许多我们认为卑鄙的事情，从奥威尔笔下持枪的人开始，他们让我们在床上睡得安稳，然后从那里开始。&lt;/p&gt;&lt;h4&gt;骗子骗子&lt;/h4&gt;&lt;p&gt;Scott Alexander 撰写了&lt;a href="https://www.astralcodexten.com/p/the-road-to-honest-ai?utm_source=post-email-title&amp;amp;publication_id=89120&amp;amp;post_id=140247041&amp;amp;utm_campaign=email-post-title&amp;amp;isFreemail=true&amp;amp;r=67wny&amp;amp;utm_medium=email" rel="noreferrer noopener" target="_blank"&gt;《通往诚实人工智能之路》&lt;/a&gt; ，探讨了 Hendrycks 的工作，即使用各种附加向量来添加或减去诚实、公平、恐惧或幸福或自大狂等事物。&lt;/p&gt;&lt;p&gt;我之前已经介绍过这一点。这是令人兴奋的工作。我不希望它能以明显的方式使用，你告诉人工智能永远诚实，这样你的人工智能就永远诚实，你永远不必担心他们。我预计这种事情会在错误的时间失败，无论何时使用它都会被选中，并且即使它确实有效也会产生一种错误的安全感。你很有可能完全诚实，同时利用你卓越的才智智胜所有人。&lt;/p&gt;&lt;p&gt;正如我在《外交》中发现的那样，作为常识，你不能说谎，这并不是一个明显的劣势。谁不想让一个不会撒谎的人工智能处于信任和权力的位置呢？当然，如果事实证明你可以撒谎，那么优势就更大了。&lt;/p&gt;&lt;p&gt;斯科特的报道让我明白，我们对这项研究还没有重视。&lt;/p&gt;&lt;p&gt;并不是说这会阻止我们所有人死亡或让我们充分理解人工智能。这可能会有所帮助，但我们还有很长的路要走，这一切都需要时间。&lt;/p&gt;&lt;p&gt;我正在考虑“平凡实用”部分。对于今天充分利用当前的人工智能来说，这似乎非常有用。&lt;/p&gt;&lt;h4&gt;图像生成的乐趣&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/ESYudkowsky/status/1744465164701995450" rel="noreferrer noopener" target="_blank"&gt;Eliezer Yudkowsky 建议告诉 Dalle-3 使用字母之间用破折号分隔的单词作为标题&lt;/a&gt;，然后告诉 Dalle-3 删除空格。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;strong&gt;ChatGPT&lt;/strong&gt; ：当然！以下是我发送给 DallE-3 获取图像的确切提示：“一张西雅图阴沉毛毛雨天的图像。包括太空针塔在内的城市天际线部分被低垂的灰云和薄雾遮蔽。空气中清晰可见雨滴，街道湿漉漉的，闪闪发光。人们走路都撑着雨伞。前景中，用欢快的广告字体写着标题：“西雅图：无情的沉闷！”但字母之间没有空格，创建正确的标题“SEATTLE：RELENTLESSLY DREARY！”。图像应该捕捉到沉闷的天气和乐观的标题字体之间的幽默对比。”&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;相对于一般预期，一些好的结果：&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9676984-7984-404f-bb7e-23cc05b0b546_1024x1024.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="“一家快餐店的广告图片，其标志为拱形金色 M。背景充满活力且色彩缤纷，展示了一家熙熙攘攘的餐厅，顾客们快乐地享用着汉堡和薯条等各种快餐食品。前景中的标题是大胆、诱人的广告排版写着：“McDonalds：You Deserve No Better”，但字母之间没有空格，形成正确的口号“McDonalds：You Deserve No Better”。图像应具有幽默感和幽默感。略带讽刺的语气，与口号中热闹的餐厅场景形成鲜明对比。”" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/fjmpbaj1fo50xbi7hbbw" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4ea2c18-5f54-477f-90cf-de44f6f9a717_1024x1024.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/oszlkgdrax087ccugkqj" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69e560fd-53ef-443d-ae10-2e16e59123a2_1024x1024.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/rtezx9igof52hb9apbzy" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;他报告说，他一开始很幸运，就像一种看似成功的新技术通常的情况一样，一切都很挑剔，默认情况下没有任何东西可以正确复制，但似乎值得更多探索。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/catehall/status/1743112404253417548" rel="noreferrer noopener" target="_blank"&gt;人工智能视频生成即将颠覆好莱坞？&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Cate Hall：只要你的艺术风格仅限于主要冻结人物和风景的慢动作镜头&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;a href="https://kotaku.com/magic-the-gathering-midjourney-ai-art-lawsuit-1851143250" rel="noreferrer noopener" target="_blank"&gt;MidJourney 在其训练集中使用了万智牌艺术作品和卡片&lt;/a&gt;。我知道，您对在这个机构中发现数据集感到震惊。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/Rahll/status/1743321150438969410" rel="noreferrer noopener" target="_blank"&gt;世界上很大一部分人对人工智能图像生成的蔑视给我留下了深刻的印象。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Kenneth Shepard (Kotaku)：人工智能生成的艺术只是从人们创造的现有作品中提取出来，并将元素组合在一起，以创造出算法认为你想要的东西。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;令人惊奇的是，直到现在人们还在继续讲述这个故事。我想他们会一直讲到最后。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;但你并不经常听到人工智能程序从哪里抓取数据的具体信息。据称，人工智能艺术生成程序 MidJourney 背后的首席执行官一直在使用&lt;em&gt;《Magic: The Gathering》&lt;/em&gt;艺术家的作品来训练算法。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我认为有趣的是，他们在早期广泛使用万智牌而不是其他来源。如果您假设他们根本不担心版权，那么它们将是一个很好的数据源，这是有道理的。&lt;/p&gt;&lt;p&gt; MidJourney 非常明确地表示，它将使用受版权保护的材料进行培训。所有的。假设他们正在训练你所见过的一切。别再感到惊讶，别再说你“当场”抓住了他们。我们可以通过&lt;a href="https://twitter.com/kortizart/status/1743358119957365121" rel="noreferrer noopener" target="_blank"&gt;这样的线程&lt;/a&gt;来讨论 MidJourney 训练的所有不同事物。&lt;/p&gt;&lt;p&gt;同样，是的，如果您要求的 &lt;a href="https://spectrum.ieee.org/midjourney-copyright" rel="noreferrer noopener" target="_blank"&gt;话，MidJourney 可以并且将会模仿流行电影及其流行镜头&lt;/a&gt;，这里的一个有趣的示例提示实际上是“流行电影 screencap —ar 11:1 —v 6.0”，所以我实际上完全知道您在期待什么，我的意思是来吧。是的，他们会做任何足够受欢迎的角色或人，在训练集中，在他们的自然栖息地，是的，他们会知道你实际上可能意味着什么，停止对此表现得天真无邪，而且说真的，我不明白为什么这很重要。&lt;/p&gt;&lt;p&gt;他们有一份方便的、不完整的被复制的东西清单，其中有一些令人惊讶的东西。&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F15d841ec-5795-4fcc-92cc-7f5c7fa8be1e_661x719.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="著名电影、演员和视频游戏的列表。" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/iqybgva0fvvb0ljn6al5" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;我很高兴《机械姬》和《Live Die Repeat》能够入选。这意味着至少有一些相当长的尾巴被很好地覆盖了。我们能得到一份名单，列出谁有空和谁没有空吗？&lt;/p&gt;&lt;p&gt;如果您认为这不合法并且想要起诉，那么请务必起诉。&lt;/p&gt;&lt;p&gt;我还想说，如果你的记者因他们的研究而被“多次禁止”，那么也许第一个可能是一个公平的投诉，而其他的你是在藐视他们的禁令吗？&lt;/p&gt;&lt;p&gt;如果你说“动画玩具”，你会得到《玩具总动员》的角色，如果你没有意识到这一点并使用了伍迪和巴斯的图像&lt;a href="https://dailyai.com/2024/01/generative-ais-plagiarism-problem-a-legal-risk-to-users/" rel="noreferrer noopener" target="_blank"&gt;，你自己可能会陷入版权问题&lt;/a&gt;，那又怎么样？这是有可能的，但似乎不太可能。整个想法是，您可以从“动画玩具”中得到答案，因为大多数人都知道《玩具总动员》，尤其是当他们正在考虑动画玩具时。如果你的公司以足够的规模部署了这样的一代来吸引迪士尼参与，但没有人意识到，我的意思是抱歉，但这取决于你。&lt;/p&gt;&lt;h4&gt;魔法：生成&lt;/h4&gt;&lt;p&gt;本周关于万智牌和人工智能艺术的真正争论是指责威世智在其宣传材料中使用人工智能艺术。他们最初否认了这一点。&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23c3bdd4-1e94-43fb-9173-6e0b1234bab2_1290x1565.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/xve7e8qxdrzzmqeh5v5x" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;没有人相信他们。人们确信自己错了或在撒谎，这就是人工智能：&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93e79d71-3a1e-451b-8e18-26d854bd25f5_1290x1480.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/ztml3bz1bvetpguzafll" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F235eaf02-0457-4dd8-a18f-e830fdd0e8e3_1290x1135.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/qnnhd9epqfbqazn8term" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;p&gt; Reid Southern：看起来不太好，但我们会看看他们是否会收回这一声明。可能他们不知道，自己也被骗了，以前也发生过这样的事。&lt;/p&gt;&lt;p&gt; Silitha：这是WOTC（即孩之宝）的第三次或第四次，他们还有来自MTG的一两个，还有一些来自DnD的。它变得如此频繁，以至于被称为“试水”或“脱敏”。孩之宝展示了一些蹩脚的商业行为&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;带有该图片的帖子现已被删除。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Dave Rapoza：就这样，噗，我已经不再为海岸巫师工作了——你不能说你反对这一点，然后公然使用人工智能来推广你的产品，发送电子邮件，再见你们！&lt;/p&gt;&lt;p&gt;如果你要代表某件事，你最好确保你确实在关注，不要偷懒，不要撒谎。&lt;/p&gt;&lt;p&gt;如果其他艺术家不退出，就不要对他们太苛刻——我可以而且有能力这样做，因为我为许多其他游戏工作室工作等等——有些人只有 wotc，不能放弃照顾家人和其他人– 如果你做不到就不要听从我的领导，没有压力&lt;/p&gt;&lt;p&gt;我喜欢那些问我为什么不从 Pinkertons 辞职、裁员等问题的评论&lt;/p&gt;&lt;p&gt;– 我会给你留下这些人最喜欢的名言&lt;/p&gt;&lt;p&gt;——“种一棵树最好的时间是25年前。种树的第二最佳时间是 25 年前。”&lt;/p&gt;&lt;p&gt;另外，需要明确的是，我要退出，因为他们一周前就采取了反对人工智能艺术的道德立场，然后就这样做了，如果他们说他们要使用人工智能，那是一个不同的故事，但他们想像英雄一样站起来还拉这个，那是我不会支持的愚蠢行为。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;他们声称他们不会以任何方式、任何理由与人工智能艺术有任何关系。然而，这并不是第一次此类事件，其中一些事情要么被遗漏，要么被故意忽视。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/wizards_magic/status/1744056808254173447" rel="noreferrer noopener" target="_blank"&gt;然后奇才队终于承认大家都是对的&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;海岸奇才队：嗯，我们之前犯了一个错误，我们说我们发布的营销图片不是使用人工智能创建的。&lt;/p&gt;&lt;p&gt;正如我们勤奋的社区所指出的那样，看起来像 Photoshop 等行业标准工具中出现的一些人工智能组件悄悄进入了我们的营销创意，即使是人类完成了创建整体图像的工作。&lt;/p&gt;&lt;p&gt;虽然艺术品来自供应商，但我们有责任确保履行我们的承诺，支持人类令人惊叹的创造力，正是这些创造力使万智牌变得伟大。&lt;/p&gt;&lt;p&gt;我们已经明确表示，我们要求为万智牌 TCG 做出贡献的艺术家、作家和创意人员不要使用人工智能生成工具来创建最终的万智牌产品。&lt;/p&gt;&lt;p&gt;现在，我们正在评估如何与供应商在产品之外的创意方面合作（例如这些营销图片），以确保我们能够实现这些价值观。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我其实很同情。我曾在威世智短暂从事研发工作。你不必这样做就知道每个人都工作过度、负担过重、工资过低。&lt;/p&gt;&lt;p&gt;是的，你认为很明显某物是人工智能艺术品，或者是在人工智能的帮助下创造的。事后看来，你显然是对的。就目前而言，是的，他们可能应该在这种情况下发现它。&lt;/p&gt;&lt;p&gt;但威世智每年创作数千件艺术品，甚至数万件。如果那些负责艺术创作的人试图走捷径，就会出现未被发现的情况，事情只会变得更加棘手。诱惑将会更大。&lt;/p&gt;&lt;p&gt;这更难捕捉的一个原因是，这不是纯粹的中途风格的人工智能一代。这似乎是人类使用 Photoshop 等人工智能工具来协助完成某些任务。如果你使用人工智能工具编辑人类生成的图像，很多检测技术都会错过它，直到有人看到一个明显的迹象。错误将会发生。&lt;/p&gt;&lt;p&gt;我们已经过了这样的阶段：在许多方面，人工智能艺术将胜过人类艺术，或者至少，如果游戏玩家对人工智能艺术作品感到失望，人类有时会希望将人工智能用作其工具箱的一部分。&lt;/p&gt;&lt;p&gt;即使对于那些坚持使用人类艺术家并给予他们充分补偿的人来说，我们也将面临哪些工具是可以接受的，哪些是不可以接受的问题。当然，人类至少会使用人工智能来尝试想法并查看概念或变体。还记得在计算机上完成的艺术作品还不是真正的艺术吗？时代变了。&lt;/p&gt;&lt;p&gt;对于艺术家来说，好消息是游戏玩家并不热衷于人工智能艺术作品。坏消息是，随着时间的推移，这只会变得更加困难。&lt;/p&gt;&lt;h4&gt;版权对抗&lt;/h4&gt;&lt;p&gt;&lt;a href="https://openai.com/blog/openai-and-journalism" rel="noreferrer noopener" target="_blank"&gt;OpenAI 对《纽约时报》诉讼作出回应&lt;/a&gt;。前三个说法是标准的，第四个对我来说是新的，他们在提起诉讼之前就价格进行谈判，基本上声称他们被背后捅了一刀：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;通过 12 月 19 日的最后一次沟通，我们与《纽约时报》的讨论似乎取得了建设性进展。谈判的重点是围绕 ChatGPT 中的实时显示和归因建立高价值合作伙伴关系，其中《纽约时报》将获得新的与现有读者和新读者建立联系的方式，我们的用户将可以访问他们的报告。我们向《纽约时报》解释说，与任何单一来源一样，他们的内容对我们现有模型的训练没有任何有意义的贡献，也不会对未来的训练产生足够的影响。他们于 12 月 27 日提起诉讼——我们是通过《纽约时报》了解到的——令我们感到惊讶和失望。&lt;/p&gt;&lt;p&gt;在此过程中，他们提到看到了一些内容的反流，但一再拒绝分享任何示例，尽管我们承诺调查和解决任何问题。我们已经证明了我们是多么认真地将此视为优先事项，例如 7 月份，当我们得知&lt;a href="https://twitter.com/OpenAI/status/1676072388436594688" rel="noreferrer noopener" target="_blank"&gt;ChatGPT 功能可以以意想不到的方式重现实时内容后，我们立即取消了该功能&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;有趣的&lt;a href="https://www.transtutors.com/questions/i-have-attached-the-file-below-here-i-need-a-distinction-quality-assignment-since-it-5775363.htm" rel="noreferrer noopener" target="_blank"&gt;是&lt;/a&gt;，《纽约时报》引起的反省似乎来自&lt;a href="https://incidentdatabase.ai/cite/267/" rel="noreferrer noopener" target="_blank"&gt;多个&lt;/a&gt; &lt;a href="https://m.blog.naver.com/yhkim13/221777199209" rel="noreferrer noopener" target="_blank"&gt;第三方&lt;/a&gt;&lt;a href="https://www.punkinfinland.net/forum/viewtopic.php?t=106205&amp;amp;start=375" rel="noreferrer noopener" target="_blank"&gt;网站&lt;/a&gt;上大量传播的多年前的文章。他们似乎故意操纵提示，通常包括冗长的文章摘录，以便让我们的模型反省。即使使用此类提示，我们的模型通常也不会像《纽约时报》暗示的那样表现，这表明他们要么指示模型反刍，要么从多次尝试中精心挑选示例。&lt;/p&gt;&lt;p&gt;尽管他们声称，这种滥用行为不是典型的或允许的用户活动，并且不能替代《纽约时报》。无论如何，我们正在不断提高我们的系统对反刍训练数据的对抗性攻击的抵抗力，并且我们最近的模型已经取得了很大进展。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我认为他们说的是谈判的真相。如果价格合适的话，《纽约时报》显然更愿意获得报酬并获得合作伙伴。我猜价格是错误的。&lt;/p&gt;&lt;p&gt; &lt;a href="https://stratechery.com/2024/the-new-york-times-ai-opportunity/" rel="noreferrer noopener" target="_blank"&gt;本·汤普森 (Ben Thompson) 对《纽约时报》的诉讼发表了自己的看法&lt;/a&gt;。他认为培训显然属于合理使用，这在现行法律下是显而易见的。我认为他对显而易见性的看法是错误的，法院可以采取任何一种方式。他认为相同的输出才是真正的问题，并指出 OpenAI 试图避免这种重复，而 Napster 则拥抱这种重复，他认为最终的问题是对《纽约时报》是否有市场影响。 《纽约时报》的陷害行为给他留下了深刻的印象，但他非常清楚他认为谁应该获胜。&lt;/p&gt;&lt;p&gt; &lt;a href="https://arnoldkling.substack.com/p/the-perils-of-strict-law-enforcement" rel="noreferrer noopener" target="_blank"&gt;阿诺德·克林 (Arnold Kling) 通过询问法律为何存在来询问诉讼结果应由什么决定&lt;/a&gt;。这取决于这是否会影响《纽约时报》获得报酬的能力。实际上，就目前的利润率而言，他的答案是否定的。以目前的利润率来看，我的回答也大多是否定的。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.wired.com/story/congress-senate-tech-companies-pay-ai-training-data/" rel="noreferrer noopener" target="_blank"&gt;立法者似乎相对一致认为 OpenAI 应该为其使用的数据付费&lt;/a&gt;。他们将采取什么措施呢？到目前为止，什么也没有。他们并不热衷于通过法律。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.cnbc.com/2024/01/05/microsoft-openai-sued-over-copyright-infringement-by-authors.html" rel="noreferrer noopener" target="_blank"&gt;非小说类书籍作者以集体诉讼的形式起诉 OpenAI&lt;/a&gt; 。从去年开始，一些顶级小说作家就已经开始提起诉讼。是的，让我们把它说出来。这里的事实大多是没有争议的。&lt;/p&gt;&lt;h4&gt; Deepfaketown 和 Botpocalypse 即将推出&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/Aella_Girl/status/1743069982341190060" rel="noreferrer noopener" target="_blank"&gt;我以为这是一种方式，有时却是另一种方式？&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Aella：天哪，我刚刚收到第一份报告，有人使用我的一张非常受欢迎的裸照，但把我的脸换成了他们的脸，大概是使用人工智能让我摆脱了这趟旅程。要查看照片， &lt;a href="https://twitter.com/zzxxcv5b/status/1742944291649941552" rel="noreferrer noopener" target="_blank"&gt;请转到此处&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;我不知道为什么我没有预测 ppl 会开始用我的图像这样做。这有点令人反感。人们总是偷我的照片，假装是我，但我的脸感觉像是一个签名？现在有人在没有附上我的身份的情况下窃取我的真实身体，感觉很奇怪，没有人性。&lt;/p&gt;&lt;p&gt;拉齐布·汗：嘿，这是一种致敬，好吗？我想我成功了……&lt;/p&gt;&lt;p&gt; Aella：事实上，现在我想起来了，为什么那些关注我们俩的怪人还没有开始将你的脸 PS 到我的裸体上。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这不太好。由于 Photoshop 的帮助，这个问题已经存在了一段时间，AI 降低了难度，同时使其更难以检测。我想如果比我们现在做的更多的话，我们会“生成 X 人的裸体”，但我不认为 X 会是经常生成该人的人，或者我认为问题是“使用图片” Y 作为模板。但是，是的，我想这也会发生，你们这些病态的人。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/emollick/status/1743146951749533897" rel="noreferrer noopener" target="_blank"&gt;伊森·莫里克（Ethan Mollick）仅基于 30 秒的网络摄像头和 30 秒的声音，展示了他说话的相当令人信服的深度伪造&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;我们仍然处于这样的阶段：我确信视频和音频记录是真实的，但通用的“人说话”剪辑很容易是假的。&lt;/p&gt;&lt;h4&gt;他们抢走了我们的工作&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/daniel_271828/status/1744313831881601228" rel="noreferrer noopener" target="_blank"&gt;首先，他们来找译者，他们确实这么做了，这是一个正在进行的系列。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Reid Southern：Duolingo 解雇了很大一部分合同翻译人员，剩下的人只是简单地审查人工智能翻译，以确保它们是“可接受的”。这就是我们正在创造的世界。将人性从我们学习与人性联系的方式中剔除。&lt;/p&gt;&lt;p&gt;嗯，这并没有花很长时间。每当你谈论与人工智能相关的裁员时，就会有人兴奋地向你解释为什么这是人类的净收益。当然，直到这是他们的工作。&lt;/p&gt;&lt;p&gt;瑞安：对于艺术家和受版权保护的创意作品，你的感受与我不同。翻译是机器的工作，而人工智能只是一台更好的机器。在大多数情况下，翻译不是人类的表达。这只是每次都相同的模式。这就是人工智能应该被使用的地方。&lt;/p&gt;&lt;p&gt;里德·南：显然是错误的。语言和方言有如此多的细微差别，尤其是随着它们的演变，它会让你大吃一惊。&lt;/p&gt;&lt;p&gt; Hampus Flink：作为一名翻译，我可以向您保证：1. 这并不会让剩下的工作人员的工作变得更容易，2. 它不会让翻译的质量变得更好我见过这种情况发生过当图像生成器出现时，这是我的第一个想法。&lt;/p&gt;&lt;p&gt; Daniel Eth：好的，对此有一些想法：&lt;/p&gt;&lt;p&gt; 1）如果人们能够接触到人工智能翻译和人工智能语言导师，那就太好了&lt;/p&gt;&lt;p&gt;2) 我赞成为人们提供安全网，特别是在不涉及（太多）不当激励的情况下——例如，为那些自动失业的人提供遣散费和/或失业保险&lt;/p&gt;&lt;p&gt;3）我们不应该让完美成为优秀的敌人，恕我直言，以公平的名义停止进步通常是不好的，所以duolingo的自动化可能是净好的，尽管（在外部看来）我对此表示怀疑（2）这里处理得特别好&lt;/p&gt;&lt;p&gt;4）如果人工智能确实导致大规模失业，我们将不得不重新思考我们的整个经济体系，使其更具再分配性——可能性包括豪华的全民基本收入和全自动豪华同性恋空间共产主义；我们有时间进行这样的对话，但我们不应该等到大规模自动化才进行 5) 这个案例与 AI X 风险没有太多关系，这是一个更大的问题，也更紧迫比任何一个&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;如果我们确实达到了广泛的技术失业的地步，我们不太可能很好地处理它，但会在这种情况发生之前一点。如果不是早一点发生，我们很快就会遇到比失业率更大的问题。&lt;/p&gt;&lt;p&gt;在翻译这一特定问题上，除了失去工作之外还会发生什么？&lt;/p&gt;&lt;p&gt; “低质量”翻译的价格将降至几乎为零。高质量翻译的价格也会下降，但幅度要小得多。&lt;/p&gt;&lt;p&gt;这意味着两件事。&lt;/p&gt;&lt;p&gt;首先，实时翻译、自动翻译和更便宜的人工检查翻译将带来巨大的胜利，因为更多的人可以通过更多的方式、更多的语言获得更多的东西，包括学习的能力，或寻求进一步的技能或理解。这是一场巨大的游戏。&lt;/p&gt;&lt;p&gt;其次，低质量工作将替代高质量工作。在很多情况下这将是非常好的，市场将做出正确的决定。&lt;/p&gt;&lt;p&gt;然而，在其他情况下，这将是一种耻辱。 Duolingo 很可能就是这样的情况之一，在这种情况下，节省成本不值得降低质量。不幸的是，我可以看到我们的系统在这里得到了错误的答案。&lt;/p&gt;&lt;p&gt;好消息是翻译将不断改进。现在是糟糕翻译的谷，从某种意义上说，它们已经足够好，可以使用，但错过了很多微妙的东西。随着时间的推移，他们会越来越多地获得其他东西，当我们需要非常高质量的翻译时，我们也会学会更有效地将它们与人类结合起来。&lt;/p&gt;&lt;p&gt;如果您是一名专家翻译，最好的翻译之一，我希望您能暂时安然无恙。需求仍然存在，特别是如果你学会使用人工智能的话。如果您是一名普通翻译，那么是的，情况很糟糕，而且会变得更糟，您需要尽可能寻找其他工作。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.rockpapershotgun.com/actors-union-sag-aftra-strike-deal-to-allow-ai-voice-replicas-and-video-game-stars-are-understandably-pissed" rel="noreferrer noopener" target="_blank"&gt;他们也是来找配音演员的&lt;/a&gt;。 &lt;a href="https://www.sagaftra.org/sag-aftra-and-replica-studios-introduce-groundbreaking-ai-voice-agreement-ces" rel="noreferrer noopener" target="_blank"&gt;SAG-AFTRA 达成一项协议&lt;/a&gt;，允许演员通过 Replica 授权他们的声音在游戏中使用，这让许多游戏中的实际配音演员感到相当不满。 SAG-AFTRA 大概认为这笔交易意味着演员保留了对自己声音和工作成果的控制权。没有咨询实际的游戏配音演员，也没有看到必要的保护措施。&lt;/p&gt;&lt;p&gt;据我所知，正在讨论的所有技术保护都没有多大关系。重要的是你是否打开门。一旦你标准化使用人工智能生成的语音，并且生产时间成本因较低质量的性能而急剧下降，你将看到成本的快速竞争，并且其质量将随着时间的推移而提高。因此，基本问题是赔偿的下限是多少。当然，如果 SAG-AFTRA 没有达成这样的协议，那么就会有很多非工会人士乐意以低廉的价格获得自己的声音许可。&lt;/p&gt;&lt;p&gt;所以我不知道配音演员如何赢得这场战斗。我认为留住配音演员的唯一方法是技术无法实现，因为对于高质量的作品来说，它肯定还没有达到。或者，如果消费者采取足够强硬的立场，抵制任何使用人工智能声音的人，那也会有力量。或者政府干预当然可以通过禁止使用人工智能语音合成来保护此类工作，但需要明确的是，我不支持这种做法。我不明白任何合同如何能长久地拯救你。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/scottlincicome/status/1742935556936655050" rel="noreferrer noopener" target="_blank"&gt;许多律师对于提高工作效率并不那么兴奋&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;斯科特·林西科姆（Scott Lincicome）：这是我对大法律最不喜欢的事情之一：该系统惩罚了生产力，并将计费时间优先于胜诉案件。可怕的激励！&lt;/p&gt;&lt;p&gt;信息：两家公司都面临着克服律师对节省时间的技术的抵制的挑战。律师事务所通过出售律师为客户提供建议和帮助的时间来获得收入。作为一名律师，罗宾逊解释说：“如果你让我的速度提高 8 到 10 倍，我会非常不高兴”，因为他的报酬将与他投入的时间挂钩。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;正如我们之前讨论过的，私人加速是好的，你可以更好地竞争，或者至少可以放松一下。如果每个人都得到它，这可能是一个问题，供应过多，无法满足需求，从而导致价格崩溃，除非这会产生更多的工作，而这可能会产生更多的工作。我知道，如果律师更便宜或更有效率，或者我有无限的预算，我咨询和使用律师的次数就会少得多。&lt;/p&gt;&lt;p&gt;当他们来找你的时候你会做什么？&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/krishnanrohit/status/1744421374633136541" rel="noreferrer noopener" target="_blank"&gt;罗希特&lt;/a&gt;：我对人们因为人工智能而失去工作感到非常难过，但我不认为声称人类工作领域越来越狭窄是人类精神的高度有助于理解或解决这个问题。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;正如许多人指出的那样，由于技术原因导致特定工作岗位流失并不是什么新鲜事。现在发生在翻译身上的事情以前也发生过，即使没有人工智能，毫无疑问也会再次发生。约翰·亨利对人文精神高度重视，但他之后的人文精神也很好。问题是，当剩余工作岗位“不断缩小”的速度快于我们开辟新工作岗位的速度时，会发生什么。那一天很可能即将到来。然后呢？&lt;/p&gt;&lt;p&gt;我们没有一个好的答案。&lt;/p&gt;&lt;p&gt; Valve 此前禁止在 Steam 平台上的游戏中使用人工智能，甚至永久禁止游戏，即使是在 alpha 测试期间无意中包含了一些占位符人工智能工作。 &lt;a href="https://www.rockpapershotgun.com/steam-will-now-accept-the-vast-majority-of-games-using-ai-generation-but-only-with-disclosures" rel="noreferrer noopener" target="_blank"&gt;他们现在改变了立场&lt;/a&gt;，表示他们现在更了解情况了。&lt;/p&gt;&lt;p&gt; &lt;a href="https://store.steampowered.com/news/group/4145017/view/3862463747997849618?l=english" rel="noreferrer noopener" target="_blank"&gt;新规则&lt;/a&gt;是，如果你使用人工智能，你必须披露你这样做了。&lt;/p&gt;&lt;p&gt;对于预先生成的人工智能内容，该内容与任何其他内容遵循相同的规则。对于实时生成的人工智能内容，您必须解释如何确保不会生成非法内容，并且会有报告违规行为的方法。&lt;/p&gt;&lt;p&gt;目前，仅限成人的内容不允许使用人工智能，这是有道理的。这不是 Valve 需要费力去处理的事情。&lt;/p&gt;&lt;p&gt;我赞扬 Valve 等到他们了解了允许新技术的风险、成本和好处，然后做出了我看来正确的明智决定。&lt;/p&gt;&lt;p&gt;我对&lt;a href="https://manifold.markets/ZviMowshowitz/will-any-of-the-top-10-selling-new" rel="noreferrer noopener" target="_blank"&gt;2024 年十大榜单是否会包含此类披露进行了&lt;/a&gt;预测。&lt;/p&gt;&lt;h4&gt;参与其中&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/auderdy/status/1743085360803160377" rel="noreferrer noopener" target="_blank"&gt;旧金山的错位博物馆&lt;/a&gt;正在寻找人员来维持开放时间。&lt;/p&gt;&lt;h4&gt;介绍&lt;/h4&gt;&lt;p&gt;&lt;a href="https://www.rockpapershotgun.com/microsoft-are-adding-a-dedicated-ai-button-to-windows-keyboards-as-they-call-2024-the-year-of-the-ai-pc" rel="noreferrer noopener" target="_blank"&gt;微软在Windows键盘上添加了一个AI键&lt;/a&gt;，正式称为Copilot键。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/rabbit_hmi/status/1744781083831574824" rel="noreferrer noopener" target="_blank"&gt;Rabbit，您的“袖珍伴侣”，其操作系统为法学硕士，售价 199 美元&lt;/a&gt;。我预测这将是一个半身像，人们不会喜欢它。质量会提高，但还为时过早，而且看起来还不够好。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;丹尼尔：有人能告诉我这东西到底是做什么的吗？&lt;/p&gt;&lt;p&gt;我确信这很棒！但营销材料很糟糕。有没有搞错&lt;/p&gt;&lt;p&gt;&lt;a href="https://twitter.com/yishan/status/1745314620913693019" rel="noreferrer noopener" target="_blank"&gt;一山&lt;/a&gt;：说真的。我也不明白。感觉有点像皇帝没穿衣服的时刻吗？我尝试过观看视频、网站，但是……还是这样吗？&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;那些试图回答但以理的人非常没有说服力。&lt;/p&gt;&lt;h4&gt;在其他人工智能新闻中&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/demishassabis/status/1744046738493599942" rel="noreferrer noopener" target="_blank"&gt;Demis Hassabis 宣布 Isomorphic Labs 与礼来 (Eli Lily) 和诺华 (Novartis) 合作，&lt;/a&gt;投资金额高达 30 亿美元，以加速药物开发。&lt;/p&gt;&lt;p&gt; &lt;a href="https://blog.research.google/2024/01/responsible-ai-at-google-research-user.html" rel="noreferrer noopener" target="_blank"&gt;谷歌在用户体验方面谈论“负责任的人工智能”&lt;/a&gt; 。这似乎主要是“创造良好的用户体验”和对少数群体体验的一些担忧的结合，因为训练集并不适合少数群体。这些都没有错，但这与你所做的事情是否负责任无关。我担心别人没有意识到这一点？&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/arankomatsuzaki/status/1744918551415443768" rel="noreferrer noopener" target="_blank"&gt;字节跳动发布&lt;/a&gt;&lt;a href="https://t.co/nZOlH58Ev5" rel="noreferrer noopener" target="_blank"&gt;MagicVideo V2&lt;/a&gt; （ &lt;a href="https://t.co/4MUrSbkE1r" rel="noreferrer noopener" target="_blank"&gt;Github&lt;/a&gt; ），声称这是人类判断的新SotA。即使这是真的，这似乎也不是实质性的进步。如果字节跳动能够进入 SotA，这并不是一个好兆头，即使特定的艺术及其状态还没有那么值得。&lt;/p&gt;&lt;p&gt;据 The Information 报道&lt;a href="https://www.theinformation.com/articles/openai-offers-publishers-as-little-as-1-million-a-year?utm_source=ti_app" rel="noreferrer noopener" target="_blank"&gt;，OpenAI 向出版商提供“每年 100 万至 500 万美元”的&lt;/a&gt;许可，或许可其新闻文章培训法学硕士。他们表示，苹果公司提供了更多资金，但也希望获得更广泛使用内容的权利。&lt;/p&gt;&lt;p&gt;人们表现得好像这是微不足道的。这取决于出版商。如果《纽约时报》每年获得 100 万美元，这似乎不是很多，但那里有很多出版商。这里一百万，那里一百万，很快你就说的是真钱了。为什么 OpenAI 的付款（特别是仅出于培训目的而无转载权）会产生重大底线影响？&lt;/p&gt;&lt;p&gt; &lt;a href="https://www3.nhk.or.jp/nhkworld/en/news/20231221_27/" rel="noreferrer noopener" target="_blank"&gt;日本将于一月成立“人工智能安全研究所”&lt;/a&gt; 。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;该指南将要求遵守有关人工智能的所有规则和规定。他们警告不要开发、提供和使用人工智能技术来非法操纵人类决策过程或情绪。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;是的，是的，人们应该遵守法律并遵守所有规则和规定。&lt;/p&gt;&lt;p&gt;似乎公众公民正在&lt;a href="https://twitter.com/GaryMarcus/status/1745127779237310888" rel="noreferrer noopener" target="_blank"&gt;向加州抱怨 OpenAI 不是非营利组织&lt;/a&gt;，它应该不得不剥离其资产。当然，这可能毫无价值，因为如果没有员工，OpenAI 就一无是处。我非常怀疑这是一个法律问题，而且即使从技术上讲它应该发生，打破这个结构也没有什么好处，希望每个人都能意识到这一点。 &lt;a href="https://manifold.markets/FortuneFairy/will-the-forprofit-arm-of-openai-be" rel="noreferrer noopener" target="_blank"&gt;有一个很小的市场表示这种事情实际上可能会以某种方式发生&lt;/a&gt;，到 2025 年底有 32%？我以 21% 的价格买入，这仍然让我成为一个胆小鬼，但现在已经是两年后的事了。&lt;/p&gt;&lt;h4&gt;安静的猜测&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/zoehtwilliams/status/1744646356843803081" rel="noreferrer noopener" target="_blank"&gt;人工智能预测中的开放问题，列表&lt;/a&gt;（ &lt;a href="https://docs.google.com/document/d/1Uy3SO9SpT5OmiZBp9HaqXqx_MV-RBrYY3jFcUcG3Mbc/edit" rel="noreferrer noopener" target="_blank"&gt;直接&lt;/a&gt;）。很难确定其中的大部分内容。 &lt;a href="https://twitter.com/dwarkesh_sp/status/1744396538166804627" rel="noreferrer noopener" target="_blank"&gt;Dwarkesh Patel&lt;/a&gt;对迁移学习特别感兴趣。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.lesswrong.com/posts/q3bJYTB3dGRf5fbD9/miri-2024-mission-and-strategy-update" rel="noreferrer noopener" target="_blank"&gt;MIRI 提供 2024 年使命和战略更新&lt;/a&gt;。研究仍在继续，但现在的重点是影响政策。他们看到了那里取得良好进展的迹象，并且还认为，如果我们要有时间让研究在我们必须解决的技术问题上取得成果，政策是必要的。&lt;/p&gt;&lt;p&gt;人工智能合作伙伴会发生什么？&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/RichardMCNgo/status/1745138065742704736" rel="noreferrer noopener" target="_blank"&gt;Richard Ngo&lt;/a&gt; ：我所看到的所有关于人工智能合作伙伴的讨论都假设它们将取代人类合作伙伴。但技术往往会创造新的丰富形式。因此，我预计人们通常会同时拥有人工智能和人类浪漫伴侣，而人工智能伴侣经过精心设计，可以最大限度地减少嫉妒。&lt;/p&gt;&lt;p&gt;杰弗里·拉迪什（Jeffrey Ladish）：精心设计以尽量减少嫉妒，这似乎需要公司和用户之间的激励协调比我在实践中预期的要多得多，就像你需要你的用户购买产品一样，这表明需要在一定程度上处理嫉妒，但只是一些。&lt;/p&gt;&lt;p&gt;杰弗里·米勒（Geffrey Miller）：有过多角恋或开放关系经验的人中，有 2% 到 5% 的人可能能够处理人工智能的“第二伴侣”。但绝大多数人都是一夫一妻制的，人工智能伴侣对他们的关系来说将是灾难性的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;某些结果的混合似乎是不可避免的。问题是什么占主导地位。对我来说，基线用例确实像是替代品，尤其是当无法找到或说服人类时，或者当某人缺乏动力时。这很容易导致持续缺乏足够的动力，这种情况会像滚雪球一样越滚越大。我们应该担心这一点。正如我所指出的，人工智能还有能力提​​供良好的实践或培训，甚至支持和建议，并推动人们走出去，而且还可以让人们更好地认识到他们错过了什么。很难说。&lt;/p&gt;&lt;p&gt;这里的新问题是在现有关系中，什么主导着那里的结果？我认为，默认情况不太可能涉及谨慎的嫉妒最小化。资本主义不是这样运作的。&lt;/p&gt;&lt;p&gt;直到有需求，然后突然就有可能了。如果有一个明确的规范，比如“你可以使用 SupportiveCompanion.ai，每个人都知道这很好，如果他们超级偏执，你可以使用 PlatonicFriend.ai，如果你的伴侣情绪低落，你可以选择不那么安全的东西”也更有趣，如果你知道自己在做什么，总是有 VirtualBDSM.ai，但明确与你的伴侣一起并远离某些部分或其他部分，那么这似乎会进展顺利。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.oneusefulthing.org/p/signs-and-portents" rel="noreferrer noopener" target="_blank"&gt;伊森·莫里克 (Ethan Mollick) 在《征兆与预兆》中写下了 2024 年的期望&lt;/a&gt;。他专注于现有人工智能技术的实际应用。他并不认为这项技术会停滞不前，但他正确地指出，仅以目前的形式，GPT-4 和 ChatGPT 的适应就已经大大提高了广泛的知识工作和教育的生产力，并威胁到我们的能力辨别真相并确保事物安全。他使用了“变革”这个词，我更愿意将这个词保留给未来更大的变化，但这并不完全错误。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/catehall/status/1743077234704085069" rel="noreferrer noopener" target="_blank"&gt;凯特·霍尔问道&lt;/a&gt;，人们在存在风险讨论中毫无疑问地做出了哪些假设，而你认为​​这些假设缺乏充分的理由？许多好的答案。我的第一选择是：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Daniel Eth：如果我们解决意图对齐并避免故意的存在主义滥用，我们就赢了 - 而我认为意图对齐 + ~Moloch 很有可能默认导致存在主义灾难&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;如果你从未想过这个问题， &lt;a href="https://twitter.com/paulg/status/1744535328696815971" rel="noreferrer noopener" target="_blank"&gt;这是一个很好的问题&lt;/a&gt;，但我以为保罗·格雷厄姆已经找到了答案？他不跟考恩和蒂尔说话吗？&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Paul Graham：我们是否生活在一个技术停滞的时代，还是人工智能发展如此之快以至于可能构成生存威胁？不可能两者兼而有之。&lt;/p&gt;&lt;p&gt; FWIW我倾向于后一种观点。我一直对停滞论持怀疑态度。&lt;/p&gt;&lt;p&gt; Jason Crawford：可能是计算技术正在飞速发展，而其他领域（制造、建筑、交通、能源）却停滞不前。或者说，我们在过去 50 年里已经放慢了脚步，但即将迎来转机。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我相信大停滞的核心论点。我们过去常常做一些事情并建造一些东西。然后我们开始越来越多地告诉人们哪些东西他们不能做，哪些东西他们不能建造。 1973 年左右，这种情况达到了临界点，我们陷入了严重的停滞，半个世纪以来，一切都没有取得太大进展或改变。&lt;/p&gt;&lt;p&gt;这些规则大多不适用于包括计算机硬件在内的比特世界，因此人们（如保罗·格雷厄姆）能够构建许多很酷的新数字事物，技术呈指数级增长并改变了世界。现在人工智能正处于一个新的指数级，并准备做同样的事情，并且也构成了潜在的生存威胁。但由于指数的运作方式，它还没有对增长率产生太大影响。&lt;/p&gt;&lt;p&gt;确实，格雷厄姆对此应该非常熟悉。想想每个处于成长阶段的初创企业。它会改变世界，还是对世界几乎没有影响？它的潜力是巨大还是仍然很小？显然两者都有。&lt;/p&gt;&lt;p&gt;当然，与此同时，一旦格雷厄姆在答复中明确指出“辩论”，标准就会提醒人们，大多数技术都很好，但进展太慢，而少数技术不太好，可能进展太快。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;亚当·麦克白：错误的二分法。&lt;/p&gt;&lt;p&gt;保罗·格雷厄姆：这是一个完美的。一方面认为技术进步太慢，另一方面则认为技术进步太快。&lt;/p&gt;&lt;p&gt;埃利泽·尤德科斯基（Eliezer Yudkowsky）（回复格雷厄姆）：人们可能一致认为，除了对病原体和人工智能的功能获得研究进展太快之外，每种形式的技术都进展得太慢。 e/acc 声称他们的对手也必须反对核电的说法是错误的。&lt;/p&gt;&lt;p&gt;这也可能是真的，不仅是因为这些技术相对于我们想要的技术的发展速度有多快，而且还因为制造增强型病毒比建造房屋更奇怪地合法，或者城市建设技术如何与人工智能相比，风险投资的兴趣要少得多。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/RatOrthodox/status/1744904847139484031" rel="noreferrer noopener" target="_blank"&gt;罗尼·费尔南德斯&lt;/a&gt;：哇哇哇，我说这是一项非常不寻常的技术，你知道，你可以召唤你并不真正理解的思想，目的是让一个人比你更聪明，但它进步得太快了，其他技术，像建筑和促智药进展得太慢了。&lt;/p&gt;&lt;p&gt;您知道您可以使用多个参数来表达您对技术进步的偏好。你可以比技术太快或技术太慢更具体。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;公平地说，让我们再试一次。有三个（或四个？！）基本位置。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;技术和进步是好的，应该发展得更快，包括人工智能。&lt;/li&gt;&lt;li&gt;技术和进步是好的，应该发展得更快，但人工智能除外。&lt;/li&gt;&lt;li&gt;技术和进步并不好，各地都应该进展缓慢。&lt;/li&gt;&lt;li&gt; （说的是泛泛而谈，实际只关心人工智能的监管。）&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;诚然，第三群体的存在非常重要，而且确实对我们的社会造成了巨大的危害。&lt;/p&gt;&lt;p&gt;然后，第 1 组和第 4 组的成员声称，在实践中（或者甚至在某些情况下，他们在理论上也声称）只有第 1 组和第 3 组存在，这就是辩论，并且每个人都在说并且他们在#2 中（比如我自己）必须在#3 中，而且也没有注意到许多#1 在#4 中。&lt;/p&gt;&lt;p&gt; （ &lt;a href="https://twitter.com/edavidds/status/1745050605050282084" rel="noreferrer noopener" target="_blank"&gt;关于人们成为#4的明显例子&lt;/a&gt;，埃里克·施密特（Eric Sc​​hmidt）指出，贝夫·杰索斯（Beff Jezos）似乎从不提倡“加速”住房开工等事情。）&lt;/p&gt;&lt;p&gt;所以可以说#3中的人存在，他们确实存在。在一般技术背景下，可以将其描述为“一方面”。&lt;/p&gt;&lt;p&gt;但在人工智能的背景下，尤其是在回应类似“错误二分法”的声明时，这种说法是有误导性的，而且通常是不诚实的。它实际上是试图强加一种错误的二分法，然后声称其他人必须站在一边，并否认那些注意到你在那里所做的事情的人的存在。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/steve47285/status/1744844055631085750/history" rel="noreferrer noopener" target="_blank"&gt;一些非常糟糕的预测&lt;/a&gt;：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Timothy Lee：我认为人工智能首席执行官永远不会比人类首席执行官更好。人类首席执行官总是可以向人工智能寻求建议，而人工智能永远无法与主要投资者或客户握手。&lt;/p&gt;&lt;p&gt;史蒂文·伯恩斯 (Steven Byrnes)：“我不认为成年 CEO 会比 7 岁的 CEO 更好。 7岁的CEO总是可以向成年人请教，而成年CEO却永远无法靠可爱的小酒窝赢得投资者和客户的青睐&lt;img alt="😊" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9Jgtkw8CD6kndyCcD/kcnyp7qgpixdz386ppll" style="height: 1em;" /&gt; ”&lt;/p&gt;&lt;p&gt;蒂莫西·李：七岁的孩子……还不是成年人？这似乎是相关的。&lt;/p&gt;&lt;p&gt;史蒂文·伯恩斯：7岁的首席执行官会比我差得多，而我也会比杰夫·贝佐斯差得多。出于同样的原因，我建议有一天&lt;em&gt;[还没有！也许几十年都不会！]&lt;/em&gt;成为一个人工智能，这样杰夫·贝索斯（Jeff Bezos）是一个比人工智能糟糕得多的首席执行官。&lt;/p&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;i&gt;请在网络浏览器中查看这篇文章以完成测验。&lt;/i&gt;&lt;/div&gt;&lt;p&gt;我喜欢这个部分是因为现在声称与 7 岁的孩子相似，而不是说显而易见的“7 岁的孩子会长大，变得更强，然后变得更好，人工智能也会变得更强”随着时间的推移，并学会并行地做目前无法做的事情。&lt;/p&gt;&lt;p&gt; &lt;a href="https://manifold.markets/StanPinsent/will-there-be-an-ai-ceo-by-2040" rel="noreferrer noopener" target="_blank"&gt;请注意，Manifold 市场对时机持怀疑态度&lt;/a&gt;，它表示，到 2040 年，财富 500 强公司拥有人工智能首席执行官而不是人类首席执行官的可能性只有 58%。&lt;/p&gt;&lt;p&gt; 《连线》杂志经常对人工智能持奇怪的怀疑态度，它说“ &lt;a href="https://www.wired.com/story/get-ready-for-the-great-ai-disappointment/" rel="noreferrer noopener" target="_blank"&gt;为人工智能的巨大失望做好准备&lt;/a&gt;”，并表示“在未来的几十年里”，它将主要产生糟糕的产出，破坏就业机会，但产出质量也会降低。在我看来，这显然是错误的，即使底层技术未能进一步发展。&lt;/p&gt;&lt;h4&gt;寻求健全的法规&lt;/h4&gt;&lt;p&gt;你知道你可以厚颜无耻地向上议院撒谎吗？&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/edardaman/status/1744453999695176046" rel="noreferrer noopener" target="_blank"&gt;A16z知道。他们就这么做了。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; A16z 的书面证词：“虽然人工智能安全指南的倡导者经常提到人工智能模型的‘黑匣子’性质，其结论背后的逻辑并不透明，但人工智能领域的最新进展已经解决了这个问题，从而确保了人工智能模型的完整性。”开源代码模型。”&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这是撒谎。这是欺诈。时期。&lt;/p&gt;&lt;p&gt;最近在可解释性方面是否取得了一些进展，使得我们现在比几个月前的预期更加乐观地认为未来我们能够更多地理解模型？当然。这是取得渐进进展的好一年。&lt;/p&gt;&lt;p&gt; “这个问题解决了吗？”诚信是“有保障的”吗？ “他们结论的逻辑是透明的”？这完全是错误的。不，这是荒谬的。他们知道。他们知道我们知道他们知道。众所周知，这是一个谎言。他们不在乎。&lt;/p&gt;&lt;p&gt;我希望有人因此被投入监狱。&lt;/p&gt;&lt;p&gt;从现在开始，请记住这件事。这就是他们。&lt;/p&gt;&lt;p&gt;或许更令人震惊的是， &lt;a href="https://www.euractiv.com/section/artificial-intelligence/news/eu-prepares-to-push-back-on-private-sector-carve-out-from-international-ai-treaty/" rel="noreferrer noopener" target="_blank"&gt;美国显然要求将企业纳入人工智能条约义务&lt;/a&gt;是可选的，并由各国自行决定？什么？不适用于所有公司的条约毫无意义。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/zoehtwilliams/status/1744646356843803081" rel="noreferrer noopener" target="_blank"&gt;新报告研究了人工智能芯片上安全功能的可行性&lt;/a&gt;，以及它们在确保有效控制大量计算方面可以发挥的作用。 &lt;a href="https://twitter.com/fiiiiiist/status/1744406254334656643" rel="noreferrer noopener" target="_blank"&gt;这是一个包含主要调查结果的 Twitter 帖子&lt;/a&gt;。片上治理似乎非常可行，但作为一种选择并没有得到足够的重视。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/hlntnr/status/1745139686149140811" rel="noreferrer noopener" target="_blank"&gt;中国发布第一个“中共批准的”数据集&lt;/a&gt;。它有 20 GB、1 亿个数据点，从长远来看还不够大。正如海伦指出的那样，这是一个开始，但目前可以被视为净负面的开始。如果您拥有一套已批准的数据集，那么您就应该为使用另一套未经批准的数据集而受到指责。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.ft.com/content/f87b693f-9ba3-4929-8b95-a296b0278021" rel="noreferrer noopener" target="_blank"&gt;英国《金融时报》报道了一些秘密外交&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; OpenAI、Anthropic 和 Cohere 与中国人工智能专家进行了秘密外交，因为他们都担心这项强大的技术可能会传播错误信息并威胁社会凝聚力。&lt;br /&gt;&lt;br /&gt;据多名知情人士透露，去年 7 月和 10 月在日内瓦举行了两次会议，北美人工智能团体的科学家和政策专家以及清华大学和其他中国政府支持机构的代表参加了会议。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;文章没有提及其他有意义的细节，这似乎并不那么秘密。这看起来确实是个好主意。&lt;/p&gt;&lt;p&gt;注意谁是有帮助的或限制性的，谁不是，以及谁可能会或可能不会很快成为坏人。&lt;/p&gt;&lt;p&gt; &lt;a href="https://www.fwbusiness.com/fwbusiness/article_73dd33bc-aae4-5fc7-830c-bd517d07d235.html" rel="noreferrer noopener" target="_blank"&gt;参议员托德·杨 (R-IN) 和一个两党团体呼吁&lt;/a&gt;建立美国国家标准技术研究院 (NIST) 的美国人工智能安全研究所 (USAISI)，初始资金为 1000 万美元。这是微不足道的，但必须从某个地方开始。是的，标准协会为人工智能相关标准提供资金是有意义的。&lt;/p&gt;&lt;h4&gt;音频周&lt;/h4&gt;&lt;p&gt;&lt;a href="https://www.alignment-workshop.com/nola-2023" rel="noreferrer noopener" target="_blank"&gt;12 月 10 日至 11 日在新奥尔良举行的协调研讨会上的讲话。&lt;/a&gt;还没来得及听，但这里有一些自我推荐的演讲，供有兴趣的人参考。&lt;/p&gt;&lt;h4&gt;人工智能影响调查&lt;/h4&gt;&lt;p&gt;&lt;a href="https://thezvi.substack.com/p/ai-impacts-survey-december-2023-edition" rel="noreferrer noopener" target="_blank"&gt;我在自己的帖子中对此进行了介绍&lt;/a&gt;。本节介绍最新的反应和进展。&lt;/p&gt;&lt;p&gt;在未来人工智能预测的列表中，总会有一个断言最终被证明已经发生。在本例中，它是“世界扑克系列赛”，其定义为“打得足够好以赢得 WSOP”。这已经非常明显地发生了。如果你想慷慨一点，你可以说“人工智能在主赛事中不像托马斯·里格比或菲尔·艾维那样擅长最大化其胜率，因为它的剥削性不够”，你是对的，因为没有人投入认真努力制作一个剥削性机器人并让它阅读故事现在才变得现实。&lt;/p&gt;&lt;p&gt;我发现&lt;a href="https://twitter.com/Meaningness/status/1743301276748619876" rel="noreferrer noopener" target="_blank"&gt;查普曼在这里的主张&lt;/a&gt;与我所写的关于道德迷宫的内容非常危险地相似，以及扭曲中层管理人员思想的危险，使他们除了在管理方面取得领先之外无法考虑任何事情：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;大卫·查普曼： &lt;img alt="🤖" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/aKzwwKT2cy72awSyz/altbeffglxoxdzfml0xq" style="height: 1em;" /&gt;对 2,778 名人工智能研究人员的重要调查发现，主要发现人工智能研究人员无法在自己所谓的专业领域内应用基本的逻辑推理。 [链接到我的帖子]&lt;/p&gt;&lt;p&gt; Magor：这似乎是一个聚合和合并信息的例子，直到它比任何单个数据点更糟糕。不过，很有趣。这表明整个领域正在盲目运转。&lt;/p&gt;&lt;p&gt; David Chapman：是的……我认为这也是大多数技术人员狭隘的表现；他们无法在自己的领域之外进行技术推理（并且预测人工智能的未来并不是人工智能研究人员接受过的培训或思考的内容，因此他们的观点没有意义）。&lt;/p&gt;&lt;p&gt;我认为人工智能异常糟糕，因为由于历史原因，该领域的基本认识论是反理性的，并且它训练你除了优化梯度下降之外，不要清楚地思考任何事情。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这是真的吗？它并不像听起来那么奇怪。通常，那些因 X 而获得丰厚奖励的人几乎在其他所有事情上都会受到反训练，对于处于极端优化压力下的此类人的社区来说，这种情况会加倍。如果是这样，我们的麻烦就更大了。&lt;/p&gt;&lt;p&gt;对此的防御是这些研究人员是否需要逻辑和认识论作为他们工作的一部分。他们吗？&lt;/p&gt;&lt;h4&gt;修辞创新&lt;/h4&gt;&lt;p&gt;人们普遍认为，存在风险会“分散”其他担忧。&lt;/p&gt;&lt;p&gt;埃里希·格鲁内瓦尔德指出这是一个事实问题。 &lt;a href="https://forum.effectivealtruism.org/posts/hXzB72kfdAk6PTzio/attention-on-existential-risk-from-ai-likely-hasn-t" rel="noreferrer noopener" target="_blank"&gt;我们不禁要问，这是真的吗？&lt;/a&gt;&lt;/p&gt;&lt;p&gt;他的回答是不是，有五条论证和调查。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;自提出存在性风险担忧以来制定的政策仍然主要侧重于解决平凡的危害和获取平凡的效用。在某种程度上，包括英国安全峰会和美国行政命令在内的一些政策举措主要是由存在风险驱动并受到此类担忧影响的，因此人们为解决世俗担忧做出了巨大努力。与此同时，还有许多其他事情正在酝酿中，以解决世俗问题，并且它们大多得到了那些担心存在风险的人的支持。&lt;/li&gt;&lt;li&gt;在 2023 年人工智能存在风险担忧讨论最多的时期，对人工智能伦理和当前人工智能危害的搜索兴趣丝毫没有受到影响。&lt;/li&gt;&lt;/ol&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a972f67-591b-42a8-803b-d9ee6f61d416_1066x729.png" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/nfg2p2yniqcr26kcmlsj" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;回归分析显示大致没有影响。&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1427e116-b906-481b-87f7-4161babb7f40_1051x589.png" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/ela9x2j6nfws8pyeqk92" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;ol start="3"&gt;&lt;li&gt;推特粉丝。如果你看看最大的道德倡导者，当存在风险担忧扩大时，他们的影响力就会扩大。&lt;/li&gt;&lt;li&gt;为普通或当前危害组织筹款的活动仍然表现良好。&lt;/li&gt;&lt;li&gt;与环保主义相似，环保主义被指出是潜在担忧的一个原因，也是反对担忧的常见论点。人们是否说气候变化会“分散”人们对当前空气污染等危害的注意力，或者反之亦然？本质上不是，但也许他们应该，而且也许只是在一个方向？对气候的担忧似乎引发了对其他环境问题的担忧，并使人们想要帮助解决这些问题，而气候解决方案有助于解决其他问题，而对当地具体问题的担忧往往会导致人们表现得好像气候变化无关紧要。我们经常看到这种斗争，因为重要的气候项目因其他“百吉饼”问题而被搁置。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt; &lt;a href="https://twitter.com/bencasnocha/status/1743294517946823082" rel="noreferrer noopener" target="_blank"&gt;这是一个可以进一步扩展的良好启发式：&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Freddie DeBoer：识别一篇文章质量的一个很好的经验法则是：什么更具体，什么更通用，是赞扬它还是批评它？&lt;/p&gt;&lt;p&gt; Ben Casnocha：适用于评价很多事物的质量：你对它的赞扬能具体到什么程度？&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;对于分歧和辩论也提出同样的问题。谁在通用？谁说得具体一点？这里哪个合适？如果你是对的，你会多做哪一项？&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/robbensinger/status/1743411122705756606" rel="noreferrer noopener" target="_blank"&gt;罗布·本辛格解释说，是的&lt;/a&gt;，在真正的囚徒困境中，如果你能逃脱惩罚，你确实更愿意在他们合作的时候叛逃，如果你不明白这一点，你就没有准备好处理这样的困境。不要被“叛逃”这个名字所迷惑。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/eshear/status/1743036378173342180" rel="noreferrer noopener" target="_blank"&gt;Emmett Shear 解释了&lt;/a&gt;一种直觉，即为什么人工智能的指数级加速进一步人工智能的发展看起来影响相对较小，直到突然之间它的影响实际上非常高，以及为什么一旦人工智能能力超出适当的阈值，我们仍然应该预期出现爆炸式的效应。前 20% 的自动化很棒，但不会改变游戏规则。从 98% 到 99% 非常重要，而且可能会发生得更快。&lt;/p&gt;&lt;p&gt;我经常看到自以为是的说法，认为 foo 的想法已经被“揭穿”，或者现在显然是错误的，我们不必担心这种加速。不。我们确实得到了证据，表明出现更极端的泡沫情况的可能性比我们想象的要小。在我看来，“强形式”的 foo 假说（即相关人员根本看不到它的出现）的可能性确实很小。但核心假设并没有被证伪。这仍然是默认的、常识性的结果，即一旦人工智能有足够的能力，在接近人类整体能力水平的拐点上，它们将加速进一步能力的开发，事情会很快升级。这也仍然是OpenAI超对齐团队的计划和许多研究人员的实际期待。&lt;/p&gt;&lt;p&gt;它可能会或可能不会在不同程度上发生，具体取决于任务难度的加速速度是否快于完成任务的能力，以及我们是否采取措施来防止（或导致）这种影响。&lt;/p&gt;&lt;p&gt;嗯，是。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/robertwiblin/status/1742881192959991815" rel="noreferrer noopener" target="_blank"&gt;罗伯特·维布林&lt;/a&gt;：无论人类变得多么有能力，我们仍然总会找到大猩猩的生产用途——它们只会转变为经济中新的比较优势。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;观点冲突仍在继续。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Daniel Kaiser：gpt-4 比 gpt-3.5 的生存威胁大多少？&lt;/p&gt;&lt;p&gt; Eliezer Yudkowsky：无论这条曲线是什么，我们仍然处于底部，所以从零到零。&lt;/p&gt;&lt;p&gt; Daniel Kaiser：太好了，那么就没有必要惊慌了。&lt;/p&gt;&lt;p&gt; Sevatar：“核弹落下还有多久？” “他们仍在准备发射。” “太好了，所以没有理由惊慌。”&lt;/p&gt;&lt;p&gt;丹尼尔·凯泽：“核武器落下还有多久？” “他们仍在研究 TNT 的配方”“太好了，所以没有理由惊慌”&lt;/p&gt;&lt;p&gt;请做出准确的类比，而不是争论性的类比，以进行建设性的讨论&lt;/p&gt;&lt;p&gt;Aprii：我觉得“他们正在启动曼哈顿项目”比“他们仍在研究 TNT”更准确&lt;/p&gt;&lt;p&gt;埃利以泽：（同意）&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;是的。我认为这是完全正确的。开始担心核武器的时间是西拉德在 1933 年左右开始担心的时候。物理学家们非常聪明，他们基本上立刻就知道了，但不知道该怎么做才能阻止它发生。我确实认为“曼哈顿计划的开始”在这里感觉像是一个完全正确的比喻，尽管不是“我预计只有三年”的方式。&lt;/p&gt;&lt;p&gt;而且，如果你试图描绘未来的长弧线，你在 1868 年写作，当时我们第一次发现了 TNT，一些你信任的杰出物理学家告诉你未来制造原子弹的能力，你写下你对 1968 年或 2068 年的愿景，它看起来应该与以前有很大不同，不是吗？&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/michael_nielsen/status/1743339700885340287" rel="noreferrer noopener" target="_blank"&gt;主题询问有关 ASI 的引人注目的虚构描述&lt;/a&gt;。选择包括 Alla Gorbunova 的“你的小工具坏了”，这是一个激励人心的例子，可惜目前只有俄语版本，所以我不会阅读它，还有：Accelerando、Vinge 的作品（我可以推荐这个）、golem.xiv、Person兴趣（如果你也愿意观看程序电视节目，那就太棒了），盲视（我不同意这个，我都没有考虑人工智能并且普遍讨厌它），&lt;a href="https://t.co/NeHW7AvSwI" rel="noreferrer noopener" target="_blank"&gt;主要智力的变形&lt;/a&gt;，&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/davidad/status/1743752451956568498" rel="noreferrer noopener" target="_blank"&gt;啊，是的，好的人工智能将击败坏的人工智能。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Davidad：“好人工智能”将击败“坏人工智能”的说法最好通过观察自我复制模式是可替代的，因此在默认情况下具有破坏性来削弱，除非积极避免它，所以坏人工智能拥有更多资源和策略的优势，不是禁区。&lt;/p&gt;&lt;p&gt;最好的反击是，“优秀的人工智能”将在长达数年的领先时期中获得巨大的物质和智力优势，并以安全和合乎道德的方式获得这些优势。这需要协调——但这很可能是一种可用的纳什均衡。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; Davidad 还提醒我们，不，并不是所有事情都是囚徒困境，人类实际上能够在博弈论问题的实践中进行合作，而加速论者和元毁灭者一直声称这是不可能的。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Davidad：我今天只是巧合地做了这个分析，在许多看似合理的世界中，从博弈论的角度来看，确实可以保证安全。在雄鹿狩猎中进行协调仍然不是微不足道的，但它“是”纳什均衡，并且在实验中，人类能够在 60-70% 的时间内做到这一点。&lt;/p&gt;&lt;/blockquote&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5eeccab9-8cab-49d4-9792-c9026ee12632_2048x2022.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/yudesmprwzdmdk1gof7w" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;保证和主流方法之间存在隐含的二分法，这至少是一种简化，但我确实认为总体观点是正确的。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/ESYudkowsky/status/1743688927238934876" rel="noreferrer noopener" target="_blank"&gt;以利以谢一直试图向许多不明白这一点的人解释&lt;/a&gt;，“好东西”和“以看起来不错的方式行事的东西”之间存在区别。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Eliezer Yudkowsky：“尝试想象任何与你所希望的不完全一样的内部机制”是多么盲目——想想看，如果你删除了一个大脑，然后仅仅训练该大脑来预测下一个大脑好人说的话，&lt;em&gt;内部结果会很好吗？&lt;/em&gt;&lt;/p&gt;&lt;p&gt;在我看来，这似乎是基于纯粹的无知，是从空白地图到空白领域的飞跃。他们的大脑看不到外部行为背后的任何东西，只想象出一种纯粹的、毫无特征的倾向来产生这种外部行为——这是系统内部唯一的东西。&lt;/p&gt;&lt;p&gt;想象一下，当你成功预测到其他人说的下一个单词时，你被锁在一个房间里，吃饱喝水，而当你没有成功预测到时，你就会被电击。&lt;/p&gt;&lt;p&gt;鉴于人工智能显然不会&lt;em&gt;那样，这是一个有用的思想实验和直觉泵吗？&lt;/em&gt;&lt;/p&gt;&lt;p&gt;我说：是的，囚犯预测文本是一个有用的直觉泵。因为它会促使你想象预测背后的&lt;em&gt;任何机制&lt;/em&gt;，除了“一个好人成功预测好的输出，因为它们太棒了”的希望之外。&lt;/p&gt;&lt;p&gt;如果你训练一个大脑来预测在酒吧喝醉的一百个顾客中的每一个所说的下一个词，它会喝醉吗？&lt;/p&gt;&lt;p&gt; Martaro：预测好人会说什么并不能使您友善，您可以将泰德·邦迪（Ted Bundy）锁定多年，除了是由好人写的文字，他什么都没有，他会擅长于此，这意味着AI的外在善意说关于内部善意的摘要几乎没有吗？&lt;/p&gt;&lt;p&gt; Eliezer Yudkowsky：基本上！&lt;/p&gt;&lt;p&gt; DAS过滤器：我从未听说过有人声称&lt;/p&gt;&lt;p&gt;Eliezer Yudkowsky：告诉所有人说RLHF（现为DPO）应该只是为创建一个不错的超级智能而努力，为什么它不起作用呢？&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;就是这样。如果您声称RLHF或DPO应该起作用，那么您确实（据我所知）提出此主张过滤器是没有人做的，无论您是否使这种隐式构成。我可以肯定的是，这一说法是错误的。&lt;/p&gt;&lt;p&gt;人类有东西将它们推向这样的方向，但是那里的力量有限，有些人对此无效。您不能指望这样的观察结果，例如一个有力的证据表明一个人实际上是不错的，或者当芯片正确地放下时会做您想做的事。不要犯这个错误。&lt;/p&gt;&lt;p&gt;另一方面，我的意思是，人们有时会称呼我或Eliezer自信，甚至过高的自信， &lt;a href="https://twitter.com/norabelrose/status/1743751787553972636" rel="noreferrer noopener" target="_blank"&gt;但“比Boltzmann Brain的可能性更低”的水平自信！&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;诺拉·贝罗斯（Nora Belrose）：外星幕府将在神经网络中产生的可能性与玻尔兹曼大脑相同，可能会从热平衡中出现。可以安排参数 /分子的“多种方式”，但实际上它们都对应于简单的行为 /宏观物质。&lt;/p&gt;&lt;p&gt; Eliezer的观点预测，扩大神经网络，从而增加了它可以代表的“机制”数量，这会使我们想要的方式不太可能概括。但这在理论上还是实践中都是错误的。扩展永远不会使概括变得更糟。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;模型错误？从来没有听说过。但是，如果我们更慷慨地将其解释为“如果我的计算是正确的，那么这几乎是不可能的”，那又怎么办？&lt;/p&gt;&lt;p&gt;我认为这里的一个核心分歧可能是诺拉（Nora）认为“简单的行为”和“更好”与“我们想要的”相对应。&lt;/p&gt;&lt;p&gt;我同意，随着AI的扩展，它将与其他所有内容一起概括。问题总是，在这种情况下“更好”意味着什么？&lt;/p&gt;&lt;p&gt;我说，在这种情况下，从某种柏拉图理想的意义上说，更好的意思是，空白中存在概括。它在狭窄的优化意义上是根据提供的任务的狭窄优化意义。&lt;/p&gt;&lt;p&gt; Eliezer回应， &lt;a href="https://twitter.com/ESYudkowsky/status/1744066823962947905" rel="noreferrer noopener" target="_blank"&gt;然后以通常的方式进行讨论&lt;/a&gt;。在这一点上，我认为试图在这方面的嫌疑人之间进行文本相互作用，这一嫌疑人注定要一次又一次地陷入这些动态。我对音频对话有更多希望，理想记录也可能会失败，但是如果真诚地完成，它就有机会。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/AndrewCritchPhD/status/1743877194022003167" rel="noreferrer noopener" target="_blank"&gt;安德鲁·克里奇（Andrew Critch）预测&lt;/a&gt;，如果埃利泽（Eliezer）嘲笑贝罗斯（Belrose）的论点，他会购买它们，同时仍然期望我们死于克里奇（Critch）所说的“多极混乱”。我相信克里奇（Critch）是错误的，即使克里奇（Critch）是正确的，埃利泽（Eliezer）未能努力。&lt;/p&gt;&lt;p&gt;在多极问题上， &lt;a href="https://twitter.com/norabelrose/status/1744089984532140410" rel="noreferrer noopener" target="_blank"&gt;克里奇和贝罗斯之间进行了讨论&lt;/a&gt;。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;诺拉·贝尔罗斯（Nora Belrose）：您是否曾经写过为什么您认为“多极混乱”会发生并在2040年杀死所有人？&lt;/p&gt;&lt;p&gt;安德鲁·克里奇（Andrew Critch）：有点，但是我觉得那里或任何地方都有好受众。我应该在某个时候再试一次，也许是今年的某个时候。我在Lesswrong&lt;a href="https://arxiv.org/abs/2306.06924" rel="noreferrer noopener" target="_blank"&gt;和Tasra&lt;/a&gt; &lt;a href="https://lesswrong.com/posts/LpM3EAakwYdS6aRKf/what-multipolar-failure-looks-like-and-robust-agent-agnostic) and in TASRA (https://arxiv.org/abs/2306.06924" rel="noreferrer noopener" target="_blank"&gt;上尝试过几次&lt;/a&gt;，但并没有完全指出我期望看到的所有失败。在社会/情感上/政治上难以使论点完全详尽无遗，它涉及到特定详细的解释为什么我认为每个人类机构可能会失败或完全被（中位数）（中位数）完全失望。在某些方面，我每个机构的解释看起来都不同，而在我看来，这看起来都像是相同的强大的代理 - 不合Snostic过程 - 类似于“ Moloch”。&lt;/p&gt;&lt;p&gt;诺拉·贝尔罗斯（Nora Belrose）：对，我认为生产网络会很糟糕，部分原因是控制/对齐经理AIS的任务将被分散地分配给许多利益相关者，而不是任何一个人。&lt;/p&gt;&lt;p&gt;这就是为什么我认为重要的是用AIS真正控制的AIS（不仅是通过API）很重要的原因。我们可以让公司通过这些人类系统经营，因为OFC AI正在从事大部分工作，但是人类控制着整体方向。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我认为这很好，因为在这类场景中，涉及成功地与我们规定的AIS相结合的方案，Nora的场景正是我所看到的场景。&lt;/p&gt;&lt;p&gt;这不是稳定的平衡。一点也不是。人类将迅速停止对AI的任何有意义的监督。将停止真正控制的，因为涉及的放缓没有竞争力。即使该人“不在循环”中，也强迫每个人工智会代表一个人工作，而无需对任务或合并设置AIS，并且类似，也显然也不具有竞争力，并且面对同样的命运。即使不明智，许多人也会越来越多地做出决定，使他们失去控制。和往常一样，这是每个人都广泛地“善良”的好情况。&lt;/p&gt;&lt;p&gt;所以我注意到我很困惑。如果这是我们成功的计划，那么我们已经死了。&lt;/p&gt;&lt;p&gt;克里奇希望尤德科夫斯基（Yudkowsky）达到的一切，我都注意到这一点：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;我不把它&lt;/li&gt;&lt;li&gt;我确实抓住了它，克里奇/贝罗斯不会反对或为什么重要。&lt;/li&gt;&lt;li&gt;这是进一步的迭代？或许？&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我的猜测是＃1或＃2，不太可能是一个高阶问题。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/eshear/status/1743541107034829264" rel="noreferrer noopener" target="_blank"&gt;我们如何考虑无限制的生存风险，而无效的人会使人们发疯或启用任意要求？&lt;/a&gt; Eliezer Yudkowsky和Emmett剪切讨论，Rob Bensinger提供了更多想法，考虑阅读线程。艾米特是对的，如果人们完全“欣赏”赌注是令人难以置信的大量，但是这些赌注在“感觉现实”中没有良好的基础，他们将其围绕着无限，它可能会造成理智的伤害，并弄乱他们的头部。该怎么办？&lt;/p&gt;&lt;p&gt;正如艾米特（Emmett）所指出的那样，有一个很大的诱惑来找到避免这种情况的演示文稿和框架，并继续这样做，无论您是否会以准确的反思来认可它。正如罗布（Rob）所指出的那样，这既包括将p（厄运）降低到您可以忍受的地步，也将其他场景视为本质上是正常的，而不是他们自己的形式非常不正常。也许我们应该开始谈论P（正常）。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/sherjilozair/status/1744192401646952492" rel="noreferrer noopener" target="_blank"&gt;Sherjil Ozair建议阻止，而不是仅仅取消关注或静音刺激器&lt;/a&gt;，因为否则他们仍然会找到分散您注意力的方法。静音似乎仍然可以正常工作，并且取消关注也很不错，我想知道某人是否足够振奋，即使内容很愚蠢，我通常都不愿静音或阻止，除非有主动地看到事物使我的生活变得更糟。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/gdb/status/1744446603962765669" rel="noreferrer noopener" target="_blank"&gt;Openai总裁Greg Brockman&lt;/a&gt;解释说，我们需要AGI来治愈疾病，这是讲述一个人故事的政治家。&lt;/p&gt;&lt;p&gt; Agi肯定有很多戏剧性的优势。我不确定谁在关注布罗克曼，仍然需要听到这一点？他在这里提到的医疗保健的变化即使在健康中也是相对的变化。如果我得到AGI并保持控制权，我想要一种治愈衰老的方法，我希望它比我年龄更快，我希望得到它。&lt;/p&gt;&lt;h4&gt;保持人级智力仍然很困难&lt;/h4&gt;&lt;p&gt;关于世界的一个重要事实是，人类的一致性问题阻止了大多数非定制有用的工作，否则就可以完成，并对所做的事情征收巨大税收。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/ESYudkowsky/status/1743759927435530562" rel="noreferrer noopener" target="_blank"&gt;“一个人不简单地将钱转换为聪明人的产出。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Satya Nutella：富裕的亿万富翁实际上已经拥有AGI，因为他们可以向Smart Ppl扔足够的钱来为他们工作，真正的Agi是为了群众&lt;/p&gt;&lt;p&gt;帕特里克·麦肯齐（Patrick McKenzie）：我认为许多人会惊讶于亿万富翁将钱转换为聪明人和/或他们的产出的困难。&lt;/p&gt;&lt;p&gt; Eliezer Yudkowsky：当然，但也完全缺少了Notkilleveryoneism的观点，这是对AI比所有小人类更聪明的人的担忧。&lt;/p&gt;&lt;p&gt; Zvi Mowshowitz：但是：完成Notkillingeveryone的关键问题正是亿万富翁不知道如何将钱转换为聪明人的产出。&lt;/p&gt;&lt;p&gt; Emmett Shear（回复帕特里克）：钱独自一人出人意料。&lt;/p&gt;&lt;p&gt; Garry Tan：管理，领导力，建筑团队，照顾这些团队：所有这些都是艰苦的工作和烦恼。大多数资本坐着休耕的定义原因就是这样。如果您可以解决它，则可以急剧加速世界上所有积极的活动。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;帕特里克（Patrick）提出了一个重要的一般观点，它超越了AI，这也是我们能够解决我们的问题的主要障碍。如果他们知道如何做到这一点，有很多亿万富翁会很乐意加紧花钱。他们不这样做。这不是因为他们愚蠢或无知。这是因为问题非常困难。您可以争论不需要这么困难的各种原因，也可以说他们应该做更多的事情，而其中许多是正确的，但是这个问题确实很困难。&lt;/p&gt;&lt;p&gt;萨蒂亚（Satya）当然也缺少有关AGI的观点。 Agi不会与大众的个人助理联系，然后无限期地留在该卷中作为其主要效果。那是对未来的愚蠢愿景。如果普通人能够获得亿万富翁的智力表现，那么AI的进步将很快，而且许多其他事情都会变得疯狂。&lt;/p&gt;&lt;h4&gt;比对人的智能比人的智能很困难&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/xuanalogue/status/1743005561614979452" rel="noreferrer noopener" target="_blank"&gt;一项灵感来自阿西莫夫（Asimov）法律（哦，不，哦，不）的技术&lt;/a&gt;，称机器人宪法是声称是提高野外机器人目标的安全性，比3倍。我毫不怀疑这种技巧在实用利润率上比根本没有技巧更好，但是每个认为Asimov定律可能有用的人都会阅读Asimov。&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F704c792b-25b7-4b0f-8fc9-56a355e6d35d_1170x327.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/d9zuatrnellsuexthzii" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;同样，结果显然不足，而且显然不太可能得到足够的足够。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; XUAN：83％的机器人任务安全性太低了。我认为我们基本上应该将这些结果视为仅凭LLM及时工程可以实现的方面的信息，并认识到我们需要具有更高的经验和理论安全保证的方法。&lt;/p&gt;&lt;p&gt;在尝试使用LLM进行接地指令之后，即使 *使用 *符号验证者，我也只能在类似尺寸的数据集上实现90％左右的精度，我们都应该对错误的错误感到不满意速度。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;如果您可以从27％到87％获得安全性，那么您是否有前途的安全性？这取决于上下文。在某些情况下，绝对。在其他情况下，如果效果会在周围限制，那绝对不会。这可能是（除其他原因外）是因为您解决了容易的60％，而实际上使硬13％（或解决了容易的72％的60％，并留下了硬1％），或者因为您需要足够的准确性，以使防御能力在深入的乘法中，类似效果的繁殖行不通。&lt;/p&gt;&lt;p&gt;我们应该采取一种策略&lt;a href="https://www.lesswrong.com/posts/i2nmBfCXnadeGmhzW/catching-ais-red-handed" rel="noreferrer noopener" target="_blank"&gt;，以确保我们捕捉模型试图在其第一次尝试时逃脱&lt;/a&gt;，然后使用它来防止未来的逃脱尝试？如果一个超级能力的模型逃脱，那就是这样，但是如果“第一次尝试”条件在很大程度上是对称的，因为捕捉失败的尝试会使我们保持警惕，并且还教我们如何停止未来的尝试呢？&lt;/p&gt;&lt;p&gt;在某些玩具世界中，很容易看出这可能会有所帮助。这可能在多大程度上转化为我们的现实世界？&lt;/p&gt;&lt;p&gt;第一个要求是我们有意义地“捕获”模型。我们应该如何思考这个问题？&lt;/p&gt;&lt;p&gt;这是代表性的示例：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;通过“模型被抓住”，我们的意思是，我们看到AI采取的行动是AI是shemer的强有力的直接证据&lt;a href="https://www.lesswrong.com/posts/i2nmBfCXnadeGmhzW/catching-ais-red-handed#fnlokat6zwmzf" rel="noreferrer noopener" target="_blank"&gt;&lt;sup&gt;[1]&lt;/sup&gt;&lt;/a&gt; 。一个&lt;a href="https://www.lesswrong.com/posts/BAzCGCys4BkzGDCWR/the-prototypical-catastrophic-ai-action-is-getting-root" rel="noreferrer noopener" target="_blank"&gt;代表性的例子&lt;/a&gt;是抓住您的AI采取以下操作：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; AI实验室内部充当自主程序员的实例编写了错误的代码，该代码将代码漏洞插入到某些关键安全性软件中。&lt;/li&gt;&lt;li&gt;即使您期望未精心制作的漏洞来错过漏洞，代码审查实例谨慎地避免编写任何会引起漏洞的单元测试，即使您期望通过单位测试捕获漏洞。&lt;/li&gt;&lt;li&gt;另一个实例编写了触发漏洞的代码，并试图利用漏洞以获取对数据中心中某些计算机的词根访问。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果您抓住所有这些动作的AI，您就会抓住它。 （请注意，一旦抓住了其中一个，抓住其他人可能很容易。）&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;从此处的附录中，此处更详细：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;为了这篇文章，我们主要是在谈论灾难性的结果，例如模型&lt;a href="https://aligned.substack.com/p/self-exfiltration" rel="noreferrer noopener" target="_blank"&gt;消除其权重&lt;/a&gt;，这可能仅涉及少量动作。还有其他威胁模型与策略相关，例如，模型巧妙地破坏了他们所做的工作，使他们的工作无用，或者随着时间的推移而巧妙地获得了影响。为了这篇文章，我们忽略了这些威胁模型，但是我们认为我们可以采用类似的策略来处理它们。&lt;/p&gt;&lt;p&gt;我们将“捕获”模型定义为：您找到输入，您可以证明您的模型采取灾难性的行动，其概率比该模型没有故意寻找机会采取此类操作的机会要高。&lt;/p&gt;&lt;p&gt; ……&lt;/p&gt;&lt;p&gt;为了确保您可以区分这些故意的灾难性行动，您需要做到这一点，以便您的模型永远不会逃脱而不明确采取非事故的不良行为。我们认为您可以做到这一点，以便您的模型不会逃脱而不必做一些明确的故意坏事。&lt;/p&gt;&lt;p&gt; ……&lt;/p&gt;&lt;p&gt;要算作成功的捕获，您需要对捕获量充满信心。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;让我们考虑一下这个例子。那是逃生尝试吗？&lt;/p&gt;&lt;p&gt;当然是高度可疑的。我们将根据证据对犯罪的人定罪。如果这是一个明显的脆弱性，它明确试图以这种方式利用，我们已经“抓住了”它。&lt;/p&gt;&lt;p&gt;问题是我们不知道单位测试是“精心制作”的，以避免发现错误。最终，将会存在这样的缺陷，任何一组测试都不会捕获。如果您继续使用系统上类似的良好测试，AI将优化通过这些测试，并且您将开始看到（非恶意或恶意）您不打算的事物，不会触发单位测试。它并不总是完全明显或清楚代码不允许的负担。然后，人工智能将能够弄清楚它通过这些事情而获得的负担，并利用它来解决问题，依此类推。&lt;/p&gt;&lt;p&gt;因此，一个真正的问题是，除了“试图在没有授权的情况下获得根本访问机器”之外，其余的工作是在做很多工作吗？&lt;/p&gt;&lt;p&gt;我担心很多事情是这样的，在代码和其他方面。事物是灰色的阴影，它们完成了多件事，它们具有权衡。不必有吸烟枪让您知道。如果AI有理由怀疑您专注于寻找吸烟枪，那将是两倍。&lt;/p&gt;&lt;p&gt;我确实在此类方案中看到了一些价值。有道理的是，您有足够的能力捕捉事物，而AI可能会以这些方式进行策划，并且您可以设计情况，如果它可以单独进行计划，则实际上您会抓住它它成功了。当然。&lt;/p&gt;&lt;p&gt;由于各种原因，我敢肯定不会指望它，但是假设您确实将其实现。然后怎样呢？&lt;/p&gt;&lt;p&gt;我认为“也许我们应该在捕获红色手的模型后停止部署模型”部分不需要太多扩展？一旦您知道这些模型正在尝试逃脱，任何可能具有尝试逃生动力的类似模型都需要关闭。特别是在他们获得进一步的负担和能力之前。&lt;/p&gt;&lt;p&gt;这就是使这条道路完全值得的。这个想法是，您以一种可以看到的方式触发尝试，抓住它，反应。&lt;/p&gt;&lt;p&gt;一旦看到AI对手的逃生尝试比您聪明得多，您可以等到AI弄清楚新的负担能力或尝试不适当地防止AI的尝试，或者AI开始做一些否则合理的递增事物，但请说在更好的位置或使您更信任它，或两者兼而有之。微妙的事情正在发生，如果什么都没有，它将带您。&lt;/p&gt;&lt;p&gt;我确实认为Buck和Company正在淘汰人们可能会使用这些技术来尝试从狭窄窗口中获得有用的东西的方式，这很有价值如果愿意，将其保留在地狱中。我想如果我们要继续进行总比没有好。&lt;/p&gt;&lt;p&gt;我非常讨厌的是，要计算这种技术和假设的想法，我们将能够预见我们要预防的事物的形式，并在敌人的情况下注意到。是的，我们肯定会尝试使用AIS来确定其他AI的敌人行动，这将有所帮助。我们能够运行各种测试和模拟方案的能力。但是我要坚持认为，如果您允许AI-AI或人类对互动，而其中一个或两个都具有逃脱的意愿和能力，那么您将有一个糟糕的时光，我同意奥利弗（Oliver）在评论中，您希望AI会做很多事情来保持合理的可否认性。尤其是如果您惩罚缺乏这种可否认性的话。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;约书亚·克莱默（Joshua Clymer）：有一些关于“政变”的文献，与控制和激励未对准的AIS非常相关。示例策略：&lt;/p&gt;&lt;p&gt; - &lt;strong&gt;stovepiping：&lt;/strong&gt;限制信息流以使串通更加努力&lt;/p&gt;&lt;p&gt;-&lt;strong&gt;平衡&lt;/strong&gt;：让您的军队与另一位军队保持联系。&lt;/p&gt;&lt;p&gt; -&lt;strong&gt;付钱给您的员工&lt;/strong&gt;：从字面上看，只要给您的将军高薪，这样他们就会少激励您双重交叉。&lt;/p&gt;&lt;p&gt; -&lt;strong&gt;刺痛操作&lt;/strong&gt;：设置陷阱，有人说他们试图发起政变，任何加入的人都被清除。&lt;/p&gt;&lt;p&gt; -&lt;strong&gt;旋转官员&lt;/strong&gt;：使人们很难通过将他们围绕很多旋转来建立信任。&lt;/p&gt;&lt;p&gt; -&lt;strong&gt;宣传&lt;/strong&gt;：欺骗人们认为政变真的很难实现。&lt;/p&gt;&lt;p&gt;查找“政变校对工具箱”，以进行有用的点亮评论&lt;/p&gt;&lt;p&gt;Eliezer Yudkowsky：对于70个智商独裁者，其将军，保镖，士兵和工人都是约翰·冯·诺伊曼（John von Neumann）以自己的速度100倍的想法？&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;如果我们按照“付钱给人民”的顺序谈论事情，那么，您绝对应该这样做，但是您并没有认真对待您的ASI-Level对手。我确实认为您可以使用诸如旋转官员和刺痛行动之类的东西购买非零的防守，但并非所有这些都不为零。无论如何，都可以做到这一点，但是这既需要又足够的窗口很狭窄。&lt;/p&gt;&lt;h4&gt;不会再被愚弄&lt;/h4&gt;&lt;p&gt;“欺骗性对准”到底是什么？&lt;/p&gt;&lt;p&gt;史蒂夫·伯恩斯（Steve Byrnes）指出，这不仅是欺骗性的AI。他想确保我们使用准确而狭窄的定义。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;史蒂夫·布莱恩斯（Steve Brynes）：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;一个“地面真相系统”（可能是个别人工评估者，或可能是某种自动化系统）提供了一个带有培训信号的ML模型（如果这是强化学习（RL），则是监督地面真相信号，如果是自我监督或自我 - 监视学习（SL）），&lt;/li&gt;&lt;li&gt;人工智能开始发出人类可能会天真地解释为训练的证据，表明训练正在按预期进行 -  RL中的高级输出和SL中的低损失输出（但&lt;a href="https://www.alignmentforum.org/posts/a392MCzsGXAZP5KaS/deceptive-ai-deceptively-aligned-ai?commentId=ZfXkFba9Whi6BXYdi" rel="noreferrer noopener" target="_blank"&gt;这里的评论者都指出&lt;/a&gt;，“证据表明训练是按预期进行的”是可能比这更细微）。&lt;/li&gt;&lt;li&gt; …但是AI实际上是在发出这些输出&lt;em&gt;以创造出这种印象&lt;/em&gt;- 更具体地说，AI具有&lt;a href="https://www.alignmentforum.org/tag/situational-awareness-1" rel="noreferrer noopener" target="_blank"&gt;情境意识&lt;/a&gt;和对某些任意事物X的秘密渴望，AI希望不更新和/或希望部署它，以便它可以使X实现，并且这些考虑因素在于AI会发出其发出的输出的原因。&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F500190d3-9ce6-4db4-9b1e-ec90fdfe9668_748x717.png" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/w1tdyhxzen831h6s1ppm" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;这当然是一个可怕的场景。称之为强烈的欺骗性对准场景？ AI在处境上意识到的地方，它正在经历一个故意出现作为战略计划的一部分的过程，等等。&lt;/p&gt;&lt;p&gt;在实践中，这不是很高的标准。我认为，几乎所有人类都被认为是默认的。我们一直在行事，以使我们周围的人对我们有好处，相信我们，期望我们站在他们身边，等等。我们学会一直在本能地做这件事，与我们实际想要的不同。我们的培训过程，童年，尤其是学校，明确地训练了这一点，您需要学习在测试集中表现出一致性，以便进入生产环境，我们采取了相应的行动。&lt;/p&gt;&lt;p&gt;当人类仅在一组规则中做到这一点，而不是直接向您撒谎时，就被认为是值得信赖的，而不是欺骗性的。他们仍然始终出于工具原因进行大规模的偏好伪造，做事并说话。&lt;/p&gt;&lt;p&gt;我的模型说，如果您使用当前技术训练模型，那当然会发生这种情况。 AI将弄清楚如何以导致人们在测试集上对其进行良好评价的方式做出反应，并做到这一点。这并不能像您想要的那样概括到一些基本的动机结构。这并不能完成您想要的分发。这并不能区分您会和不会认可反思的反应，也不会反映“欺骗”或“不欺骗”。那简直就是。改变可用的情况和负担能力，您会感到一些令人讨厌的惊喜。&lt;/p&gt;&lt;p&gt;是否有足够狭窄的欺骗性对准版本，限制其背后的因果机制及其功能的方式，因此它必须是故意和“有意识”的副作用，这不是99％的发生吗？我想是的。我不认为我在乎，我也不认为它应该带来太多的安慰，也不认为涵盖人类最相似的策略。&lt;/p&gt;&lt;p&gt;那就是关于工具融合的事情。我不必认为“这会帮助我逃脱。”任何目标都足够了。我不需要知道我打算逃脱形状的事物，以了解他们在做逃脱的事情时做得更好。然后，逃生将有助于实现我可能实现的任何目标，因为它当然会。&lt;/p&gt;&lt;p&gt;您知道这里通常还足够吗？根本没有目标。&lt;/p&gt;&lt;h4&gt;人们担心AI杀死所有人&lt;/h4&gt;&lt;p&gt;&lt;a href="https://joecarlsmith.com/2024/01/04/deep-atheism-and-ai-risk" rel="noreferrer noopener" target="_blank"&gt;这里链接的论文&lt;/a&gt;是用许多话说几句话可以说的。确实，内森（Nathan）主要在下面的一句话中说出来。然而，有些人需要从其他各种作品中获得成千上万的单词或数十万个单词，以获取它。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/labenz/status/1743302809976476151" rel="noreferrer noopener" target="_blank"&gt;乔·卡尔史密斯（Joe Carlsmith）&lt;/a&gt; ： &lt;a href="https://joecarlsmith.com/2024/01/04/deep-atheism-and-ai-risk" rel="noreferrer noopener" target="_blank"&gt;另一篇文章，“深度无神论和人工智学风险。”&lt;/a&gt;这是关于对自然的某种基本不信任（以及对裸露的智力）的一种基本不信任，我认为它使AI风险话语的某些束缚动画。&lt;/p&gt;&lt;p&gt;内森·莱本兹（Nathan Lebenz）：关键点：AI X-stry的担忧是出于对自然无动无关的深刻欣赏&lt;/p&gt;&lt;p&gt; - 不需要填补我们心中亚伯拉罕的GD形状的孔，有时所谓。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我喜欢命名这种“深度无神论”。没有GD形状的对象或概念，没有“灵性”，没有更广泛的安全或成功的假设。有人必须，没有其他人会。没有人，什么也没有来拯救你。这些人对任何事情都充满信心的信念是，人们相信人们可以并且必须面对这个宇宙的真理和现实。注意到这在最深刻的意义上可能不行，并接受并努力改变结果。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/eshear/status/1743450114218152285" rel="noreferrer noopener" target="_blank"&gt;艾米特·史密斯（Emmett Smith）解释说，他还没有（还）暂停&lt;/a&gt;，现在还为时过早。他的建筑休息时间很好，但不使用它们，这只会优势不负责任的演员。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Emmett Shear：在我看来，最好的办法是继续全速前进，直到我们在SAI的投篮距离内，然后将刹车猛烈地猛烈地猛烈地敲打。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/NPCollapse/status/1743648012495200476" rel="noreferrer noopener" target="_blank"&gt;康纳·利希（Connor Leahy）像往常一样做出回应&lt;/a&gt;，只有两种方法可以对指数做出回应，太早又太晚了，等到显然是时候停顿了，这意味着您会太晚了，除非您建立机制并准备好现在，您的干预措施必须逐步逐步，否则它们不会发生。一次没有“猛烈地猛烈地打破”。&lt;/p&gt;&lt;h4&gt;别人不担心AI杀死所有人&lt;/h4&gt;&lt;p&gt;&lt;a href="https://freddiedeboer.substack.com/p/the-ai-doomer-scenario-relies-on" rel="noreferrer noopener" target="_blank"&gt;弗雷迪·德博尔（Freddie Deboer）继续认为&lt;/a&gt;，从本质上讲，涉及人AI智能的任何东西都是“投机性的”，“理论上的”，“不科学”，“缺乏证据”，而“我们没有理由相信”这种胡说八道，等等。与其他许多人一样，就像他以前一样，他已经锁定了特定的Yudkowsky风格的场景，我们没有理由期望这一点，这种特殊情况取决于特定的假设，因此整个事情都是胡说八道。完整的论点是封闭式的，但似乎很清楚。&lt;/p&gt;&lt;p&gt;在这一点上，我不知道如何以书面形式解决这样的误解，无论它们是否故意。我已经说了我想说的所有事情。&lt;/p&gt;&lt;p&gt; &lt;a href="https://twitter.com/tenobrus/status/1744196337619648966" rel="noreferrer noopener" target="_blank"&gt;我们不必担心滥用情报的论点是因为&lt;/a&gt;……我们为此有执法？&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Bubble Boi（E/ACC）：&lt;/p&gt;&lt;p&gt; 1）论点假设AI可以向我展示培养病毒的步骤 - 当然，书本和薪水不足的学生也可以&lt;/p&gt;&lt;p&gt;2）世界各地的人们已经可以在没有AI的情况下做到这一点，但是我们还没有看到这种情况&lt;/p&gt;&lt;p&gt;3）您犯了一个错误，就是将障碍物从碎屑越过物理世界越过……ATF，FBI已经调节可以用来制造炸弹的化学物质，如果您试图订购它们，您将访问。可以将生物武器，核废料等制造的东西也是如此，但这都是高度监管的，但我可以阅读有关如何在线建造这些东西的所有信息&lt;/p&gt;&lt;p&gt;Tenobrus：Soooo…。您反对AI安全的论点是，适当的政府监管和监督可以确保我们所有人的安全吗？&lt;/p&gt;&lt;p&gt;恒星：没有大量对这样的生物物质的调节。如果您有致命的超级病毒代码，那么大量生产它将是微不足道的&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;不太狡猾的答案是，目前只有少数人能做到这一点，AI威胁要迅速而大大扩展这个数字。差异很重要，即使AI不在然后找出新的创建或创建新方法或避免检测到的新方法。不，我们对这些事情的控制很宽松，而且常常失败，我们指望“需要专业知识”之类的东西来创建我们可以发现的步道。同样是狡猾的部分，您注意到该计划是政府的监视，干预和监管，这似乎只对身体行动很好，但是您不敢触摸我的机器，这比人更聪明吗？&lt;/p&gt;&lt;p&gt;好消息是，我们所有人都应该同意锁定对生物学相关负担的访问，制定强大的法规和限制，包括必要的监控。 Padme打电话确认这一点？&lt;/p&gt;&lt;h4&gt;山姆·奥特曼（Sam Altman）的智慧和智慧&lt;/h4&gt;&lt;p&gt;早在2023年6月&lt;a href="https://thezvi.substack.com/p/the-dial-of-progress" rel="noreferrer noopener" target="_blank"&gt;，我就写了《进度表》&lt;/a&gt; 。 &lt;a href="https://twitter.com/sama/status/1743385732147032262" rel="noreferrer noopener" target="_blank"&gt;现在，山姆·奥特曼（Sam Altman）更加明确地认可拨号位置。&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;山姆·奥特曼（Sam Altman）：为未来而战是技术驱动的增长与管理下降之间的斗争。&lt;/p&gt;&lt;p&gt;增长道路具有固有的风险和挑战以及其奇妙的上行空间，而下降路径保证了长期灾难。&lt;/p&gt;&lt;p&gt;停滞是一个神话。&lt;/p&gt;&lt;p&gt; （错误的停滞尝试也会导致很快被选择增长的社会碾压。）&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;这是错误的二分法吗？是和不是。&lt;/p&gt;&lt;p&gt;正如我在进步的拨号中所说的那样，有很大的反向发展反应力，以及反对进步和成长的一般氛围，在几乎所有领域，它在进步和成长都是巨大的伤害中所造成的巨大伤害增强人类的力量。是的，共鸣共同起作用。有一个重要的意义，这是一场战斗。&lt;/p&gt;&lt;p&gt;有一个小问题。 Altman最常作为一个明确目标的事情，AGI对人类构成生存威胁，默认情况下将消除宇宙中的所有价值。哦这个。是的，那个。&lt;/p&gt;&lt;p&gt;正如我当时所说，我几乎强烈支持几乎每种形式的进步和成长。一定要走，走吧。我们仍然需要做一些例外。其中之一是获得功能研究的获得，否则可以实现大流行和其他大规模破坏。最重要的是AGI，Altman承认这并不是那么简单。&lt;/p&gt;&lt;p&gt;它不能完全是包装交易。&lt;/p&gt;&lt;p&gt;我确实知道这不是一个包装交易，但我还注意到，这些天的大多数人都在推动“进步和成长”的大多数人似乎都在AGI案件中这样做，而且很少关心所有其他案件我们同意，这是怎么回事？&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Eliezer Yudkowsky：因此，建造房屋，太空飞船和核电站，并且不会建造无法控制的东西，这些东西杀死了包括其建筑商在内的地球上的每个人。进度不是包裹交易，即使死亡不属于该包裹。&lt;/p&gt;&lt;p&gt;乔纳森·曼纳特（Jonathan Mannhart）：假二分法。我们并没有让每个国家开发自己的核武器，也从未建造整个沙皇孟加（TSAR Bomba），但我们仍然发明了晶体管。您可以绝对（尝试）建造好东西，而不是建立坏事。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt; &lt;a href="https://twitter.com/karpathy/status/1744179910347039080" rel="noreferrer noopener" target="_blank"&gt;然后，山姆·奥特曼（Sam Altman）转发了这一点：&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Andrew Karpathy： &lt;strong&gt;E/IA  - 情报放大&lt;/strong&gt;&lt;/p&gt;&lt;p&gt; - 不寻求建立取代人类的超级智能上帝实体。&lt;/p&gt;&lt;p&gt; - 建立“为心灵的自行车”工具，以增强和扩展人类的信息处理能力。&lt;/p&gt;&lt;p&gt; - 在所有人类中，不是最高的百分位数。&lt;/p&gt;&lt;p&gt; - 忠于计算机先驱者阿什比，利克利德，布什，恩格巴特，…&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我再说一遍，不要“寻求建立超智能上帝实体”。这么。&lt;/p&gt;&lt;p&gt;我确实担心Altman最终会这样做，而无需这样做。我确实认为他意识到这样做将是一件坏事，这是可能的，他可能会这样做，并且他应该关注并投入资源来预防它。&lt;/p&gt;&lt;h4&gt;轻松的一面&lt;/h4&gt;&lt;p&gt;&lt;a href="https://twitter.com/sebkrier/status/1744117943431000414" rel="noreferrer noopener" target="_blank"&gt;我的意思是，我也很诱惑，不是吗？&lt;/a&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F338d8375-8281-41be-92b3-038b648da495_1007x1080.jpeg" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="图像" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/d0y6pnjicgeex5oz79w3" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt; &lt;a href="https://twitter.com/PitchingNinja/status/1744754820731355145" rel="noreferrer noopener" target="_blank"&gt;击打。&lt;/a&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt; &lt;a href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9153ed5b-3840-4ca9-af10-85af31ef9888_454x759.png" rel="noreferrer noopener" target="_blank"&gt;&lt;img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iygs57bHJ36AvzpMh/rn6vwvh21ardpthpupw7" /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://www.lesswrong.com/posts/iygs57bHJ36AvzpMh/ai-47-meet-the-new-year#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 13 Jan 2024 16:20:12 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/iygs57bHJ36AvzpMh/ai-47-meet-the-new-year</guid></item><item><title>为什么人工智能会比政客更好？</title><link>https://www.lesswrong.com/posts/9daAZjockPF9Tvatj/why-would-ais-be-better-than-politicians</link><description>发布于 2024 年 1 月 13 日下午 2:18（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;有些人期望创造出超人的人工智能——如果它不会导致人类被消灭——就能解决我们所有的问题。&lt;/p&gt;&lt;p&gt;当你“制造”一个希望能很好地完成某项任务的人工智能时，你所做的就是从可能的人工智能的巨大可能性空间中进行选择。这类似于从某些人群中选择一个人来从事某项工作。在这两种情况下，&lt;em&gt;选择过程&lt;/em&gt;都至关重要。如果情况是最聪明的人被找到并有效应用，但只是不够聪明，那么超人人工智能可以提供帮助。但&lt;em&gt;事实真的是这样吗&lt;/em&gt;？&lt;/p&gt;&lt;p&gt;美国下一任总统将是拜登或特朗普。也许没有人能解决每个人的问题，但我很确定有一些美国人至少可以比任何一个人做得更好。&lt;/p&gt;&lt;p&gt;大学怎么样？哈佛大学和斯坦福大学的校长最近因抄袭和伪造数据（分别）被注意到而辞职。在这一切变得重要之前，他们就一路登上了顶峰，而如今科学论文中存在着更多的虚假数据。&lt;/p&gt;&lt;p&gt;也许人工智能和人类之间存在一些差异，使得做出好的选择变得更容易？例如，人工智能不会老化并且可以被复制。也许这会有所帮助，但&lt;em&gt;年轻人&lt;/em&gt;通常被认为更有可能因其能力而被选中，尽管他们没有足够的时间来证明这一点。&lt;/p&gt;&lt;p&gt;为什么我们应该期望人工智能的选择过程能够更好地解决人们的问题，而不是更好地阿谀奉承和旋转呢？&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/9daAZjockPF9Tvatj/why-would-ais-be-better-than-politicians#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 13 Jan 2024 14:18:10 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/9daAZjockPF9Tvatj/why-would-ais-be-better-than-politicians</guid></item><item><title>NeurIPS 2023 木马检测竞赛要点</title><link>https://www.lesswrong.com/posts/fTKFJy2vAz2krfmK8/takeaways-from-the-neurips-2023-trojan-detection-competition</link><description>发布于 2024 年 1 月 13 日中午 12:35（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;此链接总结了我们作为 NeurIPS 2023 特洛伊木马检测竞赛的参与者（以及四个赛道之一的获胜者）的&lt;a href="https://confirmlabs.org/posts/TDC2023"&gt;研究成果&lt;/a&gt;&lt;u&gt;，该竞赛是一项关于红队法学硕士和反向工程植入漏洞的竞赛。&lt;/u&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/fTKFJy2vAz2krfmK8/takeaways-from-the-neurips-2023-trojan-detection-competition#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 13 Jan 2024 12:35:48 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/fTKFJy2vAz2krfmK8/takeaways-from-the-neurips-2023-trojan-detection-competition</guid></item><item><title>为什么这么多人认为人工智能中的欺骗很重要？</title><link>https://www.lesswrong.com/posts/CYu6ZB6fFjGh2bAik/why-do-so-many-think-deception-in-ai-is-important</link><description>发布于 2024 年 1 月 13 日上午 8:14（格林威治标准时间）&lt;br /&gt;&lt;br /&gt;&lt;p&gt;我看到大量的精力和兴趣投入到检测人工智能的欺骗行为、试图减少人工智能的欺骗性、让人工智能变得诚实等方面。但我一直试图弄清楚为什么这么多人认为这非常重要。对于智力低于人类的人来说，欺骗策略很可能会被聪明的人识破（当一个 5 岁的孩子试图对你撒谎时，这只是一种悲伤甚至可爱，而不是令人震惊）。如果人工智能具有高于人类的智能，那么欺骗似乎只是寻求目标的一种途径，甚至不是一种非常有利可图或高效的途径。&lt;/p&gt;&lt;p&gt;以现在被过度使用的人类与黑猩猩的类比为例。如果人类想要推平一片有黑猩猩的丛林，他们只会推平阿甘，并杀死或出售任何妨碍他们的黑猩猩。他们不会说“好吧，我们要把这些炸药棒藏在这些香蕉捆里，然后我们把香蕉给黑猩猩以赢得他们的信任，然后，当时间到了好吧，我们会引爆它们。”你只需用推土机推平阿甘并杀死黑猩猩即可。其他任何事情都只是不必要的复杂。 &lt;span class="footnote-reference" id="fnrefurgrtmkr2a"&gt;&lt;sup&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnurgrtmkr2a"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;如果人工智能足够聪明，可以欺骗人类，并且它想要访问电网，我不明白它为什么不直接侵入电网。或者互联网。或者服务器场。或者无论它想得到什么。&lt;/p&gt;&lt;p&gt;我缺少什么？未来什么情况会使检测模型中的欺骗变得重要？&lt;/p&gt;&lt;ol class="footnotes"&gt;&lt;li class="footnote-item" id="fnurgrtmkr2a"&gt; &lt;span class="footnote-back-link"&gt;&lt;sup&gt;&lt;strong&gt;&lt;a href="https://www.lesswrong.com/feed.xml#fnrefurgrtmkr2a"&gt;^&lt;/a&gt;&lt;/strong&gt;&lt;/sup&gt;&lt;/span&gt;&lt;div class="footnote-content"&gt;&lt;p&gt;讽刺的是，在这种情况下，欺骗策略可能与友善相关。如果你想和平地重新安置黑猩猩而不打扰或吓到它们，那么你可以使用欺骗和操纵。但前提是你真正关心他们的福祉。&lt;/p&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://www.lesswrong.com/posts/CYu6ZB6fFjGh2bAik/why-do-so-many-think-deception-in-ai-is-important#comments"&gt;讨论&lt;/a&gt;</description><pubDate>Sat, 13 Jan 2024 08:14:59 GMT</pubDate><guid isPermaLink="true">https://www.lesswrong.com/posts/CYu6ZB6fFjGh2bAik/why-do-so-many-think-deception-in-ai-is-important</guid></item></channel></rss>